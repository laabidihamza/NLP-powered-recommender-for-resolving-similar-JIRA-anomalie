{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4hqeBB0Bv3E",
        "outputId": "06647cc1-11d2-46da-c7b9-ff61d524cc71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "qHgWPm85B9Ho",
        "outputId": "743efa5d-acaa-4a27-9a84-544f7aa5bfa9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Comment  \\\n",
              "0  I am running the command provided by the docum...   \n",
              "1  [https://jfrog.com/help/r/jfrog-release-inform...   \n",
              "2  This is the current value I would like to chan...   \n",
              "3  Ik can get the manifest from the remote repo w...   \n",
              "4  Corresponding Log record from nginx reverse pr...   \n",
              "\n",
              "                                           Comment.1  \\\n",
              "0  Hi [~accountid:6213cf7cc345490071968be0]  The ...   \n",
              "1  *According to RTDEV-5069:*\\n\\nThe feature is s...   \n",
              "2  [https://jfrog.atlassian.net/browse/RTFACT-154...   \n",
              "3                                                NaN   \n",
              "4                                                NaN   \n",
              "\n",
              "                                           Comment.2  \\\n",
              "0  Ok, thanks for your reply. \\n\\nI had seen this...   \n",
              "1  [~accountid:5f79a75eac3a2d006ffcc8b7] : \\n\\n* ...   \n",
              "2                                                NaN   \n",
              "3                                                NaN   \n",
              "4                                                NaN   \n",
              "\n",
              "                                           Comment.3  \\\n",
              "0                                                NaN   \n",
              "1  [~accountid:5f79a75eac3a2d006ffcc8b7] We have ...   \n",
              "2                                                NaN   \n",
              "3                                                NaN   \n",
              "4                                                NaN   \n",
              "\n",
              "                                           Comment.4 Comment.5 Comment.6  \\\n",
              "0                                                NaN       NaN       NaN   \n",
              "1  Since Composer *Virtual* Repository supports o...       NaN       NaN   \n",
              "2                                                NaN       NaN       NaN   \n",
              "3                                                NaN       NaN       NaN   \n",
              "4                                                NaN       NaN       NaN   \n",
              "\n",
              "  Comment.7 Comment.8 Comment.9  ... Comment.52 Comment.53 Comment.54  \\\n",
              "0       NaN       NaN       NaN  ...        NaN        NaN        NaN   \n",
              "1       NaN       NaN       NaN  ...        NaN        NaN        NaN   \n",
              "2       NaN       NaN       NaN  ...        NaN        NaN        NaN   \n",
              "3       NaN       NaN       NaN  ...        NaN        NaN        NaN   \n",
              "4       NaN       NaN       NaN  ...        NaN        NaN        NaN   \n",
              "\n",
              "  Comment.55 Comment.56 Comment.57 Comment.58  \\\n",
              "0        NaN        NaN        NaN        NaN   \n",
              "1        NaN        NaN        NaN        NaN   \n",
              "2        NaN        NaN        NaN        NaN   \n",
              "3        NaN        NaN        NaN        NaN   \n",
              "4        NaN        NaN        NaN        NaN   \n",
              "\n",
              "                                         Environment  \\\n",
              "0  version we are running is: Artifactory Online ...   \n",
              "1                                                NaN   \n",
              "2                        Developement and Production   \n",
              "3   Artifactory-pro 7.63.14 within a docker conta...   \n",
              "4                                       Linux centos   \n",
              "\n",
              "                                             Summary  \\\n",
              "0  plugin config-import not found for jfrog Artif...   \n",
              "1  RTDEV-5069 / mirroring https://asset-packagist...   \n",
              "2                    Docker - Repository Default URL   \n",
              "3       getting manifest unknown error pulling image   \n",
              "4  Caught exception while saving incoming stream ...   \n",
              "\n",
              "                                         Description  \n",
              "0  I am following the steps from [https://docs.jf...  \n",
              "1  We are running Artifactory 7.63.14 and have pr...  \n",
              "2  Similar to Issue: [https://jfrog.atlassian.net...  \n",
              "3  I am getting the following error when pulling ...  \n",
              "4  We have recently upgrade Artifactory to 7.63.1...  \n",
              "\n",
              "[5 rows x 62 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-868518eb-b7f9-4869-b93b-dd1c6f5bb026\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Comment.1</th>\n",
              "      <th>Comment.2</th>\n",
              "      <th>Comment.3</th>\n",
              "      <th>Comment.4</th>\n",
              "      <th>Comment.5</th>\n",
              "      <th>Comment.6</th>\n",
              "      <th>Comment.7</th>\n",
              "      <th>Comment.8</th>\n",
              "      <th>Comment.9</th>\n",
              "      <th>...</th>\n",
              "      <th>Comment.52</th>\n",
              "      <th>Comment.53</th>\n",
              "      <th>Comment.54</th>\n",
              "      <th>Comment.55</th>\n",
              "      <th>Comment.56</th>\n",
              "      <th>Comment.57</th>\n",
              "      <th>Comment.58</th>\n",
              "      <th>Environment</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am running the command provided by the docum...</td>\n",
              "      <td>Hi [~accountid:6213cf7cc345490071968be0]  The ...</td>\n",
              "      <td>Ok, thanks for your reply. \\n\\nI had seen this...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>version we are running is: Artifactory Online ...</td>\n",
              "      <td>plugin config-import not found for jfrog Artif...</td>\n",
              "      <td>I am following the steps from [https://docs.jf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[https://jfrog.com/help/r/jfrog-release-inform...</td>\n",
              "      <td>*According to RTDEV-5069:*\\n\\nThe feature is s...</td>\n",
              "      <td>[~accountid:5f79a75eac3a2d006ffcc8b7] : \\n\\n* ...</td>\n",
              "      <td>[~accountid:5f79a75eac3a2d006ffcc8b7] We have ...</td>\n",
              "      <td>Since Composer *Virtual* Repository supports o...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RTDEV-5069 / mirroring https://asset-packagist...</td>\n",
              "      <td>We are running Artifactory 7.63.14 and have pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is the current value I would like to chan...</td>\n",
              "      <td>[https://jfrog.atlassian.net/browse/RTFACT-154...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Developement and Production</td>\n",
              "      <td>Docker - Repository Default URL</td>\n",
              "      <td>Similar to Issue: [https://jfrog.atlassian.net...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ik can get the manifest from the remote repo w...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Artifactory-pro 7.63.14 within a docker conta...</td>\n",
              "      <td>getting manifest unknown error pulling image</td>\n",
              "      <td>I am getting the following error when pulling ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Corresponding Log record from nginx reverse pr...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Linux centos</td>\n",
              "      <td>Caught exception while saving incoming stream ...</td>\n",
              "      <td>We have recently upgrade Artifactory to 7.63.1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 62 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-868518eb-b7f9-4869-b93b-dd1c6f5bb026')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-868518eb-b7f9-4869-b93b-dd1c6f5bb026 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-868518eb-b7f9-4869-b93b-dd1c6f5bb026');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-74cbc229-20dd-4739-b9c7-13cc2bb97d3a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74cbc229-20dd-4739-b9c7-13cc2bb97d3a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-74cbc229-20dd-4739-b9c7-13cc2bb97d3a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "file_path = '/content/drive/MyDrive/Stage PFE - VERMEG/Data/cleaned_data.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rPPT6-2WDW0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dLuN-sLDF_N",
        "outputId": "8da20a29-7004-4b77-c425-3a9e86772e9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/163.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m153.6/163.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence_transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sentence_transformers-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "ed6be22ba8ec47bcb978181e0be41bb5",
            "04385d4d08204922921ce276ba5053a0",
            "48d493ec48ee48039bcd338c34af59f8",
            "acad1cfbb84649e0acf30f1a461058e0",
            "261e1c07b313413484f5613c6d6056ac",
            "a2e3b2dc5d6d4451b5736896051d99cd",
            "4e15742b25a147a8bb546fe3afdc962d",
            "53ad4119c9dd4c25bb89facbaf8e4cbf",
            "5582687724204a16bfdbe9f30403a6c0",
            "e15625a4b670404198d00cdc82490a79",
            "f36172cb31e64ebf96a5828c66cf0e39",
            "9df22c3c4f494beaaba071ab1c19794c",
            "257df0ed51c1405f95e5b86d653d0e2e",
            "71c26ccae0e64215a8eeaa1b91c17035",
            "996255f77e3c42caa12cda0a9eff5671",
            "f4c9b70759384ae991ba44abf514cdaa",
            "965c422228fd4087a0cdfa251e4ab0e7",
            "4369bb9fbc0e4a5db92e6a4f1f95e66d",
            "399869597f174dbd8c19593097e96a3f",
            "027acf9363924f1896905a01228d0a99",
            "1a472bb1391549daaf3bc8e7cdf7328e",
            "4fd0d4d719114e7eaf3b831ba82ab6e3",
            "1445669c0fd94b9096f059dafb72581e",
            "118d00faac834328a3e02aa8046354d2",
            "9c90ae623fd641cd86e8401a25cdf12a",
            "09cefdc8289f4322a2afebc5c6a88992",
            "5f3b5887f93a478d82866a0b79958695",
            "b4e82e494aeb41de984521cb47bb4310",
            "0ae38b56bc6044e692baaa07840a9cf0",
            "39127f5d2ad14dc7872837ff6f936912",
            "8b2360a169764927b269ab2ec59eb6bb",
            "e9fb23fc097a4d8d8dc7fa4c9c366274",
            "56fa35d75ca444e3b5dbd8e2568dffc4",
            "2f2c27dfc79d4dc2b7599e7f7cda84c4",
            "7f291a7ab9704fa5b99a542915194c17",
            "aa929ed0753445cea3cca612cd0af954",
            "0ccf9e1a0c84456197b3931718f9a70a",
            "dbf7ba34bd954167a724536e1e8776a8",
            "ce9aef5534d34df298a25d6a556f3e54",
            "5020085629c7458996f2c880033b19c9",
            "d42493b74f29421ab454d50ee11507a4",
            "db61459def914176b3db737a3c47633c",
            "ed9f65e96d4f45c89bf48f5299cfbd02",
            "03f38aee514b497e939aad53e4419f36",
            "889e5dcec45749b583eaf649921a3d5f",
            "2833050431b648d695abf127edfa88a2",
            "bd392a988bc143b892d2c78b8a4c4ad9",
            "06721bad3df34edaa7eb25a75a16fefe",
            "bd0770be78374e15aab4b7a586d11703",
            "d70c63c68f4546448efd1e865ebe59ed",
            "ac101e1de97c4a32824cb45b8a54c66f",
            "ea10952187484c019c709e3a15fcf646",
            "fa57d7c43d1540f48b996832e1a45b03",
            "9b562f6f3e3242d9aa263bdb5025a0e6",
            "705766867bdd47d9a97ffcb7b06579a7",
            "abf760063b22455f994c3f6bb78c1937",
            "772cf655b96d4aa6ab60c0e9efca1124",
            "3da94b12827a43afb6f9af00ecf8286e",
            "c78a661540a24d56b9fe6cf677644fa7",
            "67d47d25264c474a93db83c8f7d5f58f",
            "b7b5be369e824b5097759f7a48a2d3c2",
            "fdd59660a61345c0aa1db274a01f0f09",
            "0d70f88dd6134e4dacca2779a8b0719b",
            "fe694215208047caad80ac00520ec42d",
            "80654f68a3c8454d98ed213ff1fc9920",
            "19c239f50d9f4b38a30e00f3039a19c7",
            "19f3e8272d9142eeb2b470169362b52c",
            "8978aaf3f6324cfd9d7b6c6f79730407",
            "644fa2d39a3d4a258d61f579ca5cf0b8",
            "46cc0255ba3a41a39cad73b588e88f07",
            "ba4295f101514252833cac5a94dfda4d",
            "78f247274d1e47c6b5a0ef399e24ff06",
            "f1149055106b49f0bb0a3318ba6a7fcf",
            "72cf8e24fa03424fbfa4aaca37296551",
            "7233d349b4b44300a3d85e77e403fbc0",
            "442380d3aedb427bafd3295154348043",
            "75d51402cfbc45d8ab00fa71ec8e1848",
            "db9237ecd82946a2b007a0ce83ecff30",
            "67fc70461bbd4050a6b727e12533e6d6",
            "3f451ab9868f4a04ba113cc253a6516d",
            "4fb445ea32b1433790001cdc4e0a0132",
            "15fef7c0db194356987e1b2d60d29304",
            "99b190ec8db04c1ea380544e7e27b306",
            "069d41bffae74617920fdc585b1cd371",
            "633b2719f3d14c70b6839f8e5b889475",
            "fff435e6b74a483ebb2746785cb480aa",
            "fa10594f640d47dc9ea6494e69f4925b",
            "bf9fa08d888c4a7ebb7b37c56d39ecd8",
            "c9df1a6ca5174863b3b3e3a44544ab51",
            "191041283bc9484ab386bd9cc2d2a432",
            "03474a161aa34e13abf9d2b125ab59da",
            "1379c19b37b94e3f99be4b043aba60be",
            "66fb2c4acda84eff811ef8b26b77855e",
            "46c6665f653646a0bef42120fff00bc5",
            "5b8771aad9324fb997ab9c1b5372fb93",
            "e93c498fe79e45d48e3085e15820e145",
            "9618620cdc794e9296d031e5c6273390",
            "6bca854aac50496da16e4b6ba45d5413",
            "6b4b438591b44e96a57bf236883aedea",
            "ab2a1fa7344b45af95683648db624352",
            "31f32efc207f4f31b680dd20584ed536",
            "8e8291d407ad4a2cb573a3ceb65f6756",
            "523a4f7a67314b6a940db733ffa1b757",
            "55940f797eaf451aa1a7d87ec47f5e8d",
            "522894360b794237b95587ea7ef82c92",
            "f82971e96cf046999507b19f320db759",
            "7ad61085d6c5448e972d83e92957d577",
            "a8ff7da5251947c3b9360f0b1fa4a7d8",
            "6f2d75797fa34cea8607f5d1682cfdcc",
            "f17c8a9962c64763b9f1cfef4b7a6d4d",
            "efb5a74d1fdf4e3b9def5ffd17035597",
            "fc99920c78ab43e39fbe274f827a093b",
            "3bc23d1ef541466caac333920154d0a9",
            "b3e163e26d384732b21d897dacbe26b6",
            "03164a3308834f88a404af8a35df1ee5",
            "33934068158f4982b36ae4d6f1963274",
            "8a98b1646d034f92ab37b8a73ef94b08",
            "3e63e907e48441a9921094c6f8df240a",
            "bf38787c02ae4a56ab25e57129b458c9",
            "e532e4a197c048b99f4bacf20568f91b",
            "40b01e34f632432a8a62db18fe7e38e9"
          ]
        },
        "id": "_AGcAIpKB9Kc",
        "outputId": "a0e39e3c-93a1-458f-8c26-d93248a00e25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed6be22ba8ec47bcb978181e0be41bb5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9df22c3c4f494beaaba071ab1c19794c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/4.13k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1445669c0fd94b9096f059dafb72581e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f2c27dfc79d4dc2b7599e7f7cda84c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "889e5dcec45749b583eaf649921a3d5f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abf760063b22455f994c3f6bb78c1937"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/402 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19f3e8272d9142eeb2b470169362b52c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db9237ecd82946a2b007a0ce83ecff30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9df1a6ca5174863b3b3e3a44544ab51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab2a1fa7344b45af95683648db624352"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efb5a74d1fdf4e3b9def5ffd17035597"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z_U-1RlG4Y3",
        "outputId": "3a5ac1b9-44f1-4b7f-fc8c-8f6850916da4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLb1iR7OGa2I"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "\n",
        "  sentence = sentence.lower()\n",
        "\n",
        "  # Remove punctuation\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  sentence = sentence.translate(table)\n",
        "\n",
        "  from nltk.corpus import stopwords  # Download NLTK stopwords corpus first\n",
        "  stop_words = stopwords.words('english')\n",
        "  words = [word for word in sentence.split() if word not in stop_words]\n",
        "  sentence = ' '.join(words)\n",
        "\n",
        "  return sentence\n",
        "\n",
        "for i in range (len(df['Summary'])) :\n",
        "  df['Summary'][i] = preprocess_sentence(df['Summary'][i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "Fdynps1Mp6ku",
        "outputId": "4d146d4d-a36c-4a78-c8f1-7b6608cfccc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Comment  \\\n",
              "0  I am running the command provided by the docum...   \n",
              "1  [https://jfrog.com/help/r/jfrog-release-inform...   \n",
              "2  This is the current value I would like to chan...   \n",
              "3  Ik can get the manifest from the remote repo w...   \n",
              "4  Corresponding Log record from nginx reverse pr...   \n",
              "\n",
              "                                           Comment.1  \\\n",
              "0  Hi [~accountid:6213cf7cc345490071968be0]  The ...   \n",
              "1  *According to RTDEV-5069:*\\n\\nThe feature is s...   \n",
              "2  [https://jfrog.atlassian.net/browse/RTFACT-154...   \n",
              "3                                                NaN   \n",
              "4                                                NaN   \n",
              "\n",
              "                                           Comment.2  \\\n",
              "0  Ok, thanks for your reply. \\n\\nI had seen this...   \n",
              "1  [~accountid:5f79a75eac3a2d006ffcc8b7] : \\n\\n* ...   \n",
              "2                                                NaN   \n",
              "3                                                NaN   \n",
              "4                                                NaN   \n",
              "\n",
              "                                           Comment.3  \\\n",
              "0                                                NaN   \n",
              "1  [~accountid:5f79a75eac3a2d006ffcc8b7] We have ...   \n",
              "2                                                NaN   \n",
              "3                                                NaN   \n",
              "4                                                NaN   \n",
              "\n",
              "                                           Comment.4 Comment.5 Comment.6  \\\n",
              "0                                                NaN       NaN       NaN   \n",
              "1  Since Composer *Virtual* Repository supports o...       NaN       NaN   \n",
              "2                                                NaN       NaN       NaN   \n",
              "3                                                NaN       NaN       NaN   \n",
              "4                                                NaN       NaN       NaN   \n",
              "\n",
              "  Comment.7 Comment.8 Comment.9  ... Comment.53 Comment.54 Comment.55  \\\n",
              "0       NaN       NaN       NaN  ...        NaN        NaN        NaN   \n",
              "1       NaN       NaN       NaN  ...        NaN        NaN        NaN   \n",
              "2       NaN       NaN       NaN  ...        NaN        NaN        NaN   \n",
              "3       NaN       NaN       NaN  ...        NaN        NaN        NaN   \n",
              "4       NaN       NaN       NaN  ...        NaN        NaN        NaN   \n",
              "\n",
              "  Comment.56 Comment.57 Comment.58  \\\n",
              "0        NaN        NaN        NaN   \n",
              "1        NaN        NaN        NaN   \n",
              "2        NaN        NaN        NaN   \n",
              "3        NaN        NaN        NaN   \n",
              "4        NaN        NaN        NaN   \n",
              "\n",
              "                                         Environment  \\\n",
              "0  version we are running is: Artifactory Online ...   \n",
              "1                                                NaN   \n",
              "2                        Developement and Production   \n",
              "3   Artifactory-pro 7.63.14 within a docker conta...   \n",
              "4                                       Linux centos   \n",
              "\n",
              "                                             Summary  \\\n",
              "0  plugin configimport found jfrog artifactory cl...   \n",
              "1         rtdev5069 mirroring httpsassetpackagistorg   \n",
              "2                      docker repository default url   \n",
              "3       getting manifest unknown error pulling image   \n",
              "4  caught exception saving incoming stream file a...   \n",
              "\n",
              "                                         Description  \\\n",
              "0  I am following the steps from [https://docs.jf...   \n",
              "1  We are running Artifactory 7.63.14 and have pr...   \n",
              "2  Similar to Issue: [https://jfrog.atlassian.net...   \n",
              "3  I am getting the following error when pulling ...   \n",
              "4  We have recently upgrade Artifactory to 7.63.1...   \n",
              "\n",
              "                                             SumDesc  \n",
              "0  plugin configimport found jfrog artifactory cl...  \n",
              "1  rtdev5069 mirroring httpsassetpackagistorg \\r\\...  \n",
              "2  docker repository default url \\r\\n Similar to ...  \n",
              "3  getting manifest unknown error pulling image \\...  \n",
              "4  caught exception saving incoming stream file a...  \n",
              "\n",
              "[5 rows x 63 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d0f16b37-d894-46b1-8b73-3a43efda56a6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Comment.1</th>\n",
              "      <th>Comment.2</th>\n",
              "      <th>Comment.3</th>\n",
              "      <th>Comment.4</th>\n",
              "      <th>Comment.5</th>\n",
              "      <th>Comment.6</th>\n",
              "      <th>Comment.7</th>\n",
              "      <th>Comment.8</th>\n",
              "      <th>Comment.9</th>\n",
              "      <th>...</th>\n",
              "      <th>Comment.53</th>\n",
              "      <th>Comment.54</th>\n",
              "      <th>Comment.55</th>\n",
              "      <th>Comment.56</th>\n",
              "      <th>Comment.57</th>\n",
              "      <th>Comment.58</th>\n",
              "      <th>Environment</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Description</th>\n",
              "      <th>SumDesc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am running the command provided by the docum...</td>\n",
              "      <td>Hi [~accountid:6213cf7cc345490071968be0]  The ...</td>\n",
              "      <td>Ok, thanks for your reply. \\n\\nI had seen this...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>version we are running is: Artifactory Online ...</td>\n",
              "      <td>plugin configimport found jfrog artifactory cl...</td>\n",
              "      <td>I am following the steps from [https://docs.jf...</td>\n",
              "      <td>plugin configimport found jfrog artifactory cl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[https://jfrog.com/help/r/jfrog-release-inform...</td>\n",
              "      <td>*According to RTDEV-5069:*\\n\\nThe feature is s...</td>\n",
              "      <td>[~accountid:5f79a75eac3a2d006ffcc8b7] : \\n\\n* ...</td>\n",
              "      <td>[~accountid:5f79a75eac3a2d006ffcc8b7] We have ...</td>\n",
              "      <td>Since Composer *Virtual* Repository supports o...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>rtdev5069 mirroring httpsassetpackagistorg</td>\n",
              "      <td>We are running Artifactory 7.63.14 and have pr...</td>\n",
              "      <td>rtdev5069 mirroring httpsassetpackagistorg \\r\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is the current value I would like to chan...</td>\n",
              "      <td>[https://jfrog.atlassian.net/browse/RTFACT-154...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Developement and Production</td>\n",
              "      <td>docker repository default url</td>\n",
              "      <td>Similar to Issue: [https://jfrog.atlassian.net...</td>\n",
              "      <td>docker repository default url \\r\\n Similar to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ik can get the manifest from the remote repo w...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Artifactory-pro 7.63.14 within a docker conta...</td>\n",
              "      <td>getting manifest unknown error pulling image</td>\n",
              "      <td>I am getting the following error when pulling ...</td>\n",
              "      <td>getting manifest unknown error pulling image \\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Corresponding Log record from nginx reverse pr...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Linux centos</td>\n",
              "      <td>caught exception saving incoming stream file a...</td>\n",
              "      <td>We have recently upgrade Artifactory to 7.63.1...</td>\n",
              "      <td>caught exception saving incoming stream file a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 63 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0f16b37-d894-46b1-8b73-3a43efda56a6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d0f16b37-d894-46b1-8b73-3a43efda56a6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d0f16b37-d894-46b1-8b73-3a43efda56a6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cf433cf2-1ec9-4e67-b002-47980af58900\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cf433cf2-1ec9-4e67-b002-47980af58900')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cf433cf2-1ec9-4e67-b002-47980af58900 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df['SumDesc'] = df['Summary'] + ' \\r\\n ' + df['Description']\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "MkoL8JJxp6T2",
        "outputId": "01727f2b-7ad7-41a4-eb9e-123a1c92945c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"plugin configimport found jfrog artifactory cloud implementation \\r\\n I am following the steps from [https://docs.jfrog-applications.jfrog.io/jfrog-applications/jfrog-cli/cli-for-jfrog-cloud-transfer#routing-the-traffic-from-the-source-to-the-target-through-an-https-proxy|https://docs.jfrog-applications.jfrog.io/jfrog-applications/jfrog-cli/cli-for-jfrog-cloud-transfer#routing-the-traffic-from-the-source-to-the-target-through-an-https-proxy|smart-link]  where I have to install and activate two plugins to use the transfer-config option through the cli.\\n\\nThe plugin config-import has to be installed on the target server  (cloud ), but the wanted plugin is not found.\\n\\nThe debug logging gives the following messages:\\n\\nDebug] Downloading plugin's executable from: [https://releases.jfrog.io/artifactory/jfrog-cli-plugins/config-import/latest/linux-amd64/config-import|https://releases.jfrog.io/artifactory/jfrog-cli-plugins/config-import/latest/linux-amd64/config-import]\\n[Info] Downloading: config-import\\n[Debug] Sending HTTP GET request to: [https://releases.jfrog.io/artifactory/jfrog-cli-plugins/config-import/latest/linux-amd64/config-import|https://releases.jfrog.io/artifactory/jfrog-cli-plugins/config-import/latest/linux-amd64/config-import]\\n\\nThe subdirectory config-import is completly missing on the server repo [https://releases.jfrog.io/artifactory/jfrog-cli-plugins|https://releases.jfrog.io/artifactory/jfrog-cli-plugins/config-import/latest/linux-amd64/config-import]\\n\\nThe plugin is provided in [https://releases.jfrog.io/artifactory/jfrog-releases/config-import/1.3.1/|https://releases.jfrog.io/artifactory/jfrog-releases/config-import/1.3.1/] \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df['SumDesc'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JJHfhjZABjI"
      },
      "outputs": [],
      "source": [
        "def clean_comment(comment):\n",
        "  try:\n",
        "    end_index = comment.find(']') + 1\n",
        "    return comment[end_index:].strip()  # Remove leading/trailing whitespace\n",
        "  except ValueError:\n",
        "    return comment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym9qWK4gABLr"
      },
      "outputs": [],
      "source": [
        "for col in df.filter(like='Comment'):\n",
        "  df[col] = df[col].astype(str)\n",
        "  df[col] = df[col].apply(clean_comment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "XL410oIimHp5",
        "outputId": "11d361d3-ac66-4885-e56a-8128bbe5201e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Comment  \\\n",
              "0  I am running the command provided by the docum...   \n",
              "1  {quote}RTDEV-5069 Fixed an issue whereby, Arti...   \n",
              "2  This is the current value I would like to chan...   \n",
              "3  {\\n   \"schemaVersion\": 2,\\n   \"mediaType\": \"ap...   \n",
              "4  \"PUT ‘REPO_PATH/s.zip’ HTTP/1.1\" 400 0 \"-\" \"py...   \n",
              "\n",
              "                                           Comment.1  \\\n",
              "0  The Config Import plugin in the JFrog SaaS ins...   \n",
              "1   it that relevant to the situation you described?   \n",
              "2                                                      \n",
              "3                                                nan   \n",
              "4                                                nan   \n",
              "\n",
              "                                           Comment.2  \\\n",
              "0  or the command “jf plugin install config-impor...   \n",
              "1  : \\n\\n* _Store Artifacts Locally_ is enabled\\n...   \n",
              "2                                                nan   \n",
              "3                                                nan   \n",
              "4                                                nan   \n",
              "\n",
              "                                           Comment.3  \\\n",
              "0                                                nan   \n",
              "1  We have checked this, from our point of view [...   \n",
              "2                                                nan   \n",
              "3                                                nan   \n",
              "4                                                nan   \n",
              "\n",
              "                                           Comment.4 Comment.5 Comment.6  \\\n",
              "0                                                nan       nan       nan   \n",
              "1  Since Composer *Virtual* Repository supports o...       nan       nan   \n",
              "2                                                nan       nan       nan   \n",
              "3                                                nan       nan       nan   \n",
              "4                                                nan       nan       nan   \n",
              "\n",
              "  Comment.7 Comment.8 Comment.9  ... Comment.54 Comment.55 Comment.56  \\\n",
              "0       nan       nan       nan  ...        nan        nan        nan   \n",
              "1       nan       nan       nan  ...        nan        nan        nan   \n",
              "2       nan       nan       nan  ...        nan        nan        nan   \n",
              "3       nan       nan       nan  ...        nan        nan        nan   \n",
              "4       nan       nan       nan  ...        nan        nan        nan   \n",
              "\n",
              "  Comment.57 Comment.58                                        Environment  \\\n",
              "0        nan        nan  version we are running is: Artifactory Online ...   \n",
              "1        nan        nan                                                NaN   \n",
              "2        nan        nan                        Developement and Production   \n",
              "3        nan        nan   Artifactory-pro 7.63.14 within a docker conta...   \n",
              "4        nan        nan                                       Linux centos   \n",
              "\n",
              "                                             Summary  \\\n",
              "0  plugin configimport found jfrog artifactory cl...   \n",
              "1         rtdev5069 mirroring httpsassetpackagistorg   \n",
              "2                      docker repository default url   \n",
              "3       getting manifest unknown error pulling image   \n",
              "4  caught exception saving incoming stream file a...   \n",
              "\n",
              "                                         Description  \\\n",
              "0  I am following the steps from [https://docs.jf...   \n",
              "1  We are running Artifactory 7.63.14 and have pr...   \n",
              "2  Similar to Issue: [https://jfrog.atlassian.net...   \n",
              "3  I am getting the following error when pulling ...   \n",
              "4  We have recently upgrade Artifactory to 7.63.1...   \n",
              "\n",
              "                                             SumDesc  \\\n",
              "0  plugin configimport found jfrog artifactory cl...   \n",
              "1  rtdev5069 mirroring httpsassetpackagistorg \\r\\...   \n",
              "2  docker repository default url \\r\\n Similar to ...   \n",
              "3  getting manifest unknown error pulling image \\...   \n",
              "4  caught exception saving incoming stream file a...   \n",
              "\n",
              "                                            Comments  \n",
              "0  [I am running the command provided by the docu...  \n",
              "1  [{quote}RTDEV-5069 Fixed an issue whereby, Art...  \n",
              "2  [This is the current value I would like to cha...  \n",
              "3  [{\\n   \"schemaVersion\": 2,\\n   \"mediaType\": \"a...  \n",
              "4  [\"PUT ‘REPO_PATH/s.zip’ HTTP/1.1\" 400 0 \"-\" \"p...  \n",
              "\n",
              "[5 rows x 64 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8de8020b-d960-4a36-a61e-8ab01d5de9f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Comment.1</th>\n",
              "      <th>Comment.2</th>\n",
              "      <th>Comment.3</th>\n",
              "      <th>Comment.4</th>\n",
              "      <th>Comment.5</th>\n",
              "      <th>Comment.6</th>\n",
              "      <th>Comment.7</th>\n",
              "      <th>Comment.8</th>\n",
              "      <th>Comment.9</th>\n",
              "      <th>...</th>\n",
              "      <th>Comment.54</th>\n",
              "      <th>Comment.55</th>\n",
              "      <th>Comment.56</th>\n",
              "      <th>Comment.57</th>\n",
              "      <th>Comment.58</th>\n",
              "      <th>Environment</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Description</th>\n",
              "      <th>SumDesc</th>\n",
              "      <th>Comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am running the command provided by the docum...</td>\n",
              "      <td>The Config Import plugin in the JFrog SaaS ins...</td>\n",
              "      <td>or the command “jf plugin install config-impor...</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>...</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>version we are running is: Artifactory Online ...</td>\n",
              "      <td>plugin configimport found jfrog artifactory cl...</td>\n",
              "      <td>I am following the steps from [https://docs.jf...</td>\n",
              "      <td>plugin configimport found jfrog artifactory cl...</td>\n",
              "      <td>[I am running the command provided by the docu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{quote}RTDEV-5069 Fixed an issue whereby, Arti...</td>\n",
              "      <td>it that relevant to the situation you described?</td>\n",
              "      <td>: \\n\\n* _Store Artifacts Locally_ is enabled\\n...</td>\n",
              "      <td>We have checked this, from our point of view [...</td>\n",
              "      <td>Since Composer *Virtual* Repository supports o...</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>...</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>NaN</td>\n",
              "      <td>rtdev5069 mirroring httpsassetpackagistorg</td>\n",
              "      <td>We are running Artifactory 7.63.14 and have pr...</td>\n",
              "      <td>rtdev5069 mirroring httpsassetpackagistorg \\r\\...</td>\n",
              "      <td>[{quote}RTDEV-5069 Fixed an issue whereby, Art...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is the current value I would like to chan...</td>\n",
              "      <td></td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>...</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>Developement and Production</td>\n",
              "      <td>docker repository default url</td>\n",
              "      <td>Similar to Issue: [https://jfrog.atlassian.net...</td>\n",
              "      <td>docker repository default url \\r\\n Similar to ...</td>\n",
              "      <td>[This is the current value I would like to cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{\\n   \"schemaVersion\": 2,\\n   \"mediaType\": \"ap...</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>...</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>Artifactory-pro 7.63.14 within a docker conta...</td>\n",
              "      <td>getting manifest unknown error pulling image</td>\n",
              "      <td>I am getting the following error when pulling ...</td>\n",
              "      <td>getting manifest unknown error pulling image \\...</td>\n",
              "      <td>[{\\n   \"schemaVersion\": 2,\\n   \"mediaType\": \"a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"PUT ‘REPO_PATH/s.zip’ HTTP/1.1\" 400 0 \"-\" \"py...</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>...</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>Linux centos</td>\n",
              "      <td>caught exception saving incoming stream file a...</td>\n",
              "      <td>We have recently upgrade Artifactory to 7.63.1...</td>\n",
              "      <td>caught exception saving incoming stream file a...</td>\n",
              "      <td>[\"PUT ‘REPO_PATH/s.zip’ HTTP/1.1\" 400 0 \"-\" \"p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 64 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8de8020b-d960-4a36-a61e-8ab01d5de9f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8de8020b-d960-4a36-a61e-8ab01d5de9f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8de8020b-d960-4a36-a61e-8ab01d5de9f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0322cff4-8481-436c-b2d7-60395c12010f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0322cff4-8481-436c-b2d7-60395c12010f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0322cff4-8481-436c-b2d7-60395c12010f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "def merge_comments(df):\n",
        "\n",
        "  comment_cols = ['Comment', 'Comment.1', 'Comment.2', 'Comment.3', 'Comment.4', 'Comment.5', 'Comment.6', 'Comment.7', 'Comment.8', 'Comment.9', 'Comment.10', 'Comment.11', 'Comment.12', 'Comment.13', 'Comment.14', 'Comment.15', 'Comment.16', 'Comment.17', 'Comment.18', 'Comment.19', 'Comment.20', 'Comment.21', 'Comment.22', 'Comment.23', 'Comment.24', 'Comment.25', 'Comment.26', 'Comment.27', 'Comment.28', 'Comment.29', 'Comment.30', 'Comment.31', 'Comment.32', 'Comment.33', 'Comment.34', 'Comment.35', 'Comment.36', 'Comment.37', 'Comment.38', 'Comment.39', 'Comment.40', 'Comment.41', 'Comment.42', 'Comment.43', 'Comment.44', 'Comment.45', 'Comment.46', 'Comment.47', 'Comment.48', 'Comment.49', 'Comment.50', 'Comment.51', 'Comment.52', 'Comment.53', 'Comment.54', 'Comment.55', 'Comment.56', 'Comment.57', 'Comment.58']\n",
        "\n",
        "  # filter non-NaN comments\n",
        "  def filter_comments(row):\n",
        "    return [comment for comment in row[comment_cols] if pd.notna(comment)]\n",
        "\n",
        "  # Create a new column 'combined_comments' to store merged comments\n",
        "  df['Comments'] = df.apply(filter_comments, axis=1)\n",
        "\n",
        "  # Iterate through rows and build comment lists\n",
        "  for index, row in df.iterrows():\n",
        "    comments = [comment for comment in row[comment_cols] if pd.notnull(comment)]\n",
        "    df.at[index, 'Comments'] = comments\n",
        "\n",
        "  return df\n",
        "\n",
        "df = merge_comments(df.copy())\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nH77AXknrYYD"
      },
      "outputs": [],
      "source": [
        "df['SumDesc'] = df['SumDesc'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwAncqQxB9NO"
      },
      "outputs": [],
      "source": [
        "embeddings = []\n",
        "\n",
        "# Iterate through each row of the column\n",
        "for i in df['SumDesc']:\n",
        "    # Encode the sentence using the BERT model\n",
        "    embedding = model.encode(i)\n",
        "    # Append the embedding to the list\n",
        "    embeddings.append(embedding)\n",
        "\n",
        "df['embeddingsSumDesc'] = embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMkPdeU6B9QP"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2flZf0nLf7E"
      },
      "outputs": [],
      "source": [
        "sum_desc_input = df['SumDesc'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhVVSKWLMnLI"
      },
      "outputs": [],
      "source": [
        "df[\"embeddingsSumDesc\"] = df[\"embeddingsSumDesc\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3NLOxDAB9WJ"
      },
      "outputs": [],
      "source": [
        "# Function to calculate cosine similarity between sentences\n",
        "def calculate_similarity(input_sentence, embeddings):\n",
        "  input_embedding = model.encode(input_sentence)\n",
        "\n",
        "  similarities = []\n",
        "  for embedding in embeddings:\n",
        "    similarity = cosine_similarity(input_embedding.reshape(1, -1), embedding.reshape(1, -1))[0][0]\n",
        "    similarities.append(similarity)\n",
        "\n",
        "  return similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZ-dMrq2B9ZF",
        "outputId": "2c8fa576-02bb-4dd0-e5fa-81597ee7d1c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "This may have been tested on server end in test_no_pmix.\n",
            "\n",
            "Either extend or create new test for client end.\n",
            "\n",
            "Remove member from primary group and verify that it is also removed from secondary group., Similarity: 0.1192\n",
            "Summary & Description: group group destruction \n",
            " Test for group destruction in primary and secondary group, Similarity: -0.0203\n",
            "Summary & Description: need api similar crtgroupcreate without members \n",
            " For case of NO_PMIX, a client side needs an API which would take in a group name (remote group name that server uses) and create a locally managed group from it.\n",
            "\n",
            "The goal is to allow client side to be able to dynamically grow its group view by first creating  a remote group handle and later being able to add nodes to it. E.g.\n",
            "\n",
            "group_id = NEW_crt_group_create(\"group_name\");\n",
            "\n",
            "crt_group_node_add(group_id, ...), Similarity: 0.2855\n",
            "Summary & Description: test rpc send test rpc sendreceive context 0 \n",
            " Send rpc to any ctx other than 0. Progress that ctx.\n",
            "\n",
            "Verify that the correct ctx/endpoint receives the rpc.\n",
            "\n",
            "Test the above scenario for client-server and server-server., Similarity: 0.1927\n",
            "Summary & Description: add transfer id rpc requets track clientserver \n",
            " Request from DAOS team/Johann to add new transfer id (xid) to cart rpcs, in order to be able to track them between client and server.\n",
            "\n",
            "In addition rpc trace should print out opcode of rpcs, Similarity: 0.2878\n",
            "Summary & Description: cart contributions a21 ms154 nre report daos design documentation \n",
            " Provide any CaRT documentation required for the MS154 NRE Report.\n",
            "\n",
            "Provide any CaRT documentation updates to the DAOS design document related to these changes., Similarity: 0.2729\n",
            "Summary & Description: ms154 online server addition sow \n",
            " MS154 Online Server Addition\n",
            "\n",
            "The Subcontractor shall implement the online server addition feature. The demonstration for this milestone will show a new DAOS server can be added to a pool and that parts of existing datasets will be automatically migrated to the newly added storage. This data rebalancing process will run online while applications are accessing the datasets.\n",
            "\n",
            " \n",
            "\n",
            "*+Deliverables+*\n",
            "\n",
            "The Subcontractor shall: (1) demonstrate the online server addition feature; (2) deliver an updated version of the DAOS design document if the design has changed; and (3) push the changes to the open source. This milestone will be considered complete when: (1) the Subcontractor delivers updated DAOS design document to Argonne; (2) the Subcontractor presents the design document at the quarterly meeting; and (3) the design document is considered complete to the reasonable satisfaction of Argonne., Similarity: 0.3353\n",
            "Summary & Description: scope swim related changes \n",
            " SWIM related changes – scope out tasks/durations\n",
            "\n",
            "-- packing change\n",
            "\n",
            "-- method of swim rpc to bypass internal inflight queues\n",
            "\n",
            "-- enable/disable swim, assign to a particular context (end user)\n",
            "\n",
            "-- specify swim timeouts\n",
            "\n",
            " \n",
            "\n",
            "-- reserve context 0 for CaRT internal, Similarity: 0.1694\n",
            "Summary & Description: test plan cart scale testing theta anl \n",
            " Need to develop a test plan to present to the Argonne folks (with Kal).  We want to be able to run CaRT self tests and a memory footprint test on the Theta cluster in order to test CaRT at scale.\n",
            "\n",
            "Target is to get the testing done on Theta by the end of Q3'19\n",
            " * CaRT self-test – functional testing, scaleable testing\n",
            " * Memory footprint tests – see how memory usage scales with number of nodes\n",
            " *, Similarity: 0.2303\n",
            "Summary & Description: scope resizable group support development \n",
            " Scope out work required and tasks for Resizable group support.  This will be a dependency for the online server addition support (due in community release 1.2).\n",
            "\n",
            "Work to be done with this effort:\n",
            " * Versioning support\n",
            " * Resizable secondary groups\n",
            " * Testing\n",
            " * Refactoring group membership handling, Similarity: 0.3428\n",
            "Summary & Description: removal lm plugin pmix removal \n",
            " Removal of LM plugin from CaRt after the PMIx removal is completed.  Check with Li Wei to make sure this wont impact him, Similarity: 0.2998\n",
            "Summary & Description: change default ddmaskdaosdefault group \n",
            " Default DD_MASK=all and as per discussion with developer and part of [https://github.com/daos-stack/daos/pull/457|https://github.com/daos-stack/daos/pull/457] it's better to set the daos_default group to reduce the log sizes. \n",
            "\n",
            "Gurt allows the application (daos) in this case to create custom groups of debug bits.   DAOS creates one called daos_default by invoking d_log_dbg_grp_alloc(...).\n",
            "\n",
            "It would be nice if we had an API to set the default mask as well.   For instance, DAOS wants DD_MASK to default to daos_default but gurt sets it to \"all\" if it's not set and this is extremely chatty.\n",
            "\n",
            "We recently modified some of our default configs to set it to daos_default in the server config but think it would be cleaner if this were not required to get the expected default behavior.\n",
            "\n",
            "Instead, we would like an API to set the default (or augment the alloc API with flag bits - such as D_LOG_SET_AS_DEFAULT).   Either way, it will allow DAOS to set the DD_MASK to daos_default when the user doesn't specify it in the environment and seems the cleanest way to set the default value., Similarity: 0.2858\n",
            "Summary & Description: sigbus connecting loop psm2 \n",
            " Test case:\n",
            "- run DAOS server over psm2\n",
            "- while true; do run client process querying DAOS state (dmg); done\n",
            "\n",
            "Client process ran fine for a couple of hours, but the next day, I got the following errors:\n",
            "{noformat}\n",
            "$ orterun -np 1 --ompi-server file:/tmp/uri --allow-run-as-root  dmg query --pool=656cfd91-07ca-4bbd-ae5f-24e01211aa58 --svc=0\n",
            "-------------------------------------------------------\n",
            "Primary job  terminated normally, but 1 process returned\n",
            "a non-zero exit code. Per user-direction, the job has been aborted.\n",
            "-------------------------------------------------------\n",
            "--------------------------------------------------------------------------\n",
            "orterun noticed that process rank 0 with PID 0 on node wolf-77 exited on signal 7 (Bus error).\n",
            "--------------------------------------------------------------------------\n",
            "{noformat}\n",
            "\n",
            "Ran the process under gdb:\n",
            "{noformat}\n",
            "Program received signal SIGBUS, Bus error.\n",
            "0x00007ffff6ee4860 in __memset_sse2 () from /lib64/libc.so.6\n",
            "Missing separate debuginfos, use: debuginfo-install glibc-2.17-196.el7_4.2.x86_64 libevent-2.0.21-4.el7.x86_64 libgcc-4.8.5-16.el7_4.2.x86_64 libibverbs-13-7.el7.x86_64 libnl3-3.2.28-4.el7.x86_64 librdmacm-13-7.el7.x86_64 libuuid-2.23.2-43.el7_4.2.x86_64 libyaml-0.1.4-11.el7_0.x86_64 ncurses-libs-5.9-14.20130511.el7_4.x86_64 numactl-libs-2.0.9-6.el7_2.x86_64 readline-6.2-10.el7.x86_64 zlib-1.2.7-17.el7.x86_64\n",
            "(gdb) bt\n",
            "#0  0x00007ffff6ee4860 in __memset_sse2 () from /lib64/libc.so.6\n",
            "#1  0x00007ffff34bf41c in psmi_shm_create (ptl_gen=ptl_gen@entry=0x6ff200)\n",
            "    at /home/vishwana/opa-psm2/ptl_am/am_reqrep_shmem.c:334\n",
            "#2  0x00007ffff34c4240 in amsh_init_segment (ptl_gen=0x6ff200)\n",
            "    at /home/vishwana/opa-psm2/ptl_am/am_reqrep_shmem.c:587\n",
            "#3  amsh_init (ep=0x6fef80, ptl_gen=0x6ff200, ctl=0x6ff080)\n",
            "    at /home/vishwana/opa-psm2/ptl_am/am_reqrep_shmem.c:2453\n",
            "#4  0x00007ffff34c9fd0 in __psm2_ep_open_internal (\n",
            "    unique_job_key=unique_job_key@entry=0x616250 \"\",\n",
            "    devid_enabled=devid_enabled@entry=0x7fffffffc7e0,\n",
            "    opts_i=opts_i@entry=0x7fffffffc8e0, mq=<optimized out>,\n",
            "    epo=0x7fffffffc7c0, epido=epido@entry=0x7fffffffc7a0)\n",
            "    at /home/vishwana/opa-psm2/psm_ep.c:977\n",
            "#5  0x00007ffff34ca36e in __psm2_ep_open (unique_job_key=<optimized out>,\n",
            "    opts_i=<optimized out>, epo=<optimized out>, epido=<optimized out>)\n",
            "    at /home/vishwana/opa-psm2/psm_ep.c:1087\n",
            "#6  0x00007ffff4b7af7a in psmx2_trx_ctxt_alloc ()\n",
            "   from /home/jlombard/demo/daos/install/lib/libfabric.so.1\n",
            "#7  0x00007ffff4b836b7 in psmx2_sep_open ()\n",
            "   from /home/jlombard/demo/daos/install/lib/libfabric.so.1\n",
            "#8  0x00007ffff65f4b65 in fi_scalable_ep (context=0x0, sep=0x616060,\n",
            "    info=<optimized out>, domain=<optimized out>)\n",
            "    at /home/jlombard/demo/daos/install/include/rdma/fi_endpoint.h:169\n",
            "#9  na_ofi_sep_open (na_ofi_endpoint=0x616050, na_ofi_domain=0x615eb0)\n",
            "    at /home/jlombard/demo/daos/_build.external/mercury/src/na/na_ofi.c:2140\n",
            "#10 na_ofi_endpoint_open (na_ofi_endpoint_p=0x608b98,\n",
            "    max_contexts=<optimized out>, no_wait=<optimized out>, src_addrlen=0,\n",
            "    src_addr=<optimized out>, node=0x7fffffffca90 \"\", na_ofi_domain=0x615eb0)\n",
            "    at /home/jlombard/demo/daos/_build.external/mercury/src/na/na_ofi.c:2021\n",
            "#11 na_ofi_initialize (na_class=0x608810, na_info=<optimized out>,\n",
            "    listen=<optimized out>)\n",
            "    at /home/jlombard/demo/daos/_build.external/mercury/src/na/na_ofi.c:3276\n",
            "#12 0x00007ffff65ed12d in NA_Initialize_opt (\n",
            "    info_string=0x6087e0 \"ofi+psm2://192.168.100.77:34616\",\n",
            "    listen=listen@entry=0 '\\000',\n",
            "    na_init_info=na_init_info@entry=0x7fffffffcd60)\n",
            "    at /home/jlombard/demo/daos/_build.external/mercury/src/na/na.c:377\n",
            "#13 0x00007ffff76bd402 in crt_hg_init (addr=addr@entry=0x7fffffffce88,\n",
            "    server=server@entry=false) at src/cart/crt_hg.c:513\n",
            "#14 0x00007ffff76cb966 in crt_init_opt (grpid=<optimized out>,\n",
            "    grpid@entry=0x0, flags=flags@entry=0, opt=<optimized out>)\n",
            "    at src/cart/crt_init.c:333\n",
            "#15 0x00007ffff7b720a5 in daos_eq_lib_init () at src/client/api/event.c:100\n",
            "#16 0x00007ffff7b751e0 in daos_init () at src/client/api/init.c:143\n",
            "#17 0x00000000004014a1 in main (argc=5, argv=0x7fffffffd058)\n",
            "    at src/utils/dmg.c:943\n",
            "{noformat}\n",
            "\n",
            "Nothing really useful in the logs:\n",
            "{noformat}\n",
            "05/11-07:00:46.78 wolf-77 DAOS[83514] fi   INFO src/gurt/fault_inject.c:496 d_fault_inject_init() No config file, fault injection is OFF.\n",
            "05/11-07:00:49.32 wolf-77 DAOS[83524] fi   INFO src/gurt/fault_inject.c:496 d_fault_inject_init() No config file, fault injection is OFF.\n",
            "05/11-07:00:51.87 wolf-77 DAOS[83534] fi   INFO src/gurt/fault_inject.c:496 d_fault_inject_init() No config file, fault injection is OFF.\n",
            "05/11-07:00:53.72 wolf-77 DAOS[83544] mem  DBUG src/gurt/hash.c:674 d_hash_table_create_inplace() alloc(calloc) 'buckets': 16 * 'nr':8192 at 0x7f132e72b010.\n",
            "05/11-07:00:53.72 wolf-77 DAOS[83544] fi   INFO src/gurt/fault_inject.c:496 d_fault_inject_init() No config file, fault injection is OFF.\n",
            "05/11-07:00:53.72 wolf-77 DAOS[83544] fi   DBUG src/gurt/fault_inject.c:143 fault_attr_set() alloc(calloc) 'new_rec': 80 at 0x9cce50.\n",
            "05/11-07:00:53.72 wolf-77 DAOS[83544] fi   DBUG src/gurt/fault_inject.c:165 fault_attr_set() new fault id: 1 added.\n",
            "05/11-07:00:53.72 wolf-77 DAOS[83544] mem  DBUG src/gurt/hash.c:968 d_hhash_create() alloc(calloc) 'hhtab': 104 at 0x9cceb0.\n",
            "05/11-07:00:53.72 wolf-77 DAOS[83544] mem  DBUG src/gurt/hash.c:674 d_hash_table_create_inplace() alloc(calloc) 'buckets': 16 * 'nr':65536 at 0x7f132e62a010.\n",
            "05/11-07:00:53.72 wolf-77 DAOS[83544] crt  DBUG src/cart/crt_init.c:58 data_init() initializing crt_gdata...\n",
            "05/11-07:00:53.72 wolf-77 DAOS[83544] misc DBUG src/gurt/misc.c:581 d_getenv_int() d_getenv_int(), get ENV CRT_TIMEOUT as 600.\n",
            "05/11-07:00:53.72 wolf-77 DAOS[83544] crt  DBUG src/cart/crt_init.c:94 data_init() set the global timeout value as 600 second.\n",
            "05/11-07:00:53.72 wolf-77 DAOS[83544] crt  DBUG src/cart/crt_init.c:114 data_init() CRT_CREDIT_EP_CTX set as 32 for flow control.\n",
            "05/11-07:00:53.72 wolf-77 DAOS[83544] crt  DBUG src/cart/crt_init.c:122 data_init() crt_gdata.cg_share_na turned on.\n",
            "05/11-07:00:53.72 wolf-77 DAOS[83544] crt  DBUG src/cart/crt_init.c:136 data_init() set cg_share_na 1, cg_ctx_max_num 2.\n",
            "05/11-07:00:53.72 wolf-77 DAOS[83544] crt  DBUG src/cart/crt_init.c:303 crt_init_opt() EVN CRT_PHY_ADDR_STR: ofi+psm2.\n",
            "05/11-07:00:53.72 wolf-77 DAOS[83544] crt  DBUG src/cart/crt_init.c:652 crt_na_ofi_config_init() alloc(strndup) 'crt_na_ofi_conf.noc_interface': 4 at 0x9cd750.\n",
            "05/11-07:00:53.72 wolf-77 DAOS[83544] crt  DBUG src/cart/crt_init.c:633 crt_get_port() get a port: 41441.\n",
            "05/11-07:00:53.72 wolf-77 DAOS[83544] hg   DBUG src/cart/crt_hg.c:451 crt_get_info_string() alloc(asprintf) '*string': 32 at 0x9cd7e0.\n",
            "05/11-07:00:53.72 wolf-77 DAOS[83544] hg   DBUG src/cart/crt_hg.c:512 crt_hg_init() info_string: ofi+psm2://192.168.100.77:41441\n",
            "05/11-07:00:54.42 wolf-77 DAOS[83554] fi   INFO src/gurt/fault_inject.c:496 d_fault_inject_init() No config file, fault injection is OFF.\n",
            "05/11-07:00:56.97 wolf-77 DAOS[83567] fi   INFO src/gurt/fault_inject.c:496 d_fault_inject_init() No config file, fault injection is OFF.\n",
            "{noformat}, Similarity: 0.3009\n",
            "Summary & Description: print thread tid instead main process pid log \n",
            " Presently each log line prints the main process pid which causes debugging to be very complex/painful in a multi-threaded environment.\n",
            "\n",
            "Would be more useful if at least the current/concerned thread's tid would be printed instead.\n",
            ", Similarity: 0.2482\n",
            "Summary & Description: demo cart avocado framework team \n",
            " Demo CaRT avocado framework to the team to make sure the team knows how to add new tests in the framework., Similarity: 0.2469\n",
            "Summary & Description: port existing cart tests avocado framework \n",
            " Port all existing CaRT tests to avocado framework.\n",
            "\n",
            "Re-structure test python and yaml files to work with the framework and CI., Similarity: 0.3375\n",
            "Summary & Description: enable cart avocado ci \n",
            " Enable CaRT avocado in CI to replace test_runner.\n",
            "\n",
            "This will require\n",
            " # enabling CaRT Jenkins to run with avocado\n",
            " # creating shell script to automatically substitute test nodes in yaml\n",
            " # creating python wrappers to be able to launch tests by filters , Similarity: 0.2877\n",
            "Summary & Description: cart self test working ci \n",
            " When John M tried to run the cart self test in DAOS CI it failed.  The particular tests that failed:\n",
            "\n",
            "network/cart_self_test  hosts-large_io_bulk_get-on-server_config\n",
            "network/cart_self_test  hosts-large_io_bulk_get-off-server_config\n",
            "\n",
            "These are run using the avocado wrapper for cart self test that is in the DAOS project.  He is running these on 9 physical nodes in the wolf cluster that are reserved for CI.  Most likely it is not particular to this environment --the test is not regularly run in CI and is probably just broken., Similarity: 0.2646\n",
            "Summary & Description: create first draft cart test plan \n",
            " Need to create cart test plan by going over APIs and listing scenarios that need to be tested, Similarity: 0.2772\n",
            "Summary & Description: make cart group apis consistent regarding null group \n",
            " Some groups-related APIs such as crt_group_size() allow passing NULL for crt_group_t (defaulting to local primary group) while others (e.g. crt_group_node_add()) return error for NULL group.\n",
            "\n",
            " , Similarity: 0.1821\n",
            "Summary & Description: enable cart build master branch ofi mercury openpa \n",
            " Enable CaRT build with master branch of OFI, Mercury and OpenPA.\n",
            "\n",
            "This will require modifying the Jenkinsfile to add a new build on CentOS 7 to use master branch of OFI, Mercury and OpenPA., Similarity: 0.3841\n",
            "Summary & Description: swim put swim rpcs front queue \n",
            " Add  a new flag to RPCs based on which rpcs sent will be put in front of the queue if we exceed EP credits limit. \n",
            "\n",
            "Change SWIM rpcs to specify that flag., Similarity: 0.1326\n",
            "Summary & Description: stage1 pmix removal creation crtlauncher \n",
            " This is stage1 of pmix removal.\n",
            "\n",
            "In this stage, crt_launcher application will be added and applicable cart tests moved to it.\n",
            "\n",
            "As part of this ticket, tests that are no longer applicable (lm-based for example) will be removed.\n",
            "\n",
            " , Similarity: 0.2042\n",
            "Summary & Description: cart multiple provider support \n",
            " add multiple provider support to cart. this enables the use of multiple providers in the same cart process., Similarity: 0.2557\n",
            "Summary & Description: enable cart code coverage ci \n",
            " Enable CaRT code coverage in CI.\n",
            "\n",
            "Have CI automatically generate code coverage report with every PR push., Similarity: 0.2016\n",
            "Summary & Description: investigate cart test avocado \n",
            " Learn how Avocado works. Use DAOS tests as example.\n",
            "\n",
            "Investigate how to enable CaRT in Avocado., Similarity: 0.1361\n",
            "Summary & Description: enable bullseye coverage sconslocal \n",
            " Enable Bulleyes code coverage to build with scons_local., Similarity: 0.2116\n",
            "Summary & Description: enable code coverage cart \n",
            " Enable Bullseye code coverage in CaRT and generate a coverage report.\n",
            "\n",
            "Code coverage data will be used for identifying validation gaps., Similarity: 0.2328\n",
            "Summary & Description: remove legacy rpc registration functions \n",
            " Needs to be inserted in the Unit Tests as well., Similarity: 0.1192\n",
            "Summary & Description: occasional segfault running testepcredclient \n",
            " Segfault occurred during one of runs of test_ep_cred_client:\n",
            "\n",
            " \n",
            "\n",
            "[https://build.hpdd.intel.com/job/daos-stack/job/cart/view/change-requests/job/PR-118/2/execution/node/467/log/?consoleFull]\n",
            "\n",
            " \n",
            "\n",
            "*07:26:31*  tests/test_ep_cred_client -a cred_group -c 0 -b 20*07:26:31*  TestEpCredits: start ep credits test - input string:*07:26:31*  /var/lib/jenkins/jenkins-1/docker_1/workspace/daos-stack_cart_PR-118@2/install/Linux/bin/orterun --mca btl self,tcp  --output-filename testLogs/testRun/cart_test_ep_credits/loop0/cart_test_ep_credits_default/credits -H wolf-106vm10 -N 1  -x D_LOG_MASK=DEBUG,MEM=ERR -x D_LOG_FILE=testLogs/testRun/cart_test_ep_credits/loop0/cart_test_ep_credits_default/credits/output.log -x CRT_PHY_ADDR_STR=ofi+sockets -x OFI_INTERFACE=eth0 -x CRT_CTX_SHARE_ADDR=0 -x CRT_CTX_NUM=16 tests/test_ep_cred_client -a cred_group -c 0 -b 20 -q*07:26:31*  local group: (null) remote group: cred_group*07:26:32*  Attaching to group cred_group*07:26:33*  -------------------------------------------------------*07:26:33*  Primary job  terminated normally, but 1 process returned*07:26:33*  a non-zero exit code. Per user-direction, the job has been aborted.*07:26:33*  -------------------------------------------------------*07:26:35*  --------------------------------------------------------------------------*07:26:35*  orterun noticed that process rank 0 with PID 0 on node wolf-106vm10 exited on signal 11 (Segmentation fault).*07:26:35*  --------------------------------------------------------------------------*07:26:35*  TestEpCredits: ep credits test - return code: 139 test duration: 4*07:26:35* *07:26:35*  tearDown begin*07:26:35*  tearDown end*07:26:35* *07:26:35*  ************ Results ********07:26:35*  Number test run: 1*07:26:35*  Number skipped tests: 0*07:26:35*  Test failed*07:26:35* *07:26:35*  Number test errors: 0*07:26:35* *07:26:35*  Number test failures: 1*07:26:35*  test_ep_credits (cart_test_ep_credits.TestEpCredits)*07:26:35*  Traceback (most recent call last):*07:26:35*    File \"scripts/cart_test_ep_credits.py\", line 125, in test_ep_credits*07:26:35*      self.fail(\"ep credit client filed with %d\" % cli_rtn)*07:26:35*  AssertionError: ep credit client filed with 139, Similarity: 0.2443\n",
            "Summary & Description: export envariables crtinitoptionst \n",
            " crt_init_opt() today allows overriding of some of environmental variables via settings passed in crt_init_options_t structure. \n",
            "\n",
            "This ticket is for going through all existing supported envariables in cart (README.env lists them), and adding missing overrides to crt_init_options_t as well as handling of those values at crt_init time., Similarity: 0.2439\n",
            "Summary & Description: investigate hangs shutdown multiple servers swim rpcs arrive dead nodes \n",
            " In the scenario where multiple servers are started up, exchange rpcs among each other, and attempt to shut down, in some cases SWIM rpcs that are sent in the background end up blocking context destruction in what seems to be an infinite loop of sorts.\n",
            "\n",
            " , Similarity: 0.1750\n",
            "Summary & Description: remove pmix support cart \n",
            " This ticket is for the removal of PMIX support from cart, Similarity: 0.2547\n",
            "Summary & Description: create crtlauncher application \n",
            " This ticket is for creation of a wrapper crt_launcher application which would allow porting of existing cart tests to NO_PMIX mode.\n",
            "\n",
            "crt_launcher based on passed options would generate environment needed for running tests without pmix support, such as generation of group file that contains rank:tag:uri pairs, group size, self rank and would set OFI_PORT appropriately , Similarity: 0.3384\n",
            "Summary & Description: develop test plan cart \n",
            " # Document CaRT tests and their purpose\n",
            " # Develop a test plan for CaRT and review with team\n",
            "\n",
            " , Similarity: 0.2379\n",
            "Summary & Description: client hangs multiple rpcs inflight \n",
            " IN the MPI-IO IOR, i was testing a use case where a single client launches many I/Os inflight.\n",
            "\n",
            "In one test case, when the number of inflight RPCs changes from 32 to 64, i see that the client hangs. I think it hung after launching 320 RPCs. but I might be wrong on that.\n",
            "\n",
            "Yulu mentioned that i can play with CRT_CREDIT_EP_CTX, which i set to 0 and that seems to work.\n",
            "\n",
            "But the hang when the default is used (32), seems to indicate there is a bug when flow control is exercised?, Similarity: 0.2635\n",
            "Summary & Description: cart send rpc error multiple endpoint server using ofiverbsofirxm \n",
            " A problem reported by a CART user, ChenQi in Tsinghua university:\n",
            "\n",
            " \n",
            "\n",
            "I met some issue when using cart rpc library. here are some details.\n",
            "setup:\n",
            "server: using multiple threads, each thread runs one crt_progress instance on one private context.\n",
            "client: using multiple threads. each thread send message to different EP using round robin.\n",
            "server and client runs on the same node.\n",
            " \n",
            "software version:\n",
            "cart:\n",
            "commit ac4383ed2874d221a82673166bedddfb623b69cf\n",
            "Author: Jeff Olivier <[jeffrey.v.olivier@intel.com|mailto:jeffrey.v.olivier@intel.com]>\n",
            "Date:   Fri Jan 4 15:02:17 2019 -0700\n",
            " \n",
            "    CART-89 build: Fix compiler warnings on gcc Fedora 29\n",
            "    \n",
            "    These warnings were preventing a clean build on my box.\n",
            "    1. The PMIX field actually has space for the NULL byte and adding 1\n",
            "       fixes the warning\n",
            "    2. I simply disable the warning about array size.  It's not correct\n",
            "       anyway.  This case is below essentially x == 0 ? 0 : ARRAY_SIZE(ptr)\n",
            "       In this case, the ptr is only NULL if x is 0 so the warning that it\n",
            "       isn't an array is in dead code. I couldn't come up with a better way\n",
            "       to fix this then to disable the warning.  The extra ignored warnings\n",
            "       are to deal with the particular option not being supported by\n",
            "       various compilers\n",
            "    \n",
            "    Change-Id: I4d90655bf0cd46f08646f02aab41df2c69dc5b3e\n",
            "    Signed-off-by: Jeff Olivier <[jeffrey.v.olivier@intel.com|mailto:jeffrey.v.olivier@intel.com]>\n",
            "    Reviewed-on: [https://review.hpdd.intel.com/33861]\n",
            "    Tested-by: Jenkins\n",
            "    Reviewed-by: Alexander Oganezov <[alexander.a.oganezov@intel.com|mailto:alexander.a.oganezov@intel.com]>\n",
            " \n",
            "mercury:\n",
            "commit 0de22781cd08931416aba8050c5a6647c23abcb9\n",
            "Author: Jerome Soumagne <[jsoumagne@hdfgroup.org|mailto:jsoumagne@hdfgroup.org]>\n",
            "Date:   Fri Feb 15 11:55:34 2019 -0600\n",
            " \n",
            "    Update copyright date\n",
            " \n",
            "ofi:\n",
            "commit c243a4c660d85f1c55e02cee916422045e6414fb\n",
            "Merge: 48bf661 aefe819\n",
            "Author: Sean Hefty <[sean.hefty@intel.com|mailto:sean.hefty@intel.com]>\n",
            "Date:   Fri Mar 8 15:41:08 2019 -0800\n",
            " \n",
            "    Merge pull request #4896 from shefty/v1.7.x\n",
            "    \n",
            "    prov/verbs: Add missing include for S_IWUSR\n",
            " \n",
            "environment:\n",
            "CentOS Linux release 7.5.1804 (Core)\n",
            "Intel(R) Xeon(R) CPU E5-2643 v4 @ 3.40GHz\n",
            "results:\n",
            "when using ofi + sockets, the codes is OK. But when running using ofi + verbs, sometimes it works, but it is more likely to trigger the following error. The test codes is in the attachment.\n",
            " \n",
            "# na_ofi_msg_send_unexpected(): fi_tsend(unexpected) failed, rc: -113(No route to host) 03/12-08:08:15.74 tstore08 CaRT[1137] HG   ERR  # NA -- Error -- /root/_build.external-Linux/mercury/src/na/na_ofi.c:4089\n",
            "# na_ofi_msg_send_unexpected(): fi_tsend(unexpected) failed, rc: -113(No route to host) 03/12-08:08:15.74 tstore08 CaRT[1137] HG   ERR  # HG -- Error -- /root/_build.external-Linux/mercury/src/mercury_core.\n",
            "    c:2067\n",
            "# hg_core_forward_na(): Could not post send for input buffer 03/12-08:08:15.74 tstore08 CaRT[1137] HG   ERR  # HG -- Error -- /root/_build.external-Linux/mercury/src/mercury_core.\n",
            "    c:2067\n",
            "# hg_core_forward_na(): Could not post send for input buffer 03/12-08:08:15.74 tstore08 CaRT[1137] HG   ERR  # HG -- Error -- /root/_build.external-Linux/mercury/src/mercury_core.\n",
            "    c:4724\n",
            "# HG_Core_forward(): Could not forward buffer 03/12-08:08:15.74 tstore08 CaRT[1137] HG   ERR  # HG -- Error -- /root/_build.external-Linux/mercury/src/mercury_core.c:4724\n",
            "# HG_Core_forward(): Could not forward buffer 03/12-08:08:15.74 tstore08 CaRT[1137] HG   ERR  # HG -- Error -- /root/_build.external-Linux/mercury/src/mercury.c:209\n",
            " \n",
            " , Similarity: 0.2883\n",
            "Summary & Description: swim rpcs get reregistered accident user \n",
            " Found today while investigation of different issue with Dmitry Durnov that swim rpcs can get re-registered by end-user by mistake, which can cause issues internally later on.\n",
            "\n",
            " \n",
            "\n",
            "We need to prevent swim rpc opcodes from being re-registered, Similarity: -0.0079\n",
            "Summary & Description: provide public api events changes rank state \n",
            " We have internal API for events related to rank state. This API is used to provide rank eviction mechanism. With new bootstrapping approach we should provide ability to subscribe on those events outside of CaRT to manage groups members outside.\n",
            "\n",
            " , Similarity: 0.2352\n",
            "Summary & Description: memory leak crthgaddrlookup \n",
            " The memory allocated for completion callback is not freed in case of error in low level function call., Similarity: 0.2188\n",
            "Summary & Description: change dvlogs buffer stack perthreadlocaldata \n",
            " the original code in d_vlog() use a 1K in stack buffer, for such as frequently used low level function, it is dangerous to use so big stack space – possibly cause stack overflow if the calling depth is deep.\n",
            "\n",
            "Should refine it to use a per-thread local data., Similarity: 0.2759\n",
            "Summary & Description: selftest using rpc registration macros properly \n",
            " Looking at the RPC registration code the self-test code isn't doing the right thing with respect to RPC registration.\n",
            "\n",
            " \n",
            "\n",
            "The RPCs themselves are registered using the new macros, however the macros use \"unused\" as the struct names, and then there is another set of structs defined which are the structs the code uses, meaning the packing/unpacking RPCs are using different definitions to the code.\n",
            "\n",
            " , Similarity: 0.1115\n",
            "Summary & Description: reduce overhead debug log \n",
            " We can design debug logging to cache the value of the resolved masks for each priority/facility combination., Similarity: 0.3374\n",
            "Summary & Description: assertion epiepireqnum epiepireplynum failed \n",
            " I got a assertion failure in IOF testing locally, using master CaRT and IOF.  This was from the failover_off_readdir test but I think it could have been any of the failover tests.  After the assertion I have one ionss process left running, and a cnss process which is blocked not making any progress., Similarity: 0.2400\n",
            "Summary & Description: investigate test stability issues \n",
            " There have cropped up a number of intermittent test failures. This is an overarching ticket for root causing those and getting them fixed so test is stable again., Similarity: 0.1636\n",
            "Summary & Description: uri entry already present errors \n",
            " Occasionally runnign corpc version test results in errors with -DER_EXISTS being returned.\n",
            "\n",
            "Internally this is caused by a race condition where a uri cache entry existance and addition were not protected by the lock, Similarity: 0.1059\n",
            "Summary & Description: reset fields dfigdata dfigdatadestroy \n",
            " Reset all fields in d_fi_gdata in d_fi_gdata_destroy , otherwise d_fi_gdata might include some invalidate fields if it does d_fault_inject_fini then d_fault_inject_init() again., Similarity: 0.2288\n",
            "Summary & Description: crtgrplclookup race condition check addition \n",
            " crt_grp_lc_lookup() has a race condition between check of entry existing in hash table and addition of a new entry if such does not exist.\n",
            "\n",
            "If a new entry gets added in parallel in between check and addition of a new entry, then DER_EXISTS will be returned, which causes crt_hdlr_uri_lookup() to return error.\n",
            "\n",
            "This issue was first reported by LANL running many nodes in parallel with errors being reported during test on 1024 nodes:\n",
            "\n",
            "02/06-09:38:57.14 mo0302 CaRT[4716] GRP  ERR  src/cart/crt_group.c:2053 crt_hdlr_uri_lookup() crt_grp_lc_lookup(grp IONSS, rank 41, tag 0) failed, rc: -1004., Similarity: 0.1942\n",
            "Summary & Description: crthgfini propagating errors \n",
            " Looking at the code crt_hg_fini() returns a error code which is always zero.  We're seeing some test results where HG_Finalize() is returning an error which is logged but not passed on.\n",
            "\n",
            "The valgrind checks are catching this, but it's not causing a failure of the CaRT call., Similarity: 0.2534\n",
            "Summary & Description: hgbulktransfer never completes times \n",
            " I created a replicator for this in DAOS:\n",
            "\n",
            "[https://github.com/daos-stack/daos/tree/crt_timeout_repl]\n",
            "\n",
            " \n",
            "\n",
            "With PSM2, i get timeouts on some IOs (random as when they happen but they happen on every run) and they are retried and retry works. default timeout is 60 seconds.\n",
            "\n",
            "When running performance tests with IOR, this would kill performance reported when it happens.\n",
            "\n",
            "you can replicate with patch above with 1 server:\n",
            "\n",
            "orterun --mca mtl ^psm2,ofi --enable-recovery -np 1 --hostfile ~/srv_hosts --report-uri ~/uri.txt daos_server -c 8 -a /home/mschaara/ -d /tmp/daos_server/\n",
            "\n",
            "need 32 client ranks or more:\n",
            "\n",
            "orterun -np 32 -x DD_STDERR=ERR -x POOL_SCM_SIZE=60 --mca mtl ^psm2,ofi --hostfile ~/cli_hosts --map-by node --ompi-server [file:~/uri.txt|file:///~/uri.txt] daos_addons_test\n",
            "\n",
            " \n",
            "\n",
            "this error is observed at client side on some client ranks:\n",
            "\n",
            "01/31-16:40:49.27 boro-24 DAOS[61667] RPC  ERR  src/cart/crt_context.c:780 crt_context_timeout_check(0x2411760) ctx_id 0, (status: 0x38) timed out, tgt rank 0, tag 15\n",
            "\n",
            "01/31-16:40:49.27 boro-24 DAOS[61667] RPC  ERR  src/cart/crt_context.c:740 crt_req_timeout_hdlr(0x2411760) aborting to group daos_server, rank 0, tgt_uri ofi+psm2://2d0302:101\n",
            "\n",
            "01/31-16:40:49.27 boro-24 DAOS[61667] HG   ERR  src/cart/crt_hg.c:1229 crt_hg_req_send_cb(0x2411760) RPC failed; rc: -1011\n",
            "\n",
            "01/31-16:40:49.27 boro-24 DAOS[61667] object ERR  src/object/cli_shard.c:156 dc_rw_cb() RPC 0 failed: -1011\n",
            "\n",
            " \n",
            "\n",
            "I tried with upgraded versions of OFI:\n",
            "\n",
            "9e3979a3aba2559085a6fb63f0855119f674c73f\n",
            "\n",
            "and OPA-PSM2:\n",
            "\n",
            "git checkout tags/PSM2_11.2.78\n",
            "\n",
            " \n",
            "\n",
            "Environment setup:\n",
            "\n",
            "On Client and Server:\n",
            "\n",
            "export CRT_PHY_ADDR_STR=\"ofi+psm2\"\n",
            "\n",
            "export OFI_INTERFACE=ib0\n",
            "\n",
            "export FI_PSM2_NAME_SERVER=1\n",
            "\n",
            "export PSM2_MULTI_EP=1\n",
            "\n",
            "export FI_SOCKETS_MAX_CONN_RETRY=1\n",
            "\n",
            "export CRT_CTX_SHARE_ADDR=1\n",
            "\n",
            "export CRT_CTX_NUM=17\n",
            "\n",
            "export OFI_PORT=26850\n",
            "\n",
            "export ABT_ENV_MAX_NUM_XSTREAMS=100\n",
            "\n",
            "export ABT_MAX_NUM_XSTREAMS=100\n",
            "\n",
            " , Similarity: 0.2545\n",
            "Summary & Description: change local cache longer per context \n",
            " currently for each group, there are CRT_SRV_CONTEXT_NUM copies of NA addr caches, i.e. one cache for each local context.\n",
            "\n",
            "Change it to:\n",
            "\n",
            "1) one copy of NA addr cache per group if NA addr is the same within the process, i.e. doesn't depend on the source address\n",
            "\n",
            "2) one copy of NA addr cache per local context for each group if NA addr is different for each local context., Similarity: 0.0999\n",
            "Summary & Description: minor issues cart groups \n",
            " The check for service should be after check for initialization.\n",
            "In debug message print correct value.\n",
            ", Similarity: 0.2212\n",
            "Summary & Description: automatically generate structures crtrpcdeclare macros \n",
            " To be able to see structures members in external tools we should expand produced structures from macros into special header file., Similarity: 0.2584\n",
            "Summary & Description: daos oid allocator test failing killing servers \n",
            " This can be replicated with running daos_test -O. \n",
            "\n",
            "This was working fine until 1-2 weeks ago.\n",
            "\n",
            "DAOS version i replicated with (master): 4fe81c68c1abdabd3e5b65a660f1c3ea52c608a1\n",
            "\n",
            "Start servers:\n",
            "\n",
            "orterun -x DD_STDERR=ERR --mca mtl ^psm2,ofi --enable-recovery -np 6 --hostfile ~/srv_hosts --report-uri ~/uri.txt daos_server -c 8 -a /home/mschaara/ -d /tmp/daos_server/\n",
            "\n",
            "Start 1 client:\n",
            "\n",
            "orterun -np 1 -x D_LOG_MASK=DEBUG -x DD_STDERR=ERR --mca mtl ^psm2,ofi --hostfile ~/cli_hosts --map-by node --ompi-server [file:~/uri.txt|file:///~/uri.txt] /home/mschaara/install/daos_m/bin/daos_test -O\n",
            "\n",
            " \n",
            "\n",
            "when the test exclude & kills a target, something strange happens with the first rpc sent to the failed target:\n",
            "\n",
            "[https://github.intel.com/gist/anonymous/f8fb7f0952b560b2b7fbf47fe089f41e]\n",
            "\n",
            "timeout error is seen, but return rc is success. so daos assumes all is good, and so the out data of the rpc is used. NO handler for the timed-out rpc is seen on the server side!\n",
            "\n",
            "the second call to the failed target returns -1011, and so DAOS client refreshes the pool map and excludes the target to not send further requests to it. the issue is with the first call to the failed target that returns success.\n",
            "\n",
            " , Similarity: 0.1929\n",
            "Summary & Description: carts multinode testing leaves orte processes behind \n",
            " After the running of multi-node (i.e. 2 and 5 node) tests, there are one or more {{orte-dvm}} and/or {{orted}} processes left running on the nodes.\n",
            "\n",
            "Ideally, tests should completely clean up after themselves., Similarity: 0.1331\n",
            "Summary & Description: add method verifying pointers used input structure \n",
            " We need a method for detection of situations when input rpc structure contains pointers to the fields that are allocated on stack instead of heap. \n",
            "\n",
            "When input rpc structure points to anything on stack, it must perform progress (after crt_req_send()) while in the same stack frame, or else garbage data will be copied into input, if crt progress is done asynchronously.\n",
            "\n",
            "The method for this check does not need to run every time, so it can be non-optimal/hacky and can be enabled manually on demand to ensure we don't have bugs similar to CART-555, Similarity: 0.1995\n",
            "Summary & Description: assertion crthdlrivsync \n",
            " in daos_test we ever met such assertion by using latest cart master code (\n",
            "\n",
            "17c00672c3d29bcb737a12846fc318cd21cc3931):\n",
            "\n",
            " \n",
            "\n",
            "(gdb) bt\n",
            "\n",
            "#0  0x00007f02355951f7 in raise () from /lib64/libc.so.6\n",
            "\n",
            "#1  0x00007f02355968e8 in abort () from /lib64/libc.so.6\n",
            "\n",
            "#2  0x00007f023558e266 in __assert_fail_base () from /lib64/libc.so.6\n",
            "\n",
            "#3  0x00007f023558e312 in __assert_fail () from /lib64/libc.so.6\n",
            "\n",
            "#4  0x00007f0236f07982 in crt_hdlr_iv_sync (rpc_req=0x7efcd88e5048) at src/cart/crt_iv.c:1816\n",
            "\n",
            "#5  0x00007f0236f2a407 in crt_rpc_common_hdlr (rpc_priv=0x7efcd88e4ff0) at src/cart/crt_rpc.c:1360\n",
            "\n",
            "#6  0x00007f0236ec5ab4 in crt_corpc_req_hdlr (rpc_priv=rpc_priv@entry=0x7efcd88e4ff0) at src/cart/crt_corpc.c:920\n",
            "\n",
            "#7  0x00007f0236ec7694 in crt_corpc_initiate (rpc_priv=rpc_priv@entry=0x7efcd88e4ff0) at src/cart/crt_corpc.c:168\n",
            "\n",
            "#8  0x00007f0236ec92df in crt_corpc_chained_bulk_cb (cb_info=<optimized out>) at src/cart/crt_corpc.c:206\n",
            "\n",
            "#9  0x00007f0236ee43e2 in crt_hg_bulk_transfer_cb (hg_cbinfo=<optimized out>) at src/cart/crt_hg.c:1662\n",
            "\n",
            "#10 0x00007f02348a54d0 in hg_bulk_trigger_entry (hg_bulk_op_id=0x7efcd88d8c00) at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury_bulk.c:1040\n",
            "\n",
            "#11 0x00007f02348a559a in hg_bulk_complete (hg_bulk_op_id=<optimized out>) at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury_bulk.c:995\n",
            "\n",
            "#12 hg_bulk_transfer_cb (callback_info=callback_info@entry=0x7f021abeb7a0) at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury_bulk.c:732\n",
            "\n",
            "#13 0x00007f02348a4ed5 in hg_bulk_memcpy_get (na_class=<optimized out>, context=<optimized out>, callback=callback@entry=0x7f02348a5540 <hg_bulk_transfer_cb>, \n",
            "\n",
            "    arg=arg@entry=0x7efcd88d8c00, local_mem_handle=<optimized out>, local_address=<optimized out>, local_offset=local_offset@entry=0, remote_mem_handle=0x7efcd88dd650, \n",
            "\n",
            "    remote_address=139624430032672, remote_offset=remote_offset@entry=0, data_size=data_size@entry=72, remote_addr=remote_addr@entry=0x7efcd88bb2d0, \n",
            "\n",
            "    remote_id=remote_id@entry=0 '\\000', op_id=0x7efcd88dda10) at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury_bulk.c:318\n",
            "\n",
            "#14 0x00007f02348a5151 in hg_bulk_transfer_pieces (na_bulk_op=na_bulk_op@entry=0x7f02348a4ea0 <hg_bulk_memcpy_get>, origin_addr=origin_addr@entry=0x7efcd88bb2d0, origin_id=0 '\\000', \n",
            "\n",
            "    hg_bulk_origin=hg_bulk_origin@entry=0x7efcd88dd7b0, origin_segment_start_index=origin_segment_start_index@entry=0, \n",
            "\n",
            "    origin_segment_start_offset=origin_segment_start_offset@entry=0, hg_bulk_local=hg_bulk_local@entry=0x7efcd88d7770, local_segment_start_index=local_segment_start_index@entry=0, \n",
            "\n",
            "    local_segment_start_offset=local_segment_start_offset@entry=0, size=size@entry=72, scatter_gather=scatter_gather@entry=0 '\\000', \n",
            "\n",
            "    hg_bulk_op_id=hg_bulk_op_id@entry=0x7efcd88d8c00, na_op_count=na_op_count@entry=0x0, use_sm=0 '\\000') at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury_bulk.c:794\n",
            "\n",
            "#15 0x00007f02348a7404 in hg_bulk_transfer (op_id=op_id@entry=0x1, size=72, size@entry=139624429892304, local_offset=<optimized out>, hg_bulk_local=0x7efcd88d7770, \n",
            "\n",
            "    hg_bulk_local@entry=0x7f0100000000, origin_offset=<optimized out>, hg_bulk_origin=0x7efcd88dd7b0, origin_id=<optimized out>, origin_addr=<optimized out>, \n",
            "\n",
            "    op=(unknown: 881479328), arg=0x7efcd88dd7b0, callback=0x7f0236ee4210 <crt_hg_bulk_transfer_cb>, context=<optimized out>)\n",
            "\n",
            "    at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury_bulk.c:965\n",
            "\n",
            "#16 HG_Bulk_transfer_id (context=<optimized out>, callback=callback@entry=0x7f0236ee4210 <crt_hg_bulk_transfer_cb>, arg=arg@entry=0x7efcd88dd820, op=op@entry=HG_BULK_PULL, \n",
            "\n",
            "    origin_addr=<optimized out>, origin_id=<optimized out>, origin_handle=origin_handle@entry=0x7efcd88dd7b0, origin_offset=origin_offset@entry=0, \n",
            "\n",
            "    local_handle=local_handle@entry=0x7efcd88d7770, local_offset=local_offset@entry=0, size=size@entry=72, op_id=op_id@entry=0x1)\n",
            "\n",
            "    at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury_bulk.c:2008\n",
            "\n",
            "#17 0x00007f0236eee3da in crt_hg_bulk_transfer (bulk_desc=bulk_desc@entry=0x7f021abebaa0, complete_cb=<optimized out>, arg=<optimized out>, opid=<optimized out>, \n",
            "\n",
            "    bind=bind@entry=false) at src/cart/crt_hg.c:1722\n",
            "\n",
            "#18 0x00007f0236eb5b73 in crt_bulk_transfer (bulk_desc=bulk_desc@entry=0x7f021abebaa0, complete_cb=complete_cb@entry=0x7f0236ec8e80 <crt_corpc_chained_bulk_cb>, arg=<optimized out>, \n",
            "\n",
            "    opid=opid@entry=0x0) at src/cart/crt_bulk.c:209\n",
            "\n",
            "#19 0x00007f0236ec8a32 in crt_corpc_common_hdlr (rpc_priv=0x7efcd88e4ff0) at src/cart/crt_corpc.c:330\n",
            "\n",
            "#20 0x00007f0236eec1e5 in crt_rpc_handler_common (hg_hdl=<optimized out>) at src/cart/crt_hg.c:1017\n",
            "\n",
            "#21 0x00007f023489fd16 in hg_core_process (hg_core_handle=0x7f01fc0587f0) at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury_core.c:2739\n",
            "\n",
            "#22 hg_core_trigger_entry (hg_core_handle=0x7f01fc0587f0) at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury_core.c:3382\n",
            "\n",
            "#23 hg_core_trigger (context=0x7f01fc02bca0, timeout=<optimized out>, timeout@entry=0, max_count=max_count@entry=4294967295, actual_count=actual_count@entry=0x7f021abebdac)\n",
            "\n",
            "    at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury_core.c:3323\n",
            "\n",
            "#24 0x00007f02348a082b in HG_Core_trigger (context=<optimized out>, timeout=timeout@entry=0, max_count=max_count@entry=4294967295, actual_count=actual_count@entry=0x7f021abebdac)\n",
            "\n",
            "    at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury_core.c:5141\n",
            "\n",
            "#25 0x00007f02348a4cdd in HG_Trigger (context=context@entry=0x7f01fc02bc80, timeout=timeout@entry=0, max_count=max_count@entry=4294967295, \n",
            "\n",
            "    actual_count=actual_count@entry=0x7f021abebdac) at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury.c:2525\n",
            "\n",
            "#26 0x00007f0236ee3852 in crt_hg_trigger (hg_ctx=hg_ctx@entry=0x7f01fc026a38) at src/cart/crt_hg.c:1404\n",
            "\n",
            "#27 0x00007f0236eec5a0 in crt_hg_progress (hg_ctx=hg_ctx@entry=0x7f01fc026a38, timeout=timeout@entry=0) at src/cart/crt_hg.c:1451\n",
            "\n",
            "#28 0x00007f0236ebe770 in crt_progress (crt_ctx=0x7f01fc026a20, timeout=0, cond_cb=0x0, arg=0x0) at src/cart/crt_context.c:1178\n",
            "\n",
            "#29 0x000000000040e81b in dss_srv_handler (arg=0x24e6e50) at src/iosrv/srv.c:379\n",
            "\n",
            "---Type <return> to continue, or q <return> to quit--- \n",
            "\n",
            "#30 0x00007f0235fc6708 in ABTD_thread_func_wrapper () from /home/xliu9/src/daos_m/install/lib/libabt.so.0\n",
            "\n",
            "#31 0x00007f0235fc6c91 in make_fcontext () from /home/xliu9/src/daos_m/install/lib/libabt.so.0\n",
            "\n",
            "#32 0x0000000000000000 in ?? ()\n",
            "\n",
            "(gdb) f 4\n",
            "\n",
            "#4  0x00007f0236f07982 in crt_hdlr_iv_sync (rpc_req=0x7efcd88e5048) at src/cart/crt_iv.c:1816\n",
            "\n",
            "1816 D_ASSERT(!(sync_type->ivs_flags &\n",
            "\n",
            "(gdb) p *sync_type\n",
            "\n",
            "$1 = \\{ivs_mode = (CRT_IV_SYNC_EAGER | CRT_IV_SYNC_LAZY | unknown: 2994804284), ivs_event = (CRT_IV_SYNC_EVENT_UPDATE | unknown: 32760), ivs_flags = 2994804287}\n",
            "\n",
            " \n",
            "\n",
            "the sync_type's value looks unreasonable, probably memory corruption happened before the assertion.\n",
            "\n",
            " , Similarity: 0.1646\n",
            "Summary & Description: need define dreallocarray \n",
            " D_ALLOC_ARRAY is less error prone that using D_ALLOC to allocate an array.  One can make simple mistakes such as\n",
            "\n",
            "D_ALLOC(ptr_to_type, sizeof(ptr_to_type) * num);\n",
            "\n",
            "where the size is taken on the pointer rather than the type.\n",
            "\n",
            "D_REALLOC_ARRAY is needed for similar reasons, Similarity: 0.1206\n",
            "Summary & Description: protocol querying returning unknown versions \n",
            " The protocol query code is returning incorrect versions in some instances, if I query for versions 1,2,3 of a protocol but only 4 is regsitered on the server side I'd expect the code to return -DER_UNREG or similar, however it returns 3.\n",
            "\n",
            "In addition, I think there are two minor errors in this code, there's an off-by-one error when logging what versions are supported, and if I query for a negative value of a protocol then it logs that versions 0-0 are supported, which makes me think it's reading from wrong location somewhere., Similarity: 0.1968\n",
            "Summary & Description: add support serialization complex arrays new macro \n",
            " For complex types of arrays the new macro should be improved., Similarity: 0.1373\n",
            "Summary & Description: unable register protocol zero version \n",
            " Unable to register protocol if you specify version of protocol is not zero.\n",
            ", Similarity: 0.1864\n",
            "Summary & Description: usrincludex8664linuxgnubitsstdio2h6410 error builtinsnprintfchk specified bound 68 exceeds size 64 destination werrorstringopoverflow \n",
            " Trying to build IOF on Ubuntu 18 the following error is hit in building CaRT:\n",
            "\n",
            "{noformat}\n",
            "[Build on Ubuntu 18.04] In file included from /usr/include/stdio.h:862:0,\n",
            "[Build on Ubuntu 18.04]                  from src/include/gurt/common.h:58,\n",
            "[Build on Ubuntu 18.04]                  from src/cart/crt_internal.h:48,\n",
            "[Build on Ubuntu 18.04]                  from src/cart/crt_pmix.c:43:\n",
            "[Build on Ubuntu 18.04] In function 'snprintf',\n",
            "[Build on Ubuntu 18.04]     inlined from 'crt_pmix_uri_lookup' at src/cart/crt_pmix.c:501:2:\n",
            "[Build on Ubuntu 18.04] /usr/include/x86_64-linux-gnu/bits/stdio2.h:64:10: error: '__builtin___snprintf_chk': specified bound 68 exceeds the size 64 of the destination [-Werror=stringop-overflow=]\n",
            "[Build on Ubuntu 18.04]    return __builtin___snprintf_chk (__s, __n, __USE_FORTIFY_LEVEL - 1,\n",
            "[Build on Ubuntu 18.04]           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "[Build on Ubuntu 18.04]         __bos (__s), __fmt, __va_arg_pack ());\n",
            "[Build on Ubuntu 18.04]         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "[Build on Ubuntu 18.04] cc1: all warnings being treated as errors\n",
            "[Build on Ubuntu 18.04] scons: *** [build/Linux/src/cart/crt_pmix.os] Error 1\n",
            "{noformat} , Similarity: 0.4077\n",
            "Summary & Description: daosserver segfault latest cart \n",
            " I updated cart hash in DAOS to:\n",
            "\n",
            "e75750b8eabaf57732cfff56679835ebcda93972\n",
            "\n",
            "rebuilt ofi, mercury, cart\n",
            "\n",
            "launched daos_server:\n",
            "\n",
            "orterun -x DD_STDERR=ERR --mca mtl ^psm2,ofi --enable-recovery -np 1 --hostfile ~/srv_hosts --report-uri ~/uri.txt daos_server -c 1\n",
            "\n",
            "launched daos_test:\n",
            "\n",
            "orterun -np 1 -x DD_STDERR=ERR --mca mtl ^psm2,ofi --hostfile ~/cli_hosts --map-by node --ompi-server [file:~/uri.txt|file:///~/uri.txt] daos_test\n",
            "\n",
            " or just dmg pool create:\n",
            "\n",
            "orterun -np 1 --mca mtl ^psm2,ofi --ompi-server file:~/uri.txt dmg create --size=1GB\n",
            "\n",
            "server segfaults with this trace:\n",
            "\n",
            "[https://github.intel.com/gist/anonymous/61c70f585bcc83fb8a2e494e3f16f3d8]\n",
            "\n",
            " \n",
            "\n",
            "Env:\n",
            "\n",
            "export OFI_INTERFACE=ib0\n",
            "\n",
            "export CRT_PHY_ADDR_STR=\"ofi+sockets\", Similarity: 0.2561\n",
            "Summary & Description: lm resample rpc sent \n",
            " Whilst testing a recent mercury update I've hit a race condition in IOF failover testing.\n",
            "\n",
            "Essentially, a client is communicating with a server, and the server is killed.  My IOF RPC fails, so a resample RPC is sent to the PSR which also fails.  A resample RPC is then sent to a secondary PSR which races with the eviction on the server.  If this RPC succeeds then no further resample rpcs are sent, and the client blocks forever.\n",
            "\n",
            " \n",
            "\n",
            "Here's a section of log message, which simply repeats every timeout interval:\n",
            "\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] LM DBUG src/cart/crt_group.h:483 crt_grp_priv_decref() service group (IONSS), refcount decreased to 3.\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] RPC DBUG src/cart/crt_context.c:734 crt_req_timeout_hdlr(0x7fdf000008e0) decref to 1.\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] RPC DBUG src/cart/crt_context.c:795 crt_context_timeout_check(0x7fdf000008e0) decref to 0.\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] HG DBUG src/cart/crt_hg.c:266 crt_hg_pool_put() hg_pool 0x55eca419e858, add, chp_num 14.\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] HG DBUG src/cart/crt_hg.c:1129 crt_hg_req_destroy(0x7fdf000008e0) hg_hdl 0x55eca42121e0 put to pool.\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] HG DBUG src/cart/crt_hg.c:1148 crt_hg_req_destroy(0x7fdf000008e0) destroying\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] RPC DBUG src/cart/crt_rpc.c:222 crt_rpc_priv_free() free 'rpc_priv' at 0x7fdf000008e0.\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] HG DBUG src/cart/crt_hg.c:1169 crt_hg_req_send_cb(0x7fdefc01f340) entered\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] HG DBUG src/cart/crt_hg.c:1234 crt_hg_req_send_cb(0x7fdefc01f340) Invoking RPC callback (rank 2 tag 0) rc: 0.\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] LM DBUG src/cart/crt_lm.c:734 lm_sample_rpc_cb() group name: IONSS, local version: 0, remote version 0.\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] LM DBUG src/cart/crt_lm.c:736 lm_sample_rpc_cb() Local version up to date.\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] LM DBUG src/cart/crt_group.h:483 crt_grp_priv_decref() service group (IONSS), refcount decreased to 2.\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] RPC DBUG src/cart/crt_rpc.c:1357 timeout_bp_node_exit(0x7fdefc01f340) exiting the timeout binheap.\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] RPC DBUG src/cart/crt_context.c:603 crt_req_timeout_untrack(0x7fdefc01f340) decref to 2.\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] RPC DBUG src/cart/crt_context.c:954 crt_context_req_untrack(0x7fdefc01f340) decref to 1.\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] HG DBUG src/cart/crt_hg.c:1244 crt_hg_req_send_cb(0x7fdefc01f340) decref to 0.\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] HG DBUG src/cart/crt_hg.c:266 crt_hg_pool_put() hg_pool 0x55eca419e858, add, chp_num 15.\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] HG DBUG src/cart/crt_hg.c:1129 crt_hg_req_destroy(0x7fdefc01f340) hg_hdl 0x55eca42126d0 put to pool.\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] HG DBUG src/cart/crt_hg.c:1148 crt_hg_req_destroy(0x7fdefc01f340) destroying\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] RPC DBUG src/cart/crt_rpc.c:218 crt_rpc_priv_free() free 'rpc_priv->crp_tgt_uri' at 0x7fdefc01f700.\n",
            "11/12-15:15:00.48 debian-gnu-linux-vm CaRT[26398] RPC DBUG src/cart/crt_rpc.c:222 crt_rpc_priv_free() free 'rpc_priv' at 0x7fdefc01f340., Similarity: 0.2034\n",
            "Summary & Description: use swim cart \n",
            " Start using SWIM in CaRT for ranks failure detection.\n",
            ", Similarity: 0.1704\n",
            "Summary & Description: crtprotoregister checking input values \n",
            " Whilst writing some test code I discovered that crt_proto register does not check some values:\n",
            "\n",
            "cpf_count should not be 0\n",
            "\n",
            "cpf_base should not be 0\n",
            "\n",
            "cpf_prf should not be NULL.\n",
            "\n",
            "If any of the above are true then crt_proto_register() should return an error., Similarity: 0.1640\n",
            "Summary & Description: ofi v162 release missing upstream patch liwei \n",
            " an upstream patch from liwei was merged to OFI on 2018-08-09, commit hash 568b5884de6299c33f678137a2b061bec98d7c15\n",
            "\n",
            "however the latest OFI release v1.6.2 doesn't have that upstream patch.\n",
            "\n",
            "The OFI commit in current cart master branch (hash: 8c33f9d63d536cc3781017dd25b7bb480ac96cb5) contains the upstream patch., Similarity: 0.3623\n",
            "Summary & Description: automatically generate doxygen patch \n",
            " Doxygen documentation needs to be generated on jenkins on each patch to verify we don't break documentation, Similarity: 0.3406\n",
            "Summary & Description: req send incorrect target \n",
            " In daos testing I observed that for some cases the request possibly will be sent to incorrect target, in case of each rank creates multiple contexts and each with different uri address.\n",
            "\n",
            "initial analysis:\n",
            "\n",
            "For example a server with two ranks (A/B), each with two contexts(0/1), and set CRT_CTX_SHARE_ADDR as 0, so contexts A0, A1, B0, B1 all with different uri address.\n",
            "\n",
            "Now A0 want to send RPC to B1, by the crt_req_uri_lookup()’s handling, it will get back B0’s uri address rather than B1, this means that the req will send to incorrect target.\n",
            "\n",
            "It matches with what I observed in DAOS testing.\n",
            "\n",
            " \n",
            "\n",
            " , Similarity: 0.0756\n",
            "Summary & Description: enable secondary groups nopmix \n",
            " Alex had a chat with liwei, and there is 1 task of high priority dealing with resizable groups.\n",
            "\n",
            "We have this new mode of 'no_pmix'. currently secondary groups are not supported at all in this mode. We need to enable the ability to create secondary groups (along with all requires secondary->primary conversions internally) for no-pmix case with the old behavior, instead of no secondary groups at all., Similarity: 0.1851\n",
            "Summary & Description: crtlminit silently fails \n",
            " The function crt_lm_init() can fail in a number of ways, however does not propagate failure up the stack at all., Similarity: 0.1400\n",
            "Summary & Description: see assertion failure cart pool connect changed error \n",
            " See DAOS-1582, Similarity: 0.2389\n",
            "Summary & Description: need documentation run cart tests \n",
            " Questions about how to run cart tests keep coming up, need documentation on how to run and customize tests., Similarity: 0.2496\n",
            "Summary & Description: option daosserver require argument \n",
            " daos_io_server -a/path/\n",
            "\n",
            "writes a file to path to be able to connect to the server using singleton mode.\n",
            "\n",
            "daos_server -a/path/ does not work because go library requires a space between -a  and path.\n",
            "\n",
            "making the argument required is logical since cart by default writes to /tmp, and allows putting a space between -a and /path/, Similarity: 0.4126\n",
            "Summary & Description: incorrect locking crtexectimeoutcb \n",
            " in crt_context.c there are at least two d_list_for_each()... loops which hold a lock for the loop, but drop it for the body of the code block, before requiring it to complete the loop., Similarity: 0.1026\n",
            "Summary & Description: simplify cmf definitions \n",
            " simplify cart CMF definitions according to Jeff's comment on a previous patch:\n",
            "\n",
            " \n",
            "\n",
            "https://review.hpdd.intel.com/#/c/33184/14/src/include/cart/types.h@317, Similarity: 0.3028\n",
            "Summary & Description: cart build failure fedora \n",
            " A test build on CaRT on fedora is failing with this warning:\n",
            "\n",
            "{code}\n",
            "07:03:38 src/cart/crt_pmix.c:184:2: error: 'strncpy' output may be truncated copying 255 bytes from a string of length 255 [-Werror=stringop-truncation]\n",
            "07:03:38   strncpy(proc.nspace, myproc->nspace, PMIX_MAX_NSLEN);\n",
            "07:03:38   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "07:03:39 cc1: all warnings being treated as errors\n",
            "{code}\n",
            "\n",
            "Full log at:\n",
            "http://jem-jenkins.amr.corp.intel.com/job/cart-cart_devel/arch=x86_64,distro=fedora/648/console, Similarity: 0.2470\n",
            "Summary & Description: integrate swim cart \n",
            " It was decision to start integration of SWIM API into the CaRT. Under this ticket we will track the process of this integration., Similarity: 0.3262\n",
            "Summary & Description: fi add ability set attribute enable disable fi remote node \n",
            " We need to have ability to set fi attribute as well as enable/disable fi on the remote node via for example cart_ctl tool., Similarity: 0.3249\n",
            "Summary & Description: fi improve granularity probability \n",
            " DAOS team requested to have better granularity when selecting probability - instead of being 1% step, they would like to have 2 numbers  X out of Y, letting them specify much smaller steps., Similarity: 0.1169\n",
            "Summary & Description: wrong type struct crtarray \n",
            " The *ca_count* member is defined as *size_t*.\n",
            "{code:java}\n",
            "struct crt_array {\n",
            "\tsize_t\t\t ca_count;\n",
            "\tvoid\t\t*ca_arrays;\n",
            "};\n",
            "{code}\n",
            "\n",
            "But inside marshaling function its used as *uint64_t*.\n",
            "{code}\n",
            "hg_ret = hg_proc_hg_uint64_t(proc, &array->ca_count);\n",
            "{code}\n",
            "\n",
            "So, there is assumption that *size_t* has the same size as *uint64_t*. To avoid an issue on machines where this is not true we should change definition to \"*uint64_t ca_count;*\".\n",
            ", Similarity: 0.1105\n",
            "Summary & Description: pmix occasionally fails cart tests \n",
            " We ocassionally observe following errors from various cart tests; mostly when running under valgrind:\n",
            "*11:47:17* [36f113d8222b:01989] PMIX ERROR: NOT-FOUND in file ptl_tcp.c at line 685*11:47:17* test_corpc_version: src/test/test_corpc_version.c:617: test_init: Assertion `rc == 0' failed., Similarity: 0.2465\n",
            "Summary & Description: uri tracking changes \n",
            " Currently each local context stores node-related information as part of the crt_lookup_item structure. This structure contains fields of:\n",
            "\n",
            "316 /* connected HG addr */\n",
            "317 hg_addr_t li_tag_addr[CRT_SRV_CONTEXT_NUM];\n",
            "318 crt_phy_addr_t li_uri[CRT_SRV_CONTEXT_NUM];\n",
            "\n",
            "where li_tag_dddr is the per-tag uri-string address of the remote node.\n",
            "\n",
            "and li_tag_addr is an hg_addr_t structure returned from mercury, which (this needs to be verified) for some providers is formed by combination of local and remote tag + address.\n",
            "\n",
            " \n",
            "\n",
            "While li_tag_addr will need to be per-local-and-remote context, the li_uri is only identifying remote targets and does not need to be stored per-local tag/context.\n",
            "\n",
            "As such this optimization is to change how/where li_uri is stored. Instead of storing it per local context, it is better to store all remote uris in a single table that would be identified as (remote_rank, remote_tag) -> (remote_uri)\n",
            "\n",
            " \n",
            "\n",
            "crt_lookup_item would then be modified to simply point to that global table entry instead of storing it locally., Similarity: 0.1950\n",
            "Summary & Description: srccartcrtrpcc1408 crtreqabort req rpcpriv 0xf832ea0 opc 0xff000014 aborted need abort \n",
            " I'm seeing the following error spewing into the logs in one of my test cases, it seems to be stuck in a loop logging 100s of MB of the exact same error:\n",
            "\n",
            "src/cart/crt_rpc.c:1408 crt_req_abort() req (rpc_priv 0xf832ea0, opc: 0xff000014) aborted, need not abort again.\n",
            "\n",
            "The reproducer is [https://review.hpdd.intel.com/#/c/33172/] and the log file in question is cnss.log from here [https://build.hpdd.intel.com/job/iof-vg_review_child/2350/arch=x86_64,distro=el7/artifact/artifacts/iof/TESTING/testLogs/testRun/iof_test_local/loop0/iof_test_local_1/Testlocal/failover_readdir/]\n",
            "\n",
            "My change is to add a second thread calling crt_progress() to IOF, and this is in a failover test, it looks like the loop at L377 of crt_context.c is probably corrupted which would make sense for a change adding a second thread.  The test appears to work natively, but fails under valgrind but this could be a timing issue.\n",
            "\n",
            " \n",
            "\n",
            "Marking a Major as adding a second thread is my route out of the inval deadlock I'm seeing which is something I'm blocked on., Similarity: 0.1686\n",
            "Summary & Description: segv fault injection code \n",
            " I'm seeing an immediate segv in the fault injection code when I try and use it.  The cause appears to be if a fault value is defined in the code, however isn't in the yml file.\n",
            "\n",
            " \n",
            "\n",
            "==5208== Invalid read of size 4\n",
            "==5208== at 0x4E424D0: pthread_spin_lock (in /usr/lib64/libpthread-2.17.so)\n",
            "==5208== by 0x5304399: d_should_fail (fault_inject.c:546)\n",
            "==5208== by 0x5094CEC: crt_na_ofi_config_init (crt_init.c:616)\n",
            "==5208== by 0x5093A6F: crt_init_opt (crt_init.c:301)\n",
            "==5208== by 0x4129C4: crt_init (api.h:111)\n",
            "==5208== by 0x40FEFB: main (cnss.c:845)\n",
            "==5208== Address 0x20 is not stack'd, malloc'd or (recently) free'd\n",
            "==5208==\n",
            "==5208==\n",
            "==5208== Process terminating with default action of signal 11 (SIGSEGV)\n",
            "==5208== Access not within mapped region at address 0x20\n",
            "==5208== at 0x4E424D0: pthread_spin_lock (in /usr/lib64/libpthread-2.17.so)\n",
            "==5208== by 0x5304399: d_should_fail (fault_inject.c:546)\n",
            "==5208== by 0x5094CEC: crt_na_ofi_config_init (crt_init.c:616)\n",
            "==5208== by 0x5093A6F: crt_init_opt (crt_init.c:301)\n",
            "==5208== by 0x4129C4: crt_init (api.h:111)\n",
            "==5208== by 0x40FEFB: main (cnss.c:845)\n",
            "\n",
            " , Similarity: 0.2229\n",
            "Summary & Description: marshaling function crtprocbool encoding \n",
            " The function crt_proc_bool() use local variable to pass the value into/from Mercury. But in case of decode incoming packets the value will not be propagated into source structure.\n",
            ", Similarity: 0.2018\n",
            "Summary & Description: restore use ofiport \n",
            " From: \"Li, Wei G\" <wei.g.li@intel.com>\n",
            "To: \"Jia, Yulu\" <yulu.jia@intel.com>\n",
            "CC: \"Oganezov, Alexander A\" <alexander.a.oganezov@intel.com>, \"Liu, Xuezhao\" <xuezhao.liu@intel.com>\n",
            "Date: Thu, 30 Aug 2018 18:06:52 -0700\n",
            "Subject: RE: OFI_PORT\n",
            "\n",
            "Yes, please.\n",
            "\n",
            "We'd like a way to specify the URIs before starting DAOS servers. When the servers start, the actual URIs it listens on shall be based deterministically on what we specified. If any of the URI is unavailable, we expect CaRT to give up creating that context. (If no URI is specified, we expect CaRT to select available ones dynamically.)\n",
            "\n",
            "OFI_PORT seems to satisfy this requirement for sockets, according to cart/README.env. For some other providers, we heard from the OFI team that there will be ways to specify addresses as well, though supporting them in CaRT is not urgent.\n",
            "\n",
            "Thanks,\n",
            "liwei\n",
            "\n",
            "> -----Original Message-----\n",
            "> From: Jia, Yulu\n",
            "> Sent: Friday, August 31, 2018 1:29 AM\n",
            "> To: Li, Wei G <wei.g.li@intel.com>\n",
            "> Cc: Oganezov, Alexander A <alexander.a.oganezov@intel.com>; Liu, Xuezhao\n",
            "> <xuezhao.liu@intel.com>\n",
            "> Subject: Re: OFI_PORT\n",
            ">\n",
            "> Hi Liwei,\n",
            ">\n",
            "> Right, OFI_PORT is no longer used, port numbers are dynamically selected by\n",
            "> libfabric to avoid sporadic failures in CI.\n",
            ">\n",
            "> We can fix this. Do you want port numbers to act the old way? i.e.\n",
            "> specify a base port using OFI_PORT, then port numbers of subsequent cart\n",
            "> contexts grow conginously?\n",
            ">\n",
            "> Thanks,\n",
            "> Yulu\n",
            ">> On 08-30-18 02:07, Li, Wei G wrote:\n",
            "> >Hi Yulu,\n",
            "> >\n",
            "> >It appears OFI_PORT is no longer working (for the sockets provider):\n",
            "> >\n",
            "> > DBUG src/cart/crt_init.c:567 crt_get_port() get a port: 59265.\n",
            "> > DBUG src/cart/crt_init.c:658 crt_na_ofi_config_init() OFI_PORT 27148, use\n",
            "> it as service port.\n",
            "> > DBUG src/cart/crt_hg.c:524 crt_get_info_string() alloc(asprintf) '*string':\n",
            "> 27 at 0x1f67490.\n",
            "> > DBUG src/cart/crt_hg.c:586 crt_hg_init() info_string:\n",
            "> > ofi+sockets://192.168.1.70 DBUG src/cart/crt_hg.c:603 crt_hg_init()\n",
            "> alloc(calloc) 'hg_gdata': 16 at 0x1f52c00.\n",
            "> > DBUG src/cart/crt_hg.c:636 crt_hg_init() alloc(strndup) '*addr': 33 at\n",
            "> 0x1f67df0.\n",
            "> > DBUG src/cart/crt_hg.c:644 crt_hg_init() in crt_hg_init, listen address:\n",
            "> ofi+sockets://192.168.1.70:43586.\n",
            "> >\n",
            "> >Looking into the latest CaRT, noc_port is initialized properly, but\n",
            "> >unused otherwise. (Also, crt_get_port looks a bit weird, as it seems\n",
            "> >na_ofi is already able to get dynamic ports.)\n",
            "> >\n",
            "> >Although we're trying to design DAOS to work with dynamically assigned URIs,\n",
            "> \"specifying fixed URIs\" is still good to have. E.g., we're hoping to use\n",
            "> OFI_PORT to help development before DAOS gains the full ability to allocate\n",
            "> ranks without PMIx. Do you think at least this OFI_PORT problem can be fixed?\n",
            "> >\n",
            "> >Thanks,\n",
            "> >liwei\n",
            "\n",
            " , Similarity: 0.2311\n",
            "Summary & Description: l10 assembly intel 960507 \n",
            " Hello Support,\n",
            "\n",
            "Please help us finding the DIMM part on Intel L10 machine (960507).\n",
            "\n",
            "Regards,\n",
            "Bikram\n",
            "Penguin Computoing, Similarity: 0.1225\n",
            "Summary & Description: assert crprefcount enabling two threads progress context \n",
            " 00:16:48.380 08/23-12:58:23.33 9030637ab7a8 CaRT[977] RPC EMRG src/cart/crt_context.c:680 crt_req_timeout_hdlr() 0x86b540 decref from zero00:16:48.380 cnss: src/cart/crt_context.c:680: crt_req_timeout_hdlr: Assertion `(rpc_priv)->crp_refcount != 0' failed.Sent on:ThuFrom:Ashley Pittmanand 00:16:48.382 [9030637ab7a8:01175] PMIX ERROR: PMIX TEMPORARILY UNAVAILABLE in file ptl_tcp.c at line 685\n",
            "\n",
            " \n",
            "\n",
            "From ashley: \"this is when I enable two threads calling crt_progress() on the same context.\"\n",
            "\n",
            " \n",
            "\n",
            " , Similarity: 0.2246\n",
            "Summary & Description: update ofi \n",
            " update ofi so that we have:\n",
            "\n",
            "a3f616ee3de393e412b80dda7dc6c0793f66e188\n",
            "\n",
            "Make the 15s connection timeout configurable via environment\n",
            "variable FI_SOCKETS_CONN_TIMEOUT. Also, remove the sleep(10) in\n",
            "sock_ep_get_conn(). For example,\n",
            "\n",
            "export FI_SOCKETS_MAX_CONN_RETRY=1 # try only once\n",
            "export FI_SOCKETS_CONN_TIMEOUT=2000 # time out after 2s\n",
            "\n",
            "Signed-off-by: Wei Li [liw2@boro-70.boro.hpdd.intel.com|mailto:liw2@boro-70.boro.hpdd.intel.com]\n",
            "Signed-off-by: Jianxin Xiong [jianxin.xiong@intel.com|mailto:jianxin.xiong@intel.com], Similarity: 0.3082\n",
            "Summary & Description: add rpc completion codes ccirc cart logging \n",
            " It would be very useful for analysing test coverage to be able to know what return codes we're seeing for RPCs (and general debugging in general).  There isn't currently a log message when the callback is invoked, and the cci_rc value is not logged at all in many cases., Similarity: 0.1985\n",
            "Summary & Description: cart echo test segfaults wrong ofi interface specified \n",
            " Customer reported minor issue with cart echo tests, where it segfaults if wrong interface is specified, Similarity: 0.2157\n",
            "Summary & Description: segfault psm2 running daosperf \n",
            " Hitting segfault in psm2 while running daos_perf:\n",
            "{code:java}\n",
            "[sdwillso@boro-13 ~]$ orterun -quiet --hostfile ~/scripts/host.cli.1 --ompi-server file:~/scripts/uri.txt -x DD_SUBSYS= -x DD_MASK= -x D_LOG_FILE=/tmp/daos_perf.log daos_perf -T daos -P 2G -d 1 -a 200 -r 1000 -s 1K -C 8 -t -z\n",
            "Test :\n",
            "\tDAOS (full stack)\n",
            "Parameters :\n",
            "\tpool size     : 2048 MB\n",
            "\tcredits       : 8 (sync I/O for -ve)\n",
            "\tobj_per_cont  : 1 x 36 (procs)\n",
            "\tdkey_per_obj  : 1\n",
            "\takey_per_dkey : 200\n",
            "\trecx_per_akey : 1000\n",
            "\tvalue type    : single\n",
            "\tvalue size    : 1024\n",
            "\tzero copy     : yes\n",
            "\toverwrite     : yes\n",
            "\tverify fetch  : no\n",
            "\tVOS file      : <NULL>\n",
            "boro-13.boro.hpdd.intel.com.26609Error opening remote shared memory object in shm_open: No such file or directory (err=9)\n",
            "boro-13.boro.hpdd.intel.com.26609PSM could not set up shared memory segment (err=9)\n",
            "Failed to initialize step=2, rc=-1020\n",
            "[boro-13:26609] *** Process received signal ***\n",
            "[boro-13:26609] Signal: Segmentation fault (11)\n",
            "[boro-13:26609] Signal code: Address not mapped (1)\n",
            "[boro-13:26609] Failing at address: 0x5e00\n",
            "[boro-13:26609] [ 0] /usr/lib64/libpthread.so.0(+0xf5e0)[0x7f490c5825e0]\n",
            "[boro-13:26609] [ 1] /usr/lib64/libpsm2.so.2(+0x1ee30)[0x7f490778ee30]\n",
            "[boro-13:26609] [ 2] /usr/lib64/libpsm2.so.2(psm2_ep_close+0x146)[0x7f4907780976]\n",
            "[boro-13:26609] [ 3] /home/sdwillso/daos_m/opt/ofi/lib/libfabric.so.1(+0x88c0f)[0x7f49086fbc0f]\n",
            "[boro-13:26609] [ 4] /home/sdwillso/daos_m/opt/ofi/lib/libfabric.so.1(+0x9111c)[0x7f490870411c]\n",
            "[boro-13:26609] [ 5] /home/sdwillso/daos_m/opt/mercury/lib/libna.so.0.9.1(+0xb4be)[0x7f490ac4c4be]\n",
            "[boro-13:26609] [ 6] /home/sdwillso/daos_m/opt/mercury/lib/libna.so.0.9.1(+0xb8a9)[0x7f490ac4c8a9]\n",
            "[boro-13:26609] [ 7] /home/sdwillso/daos_m/opt/mercury/lib/libna.so.0.9.1(NA_Finalize+0x19)[0x7f490ac44fb9]\n",
            "[boro-13:26609] [ 8] /home/sdwillso/daos_m/opt/cart/lib/libcart.so(crt_hg_fini+0x4d)[0x7f490d2f41fd]\n",
            "[boro-13:26609] [ 9] /home/sdwillso/daos_m/opt/cart/lib/libcart.so(crt_finalize+0x2d2)[0x7f490d2fc9c2]\n",
            "[boro-13:26609] [10] /home/sdwillso/daos_m/install/lib/libdaos.so.0(daos_eq_lib_fini+0x167)[0x7f490d9906a7]\n",
            "[boro-13:26609] [11] /home/sdwillso/daos_m/install/lib/libdaos.so.0(daos_fini+0x34)[0x7f490d9925f4]\n",
            "[boro-13:26609] [12] daos_perf[0x404a85]\n",
            "[boro-13:26609] [13] daos_perf[0x404ce0]\n",
            "[boro-13:26609] [14] daos_perf[0x402b31]\n",
            "[boro-13:26609] [15] /usr/lib64/libc.so.6(__libc_start_main+0xf5)[0x7f490bdadc05]\n",
            "[boro-13:26609] [16] daos_perf[0x402f42]\n",
            "[boro-13:26609] *** End of error message ***\n",
            "-------------------------------------------------------\n",
            "Primary job  terminated normally, but 1 process returned\n",
            "a non-zero exit code. Per user-direction, the job has been aborted.\n",
            "-------------------------------------------------------\n",
            "{code}\n",
            " \n",
            "\n",
            "daos_perf.log:\n",
            "{code:java}\n",
            "[sdwillso@boro-13 ~]$ cat /tmp/daos_perf.log \n",
            "08/13-23:11:08.82 boro-13 DAOS[26609] HG   ERR  # NA -- Error -- /home/sdwillso/daos_m/_build.external/mercury/src/na/na_ofi.c:476\n",
            " # na_ofi_av_insert(): fi_av_insert/svc failed(node fi_addr_psmx2://40302:101, service (null)), rc: 0.\n",
            "08/13-23:11:08.82 boro-13 DAOS[26609] HG   ERR  # NA -- Error -- /home/sdwillso/daos_m/_build.external/mercury/src/na/na_ofi.c:565\n",
            " # na_ofi_addr_ht_lookup(): na_ofi_av_insert(fi_addr_psmx2://40302:101:(null)) failed, ret: 7.\n",
            "08/13-23:11:08.82 boro-13 DAOS[26609] HG   ERR  # NA -- Error -- /home/sdwillso/daos_m/_build.external/mercury/src/na/na_ofi.c:617\n",
            " # na_ofi_addr_ht_lookup_psm2(): na_ofi_addr_ht_lookup_reqhdr failed, ret: 7.\n",
            "08/13-23:11:08.82 boro-13 DAOS[26609] HG   ERR  # NA -- Error -- /home/sdwillso/daos_m/_build.external/mercury/src/na/na_ofi.c:2904\n",
            " # na_ofi_addr_lookup(): na_ofi_addr_ht_lookup(psm2://fi_addr_psmx2://40302:101) failed, ret: 7.\n",
            "08/13-23:11:08.82 boro-13 DAOS[26609] HG   ERR  # HG -- Error -- /home/sdwillso/daos_m/_build.external/mercury/src/mercury_core.c:1401\n",
            " # hg_core_addr_lookup(): Could not start lookup for address ofi+psm2://fi_addr_psmx2://40302:101\n",
            "08/13-23:11:08.82 boro-13 DAOS[26609] HG   ERR  # HG -- Error -- /home/sdwillso/daos_m/_build.external/mercury/src/mercury_core.c:4257\n",
            " # HG_Core_addr_lookup(): Could not lookup address\n",
            "08/13-23:11:08.82 boro-13 DAOS[26609] HG   ERR  src/cart/crt_hg.c:306 crt_hg_addr_lookup() HG_Addr_lookup() failed.\n",
            "08/13-23:11:08.82 boro-13 DAOS[26609] RPC  ERR  src/cart/crt_rpc.c:1146 crt_req_hg_addr_lookup() crt_addr_lookup() failed, rc -1020, opc: 0x1010001..\n",
            "08/13-23:11:08.82 boro-13 DAOS[26609] RPC  ERR  src/cart/crt_rpc.c:1216 crt_req_send_internal() crt_req_hg_addr_lookup() failed, rc -1020, opc: 0x1010001.\n",
            "08/13-23:11:08.82 boro-13 DAOS[26609] RPC  ERR  src/cart/crt_rpc.c:1319 crt_req_send() crt_req_send_internal() failed, rc -1020, opc: 0x1010001\n",
            "08/13-23:11:08.82 boro-13 DAOS[26609] RPC  ERR  src/cart/crt_context.c:304 crt_rpc_complete() rpc_priv 0x292a300 (opc: 0x1010001, to rank 0 tag 0) failed, rc: -1020.\n",
            "08/13-23:11:08.82 boro-13 DAOS[26609] mgmt ERR  src/mgmt/cli_pool.c:46 pool_create_cp() RPC error while creating pool: -1020\n",
            "{code}, Similarity: 0.3061\n",
            "Summary & Description: initial fault injection imeplementation \n",
            " Initial code for the fault injection frame work. It has the fundamental features. Users can inject faults after this patch is landed. Additional features may be added based on feedback. \n",
            " * parse yaml file to obtain configuration\n",
            " * D_SHOULD_FAIL() macro to decide if fault should be injected\n",
            " * global switch to turn on/off fault injection\n",
            " * time overhead is one if test per injection site\n",
            " * fault injection logic can be compiled out. No overhead at all in this case., Similarity: 0.3155\n",
            "Summary & Description: get segfault cart run daostest \n",
            " CART level err handling seems with problem, got a segfault in such test:\n",
            "\n",
            "run 8 daos_servers (each with 8 threads), and run \"daos_test -OR\" testing.\n",
            "\n",
            " \n",
            "\n",
            "The backtrace of the segfault is:\n",
            "\n",
            "Core was generated by `daos_io_server -c 8'.\n",
            "\n",
            "Program terminated with signal 6, Aborted.\n",
            "\n",
            "#0  0x00007f53fe8671f7 in raise () from /lib64/libc.so.6\n",
            "\n",
            "Missing separate debuginfos, use: debuginfo-install glibc-2.17-196.el7.x86_64 libaio-0.3.109-13.el7.x86_64 libevent-2.0.21-4.el7.x86_64 libgcc-4.8.5-16.el7.x86_64 libibverbs-13-7.el7.x86_64 libnl3-3.2.28-4.el7.x86_64 librdmacm-13-7.el7.x86_64 libuuid-2.23.2-43.el7.x86_64 ncurses-libs-5.9-14.20130511.el7_4.x86_64 numactl-libs-2.0.9-6.el7_2.x86_64 openssl-libs-1.0.2k-8.el7.x86_64 readline-6.2-10.el7.x86_64 zlib-1.2.7-17.el7.x86_64\n",
            "\n",
            "(gdb) bt\n",
            "\n",
            "#0  0x00007f53fe8671f7 in raise () from /lib64/libc.so.6\n",
            "\n",
            "#1  0x00007f53fe8688e8 in abort () from /lib64/libc.so.6\n",
            "\n",
            "#2  0x00007f53fe8a6f47 in __libc_message () from /lib64/libc.so.6\n",
            "\n",
            "#3  0x00007f53fe8ae619 in _int_free () from /lib64/libc.so.6\n",
            "\n",
            "#4  0x00007f53fff7d9e1 in d_rank_list_free (rank_list=0x7f53e9248cc0) at src/gurt/misc.c:235\n",
            "\n",
            "#5  0x00007f53ffd1603e in crt_grp_priv_destroy (grp_priv=0x7f53e924f040) at src/cart/crt_group.c:860\n",
            "\n",
            "#6  0x00007f53ffd0ffd0 in crt_grp_priv_decref (grp_priv=0x7f53e924f040) at src/cart/crt_group.h:343\n",
            "\n",
            "#7  crt_corpc_info_fini (rpc_priv=rpc_priv@entry=0x7f53e91e5d10) at src/cart/crt_corpc.c:117\n",
            "\n",
            "#8  0x00007f53ffd48c57 in crt_rpc_priv_free (rpc_priv=0x7f53e91e5d10) at src/cart/crt_rpc.c:459\n",
            "\n",
            "#9  0x00007f53ffd26740 in crt_hg_req_destroy (rpc_priv=rpc_priv@entry=0x7f53e91e5d10) at src/cart/crt_hg.c:1139\n",
            "\n",
            "#10 0x00007f53ffd48f09 in crt_req_destroy (rpc_priv=rpc_priv@entry=0x7f53e91e5d10) at src/cart/crt_rpc.c:642\n",
            "\n",
            "#11 0x00007f53ffd0da30 in crt_corpc_complete (rpc_priv=0x7f53e91e5d10) at src/cart/crt_corpc.c:584\n",
            "\n",
            "#12 0x00007f53ffd0e4cf in crt_corpc_reply_hdlr (cb_info=<optimized out>) at src/cart/crt_corpc.c:761\n",
            "\n",
            "#13 0x00007f53ffd23f21 in crt_hg_req_send_cb (hg_cbinfo=<optimized out>) at src/cart/crt_hg.c:1222\n",
            "\n",
            "#14 0x00007f53fdb4461c in hg_core_forward_cb (callback_info=0x7f53f5436d20) at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury.c:965\n",
            "\n",
            "#15 0x00007f53fdb43038 in hg_core_trigger_entry (hg_core_handle=0x7f53e80d0a40) at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury_core.c:3268\n",
            "\n",
            "#16 hg_core_trigger (context=0x7f53e802b320, timeout=<optimized out>, timeout@entry=0, max_count=max_count@entry=4294967295, actual_count=actual_count@entry=0x7f53f5436d9c)\n",
            "\n",
            "    at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury_core.c:3143\n",
            "\n",
            "#17 0x00007f53fdb43d7b in HG_Core_trigger (context=<optimized out>, timeout=timeout@entry=0, max_count=max_count@entry=4294967295, actual_count=actual_count@entry=0x7f53f5436d9c)\n",
            "\n",
            "    at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury_core.c:4902\n",
            "\n",
            "#18 0x00007f53fdb47cbd in HG_Trigger (context=context@entry=0x7f53e802b300, timeout=timeout@entry=0, max_count=max_count@entry=4294967295, \n",
            "\n",
            "    actual_count=actual_count@entry=0x7f53f5436d9c) at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury.c:2392\n",
            "\n",
            "#19 0x00007f53ffd237ba in crt_hg_trigger (hg_ctx=<optimized out>) at src/cart/crt_hg.c:1385\n",
            "\n",
            "#20 0x00007f53ffd0bf28 in crt_progress (crt_ctx=0x7f53e80260a0, timeout=timeout@entry=0, cond_cb=cond_cb@entry=0x0, arg=arg@entry=0x0) at src/cart/crt_context.c:1166\n",
            "\n",
            "#21 0x000000000040a63b in dss_srv_handler (arg=0x204e2b0) at src/iosrv/srv.c:371\n",
            "\n",
            "#22 0x00007f53fee3f708 in ABTD_thread_func_wrapper () from /home/xliu9/src/daos_m/install/lib/libabt.so.0\n",
            "\n",
            "#23 0x00007f53fee3fc91 in make_fcontext () from /home/xliu9/src/daos_m/install/lib/libabt.so.0\n",
            "\n",
            "#24 0x0000000000000000 in ?? ()\n",
            "\n",
            " , Similarity: 0.2790\n",
            "Summary & Description: investigate crtprogress timoeut1 causing occasional big slowdowns crtbarrier test \n",
            " CRT barrier test when ran under valgrind occasionally takes extremely long time to complete. The test contians crt_progress with timeout=1. Changes of timeouts to higher values .e.g timeout=1000 works around the issue, but need to investigate and root cause the reason for the slowdown., Similarity: 0.1537\n",
            "Summary & Description: psm2 error opening remote shared memory object shmopen file directory err9 \n",
            " Hitting error in psm2 while trying to run daos_perf:\n",
            "{code:java}\n",
            "[sdwillso@boro-3 ~]$ orterun --mca mtl ^psm2,ofi -N 1 --hostfile ~/hostlists/daos_single_server --enable-recovery --report-uri ~/scripts/uri.txt daos_server -c 1 &\n",
            "[1] 24467\n",
            "[sdwillso@boro-3 ~]$ loaded 3 items from /home/sdwillso/daos_m/install/share/control/mgmtinit_db.json\n",
            "DAOS server (v0.0.2) process 104503 started on rank 0 (out of 1) with 1 xstream(s)\n",
            "\n",
            "\n",
            "[sdwillso@boro-3 ~]$ CREDITS=1 ./daos_m/src/tests/daos_perf.sh daos 200 1000 1K\n",
            "+ /home/sdwillso/daos_m/opt/ompi/bin/orterun -quiet --hostfile /home/sdwillso/scripts/host.cli.1 --ompi-server file:/home/sdwillso/scripts/uri.txt -x DD_SUBSYS= -x DD_MASK= -x D_LOG_FILE=/tmp/daos_perf.log /home/sdwillso/daos_m/install/bin/daos_perf -T daos -P 2G -d 1 -a 200 -r 1000 -s 1K -C 1 -t -z\n",
            "Test :\n",
            "\tDAOS (full stack)\n",
            "Parameters :\n",
            "\tpool size     : 2048 MB\n",
            "\tcredits       : 1 (sync I/O for -ve)\n",
            "\tobj_per_cont  : 1 x 36 (procs)\n",
            "\tdkey_per_obj  : 1\n",
            "\takey_per_dkey : 200\n",
            "\trecx_per_akey : 1000\n",
            "\tvalue type    : single\n",
            "\tvalue size    : 1024\n",
            "\tzero copy     : yes\n",
            "\toverwrite     : yes\n",
            "\tverify fetch  : no\n",
            "\tVOS file      : <NULL>\n",
            "boro-13.boro.hpdd.intel.com.130298Error opening remote shared memory object in shm_open: No such file or directory (err=9)\n",
            "boro-13.boro.hpdd.intel.com.130298PSM could not set up shared memory segment (err=9)\n",
            "Failed to initialize step=2, rc=-1020\n",
            "-------------------------------------------------------\n",
            "Primary job  terminated normally, but 1 process returned\n",
            "a non-zero exit code. Per user-direction, the job has been aborted.\n",
            "-------------------------------------------------------\n",
            "{code}\n",
            "Setup is boro-12 single server, boro-13 client. Launch cmds run from boro-3. Server run single thread.\n",
            "\n",
            " \n",
            "\n",
            "commit 3c2ef48f7abfe11fff0629620dc84b8e57ef4ac1, DAOS-900 hash: use ptr-based htable handling from cart\n",
            "\n",
            " \n",
            "\n",
            "daos_perf.log and daos.log can both be found here:\n",
            " boro:/home/sdwillso/jira/cart-492, Similarity: 0.2860\n",
            "Summary & Description: avoid spend time debug messages preparation debug disabled \n",
            " There is a lot of time a code spend for arguments preparation even if debug is disabled. For example, the function CP_UUID() is widely used in debug macros and consume a lot of CPU time.\n",
            ", Similarity: 0.1659\n",
            "Summary & Description: pylint complains \n",
            " 3 pylint warning(s). \n",
            "test/commontestsuite.py:152:( pylint-singleton-comparison)  Comparison to None should be 'expr is not None'\n",
            "\n",
            "test/commontestsuite.py:147:( pylint-singleton-comparison)  Comparison to None should be 'expr is not None'\n",
            "\n",
            "test/cart_test_group_tiers.py:97:( pylint-len-as-condition)  Do not use `len(SEQUENCE)` to determine if a sequence is empty, Similarity: 0.1676\n",
            "Summary & Description: incorrect format specified crtgrpconfigpsrload function \n",
            " fscanf format specification '%d' expects type 'int \\*' for 'd', but parameter 3 has a different type 'uint32_t\\*' in 2780 line.\n",
            "{code}\n",
            "2780\t\t\trc = fscanf(fp, \"%*s%d\", &grp_priv->gp_size);\n",
            "{code}\n",
            ", Similarity: 0.2297\n",
            "Summary & Description: use free ivnsdestroy \n",
            " {code}\n",
            "188\t\tstatic void\n",
            "189\t\tivns_destroy(struct crt_ivns_internal *ivns_internal)\n",
            "190\t\t{\n",
            "191\t\t\tcrt_iv_namespace_destroy_cb_t\t destroy_cb;\n",
            "192\t\t\tcrt_iv_namespace_t\t\t ivns;\n",
            "193\t\t\tvoid\t\t\t\t*cb_arg;\n",
            "194\t\t \n",
            "195\t\t\tD_MUTEX_LOCK(&ns_list_lock);\n",
            "196\t\t\td_list_del(&ivns_internal->cii_link);\n",
            "197\t\t\tD_MUTEX_UNLOCK(&ns_list_lock);\n",
            "198\t\t \n",
            "199\t\t\tivns = ivns_internal;\n",
            "200\t\t\tdestroy_cb = ivns_internal->cii_destroy_cb;\n",
            "201\t\t\tcb_arg = ivns_internal->cii_destroy_cb_arg;\n",
            "202\t\t \n",
            "203\t\t\t/* addref in crt_grp_lookup_int_grpid or crt_iv_namespace_create */\n",
            "204\t\t\tcrt_grp_priv_decref(ivns_internal->cii_grp_priv);\n",
            "205\t\t \n",
            "206\t\t\tD_MUTEX_DESTROY(&ivns_internal->cii_lock);\n",
            "207\t\t\tD_SPIN_DESTROY(&ivns_internal->cii_ref_lock);\n",
            "208\t\t \n",
            "209\t\t\tD_FREE_PTR(ivns_internal->cii_iv_classes);\n",
            "210\t\t\tD_FREE_PTR(ivns_internal);\n",
            "211\t\t \n",
            "212\t\t\tif (destroy_cb)\n",
            "213\t\t\t\tdestroy_cb(ivns, cb_arg);                        <== ivns was freed in 210 line\n",
            "214\t\t}\n",
            "{code}\n",
            ", Similarity: 0.3325\n",
            "Summary & Description: use free drealloc macro \n",
            " {code:java}\n",
            "\t\t(newptr) =  realloc((oldptr), (_sz));\t\t\t\\\n",
            "\t\tif ((newptr) != NULL) {\t\t\t\t\t\\\n",
            "\t\t\tD_DEBUG(DB_MEM,\t\t\t\t\t\\\n",
            "\t\t\t\t\"realloc '\" #newptr \"': %i at %p (old '\" #oldptr \"':%p).\\n\", \\\n",
            "\t\t\t\t_sz, (newptr), (oldptr));\t\t\\\n",
            "\t\t\t(oldptr) = NULL;\t\t\t\t\\\n",
            "\t\t\tbreak;\t\t\t\t\t\t\\\n",
            "\t\t}\n",
            "{code}\n",
            "In case of success of realloc() the *oldptr* will be freed. So, it's not valid of using *oldptr* inside of if ((newptr) != NULL) block., Similarity: 0.2735\n",
            "Summary & Description: memory leak crtcontextreqtrack \n",
            " If d_hash_rec_insert() fails a just allocated epi become not freed.\n",
            "\n",
            " , Similarity: 0.1848\n",
            "Summary & Description: possible double free lock recursion crtcontextdestroy \n",
            " In crt_context_create():238\n",
            "{code:java}\n",
            "\trc = crt_hg_ctx_init(&ctx->cc_hg_ctx, crt_gdata.cg_ctx_num);\n",
            "\tif (rc != 0) {\n",
            "\t\tD_ERROR(\"crt_hg_ctx_init failed rc: %d.\\n\", rc);\n",
            "\t\tcrt_context_destroy(ctx, true);\n",
            "\t\tD_FREE_PTR(ctx);                                             <=== double free !!!\n",
            "\t\tD_RWLOCK_UNLOCK(&crt_gdata.cg_rwlock);\n",
            "\t\tD_GOTO(out, rc);\n",
            "\t}\n",
            "{code}\n",
            "In crt_context_destroy():474\n",
            "{code:java}\n",
            "\trc = crt_hg_ctx_fini(&ctx->cc_hg_ctx);\n",
            "\tif (rc == 0) {\n",
            "\t\tD_RWLOCK_WRLOCK(&crt_gdata.cg_rwlock);\n",
            "\t\tcrt_gdata.cg_ctx_num--;\n",
            "\t\td_list_del_init(&ctx->cc_link);\n",
            "\t\tD_RWLOCK_UNLOCK(&crt_gdata.cg_rwlock);\n",
            "\t\tD_FREE_PTR(ctx);                                             <=== first free !!!\n",
            "{code}\n",
            "Also lock crt_gdata.cg_rwlock will be aquired twice (recursively) but most probably this is not valid., Similarity: 0.1535\n",
            "Summary & Description: resource lost crtcontextdestroy \n",
            " In case of any error inside crt_context_destroy() the mutex ctx->cc_mutex will not be destroyed.\n",
            "\n",
            " , Similarity: 0.2466\n",
            "Summary & Description: memory leak crtgrplcuriinsert \n",
            " {code:java}\n",
            "\t\tD_ALLOC_PTR(li);\n",
            "\t\tif (li == NULL)\n",
            "\t\t\tD_GOTO(out, rc = -DER_NOMEM);\n",
            "\n",
            "\t\trc = D_MUTEX_INIT(&li->li_mutex, NULL);\n",
            "\t\tif (rc != 0)\n",
            "\t\t\tD_GOTO(out, rc);                      <====== LEAK li HEAR\n",
            "\n",
            "\t\tD_INIT_LIST_HEAD(&li->li_link);\n",
            "\t\tli->li_grp_priv = grp_priv;\n",
            "\t\tli->li_rank = rank;\n",
            "\t\tD_STRNDUP(li->li_uri[tag], uri, CRT_ADDR_STR_MAX_LEN);\n",
            "\t\tif (li->li_uri[tag] == NULL)\n",
            "\t\t\tD_GOTO(out, rc = -DER_NOMEM);         <====== LEAK li HEAR\n",
            "{code}, Similarity: 0.2289\n",
            "Summary & Description: memory leak crtgrplccreate crtgrplcdestroy \n",
            " In case of error in d_hash_table_create()/d_hash_table_destroy()  the *htables* and content of *grp_priv->gp_lookup_cache[]* will not be released properly and will be lost after root pointer destroyed.\n",
            "\n",
            " , Similarity: 0.2402\n",
            "Summary & Description: design fault injection framework cart \n",
            " * Design framework\n",
            " * Create key stories to capture development effort.\n",
            " * Have team review- review design, gather additional requirements\n",
            " ** Alex initial\n",
            " ** Then have Ashley, DAOS team review (Thur CaRT)\n",
            " *, Similarity: 0.3471\n",
            "Summary & Description: intel r2208wt2ysr \n",
            " Hello Support,\n",
            "\n",
            "We had just swapped the chassis few days back and system was and running. However this morning we installed the machine back in the rack and booted it up, waited a while and tried to access it from VMware as ESXI is installed. After a while I could not access and went back and looked at the console and it was still booting up after over 30mins had gone by. After watching it, sometimes it will not get all the way through the boot and the few times it does and up for a min or two and reboot it self.\n",
            "\n",
            ", Similarity: 0.1279\n",
            "Summary & Description: bulk io write error cd7da0f0e6cba9fa7cbe086ff4e517e6 1010104o2ib client retry rc 110 \n",
            " Dear all,\n",
            "\n",
            "I found some error messages in my oss node. It report bellow in '/var/log/messages':\n",
            "\n",
            "Jul 16 12:26:14 oss02 kernel: LustreError: 2165:0:(events.c:447:server_bulk_callback()) event type 5, status -103, desc ffff881fd45f1800\n",
            "Jul 16 12:26:14 oss02 kernel: LustreError: 2165:0:(events.c:447:server_bulk_callback()) event type 3, status -103, desc ffff881fd45f1800\n",
            "Jul 16 12:26:14 oss02 kernel: LustreError: 31710:0:(ldlm_lib.c:2796:target_bulk_io()) @@@ network error on bulk WRITE req@ffff881ffdc8dc50 x1605867050997088/t0(0) o4->cd7da0f0-e6cb-a9fa-7cbe-086ff4e517e6@10.10.10.4@o2ib:647/0 lens 488/448 e 1 to 0 dl 1531715202 ref 1 fl Interpret:/0/0 rc 0/0\n",
            "Jul 16 12:26:14 oss02 kernel: Lustre: lustre-OST0003: Client cd7da0f0-e6cb-a9fa-7cbe-086ff4e517e6 (at 10.10.10.4@o2ib) reconnecting\n",
            "Jul 16 12:26:14 oss02 kernel: Lustre: lustre-OST0003: Bulk IO write error with cd7da0f0-e6cb-a9fa-7cbe-086ff4e517e6 (at 10.10.10.4@o2ib), client will retry: rc -110\n",
            "\n",
            "I uploaded all the logs. Thank you for your help.\n",
            "\n",
            "Best Regards.\n",
            "\n",
            "Dai Cao.\n",
            "\n",
            " , Similarity: 0.2917\n",
            "Summary & Description: remove eqwithcrt \n",
            " EQ_WITH_CRT was initially introduced to support the unit tests for event queue (src/client/tests/eq_tests.c) without dragging the CaRT dependency.\n",
            "\n",
            "As a consequence, the following code was thus added to src/client/event.c:\n",
            "{noformat}\n",
            "  40 #define EQ_WITH_CRT\n",
            "  41\n",
            "  42 #if !defined(EQ_WITH_CRT)\n",
            "  43\n",
            "  44 #define crt_init(a,b,c)                 ({0;})\n",
            "  45 #define crt_finalize()                  ({0;})\n",
            "  46 #define crt_context_create(a, b)        ({0;})\n",
            "  47 #define crt_context_destroy(a, b)       ({0;})\n",
            "  48 #define crt_progress(ctx, timeout, cb, args)    \\\n",
            "  49 ({                                              \\\n",
            "  50         int __rc = cb(args);                    \\\n",
            "  51                                                 \\\n",
            "  52         while ((timeout) != 0 && __rc == 0) {   \\\n",
            "  53                 sleep(1);                       \\\n",
            "  54                 __rc = cb(args);                \\\n",
            "  55                 if ((timeout) < 0)              \\\n",
            "  56                         continue;               \\\n",
            "  57                 if ((timeout) < 1000000)        \\\n",
            "  58                         break;                  \\\n",
            "  59                 (timeout) -= 1000000;           \\\n",
            "  60         }                                       \\\n",
            "  61         0;                                      \\\n",
            "  62 })\n",
            "  63\n",
            "  64 #endif\n",
            "{noformat}\n",
            "\n",
            "However, crt_init() now takes 2 parameters whereas crt_init() above uses 3 and the eq_tests still seems to be running fine as part of the CI. As a result, I suspect that this code is just dead and EQ_WITH_CRT should just be removed., Similarity: 0.1764\n",
            "Summary & Description: psm2 broken \n",
            " Since last week, tests over OFI/PSM2 are not working.\n",
            "\n",
            "In DAOS, the issue appears when a pool is created (with dmg for example), then a pool connect is issued from another process. So daos_test can not replicate this since it create and connect to the pool in the same process/program.\n",
            "\n",
            "Something simple like this can replicate:\n",
            "\n",
            "$ orterun --hostfile ~/cli_hosts -np 1 --mca mtl ^psm2,ofi --ompi-server [file:~/uri.txt|file:///~/uri.txt] dmg create --size=1GB\n",
            "\n",
            "c1c940c9-6909-4375-b77b-21dd1ec76e37 0\n",
            "\n",
            "$ orterun --hostfile ~/cli_hosts -np 1 --mca mtl ^psm2,ofi --ompi-server [file:~/uri.txt|file:///~/uri.txt] dmg query --pool=c1c940c9-6909-4375-b77b-21dd1ec76e37 --svc=0\n",
            "\n",
            " \n",
            "\n",
            "In this  case, the daos_server asserts with the error stack below.\n",
            "\n",
            "The OFI env variables used: \n",
            "\n",
            "export CRT_PHY_ADDR_STR=\"ofi+psm2\"\n",
            "\n",
            "export OFI_INTERFACE=ib0\n",
            "\n",
            "export FI_PSM2_NAME_SERVER=1\n",
            "\n",
            "export PSM2_MULTI_EP=1\n",
            "\n",
            "export FI_SOCKETS_MAX_CONN_RETRY=1\n",
            "\n",
            "export CRT_CTX_SHARE_ADDR=1\n",
            "\n",
            "export CRT_CTX_NUM=8\n",
            "\n",
            " \n",
            "\n",
            "On the client side only we set:\n",
            "\n",
            "export FI_PSM2_DISCONNECT=1\n",
            "\n",
            " \n",
            "\n",
            "The server side assertion:\n",
            "\n",
            " \n",
            "\n",
            "0x00007ffff423e878 in psmx2_write_generic (ep=0x747750, buf=0x7fffc4283278, \n",
            "\n",
            "    len=64, desc=0xc, dest_addr=0, addr=38036672, key=2, \n",
            "\n",
            "    context=0x7fffcc9534e8, flags=268435456, data=0)\n",
            "\n",
            "    at prov/psm2/src/psmx2_rma.c:931\n",
            "\n",
            "931 if (epaddr_context->epid == ep_priv->tx->psm2_epid)\n",
            "\n",
            "Missing separate debuginfos, use: debuginfo-install glibc-2.17-196.el7.x86_64 libevent-2.0.21-4.el7.x86_64 libgcc-4.8.5-16.el7.x86_64 libibverbs-13-7.el7.x86_64 libnl3-3.2.28-4.el7.x86_64 librdmacm-13-7.el7.x86_64 libuuid-2.23.2-43.el7.x86_64 ncurses-libs-5.9-14.20130511.el7_4.x86_64 numactl-libs-2.0.9-6.el7_2.x86_64 readline-6.2-10.el7.x86_64 zlib-1.2.7-17.el7.x86_64\n",
            "\n",
            "(gdb) bt\n",
            "\n",
            "#0  0x00007ffff423e878 in psmx2_write_generic (ep=0x747750, \n",
            "\n",
            "    buf=0x7fffc4283278, len=64, desc=0xc, dest_addr=0, addr=38036672, key=2, \n",
            "\n",
            "    context=0x7fffcc9534e8, flags=268435456, data=0)\n",
            "\n",
            "    at prov/psm2/src/psmx2_rma.c:931\n",
            "\n",
            "#1  0x00007ffff423fda9 in psmx2_writemsg (ep=0x747750, msg=0x7fffd8068910, \n",
            "\n",
            "---Type <return> to continue, or q <return> to quit---\n",
            "\n",
            "    flags=268435456) at prov/psm2/src/psmx2_rma.c:1288\n",
            "\n",
            "#2  0x00007ffff52a64ca in fi_writemsg (flags=268435456, msg=0x7fffd8068910, \n",
            "\n",
            "    ep=0x747750) at /scratch/mschaara/DEPS/ofi/include/rdma/fi_rma.h:136\n",
            "\n",
            "#3  na_ofi_put (na_class=0x621c90, context=0x7fffcc02d4f0, \n",
            "\n",
            "    callback=<optimized out>, arg=<optimized out>, \n",
            "\n",
            "    local_mem_handle=<optimized out>, local_offset=<optimized out>, \n",
            "\n",
            "    remote_mem_handle=0x7fffcc0885c0, remote_offset=0, length=64, \n",
            "\n",
            "    remote_addr=0x7fffcc086040, remote_id=0 '\\000', op_id=0x7fffcc089490)\n",
            "\n",
            "    at /home/mschaara/source/deps_daos/daos_m/_build.external/mercury/src/na/na_ofi.c:3758\n",
            "\n",
            "#4  0x00007ffff54c4991 in hg_bulk_transfer_pieces (\n",
            "\n",
            "    na_bulk_op=na_bulk_op@entry=0x7ffff54c47b0 <hg_bulk_na_put>, \n",
            "\n",
            "    origin_addr=origin_addr@entry=0x7fffcc086040, origin_id=0 '\\000', \n",
            "\n",
            "    hg_bulk_origin=hg_bulk_origin@entry=0x7fffcc951950, \n",
            "\n",
            "    origin_segment_start_index=origin_segment_start_index@entry=0, \n",
            "\n",
            "    origin_segment_start_offset=origin_segment_start_offset@entry=0, \n",
            "\n",
            "    hg_bulk_local=hg_bulk_local@entry=0x7fffcc089200, \n",
            "\n",
            "    local_segment_start_index=local_segment_start_index@entry=0, \n",
            "\n",
            "    local_segment_start_offset=local_segment_start_offset@entry=0, \n",
            "\n",
            "    size=size@entry=64, scatter_gather=scatter_gather@entry=0 '\\000', \n",
            "\n",
            "    hg_bulk_op_id=hg_bulk_op_id@entry=0x7fffcc953310, \n",
            "\n",
            "    na_op_count=na_op_count@entry=0x0, use_sm=0 '\\000')\n",
            "\n",
            "    at /home/mschaara/source/deps_daos/daos_m/_build.external/mercury/src/mercu---Type <return> to continue, or q <return> to quit---\n",
            "\n",
            "ry_bulk.c:784\n",
            "\n",
            "#5  0x00007ffff54c6758 in hg_bulk_transfer (op_id=0x7fffd8068c38, \n",
            "\n",
            "    op_id@entry=0x40, size=64, size@entry=0, local_offset=<optimized out>, \n",
            "\n",
            "    hg_bulk_local=0x7fffcc089200, hg_bulk_local@entry=0x0, \n",
            "\n",
            "    origin_offset=<optimized out>, hg_bulk_origin=0x7fffcc951950, \n",
            "\n",
            "    origin_id=<optimized out>, origin_addr=<optimized out>, \n",
            "\n",
            "    op=<optimized out>, arg=0x7fffcc952f80, \n",
            "\n",
            "    callback=0x7ffff774e140 <crt_hg_bulk_transfer_cb>, \n",
            "\n",
            "    context=<optimized out>)\n",
            "\n",
            "    at /home/mschaara/source/deps_daos/daos_m/_build.external/mercury/src/mercury_bulk.c:955\n",
            "\n",
            "#6  HG_Bulk_transfer_id (context=<optimized out>, \n",
            "\n",
            "    callback=callback@entry=0x7ffff774e140 <crt_hg_bulk_transfer_cb>, \n",
            "\n",
            "    arg=arg@entry=0x7fffcc952f80, op=<optimized out>, \n",
            "\n",
            "    origin_addr=<optimized out>, origin_id=origin_id@entry=0 '\\000', \n",
            "\n",
            "    origin_handle=0x7fffcc951950, origin_offset=origin_offset@entry=0, \n",
            "\n",
            "    local_handle=local_handle@entry=0x7fffcc089200, \n",
            "\n",
            "    local_offset=local_offset@entry=0, size=size@entry=64, \n",
            "\n",
            "    op_id=op_id@entry=0x7fffd8068c38)\n",
            "\n",
            "    at /home/mschaara/source/deps_daos/daos_m/_build.external/mercury/src/mercury_bulk.c:1721\n",
            "\n",
            "#7  0x00007ffff54c69a2 in HG_Bulk_transfer (context=<optimized out>, \n",
            "\n",
            "    callback=callback@entry=0x7ffff774e140 <crt_hg_bulk_transfer_cb>, \n",
            "\n",
            "---Type <return> to continue, or q <return> to quit---\n",
            "\n",
            "    arg=arg@entry=0x7fffcc952f80, op=<optimized out>, \n",
            "\n",
            "    origin_addr=<optimized out>, origin_handle=<optimized out>, \n",
            "\n",
            "    origin_offset=0, local_handle=0x7fffcc089200, local_offset=0, size=64, \n",
            "\n",
            "    op_id=op_id@entry=0x7fffd8068c38)\n",
            "\n",
            "    at /home/mschaara/source/deps_daos/daos_m/_build.external/mercury/src/mercury_bulk.c:1643\n",
            "\n",
            "#8  0x00007ffff77532ba in crt_hg_bulk_transfer (\n",
            "\n",
            "    bulk_desc=bulk_desc@entry=0x7fffd8068c80, \n",
            "\n",
            "    complete_cb=0x7fffda3baee0 <bulk_cb>, arg=0x7fffd8068c40, \n",
            "\n",
            "    opid=0x7fffd8068c38) at src/cart/crt_hg.c:1665\n",
            "\n",
            "#9  0x00007ffff7731ec3 in crt_bulk_transfer (\n",
            "\n",
            "    bulk_desc=bulk_desc@entry=0x7fffd8068c80, \n",
            "\n",
            "    complete_cb=complete_cb@entry=0x7fffda3baee0 <bulk_cb>, \n",
            "\n",
            "    arg=arg@entry=0x7fffd8068c40, opid=opid@entry=0x7fffd8068c38)\n",
            "\n",
            "    at src/cart/crt_bulk.c:172\n",
            "\n",
            "#10 0x00007fffda3bae34 in transfer_map_buf (tx=tx@entry=0x7fffd8068e10, \n",
            "\n",
            "    svc=<optimized out>, rpc=rpc@entry=0x7fffcd214b18, \n",
            "\n",
            "    remote_bulk=0x7fffcc951950, \n",
            "\n",
            "    required_buf_size=required_buf_size@entry=0x7fffcd214c64)\n",
            "\n",
            "    at src/pool/srv_pool.c:1809\n",
            "\n",
            "#11 0x00007fffda3be992 in ds_pool_connect_handler (rpc=0x7fffcd214b18)\n",
            "\n",
            "    at src/pool/srv_pool.c:1923\n",
            "\n",
            "#12 0x00007ffff7772230 in crt_handle_rpc (arg=0x7fffcd214b18)\n",
            "\n",
            "---Type <return> to continue, or q <return> to quit---\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "    at src/cart/crt_rpc.c:1590\n",
            "\n",
            "#13 0x00007ffff67b9708 in ABTD_thread_func_wrapper ()\n",
            "\n",
            "   from /scratch/mschaara/DEPS//argobots/lib/libabt.so.0\n",
            "\n",
            "#14 0x00007ffff67b9c91 in make_fcontext ()\n",
            "\n",
            "   from /scratch/mschaara/DEPS//argobots/lib/libabt.so.0\n",
            "\n",
            "#15 0x00007fffd8068eb8 in ?? ()\n",
            "\n",
            "#16 0x00007ffff77721e0 in ?? () at src/cart/crt_rpc.c:1145\n",
            "\n",
            "   from /scratch/mschaara/DEPS//cart/lib/libcart.so\n",
            "\n",
            "#17 0x00007fffcd214b18 in ?? ()\n",
            "\n",
            "#18 0x0000000000000000 in ?? (), Similarity: 0.2858\n",
            "Summary & Description: assertion complex communication mode \n",
            " in some daos rebuild testing, occasionally will see an assertion:\n",
            "\n",
            " \n",
            "\n",
            "(gdb) bt\n",
            "\n",
            "#0 0x00007fb7144351f7 in raise () from /lib64/libc.so.6\n",
            "\n",
            "#1 0x00007fb7144368e8 in abort () from /lib64/libc.so.6\n",
            "\n",
            "#2 0x00007fb71442e266 in __assert_fail_base () from /lib64/libc.so.6\n",
            "\n",
            "#3 0x00007fb71442e312 in __assert_fail () from /lib64/libc.so.6\n",
            "\n",
            "#4 0x00007fb7134f3850 in na_ofi_addr_addref (na_ofi_addr=0x7fb6dbe01270) at /mercury/src/na/na_ofi.c:2822\n",
            "\n",
            "#5 0x00007fb7134faa66 in na_ofi_addr_addref (na_ofi_addr=0x7fb6dbe01270) at /mercury/src/na/na_ofi.c:3455\n",
            "\n",
            "#6 na_ofi_msg_recv_expected (na_class=<optimized out>, context=0x7fb6d802d4f0, callback=<optimized out>, arg=<optimized out>, buf=0x7fb6ec516740, buf_size=4096, plugin_data=0x0,\n",
            "\n",
            "   source=0x7fb6dbe01270, target_id=0 '\\000', tag=13, op_id=0x7fb6d80cd9d8) at /mercury/src/na/na_ofi.c:3445\n",
            "\n",
            "#7 0x00007fb713710055 in hg_core_forward_na (hg_core_handle=0x7fb6d80cd8d0) at /mercury/src/mercury_core.c:1990\n",
            "\n",
            "#8 0x00007fb713713929 in HG_Core_forward (handle=0x7fb6d80cd8d0, callback=callback@entry=0x7fb7137155b0 <hg_core_forward_cb>, arg=arg@entry=0x7fb6d80cdcf0, flags=<optimized out>,\n",
            "\n",
            "   payload_size=<optimized out>) at /mercury/src/mercury_core.c:4781\n",
            "\n",
            "#9 0x00007fb713718a2e in HG_Forward (handle=0x7fb6d80cdcf0, callback=callback@entry=0x7fb71599ba50 <crt_hg_req_send_cb>, arg=arg@entry=0x7fb6dbe00d20,\n",
            "\n",
            "   in_struct=in_struct@entry=0x7fb6dbe00d98) at mercury/src/mercury.c:2297\n",
            "\n",
            "#10 0x00007fb71599e84c in crt_hg_req_send (rpc_priv=rpc_priv@entry=0x7fb6dbe00d20) at src/cart/crt_hg.c:1238\n",
            "\n",
            "#11 0x00007fb7159c235f in crt_req_send_immediately (rpc_priv=<optimized out>) at src/cart/crt_rpc.c:1172\n",
            "\n",
            "#12 crt_req_send_internal (rpc_priv=rpc_priv@entry=0x7fb6dbe00d20) at src/cart/crt_rpc.c:1242\n",
            "\n",
            "#13 0x00007fb7159c37c4 in crt_req_hg_addr_lookup_cb (hg_addr=0x7fb6dbe01170, arg=0x7fb6dbe00d20) at src/cart/crt_rpc.c:717\n",
            "\n",
            "#14 0x00007fb71599b0c4 in crt_hg_addr_lookup_cb (hg_cbinfo=<optimized out>) at src/cart/crt_hg.c:276\n",
            "\n",
            "#15 0x00007fb713715685 in hg_core_addr_lookup_cb (callback_info=<optimized out>) at /mercury/src/mercury.c:459\n",
            "\n",
            "#16 0x00007fb713714005 in hg_core_trigger_lookup_entry (hg_core_op_id=0x7fb6dbde1c70) at mercury/src/mercury_core.c:3186\n",
            "\n",
            "#17 hg_core_trigger (context=0x7fb6d802b320, timeout=<optimized out>, timeout@entry=0, max_count=max_count@entry=4294967295, actual_count=actual_count@entry=0x7fb70788768c)\n",
            "\n",
            "   at mercury/src/mercury_core.c:3136\n",
            "\n",
            "#18 0x00007fb713714d7b in HG_Core_trigger (context=<optimized out>, timeout=timeout@entry=0, max_count=max_count@entry=4294967295, actual_count=actual_count@entry=0x7fb70788768c)\n",
            "\n",
            "   at mercury/src/mercury_core.c:4902\n",
            "\n",
            "#19 0x00007fb713718cbd in HG_Trigger (context=context@entry=0x7fb6d802b300, timeout=timeout@entry=0, max_count=max_count@entry=4294967295,\n",
            "\n",
            "   actual_count=actual_count@entry=0x7fb70788768c) at /mercury/src/mercury.c:2392\n",
            "\n",
            "#20 0x00007fb71599b45a in crt_hg_trigger (hg_ctx=<optimized out>) at src/cart/crt_hg.c:1370\n",
            "\n",
            "#21 0x00007fb71599f74c in crt_hg_progress (hg_ctx=0x7fb6d80260b8, timeout=<optimized out>) at src/cart/crt_hg.c:1403\n",
            "\n",
            "#22 0x00007fb715983bd8 in crt_progress (crt_ctx=0x7fb6d80260a0, timeout=timeout@entry=0, cond_cb=cond_cb@entry=0x0, arg=arg@entry=0x0) at src/cart/crt_context.c:1099\n",
            "\n",
            "#23 0x0000000000409c7a in dss_srv_handler (arg=0x1a8bb90) at src/iosrv/srv.c:371\n",
            "\n",
            "#24 0x00007fb714a0d708 in ABTD_thread_func_wrapper () from /home/xliu9/src/daos_m/install/lib/libabt.so.0\n",
            "\n",
            "#25 0x00007fb714a0dc91 in make_fcontext () from /home/xliu9/src/daos_m/install/lib/libabt.so.0\n",
            "\n",
            "#26 0x0000000000000000 in ?? (), Similarity: 0.1929\n",
            "Summary & Description: prep performance improvements \n",
            " We will be getting data/instructions soon from copa team on how to do perf measurements, and I will be meeting with them at some point to see what kind of optimizations we can do in cart., Similarity: 0.2246\n",
            "Summary & Description: uuid hash provide comparison operation optional \n",
            " Add support for additional optional comparator function callback for UUID hash. This is to support additional comparison for decision making while adding entries to the UUID hash., Similarity: 0.1694\n",
            "Summary & Description: rebuild test trigger assert evtree \n",
            " Rebuild test with 6 servers / 8 xstreams may trigger following assert :\n",
            "\n",
            "daos_io_server: src/vos/evtree.c:1776: evt_fill_entry: Assertion `entry->en_inob != 0' failed.\n",
            "\n",
            "Not sure if it's caused by some cart bug, but the evtree needs be fixed anyway, network error shouldn't trigger an evtree internal assert., Similarity: 0.2779\n",
            "Summary & Description: rebuild test never finished \n",
            " Rebuild test never finished on 6 servers / 8 xstreams. Following message showed up in daos log infinitely:\n",
            "\n",
            "06/22-01:59:14.21 boro-75 DAOS[69153] RPC  WARN src/cart/crt_register.c:340 crt_opc_lookup() version number 1 out of range [0, 0]\n",
            "06/22-01:59:14.22 boro-75 DAOS[69153] RPC  WARN src/cart/crt_register.c:340 crt_opc_lookup() version number 1 out of range [0, 0]\n",
            "\n",
            "The CRT_CTX_SHARE_ADDR=1 & CRT_CTX_NUM=8 is already set as xuezhao suggested.\n",
            ", Similarity: 0.1924\n",
            "Summary & Description: request sent wrong tag \n",
            " In my recent rebuild test, (with cart d94981d31b9e77ad44c2f2dfdce65dbe4d65dc12), it seems the daos request is being sent to the wrong tag. \n",
            "\n",
            "On the client side, the request is supposed to send to tag 1\n",
            "{noformat}\n",
            "06/22-00:50:12.76 boro-56 DAOS[26874] object DBUG src/object/cli_shard.c:352 obj_shard_rw() opc 1 72057654251356204.8.2 dkey_2 rank 0 tag 1 dkey_hash 17024565055411339361 part_nr 8\n",
            "{noformat}\n",
            "\n",
            "But it turns out the tag0 xstream got the request\n",
            "{noformat}\n",
            "06/22-00:50:12.76 boro-32 DAOS[188145] object DBUG src/object/srv_obj.c:677 ds_obj_rw_handler() opc 1 72057654251356204.8.2 dkey dkey_2 tag 0\n",
            "{noformat}\n",
            "\n",
            "Clearly, the request is being sent to the wrong tag by CART.\n",
            "\n",
            "After set \"export CRT_CTX_SHARE_ADDR=1\", suggested by Xuezhao, the problem went away, though this problem needs to be fixed anyway., Similarity: 0.2852\n",
            "Summary & Description: investigate pmix seg fault failover handling \n",
            " Try to repro and identify cause, Similarity: 0.1665\n",
            "Summary & Description: update sconslocal checksums mercury disabled \n",
            " this ticket and CORCI-326 are done at the same time., Similarity: 0.1367\n",
            "Summary & Description: iv fetch operation node causes invs ref count go 0 \n",
            " IV fetch operation when happening on the intermediate node (A->B->C scenario, node B), causes ivns ref counter to go to 0 during bulk transfer back to the child., Similarity: 0.1753\n",
            "Summary & Description: psr selection needs handled better \n",
            " we (iof) want to have a different behavior of psr selection from what we currently have.\n",
            "\n",
            " The desired behavior is:\n",
            " * If successful resampling is done we should unmark all PSRs \n",
            " * If PSR A is not responding and there are others in the list that havent been tried - try them\n",
            " * If no PSRs in the list have responded, retry them in a round-robin manner indefinately, Similarity: 0.0530\n",
            "Summary & Description: verify error codes rpc failure \n",
            " We need to ensure on cart side that when RPC fails we return proper error code based on whether rpc went out on wire or not:\n",
            "\n",
            "unreach - hasnt been sent.\n",
            "evicted - hasnt been sent node has been. \n",
            "oog - rpc may have executed remotely., Similarity: 0.1572\n",
            "Summary & Description: ioftestlocal failoverstat hangs resampling \n",
            " Ashley reported this crashlog after attempting to update to master cart:\n",
            "\n",
            "#100 0x0000000000416d56 in iof_fs_send (request=0x16b7940) at src/ioc/ioc_main.c:501\n",
            "#101 0x0000000000416af1 in ioc_simple_resend (request=0x16b7940) at src/ioc/ioc_main.c:118\n",
            "#102 0x0000000000416f49 in generic_cb (cb_info=0x7ff030ef4688) at src/ioc/ioc_main.c:455\n",
            "#103 0x00007ff03f59bc09 in crt_rpc_complete (rpc_priv=<optimized out>, rc=<optimized out>) at src/cart/crt_context.c:276\n",
            "#104 0x00007ff03f5d57bb in crt_req_send (req=<optimized out>, complete_cb=0x416e10 <generic_cb>, arg=<optimized out>) at src/cart/crt_rpc.c:1469\n",
            "#105 0x0000000000416d56 in iof_fs_send (request=0x16b7940) at src/ioc/ioc_main.c:501\n",
            "#106 0x0000000000416af1 in ioc_simple_resend (request=0x16b7940) at src/ioc/ioc_main.c:118\n",
            "#107 0x0000000000416f49 in generic_cb (cb_info=0x7ff030ef48b8) at src/ioc/ioc_main.c:455\n",
            "#108 0x00007ff03f59bc09 in crt_rpc_complete (rpc_priv=<optimized out>, rc=<optimized out>) at src/cart/crt_context.c:276\n",
            "#109 0x00007ff03f5d57bb in crt_req_send (req=<optimized out>, complete_cb=0x416e10 <generic_cb>, arg=<optimized out>) at src/cart/crt_rpc.c:1469\n",
            "#110 0x0000000000416d56 in iof_fs_send (request=0x16b7940) at src/ioc/ioc_main.c:501\n",
            "#111 0x0000000000416af1 in ioc_simple_resend (request=0x16b7940) at src/ioc/ioc_main.c:118\n",
            "#112 0x0000000000416f49 in generic_cb (cb_info=0x7ff030ef4ae8) at src/ioc/ioc_main.c:455\n",
            "#113 0x00007ff03f59bc09 in crt_rpc_complete (rpc_priv=<optimized out>, rc=<optimized out>) at src/cart/crt_context.c:276\n",
            "#114 0x00007ff03f5d846d in crt_req_hg_addr_lookup_cb (hg_addr=0x7ff010022c60, arg=0x16b7990) at src/cart/crt_rpc.c:863\n",
            "#115 0x00007ff03f5b27b0 in crt_hg_addr_lookup_cb (hg_cbinfo=<optimized out>) at src/cart/crt_hg.c:276\n",
            "#116 0x00007ff03e9633b5 in hg_core_addr_lookup_cb (callback_info=<optimized out>) at /home/ashley/coral/build-area/_build.external-Linux/mercury/src/mercury.c:460\n",
            "#117 0x00007ff03e961d65 in hg_core_trigger_lookup_entry (hg_core_op_id=0x7ff010022c00) at /home/ashley/coral/build-area/_build.external-Linux/mercury/src/mercury_core.c:3190\n",
            "#118 hg_core_trigger (context=0x16ab5d0, timeout=<optimized out>, max_count=4294967295, actual_count=0x7ff030ef4ca4) at /home/ashley/coral/build-area/_build.external-Linux/mercury/src/mercury_core.c:3140\n",
            "#119 0x00007ff03e962adb in HG_Core_trigger (context=<optimized out>, timeout=<optimized out>, max_count=<optimized out>, actual_count=<optimized out>) at /home/ashley/coral/build-area/_build.external-Linux/mercury/src/mercury_core.c:4840\n",
            "#120 0x00007ff03f5b6a32 in crt_hg_trigger (hg_ctx=<optimized out>) at src/cart/crt_hg.c:1365\n",
            "#121 0x00007ff03f59edc4 in crt_progress (crt_ctx=<optimized out>, timeout=0, cond_cb=0x0, arg=0x167a69c) at src/cart/crt_context.c:1083\n",
            "#122 0x000000000041dbde in iof_thread (arg=0x167a680) at src/ioc/ioc_main.c:1179\n",
            "#123 0x00007ff03f804e25 in start_thread () from /lib64/libpthread.so.0\n",
            "#124 0x00007ff03ec70bad in clone () from /lib64/libc.so.6\n",
            "\n",
            " \n",
            "\n",
            "To reproduce - update iof to [https://review.whamcloud.com/#/c/32446/]\n",
            "\n",
            "./test/iof_test_local.py --log-to-file --log-mask=DEBUG failover_stat, Similarity: 0.4022\n",
            "Summary & Description: segment fault daos current master \n",
            " I got segment fault when I run daos_test with  cart to master. (1c3e4e3fb7bc1bafd84dba114af8921546b31a55)\n",
            "\n",
            "{noformat}\n",
            "DAOS server (v0.0.2) process 25068 started on rank 3 (out of 8) with 8 xstream(s)\n",
            "DAOS server (v0.0.2) process 25335 started on rank 6 (out of 8) with 8 xstream(s)\n",
            "DAOS server (v0.0.2) process 21185 started on rank 5 (out of 8) with 8 xstream(s)\n",
            "DAOS server (v0.0.2) process 22269 started on rank 1 (out of 8) with 8 xstream(s)\n",
            "DAOS server (v0.0.2) process 48366 started on rank 0 (out of 8) with 8 xstream(s)\n",
            "DAOS server (v0.0.2) process 20631 started on rank 7 (out of 8) with 8 xstream(s)\n",
            "DAOS server (v0.0.2) process 21707 started on rank 2 (out of 8) with 8 xstream(s)\n",
            "DAOS server (v0.0.2) process 21191 started on rank 4 (out of 8) with 8 xstream(s)\n",
            "c11eac50: rank 5 became pool service leader 1\n",
            "2018/05/24 15:48:48 DAOS I/O server exited with error: signal: segmentation fault (core dumped)\n",
            "{noformat}\n",
            "\n",
            "{noformat}\n",
            "\n",
            "(gdb) bt\n",
            "#0  crt_uri_lookup_forward_cb (cb_info=0x7f8aa25bac30) at src/cart/crt_group.c:1773\n",
            "#1  0x00007f8ab2366ed9 in crt_hg_req_send_cb (hg_cbinfo=<optimized out>) at src/cart/crt_hg.c:1217\n",
            "#2  0x00007f8ab019a34c in hg_core_forward_cb (callback_info=0x7f8aa25bad30) at /home/wangdi/daos_m_0508/daos_m/_build.external/mercury/src/mercury.c:966\n",
            "#3  0x00007f8ab0198d98 in hg_core_trigger_entry (hg_core_handle=0x7f8a9c0be330) at /home/wangdi/daos_m_0508/daos_m/_build.external/mercury/src/mercury_core.c:3272\n",
            "#4  hg_core_trigger (context=0x7f8a9c02b370, timeout=<optimized out>, timeout@entry=0, max_count=max_count@entry=4294967295, actual_count=actual_count@entry=0x7f8aa25badac)\n",
            "    at /home/wangdi/daos_m_0508/daos_m/_build.external/mercury/src/mercury_core.c:3147\n",
            "#5  0x00007f8ab0199adb in HG_Core_trigger (context=<optimized out>, timeout=timeout@entry=0, max_count=max_count@entry=4294967295, actual_count=actual_count@entry=0x7f8aa25badac)\n",
            "    at /home/wangdi/daos_m_0508/daos_m/_build.external/mercury/src/mercury_core.c:4840\n",
            "#6  0x00007f8ab019d95d in HG_Trigger (context=context@entry=0x7f8a9c02b350, timeout=timeout@entry=0, max_count=max_count@entry=4294967295, actual_count=actual_count@entry=0x7f8aa25badac)\n",
            "    at /home/wangdi/daos_m_0508/daos_m/_build.external/mercury/src/mercury.c:2347\n",
            "#7  0x00007f8ab23667aa in crt_hg_trigger (hg_ctx=<optimized out>) at src/cart/crt_hg.c:1365\n",
            "#8  0x00007f8ab234eda8 in crt_progress (crt_ctx=0x7f8a9c0260f0, timeout=0, cond_cb=0x0, arg=0x0) at src/cart/crt_context.c:1083\n",
            "#9  0x000000000045bd49 in syscall.openat (dirfd=140233658727569, path=..., flags=0, mode=0, fd=0, err=...) at /usr/lib/golang/src/syscall/zsyscall_linux_amd64.go:46\n",
            "#10 0x0000000000000000 in ?? ()\n",
            "(gdb) p *(struct crt_rpc_priv *)0x7f8a9c0cf100\n",
            "$2 = {crp_epi_link = {next = 0x7f8a9c000078, prev = 0x7f8a9c000078}, crp_tmp_link = {next = 0x7f8a9c0cf110, prev = 0x7f8a9c0cf110}, crp_parent_link = {next = 0x7f8a9c0cf120, \n",
            "    prev = 0x7f8a9c0cf120}, crp_timeout_bp_node = {chn_idx = 0}, crp_timeout_sec = 0, crp_timeout_ts = 0, crp_complete_cb = 0x0, crp_arg = 0x0, crp_epi = 0x0, crp_pub = {\n",
            "    cr_ctx = 0x7f8a9c0260f0, cr_ep = {ep_grp = 0x0, ep_rank = 0, ep_tag = 0}, cr_opc = 4278190084, cr_input = 0x0, cr_output = 0x0, cr_input_size = 0, cr_output_size = 0, \n",
            "    cr_co_bulk_hdl = 0x0}, crp_state = RPC_STATE_INITED, crp_hg_hdl = 0x7f8a9c04f0a0, crp_hg_addr = 0x7f8a9c04f370, crp_hdl_reuse = 0x0, crp_tgt_uri = 0x0, crp_ul_req = 0x0, crp_ul_retry = 0, \n",
            "  crp_flags = 0, crp_srv = 1, crp_output_got = 0, crp_input_got = 1, crp_coll = 0, crp_uri_free = 0, crp_forward = 0, crp_in_binheap = 0, crp_reply_pending = 1, crp_have_ep = 0, \n",
            "  crp_on_wire = 0, crp_refcount = 0, crp_opc_info = 0x13abbd0, crp_corpc_info = 0x0, crp_lock = 1, crp_reply_hdr = {cch_magic = 0, cch_version = 0, cch_opc = 0, cch_cksum = 0, cch_flags = 0, \n",
            "    cch_rank = 0, cch_grp_id = 0, cch_rc = 4294966263}, crp_req_hdr = {cch_magic = 2869690860, cch_version = 1, cch_opc = 4278190084, cch_cksum = 0, cch_flags = 0, cch_rank = 0, \n",
            "    cch_grp_id = 0, cch_rc = 0}, crp_coreq_hdr = {coh_int_grpid = 0, coh_bulk_hdl = 0x0, coh_excluded_ranks = 0x0, coh_inline_ranks = 0x0, coh_grp_ver = 0, coh_tree_topo = 0, coh_root = 0, \n",
            "    coh_padding = 0}}\n",
            "{noformat}\n",
            "\n",
            "debug log\n",
            "{noformat}\n",
            "05/24-15:48:45.61 boro-32 GRP  DBUG src/cart/crt_group.c:1854 crt_hdlr_uri_lookup() ul_grp_id daos_server matches with gg_srv_pri_grp daos_server.\n",
            "05/24-15:48:45.61 boro-32 RPC  DBUG src/cart/crt_rpc.c:559 crt_rpc_priv_alloc() entering (opc: 0xff000004)\n",
            "05/24-15:48:45.61 boro-32 RPC  DBUG src/cart/crt_register.c:325 crt_opc_lookup() looking up opcode: 0xff000004\n",
            "05/24-15:48:45.61 boro-32 RPC  DBUG src/cart/crt_rpc.c:574 crt_rpc_priv_alloc() alloc(calloc) 'rpc_priv': 824 at 0x7f8a9c990a70.\n",
            "05/24-15:48:45.61 boro-32 RPC  DBUG src/cart/crt_rpc.c:583 crt_rpc_priv_alloc() rpc_priv 0x7f8a9c990a70 (opc: 0xff000004), allocated.\n",
            "05/24-15:48:45.61 boro-32 RPC  DBUG src/cart/crt_rpc.c:1421 crt_req_send() rpc_priv 0x7f8a9c990a70 (opc: 0xff000004), addref to 2.\n",
            "05/24-15:48:45.61 boro-32 RPC  DBUG src/cart/crt_rpc.c:1445 crt_req_send() rpc_priv 0x7f8a9c990a70 submitted.\n",
            "05/24-15:48:45.61 boro-32 RPC  DBUG src/cart/crt_context.c:747 crt_context_req_track() bypass tracking for URI_LOOKUP.\n",
            "05/24-15:48:45.61 boro-32 RPC  DBUG src/cart/crt_rpc.c:1151 crt_req_ep_lc_lookup() free 'uri' at (nil).\n",
            "05/24-15:48:45.61 boro-32 HG   DBUG src/cart/crt_hg.c:218 crt_hg_pool_get() hg_pool 0x7f8a9c026138, remove, chp_num 15.\n",
            "05/24-15:48:45.61 boro-32 HG   DBUG src/cart/crt_hg.c:1245 crt_hg_req_send() rpc_priv 0x7f8a9c990a70 sent.\n",
            "05/24-15:48:45.61 boro-32 RPC  DBUG src/cart/crt_rpc.c:1477 crt_req_send() rpc_priv 0x7f8a9c990a70 (opc: 0xff000004), decref to 1.\n",
            "05/24-15:48:45.61 boro-32 HG   DBUG src/cart/crt_hg.c:1016 crt_rpc_handler_common() rpc_priv 0x7f8a9c0cf100 (opc: 0xff000004), decref to 0.\n",
            "05/24-15:48:45.61 boro-32 RPC  WARN src/cart/crt_rpc.c:771 crt_req_destroy() no reply sent for rpc_priv 0x7f8a9c0cf100 (opc: 0xff000004).\n",
            "05/24-15:48:45.61 boro-32 HG   ERR  src/cart/crt_hg_proc.c:866 crt_proc_out_common() RPC failed to execute on target. rpc_priv 0x7f8a9c0cf100,opc: 0xff000004, error code: -1033.\n",
            "05/24-15:48:45.61 boro-32 HG   DBUG src/cart/crt_hg.c:1351 crt_hg_reply_error_send() Sent CART level error message back to client. rpc_priv 0x7f8a9c0cf100, opc: 0xff000004, error_code: -1033.\n",
            "05/24-15:48:45.61 boro-32 RPC  DBUG src/cart/crt_rpc.c:603 crt_rpc_priv_free() free 'rpc_priv' at 0x7f8a9c0cf100.\n",
            "{noformat}\n",
            "\n",
            "It looks like in crt_hdlr_uri_lookup(), it should hold the request somehow before calling crt_uri_lookup_forward() and return, Otherwise cart will complain about the non-replied request, free (which caused the panic) and reply the failure, see log above.\n",
            ", Similarity: 0.2081\n",
            "Summary & Description: async iv update bulk completion \n",
            " currently during iv_update():\n",
            "\n",
            "    bulk_transfer completes - - > bulk_update_transfer_done() - -> on_update() + other things\n",
            "\n",
            "after this change:\n",
            "\n",
            "    bulk_transfer completes - - > user callback - - > create ULT to do (bulk_update_transfer_done() - -> on_update() + other things), then return\n",
            "\n",
            " , Similarity: 0.3102\n",
            "Summary & Description: ivns destroy callback \n",
            " Make iv namespace destroy call take an additional ‘destroy completion callback’. This callback would be called once namespace ref count reaches 0 so that daos would know when the namespace is actually destroyed. This is few-days worth of task, Similarity: 0.1555\n",
            "Summary & Description: srccartcrtcontextc877 void crtcontextrequntrackcrtrpct assertion epiepireqnum epiepireplynum failed \n",
            " I'm seeing the above assertion failure when running master cart with master IOF., Similarity: 0.3018\n",
            "Summary & Description: remove port number cart \n",
            " remove the need/ability to specify port number in crt_init(). Instead, mecury will pick port numbers by itself. This helps to avoid port conflicts., Similarity: 0.1904\n",
            "Summary & Description: cartctl get pidhostname rank \n",
            " Need new functionality on cart_ctl to return pid/hostname from a rank., Similarity: 0.1890\n",
            "Summary & Description: improve crtinit expanding add optionsenv flags \n",
            " Currently there are number of envariables (CRT_TIMEOUT) for example that can be only set via env and not through API.\n",
            "\n",
            "The proposal/idea is to add new crt_init_opt() that would take in additional struct crt_init_options, where those params could be specified at init time.\n",
            "\n",
            "This would also allow in future to add additional flags/settings at init time without modifying API, Similarity: 0.2483\n",
            "Summary & Description: add preforward callback corpc calls \n",
            " Add new pre-forward callback to CORPCs. This is needed by DAOS for future work on group-related/pool-map related stuff., Similarity: 0.2672\n",
            "Summary & Description: remove port number mercury address hash table \n",
            " update the address hash table in the mercury OFI plugin to not use port numbers in computing the key.\n",
            "\n",
            "Chat with Xeuzhao:\n",
            "\n",
            "another thing is for COPA provider does not enable the TCP/IP stack so cannot use the PORT\n",
            " \n",
            "fi_getname,and then fi_av_straddr sth like that\n",
            " \n",
            "within the OFI plugin, the address lookup cache also need change, as now it use the IP/PORT as key for the hash table. The reqhdr related handling also need change\n",
            " \n",
            "why is there a address hash table in th OFI plugin? does libfabric store the address internally?\n",
            "fi_av_insert will return a fi_addr, the hash table is to reuse it to avoid insert it every time \n",
            " \n",
            " \n",
            " , Similarity: 0.2463\n",
            "Summary & Description: optimize rpc timeout checkinghandling \n",
            " From Ashley:\n",
            "\n",
            "\"I did look at cart timeouts before and thought there could be an general improvement though, from memory it traverses the RPC list, works out how far each one is in the future and then picks the first one to wait on, however there's an improvement to be made because you don't actually need the one that's the shortest time in future (i.e, you don't need to compare against now every loop), you can simply work out the timeout trigger time (submission time + timeout) for each one, keep an ordered list and then wait for the first one.\n",
            "it should save a lot of list iteration, calls to get_time() and computing deltas.\"\n",
            "\n",
            " \n",
            "\n",
            " , Similarity: 0.1494\n",
            "Summary & Description: per context default timeouts \n",
            " Currently there's a default cart timeout (60 seconds), a environment variable to override this for the entire library, and a function call to change a RPC timeout after it's created but before it's sent.  A API to set the default timeout, either similar to how the environment variable works, or on a per-context or per opcode basis would be useful.\n",
            "\n",
            "Setting a timeout for every RPC in IOF would be both intrusive and error-prone, and it makes sense that there should be at least an API to mirror the environment variable., Similarity: 0.2513\n",
            "Summary & Description: client segfault remote eviction \n",
            " If a client is communicating with a remote process set, and there is an eviction in the remote set then the client will segfault in the eviction code, with a stack trace similar to the following\n",
            "\n",
            " \n",
            "\n",
            "(gdb) bt #0 0x00007f17aeba916c in crt_barrier_update_master (grp_priv=grp_priv@entry=0x1d2c3b0) at src/cart/crt_barrier.c:119 #1 0x00007f17aebaa252 in crt_barrier_handle_eviction (grp_priv=grp_priv@entry=0x1d2c3b0) at src/cart/crt_barrier.c:620 #2 0x00007f17aebc3363 in crt_rank_evict (grp=grp@entry=0x1d2c3c0, rank=0) at src/cart/crt_group.c:2792 #3 0x00007f17aebd838a in lm_sample_rpc_cb (cb_info=<optimized out>) at src/cart/crt_lm.c:767, Similarity: 0.1759\n",
            "Summary & Description: exclude ranks include failure ranks crtgroupcreate \n",
            " It seems excluded_ranks should include failure ranks during crt group creation.\n",
            "{noformat}\n",
            "        /* Construct an exclusion list for crt_corpc_req_create(). The exclusion\n",
            "         * list contains all live ranks minus non subgroup members so that the\n",
            "         * RPC is only sent to subgroup members.\n",
            "         */\n",
            "        default_gp_membs = default_grp_priv->gp_membs;\n",
            "        rc = d_rank_list_dup(&excluded_ranks, default_gp_membs);\n",
            "        if (rc != 0) {\n",
            "                D_ERROR(\"d_rank_list_dup() failed, rc %d\\n\", rc);\n",
            "                D_GOTO(out, rc);\n",
            "        }\n",
            "        d_rank_list_filter(member_ranks, excluded_ranks, true /* exlude */);\n",
            "\n",
            "        rc = crt_corpc_req_create(crt_ctx, NULL, excluded_ranks,\n",
            "                             CRT_OPC_GRP_CREATE, NULL, NULL, 0,\n",
            "                             crt_tree_topo(CRT_TREE_KNOMIAL, 4),\n",
            "                             &gc_corpc);\n",
            "        d_rank_list_free(excluded_ranks);\n",
            "{noformat}, Similarity: 0.0058\n",
            "Summary & Description: check doxygen comments formatting \n",
            " Ashley-ran Docoxygen against IOF, saw lots of warnings for undocumented items, consistency issues, and saw alot of markup was wrong.  Function in/out is being placed incorrectly.  Docoxygen most IOF and Cart comments are before detailed comments, but they're really brief comments and after line of code and so docs are showing up in the wrong place.  , Similarity: 0.3946\n",
            "Summary & Description: ivops might null handleivsyncresponse \n",
            " iv_ops might be NULL if isc_do_callback is false, Similarity: 0.1864\n",
            "Summary & Description: race iv namespace destroy iv rpc \n",
            " I got this issue while running daos rebuild tests\n",
            "Because rebuild test kills server nodes, I guess it triggered a corner case\n",
            "\n",
            "commit 99f8ecf4750bab1f1aa9615d24648cf5eddf91c5\n",
            "{quote}\n",
            "#0  0x00007f8d37b261f7 in raise () from /lib64/libc.so.6\n",
            "#1  0x00007f8d37b278e8 in abort () from /lib64/libc.so.6\n",
            "#2  0x00007f8d37b1f266 in __assert_fail_base () from /lib64/libc.so.6\n",
            "#3  0x00007f8d37b1f312 in __assert_fail () from /lib64/libc.so.6\n",
            "#4  0x00007f8d38fb8051 in crt_context_req_track (req=req@entry=0x7f8d254abee8) at src/cart/crt_context.c:739\n",
            "#5  0x00007f8d38fef23a in crt_req_send (req=0x7f8d254abee8, \n",
            "    complete_cb=complete_cb@entry=0x7f8d38fdbaa0 <handle_ivupdate_response>, arg=arg@entry=0x7f8d2548c440)\n",
            "    at src/cart/crt_rpc.c:1403\n",
            "#6  0x00007f8d38fda549 in crt_ivu_rpc_issue (dest_rank=<optimized out>, \n",
            "    iv_value=iv_value@entry=0x7f8cff03a760, sync_type=sync_type@entry=0x7f8cff03a630, root_rank=2, \n",
            "    cb_info=cb_info@entry=0x7f8d2548c440, iv_key=0x7f8cff03a6b0, iv_key=0x7f8cff03a6b0)\n",
            "    at src/cart/crt_iv.c:2158\n",
            "#7  0x00007f8d38fdc01c in crt_iv_update_internal (ivns=ivns@entry=0x7f8d24b6ea30, class_id=class_id@entry=0, \n",
            "    iv_key=iv_key@entry=0x7f8cff03a6b0, iv_value=0x7f8cff03a760, shortcut=<optimized out>, sync_type=..., \n",
            "    update_comp_cb=update_comp_cb@entry=0x406ee0 <runtime.makemap>, cb_arg=cb_arg@entry=0x7f8cff03a6d0, \n",
            "    iv_ver=<optimized out>) at src/cart/crt_iv.c:2550\n",
            "#8  0x00007f8d38fdfd00 in crt_iv_update (ivns=0x7f8d24b6ea30, class_id=0, iv_key=0x7f8cff03a6b0, \n",
            "    iv_ver=<optimized out>, iv_value=<optimized out>, shortcut=<optimized out>, sync_type=..., \n",
            "    update_comp_cb=0x406ee0 <runtime.makemap>, cb_arg=0x7f8cff03a6d0) at src/cart/crt_iv.c:2598\n",
            "{quote}, Similarity: 0.2759\n",
            "Summary & Description: shutting rank0 causes rpc timeouts sending ranks \n",
            " Multi-iv server case. \n",
            "\n",
            "3 Instances of iv_server run on the same node\n",
            "iv_client sends shutdown to rank 0\n",
            "attempt to send shutdown to rank 1 timesout with:\n",
            "\n",
            "RPC  ERR  src/cart/crt_context.c:696 crt_context_timeout_check() rpc_priv 0x1a922e0 (status: 62) (opc 0xb5) timed out, tgt rank 1, tag 0.\n",
            "RPC  ERR  src/cart/crt_context.c:639 crt_req_timeout_hdlr() rpc opc: 0xb5 timedout due to URI_LOOKUP to group crt_default_srv_group, rank 1 through PSR 0 timedout.\n",
            "RPC  ERR  src/cart/crt_rpc.c:953 crt_req_uri_lookup_psr_cb() rpc_priv 0x1a92f20(opc: 0xffff0102), failed cci_rc: -1011.\n",
            "\n",
            "\n",
            "Shutting down in the order with rank 0 being last works as expected., Similarity: 0.1608\n",
            "Summary & Description: dranklistcopy unsafe \n",
            " There's a function exported by CaRT but only used in daos to copy rank lists.  The code looks at the length of the source list and copies the list to the dest, without knowing or checking the length of the dest array.\n",
            "\n",
            "An initial fix is to modify the code so that the copy will only happen if the dest list is bigger than the source list, however this has the effect of truncating the apparent size of the dest group, so it's possible that subsequent copies will fail.\n",
            "\n",
            "A complete fix would be to ensure that the list size is always correct, which would mean that list_copy() needed to perform an allocation, or to track both array size and current length in d_list_t, Similarity: 0.2054\n",
            "Summary & Description: dvlog434 write failed 9bad file descriptor \n",
            " I'm having reports of the above error from a user, trying to find more information now., Similarity: 0.3240\n",
            "Summary & Description: iv bidirectional flag issues update \n",
            " crt_fetch_update called with:\n",
            "\n",
            "ivs_mode = CRT_IV_SYNC_LAZY;\n",
            "\n",
            "ivs_event = CRT_IV_SYNC_EVENT_UPDATE;\n",
            "\n",
            "ivs_flags = CRT_IV_SYNC_BIDIRECTIONAL;\n",
            "\n",
            " \n",
            "\n",
            "Causes the following sequence of called where rank 3 is the originator and rank 1 is the root:\n",
            "\n",
            "3: ON GET - PERM 2;\n",
            "\n",
            "ON UPDATE, num_oids = 50;\n",
            "\n",
            "3: IDs not available, FORWARD 1000 oids\n",
            "\n",
            "3: ON PUT \n",
            "\n",
            "1: ON GET - PERM 2 \n",
            "\n",
            "ON UPDATE, num_oids = 1000 \n",
            "\n",
            "ROOT MAX_OID = 0 \n",
            "\n",
            "1: ON REFRESH 0 \n",
            "\n",
            "1: ON PUT \n",
            "\n",
            "3: ON REFRESH 0 \n",
            "\n",
            "3: ON PUT\n",
            "\n",
            " \n",
            "\n",
            "The first on_put on rank 3 should not be called, Similarity: 0.2395\n",
            "Summary & Description: investigate whether use pmix reference server \n",
            " If we can get this to work, it would remove complication and a lot of time from our full builds\n",
            "\n",
            "https://pmix.org/support/how-to/running-apps-under-psrvr/\n",
            "\n",
            "However, we need to investigate how it affects MPI applications using cart.  \n",
            "\n",
            "This actually brings up a point about applications that use cart on the client.   They may very well have a different stack that isn't compatible with ours.   We may need a different library for client vs server or alternatively we may need to dlopen some of our dependencies.  One example of this would be pmix.   We don't really need pmix in a singleton client so some of the issues may go away by simply removing it as a default dependence., Similarity: 0.3928\n",
            "Summary & Description: kw fix pthreadmutexlock klockwork issues \n",
            " Recent klockwork scan complains about return codes not being checked from various pthread locking/unlocking routines such as pthread_mutex_lock/unlock, spinlocks, rwlocks etc..\n",
            ", Similarity: 0.2360\n",
            "Summary & Description: iv fix iv headers \n",
            " iv.h contains number of incorrect references to wrong args, typos, wrong description of on_refresh() return value, Similarity: 0.2738\n",
            "Summary & Description: libgurtso undefined reference pthreadrwlockrdlock \n",
            " I'm unable to compile IOF on ubuntu because of the above compile error.  It looks like -lpthread is missing from the libgurt compile line., Similarity: 0.4951\n",
            "Summary & Description: public api conversion primary group ranks subgroup ranks \n",
            " Add provide user-facing api to convert from subgroup rank to primary group rank and other way around., Similarity: 0.2211\n",
            "Summary & Description: enable sending rpcs local subgroups \n",
            " As of now a rank is not allowed to send RPCs to local subgroups. Add support to enable this., Similarity: 0.1045\n",
            "Summary & Description: generate random port number \n",
            " There were cases where two service ranks running on the same node gets\n",
            "the same port number. This patch calls the python function to generate a\n",
            "random port number then pass it to the cart_test_corpc_version test., Similarity: 0.1761\n",
            "Summary & Description: iv cleanup grouprelated code \n",
            " With internal group_priv being kept now, no need to store a duplicate of rank and group size. , Similarity: 0.1260\n",
            "Summary & Description: iv ns attach causes grp ref count go without release \n",
            " attachment/creation of namespace with a group causes group lookup which increments group ref count. this must be decremented at namespace destroy time, Similarity: 0.1755\n",
            "Summary & Description: need cart api export crtglobalns \n",
            " DAOS needs an API to retrieve the global ivns from the cart, instead of always get it from the creation. So DAOS can sync the ivns if the ivns already exist., Similarity: 0.4434\n",
            "Summary & Description: crtglobalns properly put inside rpc \n",
            " During iv ns setup, it needs to transfer crt_global_ns to other nodes, but it is  internal in cart, \n",
            "\n",
            "{noformat}\n",
            "/* Structure for storing/passing of global namespace */\n",
            "struct crt_global_ns {\n",
            "        /* Namespace ID */\n",
            "        struct crt_ivns_id      gn_ivns_id;\n",
            "        /* Number of classes for this namespace; used for sanity check */\n",
            "        uint32_t                gn_num_class;\n",
            "        /* Associated tree topology */\n",
            "        int                     gn_tree_topo;\n",
            "        /* Associated group ID */\n",
            "        /* TODO: user internal group id */\n",
            "        crt_group_id_t          gn_grp_id;\n",
            "};\n",
            "{noformat}\n",
            "\n",
            "and the last item (crt_group_id_t) is a char *, which makes it impossible to put it DAOS RPC., Similarity: 0.2477\n",
            "Summary & Description: update testcartlibsh \n",
            " update test_cart_lib.sh to match the new installation tree., Similarity: 0.2874\n",
            "Summary & Description: update readmeenv reflect dlogfile dlogmask \n",
            " update README.ENV to reflect the change from CRT_LOG_FILE to D_LOG_FILE and from CRT_LOG_MASK to D_LOG_MASK, Similarity: 0.2878\n",
            "Summary & Description: remove progress callback use pmix callback fire eviction broadcasts \n",
            " remove the progress callback, use the pmix callback to fire eviction broadcasts, Similarity: 0.0999\n",
            "Summary & Description: return failure efault ivns found \n",
            " If ivns can not be found inside hdlr_iv_xxx(), let's return EFAULT to the caller, which will decide how to deal with., Similarity: 0.2806\n",
            "Summary & Description: segfault inside crtrankevicted \n",
            " In some negative testing (send RPC to a dead node), met segfault:\n",
            "\n",
            "Core was generated by `./crt_echo_cli'.\n",
            "Program terminated with signal 11, Segmentation fault.\n",
            "#0  0x00007fc41473805b in pthread_rwlock_rdlock () from /lib64/libpthread.so.0\n",
            "Missing separate debuginfos, use: debuginfo-install glibc-2.17-196.el7.x86_64 libevent-2.0.21-4.el7.x86_64 libgcc-4.8.5-16.el7.x86_64 libibverbs-13-7.el7.x86_64 libnl3-3.2.28-4.el7.x86_64 librdmacm-13-7.el7.x86_64 libuuid-2.23.2-43.el7.x86_64 numactl-libs-2.0.9-6.el7_2.x86_64 openssl-libs-1.0.2k-8.el7.x86_64 zlib-1.2.7-17.el7.x86_64\n",
            "(gdb) bt\n",
            "#0  0x00007fc41473805b in pthread_rwlock_rdlock () from /lib64/libpthread.so.0\n",
            "#1  0x00007fc414966b96 in crt_rank_evicted (grp=<optimized out>, rank=0) at src/cart/crt_group.c:2579\n",
            "#2  0x00007fc4149683d0 in crt_hg_req_send_cb (hg_cbinfo=0x7ffef4fd5c10) at src/cart/crt_hg.c:1107\n",
            "#3  0x00007fc413e1b6eb in hg_forward_cb (callback_info=0x7ffef4fd5cb0) at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury.c:826\n",
            "#4  0x00007fc413e222f9 in hg_core_trigger_entry (hg_handle=0x2147620) at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury_core.c:2856\n",
            "#5  hg_core_trigger (context=context@entry=0x2142ce0, timeout=timeout@entry=0, max_count=max_count@entry=4294967295, actual_count=actual_count@entry=0x7ffef4fd5d3c)\n",
            "    at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury_core.c:2731\n",
            "#6  0x00007fc413e22e8b in HG_Core_trigger (context=context@entry=0x2142ce0, timeout=timeout@entry=0, max_count=max_count@entry=4294967295, \n",
            "    actual_count=actual_count@entry=0x7ffef4fd5d3c) at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury_core.c:4263\n",
            "#7  0x00007fc413e1dda5 in HG_Trigger (context=context@entry=0x2142ce0, timeout=timeout@entry=0, max_count=max_count@entry=4294967295, actual_count=actual_count@entry=0x7ffef4fd5d3c)\n",
            "    at /home/xliu9/src/daos_m/_build.external/mercury/src/mercury.c:1761\n",
            "#8  0x00007fc414967e5a in crt_hg_trigger (hg_ctx=<optimized out>) at src/cart/crt_hg.c:1293\n",
            "#9  0x00007fc4149576d8 in crt_progress (crt_ctx=0x213da80, timeout=timeout@entry=1000000, cond_cb=cond_cb@entry=0x0, arg=arg@entry=0x0) at src/cart/crt_context.c:1041\n",
            "#10 0x0000000000401ecc in client_wait (num_retries=num_retries@entry=120, wait_len_ms=wait_len_ms@entry=1000, complete_flag=0x605350 <gecho+16>) at src/test/crt_echo_cli.c:52\n",
            "#11 0x0000000000402131 in run_client () at src/test/crt_echo_cli.c:160\n",
            "#12 0x000000000040190b in main (argc=1, argv=<optimized out>) at src/test/crt_echo_cli.c:413\n",
            "(gdb) f 1\n",
            "#1  0x00007fc414966b96 in crt_rank_evicted (grp=<optimized out>, rank=0) at src/cart/crt_group.c:2579\n",
            "2579\t\tpthread_rwlock_rdlock(grp_priv->gp_rwlock_ft);\n",
            "(gdb) p grp_priv\n",
            "$1 = (struct crt_grp_priv *) 0x212d050\n",
            "(gdb) p grp_priv->gp_rwlock_ft\n",
            "$2 = (pthread_rwlock_t *) 0x0\n",
            "(gdb) p *grp_priv->gp_rwlock_ft\n",
            "Cannot access memory at address 0x0\n",
            ", Similarity: 0.2802\n",
            "Summary & Description: update mercury \n",
            " latest mercury removed HG_Init_na() which cart uses. Update cart to use the new HG_Init_opt() function., Similarity: 0.1762\n",
            "Summary & Description: update latest mercury \n",
            " CaRT no longer compiles against latest mercury and hasn't since October 24, probably as a result of this commit.\n",
            "\n",
            "https://github.com/mercury-hpc/mercury/commit/09b2eeae4a4a67acfddf8f337962c3dadbdde235\n",
            "\n",
            "The latest build of CaRT to succeed was https://localhost:8445/job/cart-master/arch=x86_64,distro=el7/1068/, Similarity: 0.1995\n",
            "Summary & Description: perrpc peeraddr struct mercury \n",
            " When testing cart over ofi+sockets I identified that some code is being executed in the OFI layer, seemingly for every rpc.\n",
            "\n",
            "The code in question is na_ofi_handle_recv_event() is na_ofi.c, and in particular it's calling na_ofi_addr_alloc() for every RPC, and then using snprintf()/strdup() to populate the nao_uri variable for each RPC.\n",
            "\n",
            "By simply removing the snprintf/strup() calls I can increase the number of IOPs we get in IOF by 100%\n",
            "\n",
            "A easy fix would be to modify na_ofi_addr_to_string() to only create the URL on demand (it doesn't appear to ever be used), however there is also a hash table that is being used to cache the srt_addr in this code so potentially there is room to add peer_addr to the hash table.  I do wonder though why we're creating a new endpoint per RPC, it seems like this should be established once at startup, doing this kind of lookup per RPC is obviously significant overhead., Similarity: 0.2073\n",
            "Summary & Description: cart wont build without optimisation enabled \n",
            " Whilst trying to profile cart I removed the -O2 -g3 and tried to compile with just -g however the code fails to build with linker errors in this case.\n",
            "\n",
            "It's only the testing code so it might be enough to always add -O2 to test code., Similarity: 0.3414\n",
            "Summary & Description: iv clientserver tests create wrapper script iv clientserver runs tests \n",
            " Needs to be structured so that it will be easy to run with TestRunner later. , Similarity: 0.3813\n",
            "Summary & Description: cart tests run continuous hides program error codes \n",
            " In the test/commontestsuite.py file the code to build the orterun command line adds a --continuous option, which tells ORTE not to terminate other processes if one fails.  This may be needed for HA tests where processes are expected to exit but it has the side-effect in normal use that it causes orterun to always return 0, leading false positives., Similarity: 0.1473\n",
            "Summary & Description: refcount assertion srccartcrtgroupc806 \n",
            " src/cart/crt_group.c:806 gc_add_child_rpc() 0x23608b0 addref from zero\n",
            "\n",
            "I've seen a failure in CI which does not appear related to the change being tested, my change is https://review.whamcloud.com/#/c/30367/ which affects RPC timeout, something which should not happen in the co-rpc test.\n",
            "\n",
            "The first testing run failed on one host with an assertion relating to RPC ref counts, the relevant lines of the debug log are:\n",
            "\n",
            "12/05-10:38:34.80 ec946b17f683 CaRT[1389] RPC  DBUG src/cart/crt_rpc.c:1131 crt_req_hg_addr_lookup() rpc_priv 0x23608b0 (opc: 0xffff0001), addref to 5.\n",
            "12/05-10:38:34.80 ec946b17f683 CaRT[1389] HG   DBUG src/cart/crt_hg.c:223 crt_hg_pool_get() hg_pool 0x213efa8, remove, chp_num 14.\n",
            "12/05-10:38:34.80 ec946b17f683 CaRT[1389] HG   DBUG src/cart/crt_hg.c:1171 crt_hg_req_send() rpc_priv 0x23608b0 sent.\n",
            "12/05-10:38:34.80 ec946b17f683 CaRT[1389] RPC  DBUG src/cart/crt_rpc.c:820 crt_req_hg_addr_lookup_cb() rpc_priv 0x23608b0 (opc: 0xffff0001), decref to 3.\n",
            "12/05-10:38:34.80 ec946b17f683 CaRT[1389] RPC  DBUG src/cart/crt_rpc.c:1628 timeout_bp_node_exit() rpc_priv 0x23608b0 (opc 0xffff0001) exiting the timeout binheap.\n",
            "12/05-10:38:34.80 ec946b17f683 CaRT[1389] RPC  DBUG src/cart/crt_context.c:490 crt_req_timeout_untrack() rpc_priv 0x23608b0 (opc: 0xffff0001), decref to 2.\n",
            "12/05-10:38:34.80 ec946b17f683 CaRT[1389] RPC  DBUG src/cart/crt_context.c:837 crt_context_req_untrack() rpc_priv 0x23608b0 (opc: 0xffff0001), decref to 1.\n",
            "12/05-10:38:34.80 ec946b17f683 CaRT[1389] RPC  DBUG src/cart/crt_hg.c:1150 crt_hg_req_send_cb() rpc_priv 0x23608b0 (opc: 0xffff0001), decref to 0.\n",
            "12/05-10:38:34.80 ec946b17f683 CaRT[1389] HG   DBUG src/cart/crt_hg.c:257 crt_hg_pool_put() hg_pool 0x213efa8, add, chp_num 15.\n",
            "12/05-10:38:34.80 ec946b17f683 CaRT[1389] HG   DBUG src/cart/crt_hg.c:1044 crt_hg_req_destroy() rpc_priv 0x23608b0, hg_hdl 0x233cb90 put to pool.\n",
            "12/05-10:38:34.80 ec946b17f683 CaRT[1389] RPC  DBUG src/cart/crt_rpc.c:1338 crt_req_send() rpc_priv 0x23608b0 (opc: 0xffff0001), decref to 4.\n",
            "12/05-10:38:34.80 ec946b17f683 CaRT[1389] GRP  EMRG src/cart/crt_group.c:806 gc_add_child_rpc() 0x23608b0 addref from zero\n",
            "\n",
            "There are clearly multiple threads operating here as the decref to 4 is logged after the decref to 0, so threading is an issue but by the time the group code tries to take a reference the RPC has already been cancelled.\n",
            "\n",
            "Retriggering the job caused it to pass so this is a race condition that open happens occasionally., Similarity: 0.1107\n",
            "Summary & Description: lm code sending resample timeout nonlm rpcs \n",
            " The LM code is automatically sending a resample RPC for every timeout to a remote group, regardless of the flags for the RPC causing the timeout.\n",
            "\n",
            "On timeout it should check the RPC flags, and only send a RPC if required., Similarity: 0.0692\n",
            "Summary & Description: lm code accessing groups free \n",
            " The LM code can send a RPC to resample the status of a remote group, but it does not take a reference on the local handle so it's possible that when the RPC reply is received the group has been freed.\n",
            "\n",
            "The simple fix would be to add reference counting so that we could delay releasing the group, however an alternative fix would be to cancel all RPCs to the group as part of detach.\n",
            "\n",
            "In fact, regardless of any LM code we should be canceling all pending RPCs anyway., Similarity: 0.1416\n",
            "Summary & Description: significant performance drop increasing repetitions selftest \n",
            " The same test runs on the same set of nodes (one client, one server), exactly same parameters except \"repetitions\"\n",
            "* repetitions=10000\n",
            "{quote}self_test --group-name daos_server --endpoint 0:0 --message-sizes b1048576:0 --max-inflight-rpcs 8 --repetitions 10000\n",
            " \tRPC Bandwidth (MB/sec): 11779.94\n",
            "\tRPC Throughput (RPCs/sec): 11780{quote}\n",
            "* repetitions=100000\n",
            "{quote}self_test --group-name daos_server --endpoint 0:0 --message-sizes b1048576:0 --max-inflight-rpcs 8 --repetitions 100000\n",
            "\tRPC Bandwidth (MB/sec): 6358.02\n",
            "\tRPC Throughput (RPCs/sec): 6358{quote}\n",
            ", Similarity: 0.1619\n",
            "Summary & Description: selftest caused serverside dead lock running multiple selftest client bulk testing \n",
            " When running multiple self_test processes with bulk, it possible cause service-side dead lock:\n",
            "\n",
            "(gdb) bt\n",
            "#0  0x00007f7153bf7371 in sigwait () from /lib64/libpthread.so.0\n",
            "#1  0x000000000040418f in main (argc=<optimized out>, argv=<optimized out>) at src/server/init.c:386\n",
            "(gdb) info thread\n",
            "  Id   Target Id         Frame \n",
            "  20   Thread 0x7f714e477700 (LWP 156567) \"daos_server\" 0x00007f7153bf698d in accept () from /lib64/libpthread.so.0\n",
            "  19   Thread 0x7f7147fff700 (LWP 156569) \"daos_server\" 0x00007f71534b9a3d in poll () from /lib64/libc.so.6\n",
            "  18   Thread 0x7f7129d37700 (LWP 156570) \"daos_server\" 0x00007f71534c4923 in epoll_wait () from /lib64/libc.so.6\n",
            "  17   Thread 0x7f7123fff700 (LWP 156571) \"daos_server\" 0x00007f7153bf32ae in pthread_rwlock_wrlock () from /lib64/libpthread.so.0\n",
            "  16   Thread 0x7f7121ffd700 (LWP 156572) \"daos_server\" 0x00007f7153bf32ae in pthread_rwlock_wrlock () from /lib64/libpthread.so.0\n",
            "  15   Thread 0x7f711bfff700 (LWP 156573) \"daos_server\" 0x00007f7153bf32ae in pthread_rwlock_wrlock () from /lib64/libpthread.so.0\n",
            "  14   Thread 0x7f711a7fd700 (LWP 156574) \"daos_server\" 0x00007f7153bf32ae in pthread_rwlock_wrlock () from /lib64/libpthread.so.0\n",
            "  13   Thread 0x7f7118ffb700 (LWP 156575) \"daos_server\" 0x00007f7153bf32ae in pthread_rwlock_wrlock () from /lib64/libpthread.so.0\n",
            "  12   Thread 0x7f7106ffe700 (LWP 156576) \"daos_server\" 0x00007f7153bf32ae in pthread_rwlock_wrlock () from /lib64/libpthread.so.0\n",
            "  11   Thread 0x7f71057fc700 (LWP 156577) \"daos_server\" 0x00007f7153bf32ae in pthread_rwlock_wrlock () from /lib64/libpthread.so.0\n",
            "  10   Thread 0x7f7104ffb700 (LWP 156578) \"daos_server\" 0x00007f7153bf32ae in pthread_rwlock_wrlock () from /lib64/libpthread.so.0\n",
            "  9    Thread 0x7f70fdffd700 (LWP 156579) \"daos_server\" 0x00007f7153bf32ae in pthread_rwlock_wrlock () from /lib64/libpthread.so.0\n",
            "  8    Thread 0x7f70f3fff700 (LWP 156580) \"daos_server\" 0x00007f7153bf32ae in pthread_rwlock_wrlock () from /lib64/libpthread.so.0\n",
            "  7    Thread 0x7f70f27fd700 (LWP 156581) \"daos_server\" 0x00007f7153bf32ae in pthread_rwlock_wrlock () from /lib64/libpthread.so.0\n",
            "  6    Thread 0x7f70f0ffb700 (LWP 156582) \"daos_server\" 0x00007f7153bf32ae in pthread_rwlock_wrlock () from /lib64/libpthread.so.0\n",
            "  5    Thread 0x7f70deffe700 (LWP 156583) \"daos_server\" 0x00007f7153bf32ae in pthread_rwlock_wrlock () from /lib64/libpthread.so.0\n",
            "  4    Thread 0x7f70dd7fc700 (LWP 156584) \"daos_server\" 0x00007f7153bf32ae in pthread_rwlock_wrlock () from /lib64/libpthread.so.0\n",
            "  3    Thread 0x7f70dcffb700 (LWP 156585) \"daos_server\" 0x00007f7153bf32ae in pthread_rwlock_wrlock () from /lib64/libpthread.so.0\n",
            "  2    Thread 0x7f70d5ffd700 (LWP 156586) \"daos_server\" 0x00007f7153bf32ae in pthread_rwlock_wrlock () from /lib64/libpthread.so.0\n",
            "* 1    Thread 0x7f715511cc80 (LWP 156565) \"daos_server\" 0x00007f7153bf7371 in sigwait () from /lib64/libpthread.so.0\n",
            "(gdb) t 17\n",
            "[Switching to thread 17 (Thread 0x7f7123fff700 (LWP 156571))]\n",
            "#0  0x00007f7153bf32ae in pthread_rwlock_wrlock () from /lib64/libpthread.so.0\n",
            "(gdb) bt\n",
            "#0  0x00007f7153bf32ae in pthread_rwlock_wrlock () from /lib64/libpthread.so.0\n",
            "#1  0x00007f71548bdb65 in crt_self_test_close_session_handler (rpc_req=0x7f711c1b9cd8) at src/cart/crt_self_test_service.c:403\n",
            "#2  0x00007f71548b7890 in crt_handle_rpc (arg=0x7f711c1b9c80) at src/cart/crt_rpc.c:1566\n",
            "#3  0x00007f71539d9708 in ABTD_thread_func_wrapper () from /home/xliu9/src/daos_m/install/lib/libabt.so.0\n",
            "#4  0x00007f71539d9c91 in make_fcontext () from /home/xliu9/src/daos_m/install/lib/libabt.so.0\n",
            "#5  0x0000000000000000 in ?? ()\n",
            "(gdb) f 1\n",
            "#1  0x00007f71548bdb65 in crt_self_test_close_session_handler (rpc_req=0x7f711c1b9cd8) at src/cart/crt_self_test_service.c:403\n",
            "403\t\tret = pthread_rwlock_wrlock(&g_all_session_lock);\n",
            "(gdb) p g_all_session_lock\n",
            "$1 = {__data = {__lock = 0, __nr_readers = 90, __readers_wakeup = 4, __writer_wakeup = 72, __nr_readers_queued = 0, __nr_writers_queued = 16, __writer = 0, __shared = 0, __pad1 = 0, \n",
            "    __pad2 = 0, __flags = 0}, __size = \"\\000\\000\\000\\000Z\\000\\000\\000\\004\\000\\000\\000H\\000\\000\\000\\000\\000\\000\\000\\020\", '\\000' <repeats 34 times>, __align = 386547056640}\n",
            ", Similarity: 0.2802\n",
            "Summary & Description: assertion dlogrefcount 0 failed failed selftest running \n",
            " 11/27-08:45:37.15 boro-61 CaRT[129077] HG   ERR  # NA -- Error -- /home/xliu9/src/daos_m/_build.external/mercury/src/na/na_ofi.c:1866\n",
            " # na_ofi_initialize(): init_info->max_contexts 16 exceed limitation 3.\n",
            "11/27-08:45:38.10 boro-61 CaRT[129064] HG   ERR  # NA -- Error -- /home/xliu9/src/daos_m/_build.external/mercury/src/na/na.c:371\n",
            " # NA_Initialize_opt(): Could not initialize plugin\n",
            "11/27-08:45:38.10 boro-61 CaRT[129064] HG   ERR  src/cart/crt_hg.c:571 crt_hg_init() Could not initialize NA class.\n",
            "11/27-08:45:38.10 boro-61 CaRT[129064] MISC ERR  src/cart/crt_init.c:237 crt_init() crt_hg_init failed rc: -1020.\n",
            "11/27-08:45:38.10 boro-61 CaRT[129064] MISC ERR  src/cart/crt_init.c:286 crt_init() crt_init failed, rc: -1020.\n",
            "11/27-08:45:38.10 boro-61 CaRT[129064] ST   ERR  src/self_test/self_test.c:127 self_test_init() crt_init failed; ret = -1020\n",
            "11/27-08:45:38.10 boro-61 CaRT[129064] ST   ERR  src/self_test/self_test.c:766 run_self_test() self_test_init failed; ret = -1020\n",
            "11/27-08:45:38.10 boro-61 CaRT[129064] RPC  ERR  src/cart/crt_context.c:353 crt_context_destroy() invalid parameter (NULL crt_ctx).\n",
            "11/27-08:45:38.10 boro-61 CaRT[129064] ST   ERR  src/self_test/self_test.c:971 run_self_test() crt_context_destroy failed; ret = -1003\n",
            "11/27-08:45:38.10 boro-61 CaRT[129064] MISC ERR  src/cart/crt_init.c:357 crt_finalize() cannot finalize before initializing.\n",
            "11/27-08:45:38.10 boro-61 CaRT[129064] MISC ERR  src/cart/crt_init.c:424 crt_finalize() crt_finalize failed, rc: -1015.\n",
            "\n",
            "\n",
            "Core was generated by `./self_test --group-name daos_server --endpoint 0 0 --message-sizes 0 --max-inf'.\n",
            "Program terminated with signal 6, Aborted.\n",
            "#0  0x00007f44f92651f7 in raise () from /lib64/libc.so.6\n",
            "Missing separate debuginfos, use: debuginfo-install glibc-2.17-196.el7.x86_64 libevent-2.0.21-4.el7.x86_64 libgcc-4.8.5-16.el7.x86_64 libibverbs-13-7.el7.x86_64 libnl3-3.2.28-4.el7.x86_64 librdmacm-13-7.el7.x86_64 libuuid-2.23.2-43.el7.x86_64 numactl-libs-2.0.9-6.el7_2.x86_64 zlib-1.2.7-17.el7.x86_64\n",
            "(gdb) bt\n",
            "#0  0x00007f44f92651f7 in raise () from /lib64/libc.so.6\n",
            "#1  0x00007f44f92668e8 in abort () from /lib64/libc.so.6\n",
            "#2  0x00007f44f925e266 in __assert_fail_base () from /lib64/libc.so.6\n",
            "#3  0x00007f44f925e312 in __assert_fail () from /lib64/libc.so.6\n",
            "#4  0x00007f44fa2f79d7 in d_log_fini () at src/gurt/debug.c:179\n",
            "#5  0x0000000000401719 in main (argc=<optimized out>, argv=<optimized out>) at src/self_test/self_test.c:1841\n",
            "(gdb) f 4\n",
            "#4  0x00007f44fa2f79d7 in d_log_fini () at src/gurt/debug.c:179\n",
            "179\t\tD_ASSERT(d_log_refcount > 0);\n",
            "(gdb) p d_log_refcount\n",
            "$1 = 0\n",
            "\n",
            "self_test: src/gurt/debug.c:179: d_log_fini: Assertion `d_log_refcount > 0' failed., Similarity: 0.2668\n",
            "Summary & Description: race condition iv processing pending requests \n",
            " Pending requests in IV can have an occasional race condition causing pending request being added while they are being processed at the same time. This series of events can cause pending requests to be left in queue without being processed, Similarity: 0.1699\n",
            "Summary & Description: iv clientserver tests send result fetch request back client \n",
            " Primary work here is coming up with a good format to print all the data returned from the fetch. \n",
            "\n",
            "Idea: \n",
            "Fetch:        md5sum        number of vectors        size of vector, vector\n",
            "\n",
            "Needs to be a reasonable format that will be compatible with update also. , Similarity: 0.3513\n",
            "Summary & Description: iv clientserver tests add rpc shutdown iv server \n",
            " Want to be able to shutdown individual servers, not all servers. , Similarity: 0.2430\n",
            "Summary & Description: deadlock crtcontxtdestroy open rpcs \n",
            " We're experimenting with IOF shutdown and have some race conditions which we need to capture.  Currently we use context_destroy() and pass false to \"force\" however if we change this to true then we see the stack-trace below.\n",
            "\n",
            "0x00007f299a78842d in __lll_lock_wait () from /lib64/libpthread.so.0\n",
            "Missing separate debuginfos, use: debuginfo-install glibc-2.17-196.el7.x86_64 libevent-2.0.21-4.el7.x86_64 libgcc-4.8.5-16.el7.x86_64 libibverbs-13-7.el7.x86_64 libnl3-3.2.28-4.el7.x86_64 librdmacm-13-7.el7.x86_64 libtool-ltdl-2.4.2-22.el7_3.x86_64 libuuid-2.23.2-43.el7.x86_64 zlib-1.2.7-17.el7.x86_64\n",
            "(gdb) bt\n",
            "#0  0x00007f299a78842d in __lll_lock_wait () from /lib64/libpthread.so.0\n",
            "#1  0x00007f299a783dcb in _L_lock_812 () from /lib64/libpthread.so.0\n",
            "#2  0x00007f299a783c98 in pthread_mutex_lock () from /lib64/libpthread.so.0\n",
            "#3  0x00007f299a536a07 in crt_context_timeout_check (crt_ctx=0xbc6bf0) at src/cart/crt_context.c:646\n",
            "#4  0x00007f299a5366d6 in crt_progress (crt_ctx=<optimized out>, timeout=1, cond_cb=0x0, arg=0x0) at src/cart/crt_context.c:1029\n",
            "#5  0x00007f299a534fd1 in crt_ctx_epi_abort (rlink=<optimized out>, arg=<optimized out>) at src/cart/crt_context.c:338\n",
            "#6  0x00007f299a31fcc1 in d_chash_table_traverse (htable=0xbc6c68, cb=0x7f299a534ba0 <crt_ctx_epi_abort>, arg=0x7ffe4aceae0c) at src/gurt/hash.c:734\n",
            "#7  0x00007f299a534a2b in crt_context_destroy (crt_ctx=0xbc6bf0, force=1) at src/cart/crt_context.c:371\n",
            "#8  0x0000000000412fd8 in iof_finish (arg=0xb06c50) at src/ioc/ioc_main.c:1699\n",
            "#9  0x000000000040afea in main () at src/cnss/cnss.c:784\n",
            "(gdb) q\n",
            "A debugging session is active., Similarity: 0.3811\n",
            "Summary & Description: crtivparentget asserts root killed call \n",
            " IV generates an assert if the root node for IV value is killed right before crt_iv_parent_get() is issued internally. , Similarity: 0.1563\n",
            "Summary & Description: add crtbarrier fault tolerance tests \n",
            " This task is for addition of crt_barrier fault tolerance tests. Tests envisioned are:\n",
            "\n",
            "- Start servers on 3 nodes, kill rank=1, issue barrier\n",
            "\n",
            "- Start servers on 3 nodes. On rank=0 issue crt_barrier, sleep 1, kill rank0. On other nodes issue crt_barrier upon notification of rank0 eviction. This will test new barrier master selection upon the death of rank 0 (barrier master is chosen to be lowest rank alive).\n",
            "\n",
            ", Similarity: 0.1954\n",
            "Summary & Description: crtbarrier eviction code called \n",
            " Eviction handling code in crt_barrier()  (crt_barrier_handle_eviction) is not called anywhere. This makes barrier code not handle a case of 'barrier master' rank being evicted. , Similarity: 0.0028\n",
            "Summary & Description: crtbarrier hits assert corpc node dead \n",
            " crt_barrier hits assert in knomial tree if one of the nodes is dead when barrier is issued.\n",
            "This issue is caused by CART-348.\n",
            "\n",
            "This task is to workaround CART-348 issue by changing crt_barrier's corpc to use KARY instead of KNOMIAL tree, Similarity: 0.1988\n",
            "Summary & Description: knomial tree topology results assert corpcs \n",
            " Using knomial tree occasionally results in asserts during CORPCs when some nodes are dead.\n",
            "\n",
            "Experiment:\n",
            "Run process set on 3 nodes. Kill rank 1. Perform corpc from rank0 using knomial tree topology.\n",
            "The resultant assert will be seen:\n",
            "src/cart/crt_tree_knomial.c:141: crt_knomial_get_children_cnt: Assertion `grp_root < grp_size && grp_self < grp_size' failed.\n",
            "\n",
            "Changing knomial tree to kary causes the proper behavior.\n",
            "\n",
            "\n",
            "Backtrace of the failure using CPPR as a test:\n",
            "#2  0x00007f59d661c566 in __assert_fail_base () from /lib64/libc.so.6\n",
            "#3  0x00007f59d661c612 in __assert_fail () from /lib64/libc.so.6\n",
            "#4  0x00007f59d7036f7f in crt_knomial_get_children_cnt (\n",
            "    grp_size=<optimized out>, tree_ratio=<optimized out>,\n",
            "    grp_root=<optimized out>, grp_self=<optimized out>,\n",
            "    nchildren=<optimized out>) at src/cart/crt_tree_knomial.c:141\n",
            "#5  0x00007f59d7035ca2 in crt_tree_get_children (grp_priv=0x241a750,\n",
            "    grp_ver=<optimized out>, exclude_ranks=0x0, tree_topo=<optimized out>,\n",
            "    root=0, self=2,\n",
            "    children_rank_list=children_rank_list@entry=0x7f59cb3fd880,\n",
            "    ver_match=ver_match@entry=0x7f59cb3fd87f) at src/cart/crt_tree.c:255\n",
            "#6  0x00007f59d700b926 in crt_corpc_req_hdlr (req=req@entry=0x7f5988000fa8)\n",
            "    at src/cart/crt_corpc.c:768\n",
            "#7  0x00007f59d700dfd3 in crt_corpc_initiate (\n",
            "    rpc_priv=rpc_priv@entry=0x7f5988000f50) at src/cart/crt_corpc.c:146\n",
            "#8  0x00007f59d700e3cb in crt_corpc_common_hdlr (rpc_priv=0x7f5988000f50)\n",
            "    at src/cart/crt_corpc.c:316\n",
            "#9  0x00007f59d701af65 in crt_rpc_handler_common (hg_hdl=<optimized out>)\n",
            "    at src/cart/crt_hg.c:945\n",
            "#10 0x00007f59d63e41c5 in hg_core_process (hg_handle=0x2484960)\n",
            "    at /var/lib/jenkins/wolf-50vm2-jenkins-2-1-el7-x8664/workspace/mercury-updat                                                                                                             ---Type <return> to continue, or q <return> to quit---\n",
            "e-scratch/mercury/src/mercury_core.c:2155\n",
            "#11 hg_core_trigger_entry (hg_handle=0x2484960)\n",
            "    at /var/lib/jenkins/wolf-50vm2-jenkins-2-1-el7-x8664/workspace/mercury-update-scratch/mercury/src/mercury_core.c:2684\n",
            "#12 hg_core_trigger (context=context@entry=0x245fc90, timeout=timeout@entry=0,\n",
            "    max_count=max_count@entry=4294967295,\n",
            "    actual_count=actual_count@entry=0x7f59cb3fdccc)\n",
            "    at /var/lib/jenkins/wolf-50vm2-jenkins-2-1-el7-x8664/workspace/mercury-update-scratch/mercury/src/mercury_core.c:2621\n",
            "#13 0x00007f59d63e4ceb in HG_Core_trigger (context=context@entry=0x245fc90,\n",
            "    timeout=timeout@entry=0, max_count=max_count@entry=4294967295,\n",
            "    actual_count=actual_count@entry=0x7f59cb3fdccc)\n",
            "    at /var/lib/jenkins/wolf-50vm2-jenkins-2-1-el7-x8664/workspace/mercury-update-scratch/mercury/src/mercury_core.c:4073\n",
            "#14 0x00007f59d63dfe65 in HG_Trigger (context=context@entry=0x245fc90,\n",
            "    timeout=timeout@entry=0, max_count=max_count@entry=4294967295,\n",
            "    actual_count=actual_count@entry=0x7f59cb3fdccc)\n",
            "    at /var/lib/jenkins/wolf-50vm2-jenkins-2-1-el7-x8664/workspace/mercury-update-scratch/mercury/src/mercury.c:1731\n",
            "#15 0x00007f59d701888a in crt_hg_trigger (hg_ctx=0x245aae8)\n",
            "    at src/cart/crt_hg.c:1275\n",
            "#16 0x00007f59d70096b0 in crt_progress (crt_ctx=0x245aad0, timeout=100000,\n",
            "    cond_cb=0x0, arg=0x0) at src/cart/crt_context.c:1034\n",
            "---Type <return> to continue, or q <return> to quit---\n",
            "#17 0x00007f59d3224eda in __context0_progress (data=0x0)\n",
            "    at src/common/cppr_request.cpp:1416\n",
            "#18 0x00007f59d7258dc5 in start_thread () from /lib64/libpthread.so.0\n",
            "#19 0x00007f59d66e4ced in clone () from /lib64/libc.so.6\n",
            ", Similarity: 0.1492\n",
            "Summary & Description: make list progress callbacks contextspecific \n",
            " Right now the list of progress callbacks is global, and is only executed by in context 0. This patch changes the list to be per context so that every context can execute callbacks, and they can have different lists., Similarity: 0.2360\n",
            "Summary & Description: fix ivclient app failure start \n",
            " With recent changes to cart iv_client is failing to start during group attach due to context0 not being present at that time., Similarity: 0.3983\n",
            "Summary & Description: hg handle leak rpc failure \n",
            " It appears that if a RPC fails immediately after it is received then a hg handle is assigned to it but never released.  This can be reproduced by sending a RPC which is registered on the origin but not the server, in this case both the client and server behave as expected however there is a error about leaked handles when the server comes to shutdown.\n",
            "\n",
            "I have a reproducer for this which I'll upload., Similarity: 0.1830\n",
            "Summary & Description: valgrind errors full debug enabled \n",
            " In IOF we're seeing occasional failures with valgrind errors in CI, however without a complete stack trace.\n",
            "\n",
            "Normal code is OK however we see errors if we turn DEBUG=DEBUG on sles builds systems, and only on PMIx ras subscribers ranks., Similarity: 0.3768\n",
            "Summary & Description: iv clientserver needs proper cleanup code pass valgrindmemcheck \n",
            " Ramp up on IV by adding it to the test framework and modifying it such that all the memory is properly cleaned up when it shuts down. , Similarity: 0.3874\n",
            "Summary & Description: test crtrpcfeatnotimeout \n",
            " Write a CI test for CART-331., Similarity: 0.1536\n",
            "Summary & Description: rpc refcount problem leading accessafterdeletedouble free \n",
            " In master IOF code I'm seeing a refcount problem with RPCs in cart where the refcount drops to zero incorrectly, leading to the RPC being freed incorrectly.\n",
            "\n",
            "I'm still working on a reliable reproducer however it appears to be as simple as launch IOF and then run \"find\" against a projection.  We recently turned on client-side threading although I don't know if that had an impact.\n",
            "\n",
            "{{11/06-10:52:07.73 lin01 CaRT[9808] MEM  DBUG src/cart/crt_rpc.c:533, alloc 'rpc_priv': 760 at 0x7fa5e80255e0.\n",
            "11/06-10:52:07.73 lin01 CaRT[9808] RPC  DBUG src/cart/crt_rpc.c:542 crt_rpc_priv_alloc() rpc_priv 0x7fa5e80255e0 (opc: 0x10f02), allocated.\n",
            "11/06-10:52:07.75 lin01 CaRT[9808] RPC  DBUG src/cart/crt_rpc.c:693 crt_req_set_endpoint() rpc_priv 0x7fa5e80255e0 ep modified 0.0.\n",
            "11/06-10:52:07.77 lin01 CaRT[9808] RPC  DBUG src/cart/crt_rpc.c:1302 crt_req_send() rpc_priv 0x7fa5e80255e0 submitted.\n",
            "11/06-10:52:07.77 lin01 CaRT[9808] RPC  DBUG src/cart/crt_context.c:701 crt_context_req_track() rpc_priv 0x7fa5e80255e0 (opc: 0x10f02), addref to 2.\n",
            "11/06-10:52:07.77 lin01 CaRT[9808] RPC  DBUG src/cart/crt_context.c:459 crt_req_timeout_track() rpc_priv 0x7fa5e80255e0 (opc: 0x10f02), addref to 3.\n",
            "11/06-10:52:07.77 lin01 CaRT[9808] RPC  DBUG src/cart/crt_rpc.c:1611 timeout_bp_node_enter() rpc_priv 0x7fa5e80255e0 (opc 0x10f02) entering the timeout binheap.\n",
            "11/06-10:52:07.77 lin01 CaRT[9808] HG   DBUG src/cart/crt_hg.c:1163 crt_hg_req_send() rpc_priv 0x7fa5e80255e0 sent.\n",
            "11/06-10:52:07.77 lin01 CaRT[9808] RPC  DBUG src/cart/crt_rpc.c:752 crt_req_addref() rpc_priv 0x7fa5e80255e0 (opc: 0x10f02), addref to 4.\n",
            "11/06-10:52:07.77 lin01 CaRT[9808] RPC  DBUG src/cart/crt_rpc.c:1627 timeout_bp_node_exit() rpc_priv 0x7fa5e80255e0 (opc 0x10f02) exiting the timeout binheap.\n",
            "11/06-10:52:07.77 lin01 CaRT[9808] RPC  DBUG src/cart/crt_context.c:490 crt_req_timeout_untrack() rpc_priv 0x7fa5e80255e0 (opc: 0x10f02), decref to 3.\n",
            "11/06-10:52:07.77 lin01 CaRT[9808] RPC  DBUG src/cart/crt_context.c:784 crt_context_req_untrack() rpc_priv 0x7fa5e80255e0 (opc: 0x10f02), decref to 2.\n",
            "11/06-10:52:07.77 lin01 CaRT[9808] RPC  DBUG src/cart/crt_hg.c:1142 crt_hg_req_send_cb() rpc_priv 0x7fa5e80255e0 (opc: 0x10f02), decref to 1.\n",
            "11/06-10:52:07.86 lin01 CaRT[9808] RPC  DBUG src/cart/crt_rpc.c:770 crt_req_decref() rpc_priv 0x7fa5e80255e0 (opc: 0x10f02), decref to 0.\n",
            "11/06-10:52:07.86 lin01 CaRT[9808] HG   DBUG src/cart/crt_hg.c:1041 crt_hg_req_destroy() rpc_priv 0x7fa5e80255e0, hg_hdl 0x1799a50 put to pool.\n",
            "11/06-10:52:07.86 lin01 CaRT[9808] MEM  DBUG src/cart/crt_rpc.c:564, free 'rpc_priv' at 0x7fa5e80255e0.\n",
            "11/06-10:52:08.44 lin01 CaRT[9808] MEM  DBUG src/ioc/ops/readdir.c:435, alloc 'buf': 4096 at 0x7fa5e80255e0.\n",
            "11/06-10:52:08.45 lin01 CaRT[9808] MEM  DBUG src/ioc/ops/readdir.c:539, free 'buf' at 0x7fa5e80255e0.\n",
            "11/06-10:52:09.11 lin01 CaRT[9808] MEM  DBUG src/ioc/ops/readdir.c:435, alloc 'buf': 4096 at 0x7fa5e80255e0.\n",
            "11/06-10:52:09.12 lin01 CaRT[9808] MEM  DBUG src/ioc/ops/readdir.c:539, free 'buf' at 0x7fa5e80255e0.\n",
            "11/06-10:52:09.43 lin01 CaRT[9808] MEM  DBUG src/ioc/ops/readdir.c:435, alloc 'buf': 4096 at 0x7fa5e80255e0.\n",
            "11/06-10:52:09.43 lin01 CaRT[9808] MEM  DBUG src/ioc/ops/readdir.c:539, free 'buf' at 0x7fa5e80255e0.\n",
            "11/06-10:52:10.17 lin01 CaRT[9808] MEM  DBUG src/cart/crt_rpc.c:533, alloc 'rpc_priv': 760 at 0x7fa5e80255e0.\n",
            "11/06-10:52:10.17 lin01 CaRT[9808] RPC  DBUG src/cart/crt_rpc.c:542 crt_rpc_priv_alloc() rpc_priv 0x7fa5e80255e0 (opc: 0x10f02), allocated.\n",
            "11/06-10:52:10.19 lin01 CaRT[9808] RPC  DBUG src/cart/crt_rpc.c:693 crt_req_set_endpoint() rpc_priv 0x7fa5e80255e0 ep modified 0.0.\n",
            "11/06-10:52:10.28 lin01 CaRT[9808] RPC  DBUG src/cart/crt_rpc.c:1302 crt_req_send() rpc_priv 0x7fa5e80255e0 submitted.\n",
            "11/06-10:52:10.28 lin01 CaRT[9808] RPC  DBUG src/cart/crt_context.c:701 crt_context_req_track() rpc_priv 0x7fa5e80255e0 (opc: 0x10f02), addref to 2.\n",
            "11/06-10:52:10.28 lin01 CaRT[9808] RPC  DBUG src/cart/crt_context.c:459 crt_req_timeout_track() rpc_priv 0x7fa5e80255e0 (opc: 0x10f02), addref to 3.\n",
            "11/06-10:52:10.28 lin01 CaRT[9808] RPC  DBUG src/cart/crt_rpc.c:1611 timeout_bp_node_enter() rpc_priv 0x7fa5e80255e0 (opc 0x10f02) entering the timeout binheap.\n",
            "11/06-10:52:10.28 lin01 CaRT[9808] RPC  DBUG src/cart/crt_rpc.c:1627 timeout_bp_node_exit() rpc_priv 0x7fa5e80255e0 (opc 0x10f02) exiting the timeout binheap.\n",
            "11/06-10:52:10.28 lin01 CaRT[9808] RPC  DBUG src/cart/crt_context.c:490 crt_req_timeout_untrack() rpc_priv 0x7fa5e80255e0 (opc: 0x10f02), decref to 2.\n",
            "11/06-10:52:10.28 lin01 CaRT[9808] RPC  DBUG src/cart/crt_context.c:784 crt_context_req_untrack() rpc_priv 0x7fa5e80255e0 (opc: 0x10f02), decref to 1.\n",
            "11/06-10:52:10.28 lin01 CaRT[9808] RPC  DBUG src/cart/crt_hg.c:1142 crt_hg_req_send_cb() rpc_priv 0x7fa5e80255e0 (opc: 0x10f02), decref to 0.\n",
            "11/06-10:52:10.28 lin01 CaRT[9808] HG   DBUG src/cart/crt_hg.c:1041 crt_hg_req_destroy() rpc_priv 0x7fa5e80255e0, hg_hdl 0x7fa5d8022430 put to pool.\n",
            "11/06-10:52:10.28 lin01 CaRT[9808] MEM  DBUG src/cart/crt_rpc.c:564, free 'rpc_priv' at 0x7fa5e80255e0.\n",
            "11/06-10:52:10.28 lin01 CaRT[9808] HG   DBUG src/cart/crt_hg.c:1163 crt_hg_req_send() rpc_priv 0x7fa5e80255e0 sent.\n",
            "11/06-10:52:10.28 lin01 CaRT[9808] RPC  DBUG src/cart/crt_rpc.c:752 crt_req_addref() rpc_priv 0x7fa5e80255e0 (opc: 0x10f02), addref to 1.\n",
            "11/06-10:52:10.32 lin01 CaRT[9808] RPC  DBUG src/cart/crt_rpc.c:770 crt_req_decref() rpc_priv 0x7fa5e80255e0 (opc: 0x10f02), decref to 0.\n",
            "11/06-10:52:10.32 lin01 CaRT[9808] HG   DBUG src/cart/crt_hg.c:1041 crt_hg_req_destroy() rpc_priv 0x7fa5e80255e0, hg_hdl 0x7fa5d8022430 put to pool.\n",
            "11/06-10:52:10.32 lin01 CaRT[9808] MEM  DBUG src/cart/crt_rpc.c:564, free 'rpc_priv' at 0x7fa5e80255e0.\n",
            "}}, Similarity: 0.2994\n",
            "Summary & Description: hash table decref count \n",
            " The way fuse operates it performs lots of lookups, each taking a reference and then batch-drops all references at once so a version of d_chash_rec_decref() which takes an additional count parameter would be useful.\n",
            "\n",
            "Currently we are just using a loop around d_chash_rec_decref() however this takes an additional lock every iteration., Similarity: 0.0660\n",
            "Summary & Description: gurt hash duplicate dchashrecinsert unique0 causes undefined behavior \n",
            " When calling d_chash_rec_insert (with unique = 0), the hash table accepts the insertion but causes problems later. For example, if you run d_chash_table_traverse, it loops forever finding the same keys over and over.\n",
            "\n",
            "There's another function, d_chash_rec_find_insert, which first searches for an existing value (rlink) in the table and returns that if it exists, otherwise inserts. \n",
            "\n",
            "Instead of current behavior it should probably do one of the following things: \n",
            "- Remove unique argument, consider it always unique = 1 to prevent duplicate inserts\n",
            "- Treat duplicate inserts of same key as update instead, Similarity: 0.0363\n",
            "Summary & Description: allow bcast piggyback flag destroy group \n",
            " For example in daos usage, ds_pool_svc_destroy firstly bcast a RDB_STOP rpc, and when it finished destroy the pool group. This actually involved two times bcast.\n",
            "\n",
            "allow bcast to piggyback a flag to destroy the group can save one bcast in that case., Similarity: 0.1483\n",
            "Summary & Description: overhaul crtreqaddrefdecref usage throughout codebase \n",
            " Looking through the code there is a lot of inconsistency with how addref and decref are handled on RPCs.  There are two functions which are part of the public API and both return error codes, crt_req_addref() only returns an error if NULL is passed, crt_req_decref() returns an error on NULL, and doesn't currently but as an improvement cound return -DER_PROTO if crt_reply_send() wasn't called.  Both of these functions log with D_ERROR() if they return non-zero.\n",
            "\n",
            "Throughout the code most invocations of these function do not check the return code, but among the call sites that do many log the error, again with D_ERROR() and then drop it, although one or two do propagate the decref() error.\n",
            "\n",
            "I propose adding RPC_ADDREF() and RPC_DECREF() macros to be used internally that would modify the reference count in sites where there is a rpc_priv pointer anyway, and remove all additional code to log addref/decref errors outside of these macros (rpc_priv pointers are heavily checked for NULL anyway so it's incredibly unlikely that they would ever fire).\n",
            "\n",
            "Call sites that do not hold a rpc_priv pointer, for example the lookup/corpc code build build on top of RPCs rather than handle the internals would continue to call the public functions.\n",
            "\n",
            "As a big advantage to this the addref/decref logging code would show the actual file/line numbers where the references were being held which would be a big improvement in logging., Similarity: 0.1591\n",
            "Summary & Description: applications need way keep progressing queue empty \n",
            " When CaRT does a broadcast, the handler is invoked before reply aggregation occurs.   This is problematic for shutdown RPCs which initiate a shutdown sequence after executing the handler, potentially stopping the progress thread.\n",
            "\n",
            "The current workaround is to call crt_progress in a loop with a long timeout (e.g. 1 second) and loop until it returns -DER_TIMEDOUT.   This workaround allows the reply aggregation to execute so that a reply gets sent to the parent before the process stops calling crt_progress.   It works fairly well in practice but this same code is duplicated throughout numerous projects and this should be handled in cart.  We either need a way to flush the queue when shutting down or a flag to crt_destroy that does the same., Similarity: 0.1807\n",
            "Summary & Description: crtreplysend allocating memory \n",
            " I had a local failure whilst testing IOF and it appears that crt_reply_send() allocates memory in order to perform the operation.\n",
            "\n",
            "Investigate this, and remove the memory operations if possible., Similarity: 0.2284\n",
            "Summary & Description: flag allow infinite timeout per rpc \n",
            " add a flag to crt_req_send() to set infinite timeout. \n",
            "\n",
            "/param infinite_timeout [IN]        when false, use the global timeout for this RPC\n",
            "                                                   when true, this RPC never times out. Instead, when the global timeout is reached, we check for any errors. If no error is reported, we reset the elapsed time \n",
            "                                                   so this RPC will wait for the global timeout to expire again.\n",
            "int crt_req_send(crt_rpc_t *req, bool infinite_timeout, crt_cb_t complete_cb, void *arg);\n",
            "\n",
            ", Similarity: 0.0320\n",
            "Summary & Description: gurt hash addrefdecref take release refcount free \n",
            " Insert elements  \n",
            "Lookup elements and add references to them  \n",
            "Decref elements  \n",
            "Walk hash table and make sure it is empty, Similarity: 0.1953\n",
            "Summary & Description: gurt hash addrefdecref parallel tests \n",
            " Insert elements\n",
            "Lookup elements and add varying references to them\n",
            "Delete them from hash table and verify they haven't been free'd (no segfault)\n",
            "Free elements, Similarity: 0.2278\n",
            "Summary & Description: gurt hash readwrite lock parallel simultaneous insertlookupdelete \n",
            " Create with read/write lock\n",
            "Parallel:\n",
            "  Insert entries many times on one thread, updating their values each time\n",
            "  Look up random entries until insert thread completes\n",
            "  Remove random entries at the same time as they are inserted on another thread\n",
            "Look up entries and see that they either have the final value or zero\n",
            "Walk table and ensure only final value or zero key/value pairs\n",
            "Free, Similarity: 0.1443\n",
            "Summary & Description: gurt hash readwrite lock parallel insertlookupdelete \n",
            " Create with read/write lock\n",
            "Parallel:\n",
            "  Insert entries\n",
            "Walk nodes and count 64k\n",
            "Parallel:\n",
            "  Look up all entries randomly, lookups each on a different thread\n",
            "Parallel:\n",
            "  Remove entries\n",
            "Walk nodes and count 0\n",
            "Free, Similarity: 0.1849\n",
            "Summary & Description: gurt hash simple insert lookup update delete test \n",
            " Create\n",
            "Insert 64k entries\n",
            "Walk nodes and count 64k\n",
            "Look up all 64k entries randomly\n",
            "Update all 64k entries randomly\n",
            "Look up all 64k entries randomly\n",
            "Remove 64k entries\n",
            "Walk nodes and count 0Free, Similarity: 0.1265\n",
            "Summary & Description: gurt hash empty table test \n",
            " Create\n",
            "Walk nodes and verify there are none\n",
            "Look up random entries and verify none succeed\n",
            "Remove random entries\n",
            "Free, Similarity: 0.0611\n",
            "Summary & Description: create way test dalloc failures \n",
            " Iterate over allocation failures (or perhaps random)\n",
            "\n",
            "Maybe some config also to allow failure after a specific number of calls to D_ALLOC in a particular place. , Similarity: 0.1423\n",
            "Summary & Description: add unit tests iof mempool \n",
            " src/common/include/iof_pool.h, Similarity: 0.3078\n",
            "Summary & Description: skip evicted ranks crttreexxx functions \n",
            " skip locally known evicted ranks in crt_tree_xxx functions, i.e.\n",
            "\n",
            "crt_tree_get_nchildren()\n",
            "\n",
            "crt_tree_get_children()\n",
            "\n",
            "crt_tree_get_parent(), Similarity: 0.0780\n",
            "Summary & Description: add tests crtgroupcreate \n",
            " Add tests for crt_group_create, Similarity: 0.1727\n",
            "Summary & Description: add tests fault tolerance cart tree apis \n",
            " Should skip nodes that are dead\n",
            ", Similarity: 0.2708\n",
            "Summary & Description: add tests corpc \n",
            " Need to check coverage vs what Nayan already did, Similarity: 0.1214\n",
            "Summary & Description: add tests fault tolerance eviction callbacks \n",
            " LM Attach\n",
            "Resample membership list on RPC timeout\n",
            "PSR Failover, Similarity: 0.1178\n",
            "Summary & Description: fix race condition writtingreading singleton attach info file \n",
            " to generate the singleton attach info file, we should write a temporary file and rename it. this way we avoid the race condition where the client comes to read the file when server has created it but hasn't written anything to it., Similarity: 0.2926\n",
            "Summary & Description: met assertion inside crtcontextdestroy \n",
            " as topic, Similarity: 0.1133\n",
            "Summary & Description: make resample timeout optional \n",
            " do not enable resample-on-timeout on clients by default. make it optional for each service process set the client attaches to., Similarity: 0.1992\n",
            "Summary & Description: iv fault tolerance fetch path \n",
            " Fault tolerance/node death handling for IV fetch path., Similarity: 0.3189\n",
            "Summary & Description: add tests crttree functions \n",
            " Especially focus on when nodes are excluded, Similarity: 0.1618\n",
            "Summary & Description: unify name callback arguments arg \n",
            " the code currently uses arg, args, priv as the names for the argument to callback functions in various places. We should unify them to one name: arg., Similarity: 0.1616\n",
            "Summary & Description: memory allocation functionslogging \n",
            " As discussed on the CaRT call the extra size parameter to C_FREE() provides little benefit, it is not needed in userspace and we don't currently have any tools to track it it's correct.  The suspicion is that were the value ever to be discovered to be incorrect it would be a bug in the size tracking itself, rather than in cart.\n",
            "\n",
            "Userspace tools (memcheck specifically) provide a much better job of identifying the types of error that this was intended to help with and removing this would both simplify the code and make logging clearer., Similarity: 0.2409\n",
            "Summary & Description: hash table crtregisterc \n",
            " There is code in crt_register.c which very closely resembles the hash table code, if this is actually then opcodes should be migrated to use the existing hash table implementation rather than implementing it's own.\n",
            "\n",
            "As opcodes are integers it may be better to implement a binary tree rather than a hash table and then migrate crt_register.c to use that., Similarity: 0.1444\n",
            "Summary & Description: gurt hash table improvements \n",
            " Add a couple of new features to gurt hash table:\n",
            "* a new feature bit \"ephemeral\", which means the hash table will not take refcount on elements, so an element will be atomically removed from the hash table on the last decref()\n",
            "* a new function find_insert(), it try to returns the element with the provided key, or insert the input element if the key can't be found in the hash table., Similarity: 0.1156\n",
            "Summary & Description: deadlock crtgrpattach \n",
            " On updating IOF to latest cart 53e36b0278976c6120c43816b448bf20926cf0c5 we're seeing a deadlock in iof when attaching to a process set with > 1.\n",
            "\n",
            "{{(gdb) bt\n",
            "#0  0x00007f1f0895ea0b in do_futex_wait.constprop.1 () from /lib64/libpthread.so.0\n",
            "#1  0x00007f1f0895ea9f in __new_sem_wait_slow.constprop.0 () from /lib64/libpthread.so.0\n",
            "#2  0x00007f1f0895eb3b in sem_wait@@GLIBC_2.2.5 () from /lib64/libpthread.so.0\n",
            "#3  0x00007f1f0872be24 in lm_grp_priv_init (grp=<optimized out>, grp=<optimized out>) at src/cart/crt_lm.c:974\n",
            "#4  crt_lm_attach (tgt_grp=0x13a5090, lm_grp_priv=0x7fffd33fd910) at src/cart/crt_lm.c:1273\n",
            "#5  0x00007f1f08719d63 in crt_grp_attach (srv_grpid=0x13a4be0 \"IONSS\", attached_grp=0x7fffd33fd970) at src/cart/crt_group.c:1889\n",
            "#6  0x00007f1f0871960d in crt_group_attach (srv_grpid=0x13a4be0 \"IONSS\", attached_grp=0x1394720) at src/cart/crt_group.c:1764\n",
            "#7  0x0000000000412f6a in attach_group (iof_state=0x12e6e50, group=0x1394720, id=0) at src/ioc/ioc_main.c:314\n",
            "#8  0x000000000040f236 in iof_reg (arg=0x12e6e50, cb=0x13081c0, cb_size=104) at src/ioc/ioc_main.c:683\n",
            "#9  0x0000000000407d75 in main () at src/cnss/cnss.c:675\n",
            "(gdb) q}}, Similarity: 0.3988\n",
            "Summary & Description: enable lm plugin cart default \n",
            " currently the cart user have to call crt_lm_init() to enable the lm plugin. This change enables the lm plugin in crt_init(), and the crt_lm_init() and crt_lm_finalize() are not public any more., Similarity: 0.3618\n",
            "Summary & Description: add atomics header gurt \n",
            " Rather than using gcc intrinsics, we should have a header in gurt that abstracts compiler specific atomic intrinisics.  , Similarity: 0.1129\n",
            "Summary & Description: add pmix notification test \n",
            " the PMIx notification feature in ompi/pmix is not very stable. We need a CI test to indicate if a ompi build works for PMIx notifications. I've been testing it by hand, it is time consuming., Similarity: 0.2925\n",
            "Summary & Description: eviction callback triggered crtrankevict \n",
            " add a function to allow the user to register rank eviction callbacks. the callbacks will be triggered by crt_rank_evict()., Similarity: 0.0394\n",
            "Summary & Description: hash table hashing function giving memcheck errors \n",
            " The default hashing function for the hash table in libpouch is returning undefined data according to valgrind, which then leads to memcheck errors when it comes to the list manipulation code (presumably because memcheck thinks idx isn't properly defined).\n",
            "\n",
            "I strongly suspect this warning is benign however it is throwing errors which is causing test failures.\n",
            "\n",
            "Possible fixes are:\n",
            "# Require a user-provided hashing function\n",
            "# Change the default hashing function\n",
            "# Annotate the source to instruct valgrind that it's defined.\n",
            "# Add suppressions for the warnings., Similarity: 0.2696\n",
            "Summary & Description: neither cart pouch libraries built version numbers \n",
            " Looking through the build files it appears neither libcart or libpouch are built with shared library versioning enabled.\n",
            "\n",
            "This should be fixed, look at the IOF build for an example of how to do this in scons., Similarity: 0.4088\n",
            "Summary & Description: cart header files individually includable \n",
            " Some CaRT header files have dependencies on system headers that are not included in the header file thus forcing users to include system headers unrelated to their code\n",
            "\n",
            "To fix this, we should ensure that each public header file can be included without any other headers.\n",
            "\n",
            "In other words, if a user only includes cart/types.h, the shouldn't need to include other cart headers or any system headers.   Currently, cart/types.h requires uuid/uuid.h to be included first.\n",
            "\n",
            "Aside from the fix, we should have a test that checks each file individually for \"leaks\"., Similarity: 0.2678\n",
            "Summary & Description: hash table traversedrain function \n",
            " I want to be able to iterate a hash table on shutdown to correctly free any still active resources.\n",
            "\n",
            "The traverse function nearly lets me do this however it's not safe to remove entries during the traverse callback so whilst I can use this to release other resources I can't use it to free hash table entries themselves.\n",
            "\n",
            "[~accountid:60357e4f25b84e00693d0050] suggested the possibility of changing the API to allow passing NULL into rec_find() to fetch a pointer to the first entry allowing the user to loop, fetching and deleting entries until empty.  This is one possibility although it might be simpler to have a separate function specifically for this use case., Similarity: 0.1804\n",
            "Summary & Description: let servers sign pmix notifications \n",
            " right now every service process signs up for PMIx notifications. The correct behaviour is only a subset should sign up., Similarity: 0.2184\n",
            "Summary & Description: cart tests deterministic \n",
            " CaRT tests make use of sleep for synchronizations\n",
            "\n",
            "Example:\n",
            "\n",
            "crt_req_send(/* shutdown rpc */);\n",
            "sleep(1);\n",
            "/* cleanup and exit */\n",
            "\n",
            "Not only is this inefficient but it is also racy and error prone and will lead to non-deterministic results.   Longer sleeps are not the option as they are even worse.\n",
            "\n",
            "We need to make a pass through existing tests to remove such sleeps and make use of the callbacks provided to ensure completion of rpcs.   Tests should be fully deterministic as long as the machine is in a reasonable state (e.g. no node/network failures), Similarity: 0.1299\n",
            "Summary & Description: iv inconsistent onrefresh invocation \n",
            " on_refresh() callback is not called consistently on the originator node.\n",
            "\n",
            "If originator is not root then (once the value is returned) the call sequence is:\n",
            "on_refresh()\n",
            "fetch_completion_callback()\n",
            "on_put()\n",
            "\n",
            "If however the originator ended up serving the value then the call sequence ends up being:\n",
            "fetch_completion_callback()\n",
            "on_put()\n",
            "\n",
            "Such inconsistency causes problems when actions are to be performed during on_refresh()\n",
            "\n",
            ", Similarity: 0.2125\n",
            "Summary & Description: update ompi \n",
            " Update ompi to the tip of master. We want this to get PMIx notification working. Ralph just pushed a fix to ompi so we can build it with external pmix. this has been failing in Jenkins since July 15. , Similarity: 0.3024\n",
            "Summary & Description: port mempool iof cart \n",
            " port the mempool implementation in IOF to libpouch. The IOF code is in:\n",
            "src/common/iof_pool.c\n",
            "src/common/iof_pool.h\n",
            "the IOF ticket is : IOF-533\n",
            "gerrit page is https://review.whamcloud.com/#/c/27871/7\n",
            "\n",
            "After reading the code I think if I copy the code to CART then change the function names, mempool should just work.\n",
            "\n",
            "two possible ajustments:\n",
            "1) add a magic number or type ID for each type to ensure a memory object is always released to the matching pool\n",
            "2) Add a new struct to free the user from defining a new struct containing a crt_list_t field. i.e.\n",
            "    struct mem_obj {\n",
            "        void                *ptr; // pointer to user's memory\n",
            "        crt_list_t           crt_list_t link;\n",
            "}, Similarity: 0.4872\n",
            "Summary & Description: selftest test ci running whats intended \n",
            " Looking at the code in test/cart_self_test.py there are a list of message sizes listed, the intention being that self-test should iterate over them and produce a number for each.\n",
            "\n",
            "It seems that a combination of the way python is handling arguments and the getopt code in self_test itself is meaning these aren't getting parsed correctly however so only two sets of values from the list are being executed.\n",
            "\n",
            "In addition the tests are being run with full debug logs enabled which means the output is mixed with debug logs.\n",
            "\n",
            "A combination of these two factors mean it's not currently possible to observe the CaRT performance by looking at the CI results., Similarity: 0.1272\n",
            "Summary & Description: move pmixregistereventhandler pmixinit \n",
            " Currently  PMIx_Register_event_handler() is called before PMIx_Init(). swap the order., Similarity: 0.2393\n",
            "Summary & Description: second call crtreqsend waits existing presubmitted lookup rpc \n",
            " if many back-to-back RPCs are sent to the same target for the first time, only the first RPC should try to resolve the target address, all subsequent calls to crt_req_send() should waits for the existing, pre-submitted lookup RPC., Similarity: 0.1103\n",
            "Summary & Description: iv call onrefresh return failed fetch \n",
            " on_refresh() callback is currently only invoked on the way down from root if the fetch was successful. \n",
            "This ticket is to change the behavior to always call on_refresh() on the way down from root. In case of a failure a null iv_value will be supplied to indicate the failure.\n",
            "\n",
            "This change is required for potential cleanup that the node has to do during fetch-return cycle., Similarity: 0.2158\n",
            "Summary & Description: memory leaks collective operations \n",
            " There appears to be a resource leak in the collective code in CaRT, a change to IOF to use multiple processes in CI has meant that IOF tests are failing with memcheck errors which appear to originate from cart.\n",
            "\n",
            "The changeset that triggers this problem is at https://review.whamcloud.com/#/c/28258/\n",
            "\n",
            "Here's an extract from the Jenkins error page.\n",
            "   fun:calloc\n",
            "   fun:crt_tree_get_children\n",
            "   fun:crt_corpc_req_hdlr\n",
            "   fun:crt_req_send\n",
            "   fun:cnss_detach_handler\n",
            "   fun:crt_rpc_common_hdlr\n",
            "   fun:crt_rpc_handler_common\n",
            "   fun:hg_core_process\n",
            "   fun:hg_core_trigger_entry\n",
            "   fun:hg_core_trigger\n",
            "   fun:crt_hg_trigger\n",
            "   fun:crt_progress\n",
            "   fun:progress_thread\n",
            "   fun:start_thread\n",
            "\n",
            "Set as priority Major as this is blocking IOF progress currently.\n",
            ", Similarity: 0.3771\n",
            "Summary & Description: per bucket locks hash table \n",
            " The hash table code in cart_util currently uses a lock per hash table however this could be changed to use a hash per bucket for reduced contention between threads, Similarity: 0.1709\n",
            "Summary & Description: clarify function used \n",
            " Add more description to crt_api.h to clarify whether each function can be called i.e. on server side, on client side or on both sides, Similarity: 0.2264\n",
            "Summary & Description: iv fetch path leaks rpc handle intermediate nodes \n",
            " IV fetch path leaks rpc handles when there is an intermediate node involved between requestor and root. rpc handle gets leaked on the intermediate node, Similarity: 0.2824\n",
            "Summary & Description: iv propagate timeout error back fetchdone callback \n",
            " Propagate cart errors such as timeout back to the fetch completion callback to allow client to handle node-death situations, Similarity: 0.2378\n",
            "Summary & Description: reduce memory allocations rpcs \n",
            " Reduce the malloc/free calls in the standard-path RPC code.\n",
            "\n",
            "* Remove the separate allocations for RPC, input and output buffers and replace with a single allocation (on both origin and target)\n",
            "* Create a crt_req_create_inplace() function to allow allocation less sends from the origin.\n",
            "\n",
            "This will help in a number of ways, reducing latency so improving performance, reducing variation in performance and reducing the number of error paths in the code., Similarity: 0.1451\n",
            "Summary & Description: add selftest log facility \n",
            " add a log facility for self_test., Similarity: 0.3040\n",
            "Summary & Description: cartctl command line tool peer list \n",
            " cart_ctl peer_list --target server_grp_name --rank 0\n",
            "\n",
            "Search the internal lookup cache and dump the target peers's addresses, Similarity: 0.2857\n",
            "Summary & Description: selftest invalid ranks crashing origin \n",
            " Using self-test from a rank within a process set to an invalid rank is causing the origin rank to segv., Similarity: 0.0739\n",
            "Summary & Description: selftest invalid tags reporting zero latency \n",
            " If you use self-test to in invalid target tag then it reports zero errors and zero time for RPC latencies., Similarity: 0.1862\n",
            "Summary & Description: masterendpoint working \n",
            " self-test claims to use the local binary as the test origin if master-endpoint option isn't passed however it looks to be using the endpoint as both the origin and target at this point., Similarity: 0.1371\n",
            "Summary & Description: selftest logging crtinit \n",
            " Self-test is making heavy use of the debug macros however it is not possible to enable the output before crt_init(), Similarity: 0.2156\n",
            "Summary & Description: cerror macro per rpc variant \n",
            " In the CaRT logs C_DEBUG() is reasonably good at including the rpc_priv pointer however the C_ERROR() output almost never does.\n",
            "\n",
            "We should add either a C_ERROR_REQ() or C_ERROR_OBJ() macro that would work like C_ERROR but take an additional option of a extra pointer to print.  This could either be generic (C_ERROR_OBJ) or the macro could pull data out of req (C_ERROR_REQ).\n",
            "\n",
            "This would make parsing the log files easier and be essential for any correlation of errors to RPCs., Similarity: 0.1988\n",
            "Summary & Description: prefer x rather 0xx printing hex values \n",
            " This is entirely stylistic however I've noticed that CaRT uses 0x%x to print values where the newer %#x would be clearer, make the code easier to read and strings (lines of code) shorter.\n",
            "\n",
            "This is a simple change and could be performed with sed if there is agreement., Similarity: 0.0739\n",
            "Summary & Description: crtreqsetendpoint function \n",
            " In IOF we are pre-creating a lot of our descriptors to move the computation off the critical path, however this means that we lock ourself to an endpoint at crt_req_create().  We'd like the option to call the following functions, in order:\n",
            "\n",
            "crt_req_create(); /* In advance, non performance critical */\n",
            "crt_req_set_endpoint(); /* as IOF receives a request */\n",
            "crt_req_send(); /* Send an EP, as now */\n",
            "\n",
            "I have a changeset for this which I shall update to reference this ticket., Similarity: 0.2570\n",
            "Summary & Description: crturilookup rpc takes unused group option \n",
            " This RPC requires a group parameter as a string, however only one value is valid per target so this could be removed.\n",
            "\n",
            "This is cosmetic, likely below ZBB line, Similarity: 0.1439\n",
            "Summary & Description: crtendpointt passed value reference \n",
            " The functions crt_req_create() and crt_ep_abort() take a crt_endpoint_t by value rather than taking a pointer to it.  This will be inefficient and use more space on the stack than required., Similarity: 0.1547\n",
            "Summary & Description: initialize rc 0 crtgrplcctxinvalid crtgrpctxinvalid \n",
            " crt_finalize() fails because some crt_context is not destroyed. initializing rc = 0 in crt_grp_lc_ctx_invalid() and crt_grp_ctx_invalid() fixes the problem., Similarity: 0.2244\n",
            "Summary & Description: iv fetch improvements framework \n",
            " Improvements to the IV framework:\n",
            "- Modify crt_iv_fetch() to no longer take iv_value argument, instead on_get() and on_put() will be called on all nodes.\n",
            "- Modify on_get() callback to take in void **user_priv argument\n",
            "- Modify on_put(), on_refresh(), on_fetch() callbacks to take in void **user_priv argument, Similarity: 0.2952\n",
            "Summary & Description: mark rankmap crtrankevict \n",
            " mark the evicted rank as evicted in the liveness map inside the function crt_rank_evict(), Similarity: 0.0092\n",
            "Summary & Description: cart issue daos rebuild testing \n",
            " with latest mercury/cart/daos, the rebuild testing failed at the end:\n",
            "\n",
            "# HG -- Error -- /home/xliu9/src/daos_m/_build.external/mercury/src/mercury_core.c:2849\n",
            " # HG_Core_context_destroy(): HG handles must be freed before destroying context (1 remaining)\n",
            "daos_fini() failed with -1020, Similarity: 0.2643\n",
            "Summary & Description: cartctl command line tool \n",
            " 4 parts.  Lengthy ticket.\n",
            "\n",
            "Break up unto one week tasks or smaller.\n",
            "\n",
            "==============\n",
            "\n",
            "Hi Yulu,\n",
            "\n",
            "We can implement a binary tool over cart, can be called as ³cart_ctl² to\n",
            "facilitate the diagnose for cart.\n",
            "With similar purpose/functionalities as lustre¹s lctl.\n",
            "\n",
            "From the beginning, we can with the following functionalities:\n",
            "1) list one server¹s context/endpoint addresses\n",
            "For example: ³cart_ctl list_ctx --target server_grp_name --rank 0² (can\n",
            "support \"--rank [0, 3~5, 7]² format, if no rank parameter can use rank 0)\n",
            "The output should include the information like:\n",
            "Server group name: xxxx, rank [y]:\n",
            "\tContext [0], address: ofi+sockets://ip:port\n",
            "\tContext [1]Š\n",
            "2) query the cart server corresponding build version and commit number\n",
            "For example ³cart_ctl build_ver --taget server_grp_name --rank 0² (if no\n",
            "rank parameter can use rank 0)\n",
            "For this you also need some changes to cart build script (for example, get\n",
            "the version number and git commit number, and generate a .h file which is\n",
            "included by cart code, and in crt_init copy it to an internal string,\n",
            "define an internal RPC to allow it to be queried).\n",
            "3) ping\n",
            "3.1) P2P ping\n",
            "For example ³cart_ctl ping --target server_grp_name --src 0:0 --dst 1:0\n",
            "--msg ³ping from rank 0 to rank 1²² (0:0 means rank:tag, if no tag then\n",
            "can use tag 0).\n",
            "The optional ping msg can be logged to cart log, and show on the output\n",
            "also.\n",
            "The --dst can include multiple ranks \"--dst [0, 5:1, 6-15]² for example,\n",
            "and the output should with information like which set of target\n",
            "unreachable.\n",
            "3.2) corpc ping\n",
            "For example ³cart_ctl co_ping --taget server_grp_name ‹src 0:0 --dst [0,\n",
            "5:1, 6-15] --msg ³corpc ping Š..²\n",
            "The corpc ping should based on corpc.\n",
            "4) peer list\n",
            "³cart_ctl peer_list --target server_grp_name --rank 0²\n",
            "Can search the internal lookup cache and dump the target peers¹ address\n",
            "5) send a signal\n",
            "³cart_ctl signal --target server_grp_name ‹rank 0 --signal SIGKILL²\n",
            "To send a signal SIGKILL/SIGTERM etc to a target rank.\n",
            "6) dump internal statistic information\n",
            "³cart_ctl dump Š² I¹ll add some needed statistic information to cart\n",
            "later, detailed to be defined.\n",
            "\n",
            "For that we can define some cart internal RPCs. What need to do is\n",
            "defining those RPCs and implement the binary tool (as a cart client\n",
            "program).\n",
            "\n",
            "We can add more commands to it later.\n",
            "You can refer the usage of lctl, it support an interactive shell which is\n",
            "good.\n",
            "We can do similar as that after cart_ctl it output with:\n",
            "cart_ctl > (from here can input command)\n",
            "And then can attach or detach to a server group (so need not input\n",
            "\"--target server_grp_name² ever time in the interactive shell).\n",
            "I mean can support both one line cmd like above and interactive shell\n",
            "(enter the cart_ctl shell and then \"attach,\n",
            "list_ctx/ping/peer_list/signal/dump/Š , detach, exit²).\n",
            "\n",
            "I think it useful when diagnose it in developing. Do yo think is it\n",
            "reasonable? If it is not clear to you please ping me at any time.\n",
            "\n",
            "BTW, please rebase your patches on hand to latest cart.\n",
            "\n",
            "Thanks,\n",
            "Xuezhao\n",
            ", Similarity: 0.2830\n",
            "Summary & Description: log mask check inlined avoid function call overhead \n",
            " Users of cart logging must make a function call when logging.  The checking of the mask can be moved so that it can happen inline at the call site rather than having the overhead of a function call.   This is a fairly simple change., Similarity: 0.2596\n",
            "Summary & Description: crtreqsend serialize arguments returning \n",
            " After the asynchronous address lookup change, if the address isn't cached, crt_req_send no longer serializes arguments.   This can result in random failures when the caller deallocates a buffer after the call.\n",
            "\n",
            "For example, \n",
            "req->in->str = strdup(foo);\n",
            "crt_req_send(rpc, complete_cb, NULL);\n",
            "free(foo);\n",
            "\n",
            "If foo isn't serialized in crt_req_send, as happens if the address isn't cached, then it can result in reading garbage data or crashing when it eventually serializes the input data., Similarity: 0.1065\n",
            "Summary & Description: fix crtgroupcreate \n",
            " The issue is crt_group_create() references the grp_id argument after the function returns. This is because after the asynchronous address resolution changeset, crt_req_send() may return before the input arguments are serialized and buffered by Mercury., Similarity: 0.1705\n",
            "Summary & Description: valgrind ofi plugin takes long time nainitialize 40 seconds \n",
            " When running tests that perform crt_init() through a valgrind, tests hang for many seconds (between 40 and 300+seconds) in NA_Initialize(). This only happens when CRT_PHY_ADDR_STR is set to \"ofi+sockets\". When set to \"cci+tcp\" the test runs at the expected speed with NA_Initialize() taking less than 1 second.\n",
            "\n",
            "This behavior was repeated with both cppr tests that use crt and with 'crt_echo_cli' sample.\n",
            "In experiments it was running on wolf-31; same behavior was reproduced on other wolf nodes (wolf-32, wolf-11).\n",
            "\n",
            "Command ran was: \n",
            "\n",
            "valgrind --xml=yes --xml-file=/home/aaoganez/global/mv_test-valgrind.xml --suppressions=/scratch/jenkins-2/artifacts/cart-update-scratch/472/cart/etc/memcheck-cart.supp --suppressions=/scratch/jenkins-2/artifacts/iof-update-scratch/814/iof/etc/memcheck-iof.supp --leak-check=full --partial-loads-ok=yes /home/aaoganez/forreview/cart/install/Linux/TESTING//tests/crt_echo_cli\n",
            "\n",
            "By adding timestamps around NA_Initialize() call, with ofi+sockets it takes random amount of time on each run, but always very prolonged delays. Example of 3 separate runs of crt_echo_cli using the command above:\n",
            "\n",
            "NA_Initialize took 328246273 usec (328.246 sec) to execute\n",
            "NA_Initialize took 41784738 usec (41.785 sec) to execute\n",
            "NA_Initialize took 85022136 usec (85.022 sec) to execute\n",
            ", Similarity: 0.2910\n",
            "Summary & Description: cart log messages go log possible \n",
            " I recently ran into an issue where logging of an error went to stdout and the rest of the logs, showing the actual error went to the log file.   I took quite a lot of time tracking down the actual issue where it wouldn't have been as difficult had the logs been in the same place.   The logger is reference counted so we can call crt_log_init at the start of crt_init without any issues., Similarity: 0.2671\n",
            "Summary & Description: refine cart flow control handling \n",
            "  Make current cart flow control be controllable by ENV\n",
            " Need to return EAGAIN to user? (TBD), Similarity: 0.2237\n",
            "Summary & Description: use bcast create destroy sub groups \n",
            " use corpc to create and destroy sub groups. this allows us to take advantage of the tree topology of the corpc. Currently sub group creation and destroy are done using point-to-point RPC., Similarity: 0.0966\n",
            "Summary & Description: exclude failed nodes corpc fail corpc group version different \n",
            " root of corpc packs its version number in the message. The corpc should fail if the version number in the message doesn't match the version number on any of the children nodes.\n",
            "\n",
            "In addition to the exclusion list, the root of corpc should automatically skip failed nodes when computing the tree., Similarity: 0.1008\n",
            "Summary & Description: free newly returned hgaddr already exists \n",
            " in crt_grp_lc_addr_insert() if the hg_addr is already inserted into the address cache by somebody else, free the newly returned hg_addr., Similarity: 0.2491\n",
            "Summary & Description: self test invalid write selftest startup \n",
            " the self-test application is reporting the following error at startup.  It looks likely that the signon RPC used for self-test has an incorrect input handler.\n",
            "\n",
            "==98416== Invalid write of size 4\n",
            "==98416==    at 0x4031F9: test_msg_size (self_test.c:501)\n",
            "==98416==    by 0x4031F9: run_self_test (self_test.c:919)\n",
            "==98416==    by 0x4031F9: main (self_test.c:1811)\n",
            "==98416==  Address 0x8734aac is 0 bytes after a block of size 44 alloc'd\n",
            "==98416==    at 0x4C2B974: calloc (in /usr/lib64/valgrind/vgpreload_memcheck-amd64-linux.so)\n",
            "==98416==    by 0x537995E: crt_rpc_inout_buff_init (crt_rpc.c:1331)\n",
            "==98416==    by 0x537995E: crt_rpc_priv_init (crt_rpc.c:1381)\n",
            "==98416==    by 0x537974C: crt_req_create_internal (crt_rpc.c:550)\n",
            "==98416==    by 0x5379D26: crt_req_create (crt_rpc.c:607)\n",
            "==98416==    by 0x40319A: test_msg_size (self_test.c:486)\n",
            "==98416==    by 0x40319A: run_self_test (self_test.c:919)\n",
            "==98416==    by 0x40319A: main (self_test.c:1811)\n",
            "==98416==, Similarity: 0.1734\n",
            "Summary & Description: way running selftest iof run using dvm \n",
            " It should be possible to launch IOF in one window, then in another launch self-test targetting the IONSS.\n",
            "\n",
            "I want to be able to run \"./test/iof_test_local.py --launch\" and then elsewhere run \"self_test --group-name IONSS -e 0:0\" and be able to get some performance numbers.  The CNSS already exports the singleton attach file however there doesn't seem to be any way of telling self-test to pick this up., Similarity: 0.3655\n",
            "Summary & Description: incorrect debug message printed crthgc \n",
            " line is printing an incorrect message\n",
            "\n",
            "                C_DEBUG(\"New context(idx:%d), listen address: cci+%s.\\n\",\n",
            "                        idx, addr_str);\n",
            "\n",
            "it list the interface has 'cci'. found while test ofi\n",
            "\n",
            "in \"crt_hg.c\" line 511, Similarity: 0.2429\n",
            "Summary & Description: update starting processes one node use n \n",
            " When starting processes on more than one node the orterun call should use '-N' and not '-n'. The '-N' option will create that number of processes on each node in the supplied node list\n",
            "\n",
            " , Similarity: 0.0953\n",
            "Summary & Description: query function discover network protocol use \n",
            " In IOF the CNSS process needs to communicate with the interception library to tell it which CaRT network protocol is in use.  The singleton attach file contains the URIs but not the protocol, and the only way the CNSS knows the protocol is through the CRT_PHY_ADDR_STR however this may be missing.\n",
            "\n",
            "A query function is needed in CaRT so the CNSS can fetch the in-use protocol string to pass to the IL., Similarity: 0.3047\n",
            "Summary & Description: single node barrier test doesnt work used infrastructure issue \n",
            " The single node barrier test used to grab all availables nodes.   Now, it seems to leave at least one node out.   Running test on Jenkins says \"no available servers\"., Similarity: 0.3062\n",
            "Summary & Description: ha 2 node self test fails \n",
            " review: [https://review.whamcloud.com/#/c/27104/8]\n",
            "\n",
            "The 2 node HA/Maloo test job fails the cart self test. There looks to be a time out with one of the processes. this is with ofi enabled.\n",
            "\n",
            "Maloo results:\n",
            "\n",
            "([{color:#0654ac}[https://testing.hpdd.intel.com/test_sessions/72a60c28-d8f9-4395-a4ac-afe683a8fa5e]{color}]). Ran 7 tests.  1 tests failed: cart_self_test.\n",
            "\n",
            " \n",
            "\n",
            "looks to also fail without ofi enabled\n",
            "\n",
            "[https://testing.hpdd.intel.com/test_sessions/d2340194-de95-4ca2-b2f3-a14f53679eb9]\n",
            "\n",
            " , Similarity: 0.2348\n",
            "Summary & Description: carttestgroup fials valgrind jenkens \n",
            " The cart_test_group fails valgrind when ofi  is enabled, [https://review.whamcloud.com/#/c/27104/] . The 2nd process times out and fails to attach.\n",
            "\n",
            " \n",
            "\n",
            "Jenkins job\"\n",
            "\n",
            "[https://localhost:8445/job/daos_cart_review_memcheck/860/]\n",
            "\n",
            "or\n",
            "\n",
            "[https://jenkins-2.wolf.hpdd.intel.com/job/daos_cart_review_memcheck/860/] , Similarity: 0.3817\n",
            "Summary & Description: pmix scons options sticky \n",
            " The PMIX_PREBUILT command line option is not \"sticky\" or saved between invocations.\n",
            "\n",
            "This looks to be because prereqs.require() is not called for pmix before opts.Save() is called.\n",
            "\n",
            "Without this option being set saved it's not clear how to build cart from source directly without using a wrapper script unless the setting is added another way, perhaps left-over from a previous version where the value was saved?, Similarity: 0.3588\n",
            "Summary & Description: iv fetch aggregation provide key comparison callback fetch flags \n",
            " CPPR project embeds various information into the key including debug information for traceability such as originator rank, timestamps and such. \n",
            "\n",
            "This information causes 2 keys that request same data look different due to IV framework internally using memcmp to compare keys between each other.\n",
            "\n",
            "An improvement request is to provide optional key comparison callback allowing clients if needed to decide which part of the key should be used for comparison purposes.\n",
            "\n",
            "In addition CPPR needs a flag during fetch specifying whether or not fetch was performed as part of 'fetch aggregation logic'; such flag allows optimization in CPPR.\n",
            ", Similarity: 0.3033\n",
            "Summary & Description: pack group signature corpc \n",
            " the initiator of a corpc packs the live membership signature into the corpc. a child node in the corpc tree compares the received signature with its locally calculated signature. if the two signatures don't match, fail the corpc. The goal is to make sure every body in the corpc are on the same page with respect to the liveness map. The signature is a hash of the live member list and the tree topology code., Similarity: 0.1551\n",
            "Summary & Description: cart level error reporting \n",
            " When a target encounters an error when processing RPC requests and the error occurs inside CART (as opposed in the user-provided handler), the target notifies the the origin by passing back an error code., Similarity: 0.1301\n",
            "Summary & Description: fix symble check \n",
            " utils/test_cart_lib.sh requires that all symbols in the library begin with crt_, Similarity: 0.2336\n",
            "Summary & Description: improve debug logging interface cart \n",
            " The debug logging in clog is odd.   There are 16 bits available to set for various debug levels.  That is sane.   The way to specify the debug levels is very strange.   There are various levels defined by D and combinations of 3 digits which can be 1,2,3, or -.\n",
            "\n",
            "It would be nice if they were instead just simple levels such as D0, D1, ..., D15\n",
            "\n",
            "So, use could specify something like CLOG_DBG_BASE + level when logging where existing CLOG_DBG would still specify a full mask.\n",
            "\n",
            "Furthermore, one may wish to set multiple levels at once.   This could be done via D0x???? where ???? specifies a 16 bit mask in hex format.\n",
            "\n",
            "This would allow flexibility while implementing a sane interface., Similarity: 0.2616\n",
            "Summary & Description: iv ivfetch aggregator works incorrectly \n",
            " iv fetch aggregator does not work correctly, causing wrong iv_values being passed in certain scenarios.\n",
            "\n",
            "In addition fetch takes a massive lock on the whole ivns context during fetch event processing causing multiple iv keys to be blocked on one another. This can lead to a deadlock if 2 keys are dependent upon each other., Similarity: 0.2635\n",
            "Summary & Description: use ofi cart tests \n",
            " update CI to use OFI for CART tests, Similarity: 0.2741\n",
            "Summary & Description: iv pending fetches use temporary ivvalue \n",
            " When pending iv_fetches get processed (fetch aggregation logic) a temporary iv_value is used. This causes 'fetch_done' being called with a temporary iv_value instead of the iv_value initially supplied by the user during crt_iv_fetch() call.\n",
            "\n",
            "Such behavior complicates 'fetch_done' processing as 'fetch_done' cannot free iv_value passed, as it could end up being a temporary variable. (In order to cleanup iv_value properly in fetch_done, one would have to pass pointer to it as one of callback arguments)\n",
            "\n",
            "Instead the desired behavior is for 'fetch_done' to be called with the same iv_value as was provided during crt_iv_fetch() call.\n",
            "\n",
            "Similar issue occurs with iv_keys passed to fetch_done function\n",
            "\n",
            ", Similarity: 0.2742\n",
            "Summary & Description: support psr failover singleton interface \n",
            " This is a placeholder to document that the current singleton interface doesn't work if the PSR fails.   We need a solution to this issue but until we handle PSR failover, we can defer this work., Similarity: 0.2385\n",
            "Summary & Description: iv ivfetch corrupts ivkey occasionally \n",
            " iv_key can get corrupted during iv_fetch operation.\n",
            "This happens due to key pointer being saved, while key points to the input buffer that can get destroyed. , Similarity: 0.2037\n",
            "Summary & Description: iv ivfetch callback doesnt get called 500 fetches \n",
            " Using 2 node setup when performing iv fetches large number of times (500+) using different keys, the fetches stop propagating to the remote node.\n",
            "\n",
            "Internally this is caused by leak of rpc handle that gets incremented extra time, eventually leading to max number of inflight rpcs, Similarity: 0.2250\n",
            "Summary & Description: add oneway rpc \n",
            " One way RPC is without reply, fire and forget., Similarity: 0.0838\n",
            "Summary & Description: iv onput callback fetch occasionally gets called wrong ivvalue \n",
            " during iv_fetch operation on_put() callback gets occasionally called with iv_value pointers that are different from pointers provided during on_get() operation. \n",
            "\n",
            "This happens due to pointers being stored on stack in internal iv function, being lost by the time on_put() needs to be performed, Similarity: 0.2139\n",
            "Summary & Description: crtreqreplyget error checking \n",
            " Do we need to check the return code of these two functions?\n",
            "\n",
            "The IOF code currently does but the error handling for these functions is difficult, looking at the CaRT code however this doesn't seem necessary so is it safe to remove these checks?, Similarity: 0.2206\n",
            "Summary & Description: collective rpc fails request format null \n",
            " The RPC handler registration APIs {{crt_rpc_srv_register}} and {{crt_corpc_register}} accept an argument for the request format which defines the input and output message fields for the RPC. There needs to be a way to define the request format in cases where either the input or the output or both are absent.\n",
            "\n",
            "The peer-to-peer RPC registration allows the use of {{NULL}} as a valid request format for this purpose. It is expected that this behavior be identical for collective RPCs. Alternatively, the API should allow the user to define a request format with {{NULL}} input and/or output message fields.\n",
            "\n",
            "In both cases, namely, request format being {{NULL}} or request format having a {{NULL}} output message field, a collective RPC call fails with an assertion failure:\n",
            "{code:java}\n",
            "src/crt/crt_corpc.c:790: crt_corpc_req_hdlr: Assertion `child_rpc->cr_output != ((void *)0)' failed.\n",
            "\n",
            "{code}\n",
            "This forces the user to define an output message field even when it is unnecessary., Similarity: 0.2086\n",
            "Summary & Description: sanity test 27u may fail witn 1 object ost0 run 0a 27u \n",
            " When running sanity test in batch, 27u may fail from time to time.\n",
            "\n",
            "Reproducer: run sanity test using:\n",
            "{quote}\n",
            "./auster -v -f <conf> -d /mnt/share/result sanity --start-at 0a --stop-at 27u\n",
            "{quote}\n",
            "Sometime it will fail with file t-0 in ost0.\n",
            "{quote}\n",
            "== sanity test 27u: skip object creation on OSC w/o objects ========================================== 11:03:43 (1491750223) fail_loc=0x139 total: 1000 creates in 0.69 seconds: 1454.46 creates/second fail_loc=0\n",
            "\n",
            "unlinked 0 (time 1491750226 ; total 0 ; last 0) total: 1000 unlinks in 1 seconds: 1000.000000 unlinks/second sanity test_27u: @@@@@@ FAIL: 1 objects created on OST-0. See /mnt/lustre/f27u.sanity.getstripe\n",
            "{quote}\n",
            " lod_alloc_qos forgot to initialize {{ltd_qos.ltq_usable}} os unusable ost to 0.  Apply the following patch, and the problem was solved:\n",
            "{quote}\n",
            "diff --git a/lustre/lod/lod_qos.c b/lustre/lod/lod_qos.c\n",
            " index 22004ba..ad5f18d 100644\n",
            " — a/lustre/lod/lod_qos.c\n",
            " +++ b/lustre/lod/lod_qos.c\n",
            " @@ -1413,6 +1413,9 @@ static int lod_alloc_qos(const struct lu_env *env, struct lod_object *lo,\n",
            " good_osts = 0;\n",
            " /* Find all the OSTs that are valid stripe candidates */\n",
            " for (i = 0; i < osts->op_count; i++) \\{\n",
            " + ost = OST_TGT(m,osts->op_array[i]);\n",
            " + ost->ltd_qos.ltq_usable = 0;\n",
            " +\n",
            " if (!cfs_bitmap_check(m->lod_ost_bitmap, osts->op_array[i]))\n",
            " continue;\n",
            "\n",
            "@@ -1434,7 +1437,6 @@ static int lod_alloc_qos(const struct lu_env *env, struct lod_object *lo,\n",
            " osts->op_array[i] == 0)\n",
            " continue;\n",
            "\n",
            "- ost = OST_TGT(m,osts->op_array[i]);\n",
            " ost->ltd_qos.ltq_usable = 1;\n",
            " lod_qos_calc_weight(m, osts->op_array[i]);\n",
            " total_weight += ost->ltd_qos.ltq_weight;\n",
            "  \n",
            "{quote}, Similarity: 0.0305\n",
            "Summary & Description: modify crtlogsetmasks return error issue mask \n",
            " The IOF CNSS has a  control variable for setting the log mask at runtime.   Cart should return an error if the log mask passed to crt_log_setmasks is invalid., Similarity: 0.3311\n",
            "Summary & Description: move ras notification code lm module \n",
            " rebase the RAS notificatino broadcast/server eviction code to the plugin interface. This feature is disabled by default, a CART user can choose to enable this feature by calling lm_init()., Similarity: 0.2103\n",
            "Summary & Description: selftest race bug selftest service \n",
            " There's a bug in crt_self_test_service.c someplace - it's possible to get self-test into a state where it loops infinitely trying to get a free buf_entry in crt_self_test_msg_handler(). \n",
            "\n",
            "It's definitely possible to reproduce this with these arguments, though it doesn't seem to happen every time: \n",
            "--group-name test1 --endpoint 0-1:0 --max-inflight-rpcs 16 -s \"b1000\" -m 1:0 -r 20\n",
            ", Similarity: 0.1134\n",
            "Summary & Description: selftest default masterendpoint working documented \n",
            " Currently the --master-endpoint argument of self-test claims that it will use the command line application itself is not specified. Instead, it actually currently uses the rank/tag of the command-line application, but the group of the test target. This works, but not as desired. \n",
            "\n",
            "Fixing this will require a new parameter to be passed in the start message (the target group name string). , Similarity: 0.1921\n",
            "Summary & Description: allow set timeout value specific rpc request \n",
            " allow to set timeout value for specific RPC request, originally it only use a global timeout value for all RPCs., Similarity: 0.0351\n",
            "Summary & Description: implement crterrstr \n",
            " There's currently only a prototype for crt_errstr in crt_errno.h. Attempting to actually use this function fails - there's no actual implementation. This should be implemented to make it easier to print reasonable error messages. , Similarity: 0.2032\n",
            "Summary & Description: devstdout isnt available platforms crt log supports stdout flag \n",
            " On some docker systems, /dev/stdout isn't available.   Cart is setting that as the filename when the logfile isn't set.   Instead, we can just pass NULL and set the CLOG_FLV_STDOUT flag., Similarity: 0.3701\n",
            "Summary & Description: rearrange selftest message structures pack correctly without pragma pack \n",
            " Currently the self-test session ID is 4 bytes and is located at the beginning of self-test messages. This means that the following items are misaligned (on an 8-byte boundary) and so a pragma is currently used to force no padding to be inserted. Using a pragma in this way might cause problems later (based on real problems DAOS is having already with similar code). \n",
            "\n",
            "To fix this, the session-id needs to be promoted to an 8-byte value. , Similarity: 0.1369\n",
            "Summary & Description: review score maloo \n",
            " One of our changesets today has not received a score from Maloo, there is a report from one of the two maloo jobs but not the other, and no vote has been registered.\n",
            "\n",
            "It is patchset 3 of this changeset.\n",
            "https://review.whamcloud.com/#/c/25695/3\n",
            "\n",
            "Speaking to [~accountid:6062467ed1155500698beec6] in the meeting today he said there were JSON errors uploading the results., Similarity: 0.1707\n",
            "Summary & Description: add switch measure selftest bandwidth mib mb \n",
            " Currently self-test computes MB (by dividing by 1024). This doesn't match network throughput which is usually measured in MiB. There should be a switch to adjust the display to each of the two modes. , Similarity: 0.1795\n",
            "Summary & Description: valgrind test reporting failures sles12 sp1 \n",
            " 27July: Check this status with [~accountid:5c8fb47d0769b92d18511a97]\n",
            "\n",
            "The Valgrind test is failing for sles12sp1.  It is passing for sles12sp2, el7.2, and el7.3.\n",
            "\n",
            "Similar to IOF-420.\n",
            "{code}\n",
            "unknown tool   build/Linux/src/utest/test_linkage (299)  298    Invalid Read:2\n",
            "unknown tool   build/Linux/src/utest/test_util (302)         301\n",
            "{code}, Similarity: 0.2419\n",
            "Summary & Description: add ofi supporting \n",
            " Using ENV to select the NA plugin, including the OFI socket., Similarity: 0.3520\n",
            "Summary & Description: add option validate selftest buffer integrity \n",
            " Currently self-test buffers are only sent via CART but are not validated - there needs to be an option to check that data was sent correctly. , Similarity: 0.1839\n",
            "Summary & Description: cart self test fails ib \n",
            " On running Cart Self Test on IB, the test progresses quickly almost till the end of the run. Just before stopping the processes, the tests timeout; hence the test fails.\n",
            "Please find attached the link to the test run on wolf-25 and wolf-26:\n",
            "https://testing.hpdd.intel.com/test_sets/1d8faad4-fab4-11e6-92dd-5254006e85c2, Similarity: 0.1329\n",
            "Summary & Description: self test seperate buffers rpc \n",
            " Currently all of the self-test RPCs issued by a client share the same outgoing buffer - this needs to change for bulk to work correctly. A good intermediate step on the way to bulk. , Similarity: 0.1382\n",
            "Summary & Description: implement iv udpateiv invalidate operations stage1 \n",
            " This task/feature deals with implementation of crt_iv_update and crt_iv_invalidate operations. In stage1, versioning will not be supported.\n",
            "\n",
            ", Similarity: 0.2251\n",
            "Summary & Description: exclude failed nodes corpc broadcast fail rpcs different group membership \n",
            " Collective RPC's should not require the user to create an exclude list including nodes that have failed.   Furthermore, it would be ideal if the collective RPC would fail if the membership version of the sender doesn't match that of any of the receivers.   That way the caller can be sure that the RPC was executed on all live nodes as of the time it was sent., Similarity: 0.0395\n",
            "Summary & Description: destroy data structures proper order selftest \n",
            " destroy data structures in self_test in proper order to prevent deadlocks or error messages at tear down.\n",
            "\n",
            "1) call crt_context_destroy() after the cart context is not needed anymore. \n",
            "2) do not call pthread_join() if pthread_create() has failed. \n",
            "3) call pthread_join() to terminate the progress thread during cleanup, Similarity: 0.2305\n",
            "Summary & Description: clogc compile warning ubuntu 14045 \n",
            " 27July: ask [~accountid:5c8fb47d0769b92d18511a97] if this is still an issue\n",
            "\n",
            "An experimental Ubuntu 14.04 .5 build of cart is failing on a compile warning.\n",
            "\n",
            "http://jem-jenkins.amr.corp.intel.com/view/daos/job/cart-master_ubuntu/arch=x86_64,distro=ubuntu1404/\n",
            "\n",
            "{code}\n",
            "scons: done reading SConscript files.\n",
            "scons: Building targets ...\n",
            "scons: building associated VariantDir targets: build/Linux/src/util\n",
            "gcc -o build/Linux/src/util/clog.os -c -g -Wall -Werror -fpic -D_GNU_SOURCE -O2 -fPIC -Isrc/include -I/usr/include -Isrc/util src/util/clog.c\n",
            "src/util/clog.c: In function 'vclog':\n",
            "src/util/clog.c:456:3: error: ignoring return value of 'write', declared with attribute warn_unused_result [-Werror=unused-result]\n",
            "   (void) write(mst.logfd, b, tlen);\n",
            "   ^\n",
            "cc1: all warnings being treated as errors\n",
            "scons: *** [build/Linux/src/util/clog.os] Error 1\n",
            "scons: building terminated because of errors.\n",
            "{code}\n",
            ", Similarity: 0.3780\n",
            "Summary & Description: clean attach file shutdown \n",
            " Attach file should be cleaned up on shutdown., Similarity: 0.2309\n",
            "Summary & Description: invalid rpc opcode handling \n",
            " The current code seems to have a problem with sending RPCs with invalid opcodes.\n",
            "\n",
            "On the origin side the RPC times out, but other than that the code seems unaffected.\n",
            "\n",
            "On the target side however cart seems to stop processing any more incoming RPCs at all.\n",
            "\n",
            "Ideally the code would identify this, send back a reply itself and pass a special value to cci_rc in the callback on the origin., Similarity: 0.1071\n",
            "Summary & Description: srccrtcrthgc833 crthgreplysendcb crthgreplysendcb \n",
            " We are seeing errors like the below from CaRT on occasion.\n",
            "\n",
            "02/02-13:04:50.83 lin01 CaRT[7169] CRT  ERR  src/crt/crt_hg.c:833 crt_hg_reply_send_cb crt_hg_reply_send_cb, hg_cbinfo->ret: 4, opc: 0x204.\n",
            "\n",
            "This happens when we send a direct (non-bulk) rpc where the reply contains a iov which is bigger than the network can support, although the threshold seems to depend on the network MTU so can differ, even for TCP/IP systems.\n",
            "\n",
            "The above error is reported by the target of the RPC although no errors are detectable by the RPC handler.  On the origin side the completion callback sees cb_info->cci_rc set to --1020 which is -CER_HG, and the iov is NULL, with 0 size.-\n",
            "\n",
            "We can work around this error, although the current approach is to restrict the amount of data set via iovs.\n",
            "\n",
            "The ideal fix would be if the network could know the limit in advance, export this information to the application somehow, and return an error from the crt_iov_set() function on the target if the threshold was breached.\n",
            "\n",
            "I have not tried sending larger iovs with an RPC rather than in the reply., Similarity: 0.1937\n",
            "Summary & Description: issuing corpc bulk handle passed eventually leads crashsegfault \n",
            " Issuing CORPC with passed bulk handle eventually leads to a crash somewhere in cart. Crash/Segfault appears to be random.\n",
            "\n",
            "Following review contains test_client/test_server illustrating the problem.\n",
            "https://review.whamcloud.com/#/c/25150/\n",
            "\n",
            "In order to run:\n",
            "- get patch from the above review\n",
            "- modify test/start_srv.sh and test/start_cli.sh and specify proper cart location\n",
            "- run ./start_srv.sh &\n",
            "- once servers are started run  ./start_cli.sh\n",
            "\n",
            "start_cli.sh/client will attempt to trigger 100 CORPCs one at a time (waiting for previous to complete). Segfault typically happens on 20-30th CORPC.\n",
            "\n",
            "For comparison, if instead of local_bulk you pass NULL On line 243 of test_server.c, all 100 CORPCs complete fine.\n",
            "\n",
            "240         rc = crt_corpc_req_create(main_ctx, server_group,\n",
            "241                                 &excluded_list,\n",
            "242                                 CORPC_SEND_DATA,\n",
            "243                                 local_bulk, /* Pass NULL to avoid crash */\n",
            "244                                 NULL, 0,\n",
            "245                                 crt_tree_topo(CRT_TREE_KARY, 2),\n",
            "246                                 &rpc);\n",
            "\n",
            "Example run:\n",
            "...\n",
            "\n",
            "[wolf-31::CLIENT]       Triggering CORPC with fill_data=20\n",
            "[wolf-31:0:SERV]        Got TEST_START rpc request\n",
            "[wolf-31:0:SERV]        Issuing CORPC call with fill_value=20\n",
            "[wolf-32:1:SERV]        CORPC_SEND_DATA handler called with fill=20\n",
            "[wolf-11:2:SERV]        CORPC_SEND_DATA handler called with fill=20\n",
            "[wolf-12vm4:6:SERV]     CORPC_SEND_DATA handler called with fill=20\n",
            "[wolf-12vm2:4:SERV]     CORPC_SEND_DATA handler called with fill=20\n",
            "[wolf-12vm1:3:SERV]     CORPC_SEND_DATA handler called with fill=20\n",
            "[wolf-12vm3:5:SERV]     CORPC_SEND_DATA handler called with fill=20\n",
            "[wolf-12vm7:9:SERV]     CORPC_SEND_DATA handler called with fill=20\n",
            "[wolf-12vm11:13:SERV]   CORPC_SEND_DATA handler called with fill=20\n",
            "[wolf-12vm10:12:SERV]   CORPC_SEND_DATA handler called with fill=20\n",
            "[wolf-12vm8:10:SERV]    CORPC_SEND_DATA handler called with fill=20\n",
            "[wolf-12vm6:8:SERV]     CORPC_SEND_DATA handler called with fill=20\n",
            "[wolf-12vm5:7:SERV]     CORPC_SEND_DATA handler called with fill=20\n",
            "[wolf-12vm9:11:SERV]    CORPC_SEND_DATA handler called with fill=20\n",
            "[wolf-12vm12:14:SERV]   CORPC_SEND_DATA handler called with fill=20\n",
            "[wolf-31:0:SERV]        CORPC RESPONSE received!\n",
            "[wolf-31::CLIENT]       Run finished; rc = 0\n",
            "\n",
            "[wolf-31::CLIENT]       Triggering CORPC with fill_data=21\n",
            "[wolf-31:0:SERV]        Got TEST_START rpc request\n",
            "[wolf-31:0:SERV]        Issuing CORPC call with fill_value=21\n",
            "[wolf-32:1:SERV]        CORPC_SEND_DATA handler called with fill=21\n",
            "[wolf-12vm2:4:SERV]     CORPC_SEND_DATA handler called with fill=21\n",
            "[wolf-12vm1:3:SERV]     CORPC_SEND_DATA handler called with fill=21\n",
            "[wolf-12vm7:9:SERV]     CORPC_SEND_DATA handler called with fill=21\n",
            "[wolf-12vm6:8:SERV]     CORPC_SEND_DATA handler called with fill=21\n",
            "[wolf-12vm8:10:SERV]    CORPC_SEND_DATA handler called with fill=21\n",
            "[wolf-12vm5:7:SERV]     CORPC_SEND_DATA handler called with fill=21\n",
            "-------------------------------------------------------\n",
            "Primary job  terminated normally, but 1 process returned\n",
            "a non-zero exit code. Per user-direction, the job has been aborted.\n",
            "-------------------------------------------------------\n",
            "--------------------------------------------------------------------------\n",
            "orterun noticed that process rank 2 with PID 66102 on node wolf-11 exited on signal 11 (Segmentation fault).\n",
            "--------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            ", Similarity: 0.2370\n",
            "Summary & Description: print count failed rpc selftest \n",
            " Currently self-test stores the return codes for each individual RPC, but only reports a total count of those that failed. It would be nicer if self-test would tell you how many of each failure occurred. This probably also requires implementing crt_errstr(), Similarity: 0.0312\n",
            "Summary & Description: implement iv fetch operation \n",
            " Implement IV Fetch operation inside of the CART.\n",
            "As part of this effort following APIs previously defined in crt_iv.h should be implemented:\n",
            "\n",
            "crt_iv_namespace_create()\n",
            "crt_iv_namespace_attach()\n",
            "crt_iv_namespace_destroy()\n",
            "crt_iv_fetch()\n",
            "\n",
            "This is stage1 implementation of those APIs. Not all features are supported, such as no support for 'iv_ver' field during fetch.\n",
            "\n",
            ", Similarity: 0.3569\n",
            "Summary & Description: potential reduction pmix operations startup \n",
            " There is the potential to streamline startup, reduce the number of PMIx calls during startup, and therefore considerably improve portability and startup times.\n",
            "\n",
            " \n",
            "\n",
            "Currently there are three ways of starting two process sets and having them attach, as listed below.\n",
            " # Run them all at the same time, in the same namespace.  This would look like \"orterun -n 2 <app>\", and presumably the app would have to look at PMIX_RANK and then provide a different value for process set name based on PMIX RANK.  It's not clear this was ever used in MCL and it hasn't been used in CaRT to my knowedge\n",
            " # Run them all at the same time, in different namespaces.  This looks like \"orterun -n 1 <app1> : -n 1 <app2>, and allows either different binaries to be run, or the same binary with different command lines.  This is commonly used throughout our test code.----\n",
            " # Run them at different times under \"DVM\".  This look like \"ortedvm --report-uri <file>\" ; \"orterun --hnp file:<file> -n 1 <app1>\" ; \"orterun --hnp file:<file> -n 1 <app2>\"  This is the best option, and is used by some of our tests.\n",
            "\n",
            "The way PMIx is currently used is every process publishes their process set name, then each process fetches the process set name from each other process, and makes a local list of process sets, then for each group of names assigns ranks locally (this uses common input data so the same result is calculated everywhere)\n",
            "\n",
            "If we only supported option above the the initial publish of names could be avoided, and we could just assume CaRT rank was the same as PMIx rank, making the code both cleaner, faster and easier to port to other systems.\n",
            "\n",
            "This ticket is to formally deprecate option 1, establish what changes could be made whilst still supporting option 2, then decide if we want to keep it and make the appropriate changes.\n",
            "\n",
            " , Similarity: 0.2845\n",
            "Summary & Description: add test sessions selftest \n",
            " Currently memory is allocated by the service after receiving the first ping request that requires return value. This would allow for some cleanup once the session closes. This is also required for bulk tests., Similarity: 0.1818\n",
            "Summary & Description: improve selftest timeout eviction handling \n",
            " Currently self-test detects timeouts and stores the latency as -1. However, this still gets averaged into the rest of the latencies for results reporting and also reduces the number of RPCs in flight by 1 for each timeout. Also need to detect when nodes have been evicted and stop sending self-test messages to them for 1:many , Similarity: 0.0532\n",
            "Summary & Description: modify singleton interface \n",
            " The singleton interface lacks some flexibility and it causes periodic problems with CPPR testing.  If more than one CPPR server is running under the same user, even though they use different directories, the singleton file will always be the same.\n",
            "\n",
            "I propose making the following changes\n",
            "1. Remove the flags from crt_init.\n",
            "2. Add an API, something like the following:\n",
            "/* If crt is initialized, write out attach information to a file.   If filename isn't NULL, generate a unique filename and return the name.  If it is NULL, a filename is created using old behavior based on the server name.   The server application can make this filename available to clients.   If called more than once, it can just return the filename.\n",
            "*/\n",
            "int crt_allow_singleton(const char **filename);\n",
            "\n",
            "/* Attach a singleton to the server described in filename.  If filename is NULL, it defaults to old behavior based on group id */\n",
            "int crt_group_attach_singleton(crt_group_id_t srv_id, const char *filename, crt_group_t **attached_grp);\n",
            "\n",
            "If the singleton is created, it is unlinked on crt_finalize.   \n",
            "\n",
            "The CNSS has a mechanism for exporting information (such as this filename) to users so this gives us flexibility we need.   , Similarity: 0.2746\n",
            "Summary & Description: reporting mallinfo resultsdelta \n",
            " Self-test should have an option to report, sample and report deltas on mallinfo data from libc on both the origin and target.\n",
            "\n",
            "This will allow us to monitor heap usage during RPCs.  Unfortunately mallinfo only shows active bytes, not the total number of all-time alloc()/free() calls which would mean that if RPCs are both allocating and releasing data we would not be able to observe it with this call.\n",
            "\n",
            "By Delta I mean to be able to sample the mallinfo struct before test start, sample it again afterwards and report on changes., Similarity: 0.1693\n",
            "Summary & Description: move selftest client cart \n",
            " This is a tough one - need to get the client itself integrated into CART. This means it'll have to make use of whatever thread(s) it has available from the host application, and will be significantly more restricted in the things it can do. , Similarity: 0.3294\n",
            "Summary & Description: implement selftest manymany \n",
            " This will probably get implemented as some kind of wrapper around self-test that invokes it multiple times. Maybe Python?, Similarity: 0.0923\n",
            "Summary & Description: integrate self test test system \n",
            " Self test needs to be exercised by the automatic tests that get run when patches are pushed to Gerrit. , Similarity: 0.1942\n",
            "Summary & Description: improve results output format self test 1many \n",
            " Currently latency results are only reported in aggregate. Need a way to report results for individual nodes in 1:many so that outliers can be easily observed, Similarity: 0.2005\n",
            "Summary & Description: possible cart bug srcutilhashc584 chashrecdecref assertion zombie crtlistemptyrlink failed \n",
            " Currently merged self-test occasionally manages to trigger the following assert: \n",
            "{{src/util/hash.c:584: chash_rec_decref: Assertion `!zombie || crt_list_empty(rlink)' failed.}}\n",
            "\n",
            "This happens occasionally, but seems more frequent when: \n",
            "Larger messages are being sent\n",
            "More messages are sent from two threads simultaneously\n",
            "\n",
            "Running self-test with these arguments has a reasonable chance to encounter this assert: \n",
            "{{ --max-inflight-rpcs 10000 --repetitions-per-size 10000 --message-sizes 100000}}\n",
            "\n",
            "I tested this on the latest commit in Gerrit as of today - {{c1467cae4c76faf12e64b1a02a58ac776a02dbd6}}\n",
            "\n",
            "I have attached the script I'm using to run self-test. All of the testing I've been doing has been on wolf-30, though Jeff mentioned he ran into this on his own system at least once so I know it isn't specific to my setup. \n",
            "\n",
            "Here is the cci.ini settings I am using (though I'm a bit suspicious that the MTU isn't actually getting set correctly by my script): \n",
            "{{transport = tcp\n",
            "interface = eth0\n",
            "port = 25588\n",
            "priority = 10\n",
            "mtu = 9000}}\n",
            "\n",
            "\n",
            "\n",
            "\n",
            ", Similarity: 0.1470\n",
            "Summary & Description: add cart test singleton attach \n",
            " Singleton attach is used by CPPR to attach to the local CNSS process.   It stopped working in a recent version of CaRT.\n",
            "\n",
            "Please add a test for this feature to avoid this problem in the future.   The existing CaRT echo test can actually be used but the line needed is commented out.\n",
            "\n",
            "In line 169 of crt_echo.h, the flags need to be set to CRT_FLAG_SINGLETON.   \n",
            "For it to work on the client, CRT_ALLOW_SINGLETON=1 should be set in the environment for both the client and server and the bit should be set on the client in crt_init.   Unfortunately, you don't want to set that bit when you don't want to be treated as a singleton client so the test case can't be checked in without further modification to make that bit setting optional.  One option would be to set the bit if CRT_ALLOW_SINGLETON is set in the environment.\n",
            "\n",
            "e.g.\n",
            "if (getenv(\"CRT_ALLOW_SINGLETON\")) flags |= CRT_FLAG_BIT_SINGLETON;\n",
            "\n",
            "Then a test needs to be added to set that bit.\n",
            "\n",
            "See CART-109 which has usage.   You run the server with orte and the client without orte., Similarity: 0.2593\n",
            "Summary & Description: singleton attach stopped working cart \n",
            " I modified crt_echo.h to uncomment the SINGLETON line\n",
            "\n",
            "export CRT_ALLOW_SINGLETON=1 \n",
            "orterun -x CCI_CONFIG -x PATH -x LD_LIBRARY_PATH -N 1 -H wolf-31 -x CRT_ALLOW_SINGLETON ./tests/crt_echo_srv\n",
            "\n",
            "In another window\n",
            "export CRT_ALLOW_SINGLETON=1\n",
            "tests/crt_echo_cli\n",
            "\n",
            "You can see from the logs that it is trying to do PMIx lookups\n",
            "\n",
            "I'm rank 0 in group crt_default_cli_group(size 1), srv_group crt_default_srv_group with size 1.\n",
            "12/19-21:52:32.10 wolf-31 CaRT[2229] CRT  ERR  src/crt/crt_pmix.c:490 crt_pmix_uri_lookup PMIx_Lookup cart-crt_default_srv_group-0-uri failed, rc -113, value type: 0.\n",
            "12/19-21:52:32.10 wolf-31 CaRT[2229] CRT  ERR  src/crt/crt_pmix.c:507 crt_pmix_uri_lookup crt_pmix_uri_lookup failed, rc: -1023.\n",
            "12/19-21:52:32.10 wolf-31 CaRT[2229] CRT  ERR  src/crt/crt_group.c:1645 crt_grp_uri_lookup crt_grp_uri_lookup(grp_id crt_default_srv_group, rank 0) failed, rc: -1023.\n",
            "12/19-21:52:32.10 wolf-31 CaRT[2229] CRT  ERR  src/crt/crt_group.c:419 crt_grp_lc_lookup crt_grp_uri_lookup failed, rc: -1023.\n",
            "12/19-21:52:32.10 wolf-31 CaRT[2229] CRT  ERR  src/crt/crt_hg.c:604 crt_hg_req_create crt_grp_lc_lookup failed, rc: -1023, opc: 0xa0.\n",
            "12/19-21:52:32.10 wolf-31 CaRT[2229] CRT  ERR  src/crt/crt_rpc.c:282 crt_req_create_internal crt_hg_req_create failed, rc: -1023, opc: 0xa0.\n",
            "12/19-21:52:32.10 wolf-31 CaRT[2229] CRT  ERR  src/crt/crt_rpc.c:335 crt_req_create crt_req_create_internal failed, opc: 0xa0, rc: -1023.\n",
            "crt_echo_cli: src/test/crt_echo_cli.c:150: run_client: Assertion `rc == 0' failed.\n",
            "\n",
            "\n",
            ", Similarity: 0.3265\n",
            "Summary & Description: initial implementation onetomany selftest \n",
            " Depends on CART-123. Need to be able to address groups of endpoints and round-robin traffic between them. , Similarity: 0.2432\n",
            "Summary & Description: improve ability address nodes selftest \n",
            " Currently only possible to address rank 0 in the self-test client. Need to make it possible to address arbitrary endpoints. , Similarity: 0.2224\n",
            "Summary & Description: self test configurable memory alignment \n",
            " Configurable alignment for sent data, Similarity: 0.2252\n",
            "Summary & Description: core cart api ras notifications \n",
            " Add a new API to the core CaRT to allow the CaRT user to subscribe for RAS notification. When this API is used, CaRT should:\n",
            "- subscribe to RAS notification to PMIx\n",
            "- convert the PMIx rank to CaRT rank\n",
            "- invoke the user callback\n",
            "\n",
            "For now, we only care about notifications concerning the nodes that are part of the service process set. We will extend this to client in the future., Similarity: 0.2350\n",
            "Summary & Description: cart rebase latest mercury \n",
            " Port CaRT to latest version of Mercury. , Similarity: 0.2128\n",
            "Summary & Description: embed service process set liveness delta rpc reply \n",
            " Building from CART-102 RPCs with a remote service process set should automatically update the clients liveness map, without requiring any additional RPCs.\n",
            "\n",
            "The client should send the generation number it knows about with every RPC, and every reply should contain the new generation number, and the delta between the two.  The client can then evict remote ranks without sending additional network traffic., Similarity: 0.2112\n",
            "Summary & Description: build usability improvements \n",
            " There are some issues with the cart build currently using the wrong compiler flags.\n",
            "\n",
            "* We should be building the code with -pthread, but not linking with -lpthread\n",
            "* We should be using rpath\n",
            "* It should be possibly to link with cart and not require LD_LIBRARY_PATH to be set in order to run., Similarity: 0.4433\n",
            "Summary & Description: remove liveness map entirely \n",
            " The code should not be using a liveness map for peer health, any failed peers should be identified either by the failed rank list, or by a \"evicted\" marker in the hash table.\n",
            "\n",
            "PMIx rank to local rank lookups should happen via a lookup array within the crt_pmix.c but these lookups should happen at as lower a level as possible and PMIx ranks should not be used elsewhere in the code., Similarity: 0.1458\n",
            "Summary & Description: attach multiple service process sets \n",
            " Process sets should be able to attach to multiple remote service process sets., Similarity: 0.2765\n",
            "Summary & Description: ortedvm start wait long enough \n",
            " In the DvmRunner code in the test runner there is a sleep(3) call to ensure that the DVM is ready to receive jobs before any are launched.  This sleep is not long enough to ensure that the DVM is started correctly, and is leading to tests failing with the following error:\n",
            "\n",
            "--------------------------------------------------------------------------\n",
            "A ppr pattern was specified, but the topology information\n",
            "for the following node is missing:\n",
            "\n",
            "  Node:  wolf-18vm1\n",
            "--------------------------------------------------------------------------\n",
            "\n",
            "Setting as Critical as this is the cause of a lot of test failures we've seen in CI.\n",
            "\n",
            "Immediately we need to increase the delay to at least 10 seconds however we should also check for the \"DVM ready\" output properly, both to ensure that the DVM has started properly, but also to avoid unnecessary delays when running the tests interactively., Similarity: 0.1451\n",
            "Summary & Description: make message size asymmetrically configurable \n",
            " Builds on CORFSHIP-305, Similarity: 0.2127\n",
            "Summary & Description: hgaddrlookup code periodically timing \n",
            " The lookup callback is never called after CaRT issues HG_Addr_lookup on a peer.   This doesn't happen every time but often enough that it makes it nearly impossible to run CPPR on more than a few nodes with later versions of CaRT.\n",
            "\n",
            "For now, we've worked around the issue by using build 189 of CaRT which is right before the tree barrier code was added.    The build we were using was 205., Similarity: 0.2537\n",
            "Summary & Description: fix test log files names include type testlog \n",
            " the name for the sub test log file need to include a type. using  'test_log', Similarity: 0.2760\n",
            "Summary & Description: correct host name ga node yaml file \n",
            " the node name needs to be this wolf-##, the name used in creating the log file names for Maloo. The name is wolf-##.hpdd.intel.com right now. the full qualified name needs to be removed., Similarity: 0.2489\n",
            "Summary & Description: test logs viewable within maloo web interface \n",
            " We need to be able to see stdout/error logs from tests within the malloo web interface., Similarity: 0.3303\n",
            "Summary & Description: increase number clusters availble cart ci \n",
            " Martin tells us that Cart CI testing is not currently able to run across all available wolf VMs.  Martin is to define more clusters using the existing VMs to improve throughput of Cart results., Similarity: 0.2647\n",
            "Summary & Description: ability run ci tests 2 nodes \n",
            " For Cart features which are currently in development we need our CI testing to run over more than 2 nodes, our current requirement is for 5 nodes although this may increase further in future.\n",
            "\n",
            "We need HA to allocate 5 vms for VM testing., Similarity: 0.2482\n",
            "Summary & Description: self test manymany \n",
            " Ability to run many 1:many self-tests simultaneously from different origins, Similarity: 0.0593\n",
            "Summary & Description: self test 1many \n",
            " Ability to self-test between one node and a set of many other nodes, Similarity: 0.0798\n",
            "Summary & Description: self test servertoserver \n",
            " The ability to initiate a self-test between any two CART-enabled applications - critically including those that know nothing about self-test. \n",
            "This requires both the RPC generator and recipient to be in the CART library.  \n",
            "(Not to be confused with Self Test 1:1), Similarity: 0.2425\n",
            "Summary & Description: cart build improvements \n",
            " Generic improvements to the CaRT build., Similarity: 0.2219\n",
            "Summary & Description: need crthhashlinkgetref \n",
            " This is required by http://review.whamcloud.com/23509 for client pool handle (dc_pool) usage. I will submit a patch shortly., Similarity: 0.4387\n",
            "Summary & Description: hashproc functions changed mercury upstream \n",
            " Currently cart will not complie against mercury Master becuase of the following commit to mercury.\n",
            "\n",
            "https://github.com/mercury-hpc/mercury/commit/198f059045b2348c885fbac578f60a508a2cccae, Similarity: 0.2366\n",
            "Summary & Description: implement barrier cart \n",
            " We need a barrier to enable two phase startup and shutdown, Similarity: 0.1988\n",
            "Summary & Description: cart tests print values return codes rather asserting \n",
            " We recently ran across a spurious error in test_group.c where an assertion fired on rc != 0.   In the log, all we see is that the assertion fired but we have no idea what the return code is.    The tests should be refactored to give as much information as possible on such errors so we can make reasonable guesses at the problem, especially when it isn't reliably reproducible., Similarity: 0.0254\n",
            "Summary & Description: testing need minimize conflicts ports \n",
            " Currently using a static cci.ini file causes some issues with testing if stale processes are alive which prevent reuse of the same port.  This can be minimized by using some heuristics to select the port number used., Similarity: 0.3005\n",
            "Summary & Description: singleton client cciverbs fails connect server \n",
            " setting CRT_PHY_ADDR_STR to \"cci+verbs\", causes singleton client to fail to connect to the server with error:\n",
            "\n",
            "2016/10/27-03:09:48.92 wolf-31 CaRT[19014] CRT  ERR  src/crt/crt_hg.c:122 Could not connect to verbs://192.168.1.31:20068 within 10 second (rank 0, host wolf-31.wolf.hpdd.intel.com).\n",
            "2016/10/27-03:09:48.92 wolf-31 CaRT[19014] CRT  ERR  src/crt/crt_group.c:273 Could not connect to verbs://192.168.1.31:20068, rc: -1011.\n",
            "2016/10/27-03:09:48.92 wolf-31 CaRT[19014] CRT  ERR  src/crt/crt_group.c:282 crt_conn_tag (base_addr verbs://192.168.1.31:20068, tag 0) failed, rc: -1011.\n",
            "2016/10/27-03:09:48.92 wolf-31 CaRT[19014] CRT  ERR  src/crt/crt_hg.c:619 crt_grp_lc_lookup failed, rc: -1011, opc: 0xb3.\n",
            "2016/10/27-03:09:48.92 wolf-31 CaRT[19014] CRT  ERR  src/crt/crt_rpc.c:250 crt_hg_req_create failed, rc: -1011, opc: 0xb3.\n",
            "\n",
            "\n",
            "Setting CRT_PHY_ADDR_STR  to \"cci+tcp\" works fine.\n",
            "\n",
            "cci.ini contents are:\n",
            "[server_tcp]\n",
            "transport = tcp\n",
            "interface = eth0\n",
            "port = 12191\n",
            "priority = 10\n",
            "mtu = 9000\n",
            "\n",
            "[server_ib]\n",
            "transport = verbs\n",
            "interface = ib0\n",
            "port = 20068\n",
            "priority = 10\n",
            ", Similarity: 0.3135\n",
            "Summary & Description: refactor test scripts \n",
            " Refactor the test scripts in CART:\n",
            "cart_echo_test and cart_test_group\n",
            "Refactor the test script in IOF:\n",
            "iof_test_ionss\n",
            "\n",
            "Add a commontestuite to each project., Similarity: 0.3564\n",
            "Summary & Description: replace check orte path env var tests \n",
            " Both the cart_echo_test and cart_group_test files check for the orte.uri file; replace this condition with environment variable TR_USE_URL. This does not change the logic., Similarity: 0.1569\n",
            "Summary & Description: occasional crash trigger loop \n",
            " CPPR daemon running with cart on multiple nodes (daemons talking to each other) frequently runs into crash on context0 thread with traceback shown below.\n",
            "\n",
            "This issue unfortunately so far is only reproducible running full cppr_daemon port on multiple nodes.\n",
            "\n",
            "[Switching to Thread 0x7f000a4a8700 (LWP 98606)]\n",
            "0x00007f00225e35f7 in raise () from /lib64/libc.so.6\n",
            "(gdb) backtrace\n",
            "#0  0x00007f00225e35f7 in raise () from /lib64/libc.so.6\n",
            "#1  0x00007f00225e4ce8 in abort () from /lib64/libc.so.6\n",
            "#2  0x00007f0022623327 in __libc_message () from /lib64/libc.so.6\n",
            "#3  0x00007f002262b053 in _int_free () from /lib64/libc.so.6\n",
            "#4  0x00007f002403dd8d in NA_Trigger (context=0x7effec000b90, timeout=timeout@entry=0, max_count=max_count@entry=1,\n",
            "    actual_count=actual_count@entry=0x7f000a4a7c2c) at /home/aaoganez/mercury/mercury/src/na/na.c:1595\n",
            "#5  0x00007f0024247e9b in hg_core_progress_na (timeout=<optimized out>, context=0x7effec000a30)\n",
            "    at /home/aaoganez/mercury/mercury/src/mercury_core.c:1855\n",
            "#6  hg_core_progress (context=context@entry=0x7effec000a30, timeout=timeout@entry=100)\n",
            "    at /home/aaoganez/mercury/mercury/src/mercury_core.c:1944\n",
            "#7  0x00007f00242490fa in HG_Core_progress (context=context@entry=0x7effec000a30, timeout=timeout@entry=100)\n",
            "    at /home/aaoganez/mercury/mercury/src/mercury_core.c:2910\n",
            "#8  0x00007f0024249c65 in HG_Progress (context=context@entry=0x7effec000a30, timeout=timeout@entry=100)\n",
            "    at /home/aaoganez/mercury/mercury/src/mercury.c:1081\n",
            "#9  0x00007f0023a1d97a in crt_hg_progress (hg_ctx=0x7effec0008d8, timeout=<optimized out>) at src/crt/crt_hg.c:922\n",
            "#10 0x00007f0023a15be4 in crt_progress (crt_ctx=0x7effec0008c0, timeout=100000, cond_cb=0x0, arg=<optimized out>)\n",
            "    at src/crt/crt_context.c:657\n",
            "#11 0x00007f000a9fc8ef in __context0_progress (data=0x0) at src/common/cppr_request.cpp:863\n",
            "#12 0x00007f0023197dc5 in start_thread () from /lib64/libpthread.so.0\n",
            "#13 0x00007f00226a4ced in clone () from /lib64/libc.so.6\n",
            "\n",
            "\n",
            "\n",
            "Running with valgrind memcheck enabled it complains about the following:\n",
            " 672   <auxwhat>Address 0x32a9ae40 is 64 bytes inside a block of size 192 free'd</auxwhat>\n",
            " 673   <stack>\n",
            " 674     <frame>\n",
            " 675       <ip>0x4C2AD17</ip>\n",
            " 676       <obj>/usr/lib64/valgrind/vgpreload_memcheck-amd64-linux.so</obj>\n",
            " 677       <fn>free</fn>\n",
            " 678     </frame>\n",
            " 679     <frame>\n",
            " 680       <ip>0x5706D8C</ip>\n",
            " 681       <obj>/home/aaoganez/cart/scons_local/install/lib/libna.so.0.8.9</obj>\n",
            " 682       <fn>NA_Trigger</fn>\n",
            " 683       <dir>/home/aaoganez/mercury/mercury/src/na</dir>\n",
            " 684       <file>na.c</file>\n",
            " 685       <line>1595</line>\n",
            " 686     </frame>\n",
            " 687     <frame>\n",
            " 688       <ip>0x54FBE9A</ip>\n",
            " 689       <obj>/home/aaoganez/cart/scons_local/install/lib/libmercury.so.0.8.9</obj>\n",
            " 690       <fn>hg_core_progress_na</fn>\n",
            " 691       <dir>/home/aaoganez/mercury/mercury/src</dir>\n",
            " 692       <file>mercury_core.c</file>\n",
            " 693       <line>1855</line>\n",
            " 694     </frame>\n",
            " 695     <frame>\n",
            " 696       <ip>0x54FBE9A</ip>\n",
            " 697       <obj>/home/aaoganez/cart/scons_local/install/lib/libmercury.so.0.8.9</obj>\n",
            " 698       <fn>hg_core_progress</fn>\n",
            " 699       <dir>/home/aaoganez/mercury/mercury/src</dir>\n",
            " 700       <file>mercury_core.c</file>\n",
            " 701       <line>1944</line>\n",
            " 702     </frame>\n",
            " 703     <frame>\n",
            " 704       <ip>0x5D24979</ip>\n",
            " 705       <obj>/home/aaoganez/cart/install/Linux/lib/libcrt.so</obj>\n",
            " 706       <fn>crt_hg_progress</fn>\n",
            " 707       <dir>/home/aaoganez/cart/src/crt</dir>\n",
            " 708       <file>crt_hg.c</file>\n",
            " 709       <line>922</line>\n",
            " 710     </frame>\n",
            " 711     <frame>\n",
            " 712       <ip>0x5D1CBE3</ip>\n",
            " 713       <obj>/home/aaoganez/cart/install/Linux/lib/libcrt.so</obj>\n",
            " 714       <fn>crt_progress</fn>\n",
            " 715       <dir>/home/aaoganez/cart/src/crt</dir>\n",
            " 716       <file>crt_context.c</file>\n",
            " 717       <line>657</line>\n",
            " 718     </frame>\n",
            "\n",
            ", Similarity: 0.3104\n",
            "Summary & Description: investigate usage scalable allocators \n",
            " It is well known that malloc isn't scalable.    There are several allocators that are including tbb, tcmalloc, jemalloc, and even CPPR's allocator.    Look into how we might take advantage of them in our components., Similarity: 0.2395\n",
            "Summary & Description: memory corruption crtreqdecref \n",
            " Performing asynchronous rpc calls sometimes results in memory corruption; this was observed both with cppr_daemon as well as sample cart program.\n",
            "\n",
            "Sample cart program can be available at:\n",
            "http://review.whamcloud.com/#/c/23066/4/\n",
            "\n",
            "Corruption happens during RPC call between client and server.\n",
            "Client performs rpc call.\n",
            "Server does:\n",
            "\n",
            "308 void *__respond_to_test(void *data)\n",
            "309 {\n",
            "\n",
            "312         crt_rpc_t *rpc;\n",
            "315         rpc = (crt_rpc_t *)data;\n",
            "\n",
            "323         crt_reply_send(rpc);\n",
            "324         crt_req_decref(rpc);\n",
            "325\n",
            "326         return NULL;\n",
            "327 }\n",
            "\n",
            "/* RPC callback function on the server side */\n",
            "330 int test_cb(crt_rpc_t *rpc)\n",
            "331 {\n",
            "332         pthread_t thread;\n",
            "\n",
            "334         int rc;\n",
            "341         crt_req_addref(rpc);\n",
            "\n",
            "343         rc = pthread_create(&thread, 0, __respond_to_test, rpc);\n",
            "344         assert(rc == 0);\n",
            "\n",
            "346         return 0;\n",
            "347 }\n",
            ", Similarity: 0.1714\n",
            "Summary & Description: attach info needs visible ranks \n",
            " Currently /tmp/ file with attach info is only visible on rank0. This attach info needs to be visible on all ranks.\n",
            "\n",
            "In addition for development purposes need an ability to specify prefix/postfix for generated attach info file; otherwise multiple users running same project would end up clashing with each other., Similarity: 0.3718\n",
            "Summary & Description: cart induce network saturation send many pings asynchronously \n",
            " Need to staturate the in flight RPC count and recieve replies asynchronously\n",
            "\n",
            "a) Meaure throughput this way\n",
            "b)pings per second, Similarity: 0.1489\n",
            "Summary & Description: cart write self test binary cart send rpcs measure latency \n",
            " CaRT Self test binary:\n",
            "\n",
            "Location: src/self_test\n",
            "\n",
            "1. Needs to be build into a separate binary (modify sconscript etc) callable directly by user\n",
            "\n",
            "2. Needs to send RPC's configurable by (for now):\n",
            "  a) Message size\n",
            "b) repetition count\n",
            "\n",
            "3. Measure latency \n",
            "\n",
            "4. Needs to attach as a client group. \n",
            "\n",
            ", Similarity: 0.2359\n",
            "Summary & Description: stricter typecheck crtbulkfree \n",
            " It would be nice if compiler complained about freeing of wrong type for bulk handle.\n",
            "\n",
            "For example if you do the following below, both of those will compile without warnings:\n",
            "crt_bulk_t bulk_handle;\n",
            "\n",
            "crt_bulk_free(handle);\n",
            "crt_bulk_free(&handle);\n",
            "\n",
            "It would be nice if passing wrong type to crt_bulk_free() (e.g crt_bulk_free(&handle)) would cause compiler warning instead; finding a bug was quite difficult when I passed wrong type to free, as it ended up causing mem corruption\n",
            ", Similarity: 0.2231\n",
            "Summary & Description: consequitive bulktransfer get fails hg error 1 hgnaerror \n",
            " Performing 2 consecutive crt_bulk_transfer() calls with increasing sizes (second bulk transfer size is bigger than first bulk transfer size) causes failure inside of cart/mercury.\n",
            "\n",
            "In our use case the following happens:\n",
            "client issues RPC call\n",
            "server responds with output, which contains bulk handle\n",
            "client creates local bulk handle\n",
            "client performs crt_bulk_transfer() with CRT_BULK_GET\n",
            "\n",
            "\n",
            "First time, we transport data of 1024 bytes\n",
            "Second time we attempt to perform transport of 2048 bytes\n",
            "\n",
            "The second crt_bulk_transfer() returns error with following printed to the log:\n",
            "The error code returned by second transfer is:\n",
            "2016/10/06-13:21:37.49 wolf-31 CaRT[10858] CRT  ERR  src/crt/crt_hg.c:1204 HG_Bulk_transfer failed, hg_ret: 1.\n",
            "2016/10/06-13:21:37.49 wolf-31 CaRT[10858] CRT  ERR  src/crt/crt_bulk.c:172 crt_hg_bulk_transfer failed, rc: -1020.\n",
            "\n",
            "During each transfer, we create everything new -- new local handles, new remote handle, new context, new buffers.\n",
            "\n",
            "If the second bulk transfer size is smaller than the initial bulk transfer size, then bulk transfer works fine.\n",
            "\n",
            "Adding print internally into cart() following are parameters to cart:\n",
            "Call 0 (successful):\n",
            "\n",
            "HG_Bulk_transfer(\n",
            "        bulk_ctx = 0x7f1b20001fe0,\n",
            "        transfer_cb = 0x7f1b4c39d850,\n",
            "        bulk_cbinfo = 0x7f1afc026d40,\n",
            "        op = 1,\n",
            "        na_addr = 0x7f1b200010f0,\n",
            "        remote_hdl = 0x7f1afc0265e0,\n",
            "        0,\n",
            "        local_hdl = 0x7f1afc025f00,\n",
            "        0,\n",
            "        len = 1024, ...)\n",
            "\n",
            "\n",
            "Call 1 (failing)\n",
            "HG_Bulk_transfer(\n",
            "        bulk_ctx = 0x7f1b24001a00,\n",
            "        transfer_cb = 0x7f1b4c39d850,\n",
            "        bulk_cbinfo = 0x7f1af00269e0,\n",
            "        op = 1,\n",
            "        na_addr = 0x7f1b200010f0,\n",
            "        remote_hdl = 0x7f1af0025f90,\n",
            "        0,\n",
            "        local_hdl = 0x7f1af0025e80,\n",
            "        0,\n",
            "        len = 2048, ...)\n",
            "\n",
            "\n",
            "Code snippet on 'client' size (inside of rpc response handler):\n",
            " 627         crt_bulk_t local_bulk_handle;\n",
            " 628         crt_sg_list_t *sgl;\n",
            " 629         struct crt_bulk_desc bulk_desc;\n",
            " \n",
            " 654         crt_iov_t *iov;\n",
            " 655\n",
            " 656         iov = (crt_iov_t *) malloc(sizeof(crt_iov_t));\n",
            " 657\n",
            " 658         iov->iov_buf = addr;\n",
            " 659         iov->iov_buf_len = out_bulk_len;\n",
            " 660         iov->iov_len = out_bulk_len;\n",
            " 661\n",
            " 662         sgl = (crt_sg_list_t *)malloc(sizeof(crt_sg_list_t));\n",
            " 663\n",
            " 664         sgl->sg_nr.num = 1;\n",
            " 665         sgl->sg_iovs = iov;\n",
            "\n",
            " 671         crt_ctx = rpc_req->dr_ctx;\n",
            " \n",
            " 675         rc = crt_bulk_create(crt_ctx, sgl, CRT_BULK_RO, &local_bulk_handle);\n",
            " 676\n",
            " 677         if (rc != 0) {\n",
            " 678                 _CPPR_LOG_DEBUG(\"Failed to create local bulk handle\");\n",
            " 679         }\n",
            " 680\n",
            " 682         bulk_desc.bd_rpc = rpc_req;\n",
            " 683         bulk_desc.bd_bulk_op = CRT_BULK_GET;\n",
            " 684         bulk_desc.bd_remote_hdl = output->bulk_handle;\n",
            " 685         bulk_desc.bd_remote_off = 0;\n",
            " 686         bulk_desc.bd_local_hdl = local_bulk_handle;\n",
            " 687         bulk_desc.bd_local_off = 0;\n",
            " 688         bulk_desc.bd_len = out_bulk_len;\n",
            " 689\n",
            " 690         rc = crt_req_addref(rpc_req);\n",
            "\n",
            " 704         rc = crt_bulk_transfer(&bulk_desc, __process_bulk_cget_response, cb_info, NULL);\n",
            " 705\n",
            " 706         if (rc != 0) {\n",
            " 707                 _CPPR_LOG_ERROR(\"Failed to do bulk transfer of data\");\n",
            "\n",
            "Code snippet from server side:\n",
            "1593         crt_sg_list_t *sgl;\n",
            "1594         crt_iov_t *iov;\n",
            "1595         crt_context_t crt_ctx;\n",
            "1596\n",
            "1597         iov = (crt_iov_t *)malloc(sizeof(crt_iov_t));\n",
            "1598\n",
            "1599         iov->iov_buf = mmap_addr;\n",
            "1600         iov->iov_buf_len = file_size;\n",
            "1601         iov->iov_len = file_size;\n",
            "1602\n",
            "1603         sgl = (crt_sg_list_t *)malloc(sizeof(crt_sg_list_t));\n",
            "1604\n",
            "1605         sgl->sg_nr.num = 1;\n",
            "1606         sgl->sg_iovs = iov;\n",
            "1607\n",
            "\n",
            "1610         crt_ctx = req->child_rpc->dr_ctx;\n",
            "1611\n",
            "1612         rc = crt_bulk_create(crt_ctx, sgl, CRT_BULK_RO, &output->bulk_handle);\n",
            "\n",
            "\n",
            "Similar model worked fine using pure mercury to do bulk transfers of data before cart port. , Similarity: 0.2557\n",
            "Summary & Description: need clean separation libcrt libcrtutil \n",
            " As we are starting a CPPR port to CaRT, we noticed that there is some cross contamination between headers and libraries that may not be intended.\n",
            "\n",
            "For example, ARRAY_SIZE is used in crt_api.h but defined in crt_util/common.h and crt_util/common.h includes crt_util/clog.h\n",
            "\n",
            "Speaking of clog.h, clog is defined in crt_util but also used in libcrt.    If we have two libraries, perhaps it would be best to have a clean separation between them such that one doesn't depend on the other.   For example, perhaps the hash table fits nicely in libcrt_util but the logging should just be part of libcrt.   I should not need to include anything in crt_util to use libcrt and vice versa.   Otherwise, they should be combined as there is no clear reason to separate them., Similarity: 0.3074\n",
            "Summary & Description: remove suppression blocks hgaddrlookup \n",
            " ﻿Remove suppression blocks in the valgrind suppression file. These blocks are a temporary fix for the memory issues inside HG_Addr_lookup(). The memory leak is observed when HG_Addr_lookup() is called inside an RPC callback, and seems to happen only when the cci plugin. Can be merged after Mercury fixes those memory issues.\n",
            ", Similarity: 0.2657\n",
            "Summary & Description: remove valgrind suppression block pmix issues \n",
            " Remove suppression blocks in the valgrind suppression file. These blocks are a temporary fix for the memory issues inside PMIx. Can be merged after PMIx fixes those memory issues., Similarity: 0.2861\n",
            "Summary & Description: write complete list pmix requirements \n",
            " We need this to ensure that PMIx supports the features we need, in advance of when we need them., Similarity: 0.2516\n",
            "Summary & Description: remove compiler errors upstream mercury \n",
            " At the recent face to face upstream expressed surprise that mercury is generating compiler errors although our experience is that a lot are generated.\n",
            "\n",
            "Where possible we should resolve these over time and submit upstream.\n",
            "\n",
            "This will make a good self-contained background activity for anybody that is blocked on other work or completes their sprint early., Similarity: 0.2005\n",
            "Summary & Description: psr secondary process sets \n",
            " each client process should pick a PSR in each secondary process set\n",
            "\n",
            "mcl_lookup() sends RPCs to it's PSR in the secondary process set when called with a set structure of a secondary set. If the client process gets a time out, it calls the query function to send an RPC to the global RPC., Similarity: 0.1226\n",
            "Summary & Description: live proc map info mcllookup \n",
            " mcl_lookup() should send a version number and get back a delta of the liveness map of the service set, Similarity: 0.2309\n",
            "Summary & Description: export current secondary process set list psr \n",
            " Add ability for clients to query PSR list, receive updates to PSR list and attach to remote secondary process sets., Similarity: 0.1971\n",
            "Summary & Description: psr failover \n",
            " Clients should have an algorithm for picking secondary PSR nodes and automatically contact secondary PSR should there be a timeout on the primary PSR.  If the PSR is evicted the client needs to register with the new PSR.\n",
            "\n",
            "only on timeout.\n",
            "\n",
            "lazily\n",
            "\n",
            "Attached clients should fail over to secondary PSR on PSR failure., Similarity: 0.1678\n",
            "Summary & Description: add minimum viable size feature \n",
            " If the process sets shrinks below the minimum viable size the remaining members should shut down.\n",
            "\n",
            "Enough members of a process set need to register with RAS so that at least one member registered member is still running whilst the MVS threshold has not be violated.\n",
            "\n",
            "the root does a broadcast, evertybody makes it own decision, Similarity: 0.0685\n",
            "Summary & Description: use broadcast communicating ras notifications \n",
            " the root of the subscribed service processes broadcasts RAS notifications to the entire process set\n",
            "\n",
            "the broadcast needs to be fault tolerant as well. the next root has to take over if the real root dies\n",
            "\n",
            "\n",
            "A reminder of how the RAS broadcast needs to work:\n",
            "\n",
            "# Some ranks are selected to subscribe to RAS notifications.\n",
            "# RAS subscribers early inject RAS events and put them on a pending queue\n",
            "# The RAS leader (the subscribed node with the lowest rank) send out a broadcast for each eviction.  The broadcast goes to the process set, however excludes ranks which are on the pending queue.\n",
            "# The broadcast is retried until success, potentially allowing for more RAS events and therefore longer exclude lists to allow previously failing broadcasts to succeed.\n",
            "# After a successful broadcast then the RAS leader then broadcasts the next pending eviction on the list.  In this way there is only ever one broadcast on the wire at a time.\n",
            "# The RAS leader repeats until there are no more pending RAS events on the queue.\n",
            "# If a subscribed node becomes the RAS leader because it sees a pending event through RAS for all lower-ranked subscribed nodes then it assumes the leadership role and starts broadcasting eviction events, starting with the latest eviction broadcast it itself received.\n",
            "\n",
            "This is safe because it relies on the following semantics:\n",
            "* There is only one broadcast in progress at any one time.\n",
            "* On RAS leader failover a new leader steps in, and replays any event which may not have been globally acknowledged.\n",
            "* Broadcasts are idempotent on all nodes, as the same eviction broadcast may be received more than once, Similarity: 0.0204\n",
            "Summary & Description: bulk include bulk transfers self test \n",
            " Send bulk transfers determined by:\n",
            "\n",
            "1. message range. repittion count\n",
            "2. misaligned vs aligned ( need to have this user configurable)\n",
            "\n",
            "Measure: bandwidth, Similarity: 0.2901\n",
            "Summary & Description: self test 11 \n",
            " Ability to self-test between two arbitrary nodes\n",
            "Required by SIP4, Similarity: 0.1595\n",
            "Summary & Description: node configuration \n",
            " setup and test the configuration scripts need to setup test nodes to test P/S over IB, Similarity: 0.3188\n",
            "Summary & Description: ability embed mcl process set log filename \n",
            " A new, updated,  interface to mcl log is needed to be able set the log file name. This interface could be a marco that sets the environment variable before calling mcl log open., Similarity: 0.3109\n",
            "Summary & Description: create core environment parsing feature \n",
            " Create a wrapper around getenv() to ensure that we can track what environment variables are in use and the values and that their use is recorded in the debug output.\n",
            "\n",
            "As a starting point we will want at least mcl_getenv_str(), mcl_getenv_bool() and mcl_getenv_int()\n",
            "\n",
            "For IOF we want the IONSS processes to get their configuration over the network from the CNSS so we'll likely want to also store configuration options in a table so that they can be referenced later on., Similarity: 0.3681\n",
            "Summary & Description: logo update \n",
            " Updated UI with some proposed logo work, this doesn't need to be merged, just putting it out there if people want to look at it themselves., Similarity: 0.1926\n",
            "Summary & Description: refactored multiproject build \n",
            " This is now a multi-project build.   All artifacts can be built at the same time.\n",
            "\n",
            "idea project config added\n",
            "build should build the capsule, Similarity: 0.2902\n",
            "Summary & Description: provides webuiurl frameworkinfo \n",
            " Issue MYRIAD-50 Mesos now displays the webui url as http://<resource_manager>:8192 or however configured., Similarity: 0.3862\n",
            "Summary & Description: support mesos framework authentication \n",
            " This is for MYRIAD-22 .\n",
            "I'm pleased if I could have some feedbacks., Similarity: 0.1997\n",
            "Summary & Description: myriad flexup crash mesosslave \n",
            " This hasn't been replicated on a cluster yet. Locally, if a myriad flexup request asks for too many resources, the mesos-slave process crashes and myriad produces no error messages., Similarity: 0.3326\n",
            "Summary & Description: web api broken \n",
            " Currently web API is broken.\n",
            "\n",
            "We need to add default constructors for:\n",
            "FlexDownClusterRequest.java\n",
            "FlexUpClusterRequest.java\n",
            "GetConfigurationResponse.java\n",
            "GetSchedulerStateResponse.java, Similarity: 0.5416\n",
            "Summary & Description: added default constructors \n",
            " FlexDownClusterRequest.java\n",
            "FlexUpClusterRequest.java\n",
            "GetConfigurationRequest.java\n",
            "\n",
            "Fixes issue MYRIAD-75, Similarity: 0.4414\n",
            "Summary & Description: findbugs fixes \n",
            " findbugs added to the project and all findbug issues fixed., Similarity: 0.2385\n",
            "Summary & Description: enable mesos framework checkpointing \n",
            " Should be done once scheduler HA works. Otherwise, when the scheduler exits, all the Mesos tasks/NMs will be killed., Similarity: 0.1987\n",
            "Summary & Description: vagrant image doesnt jdk \n",
            " setup-yarn-2.sh fails in the vagrant vm because there is no jdk installed by default., Similarity: 0.4018\n",
            "Summary & Description: klocwork defects \n",
            " A couple defects I found with Klocwork. Nothing huge. I'm a sales engineer for the product and I check open-source projects from time to time to gather material for demos., Similarity: 0.2788\n",
            "Summary & Description: curious code \n",
            " I'm running static analysis using Klocwork on Myriad code (as I'm a sales engineer for Klocwork, and always looking for defects that I can use to support a demo). Noticed this odd bit:\n",
            "\n",
            "    case TASK_RUNNING:\n",
            "        schedulerState.makeTaskActive(taskId);\n",
            "        NodeTask task = schedulerState.getTask(taskId);\n",
            "        break;\n",
            "    case TASK_FINISHED:\n",
            "\n",
            "The \"task\" variable doesn't appear anywhere in the scope of the switch statement, but it looks like it was supposed to mean something at one point. A few revisions ago, the block looked like this:\n",
            "\n",
            "\tcase TASK_RUNNING:\n",
            "\t\tschedulerState.makeTaskActive(taskIdValue);\n",
            "\t\tNodeTask task = schedulerState.getTask(taskIdValue);\n",
            "\t\tschedulerState.releaseLock(task.getClusterId());    <--- interesting\n",
            "\t\tbreak;\n",
            "\tcase TASK_FINISHED:\n",
            "\n",
            "Investigating further...the call to {{releaseLock()}} was dropped in 7a81b91ccde7bdd63ef5d87622d85fae6ef98d94 (\"Removed cluster level locking as we are only dealing with 1 cluster now\"). So that was probably intentional, and probably the assignment to {{task}} left was by accident...well, there you go., Similarity: 0.3991\n",
            "Summary & Description: setting static ip address \n",
            " It is convenient for demos and tutorials to have a static IP.  The [Playa project|https://github.com/mesosphere/playa-mesos] uses 10.141.141.10.  It made sense to use something similar.   This is setup as 10.141.141.20., Similarity: 0.3532\n",
            "Summary & Description: run mapreduce job \n",
            " after exec \"bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar pi 1 100\"\n",
            "the log is below:\n",
            "Starting Job\n",
            "14/12/25 02:52:30 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
            "14/12/25 02:52:30 INFO input.FileInputFormat: Total input paths to process : 1\n",
            "14/12/25 02:52:30 INFO mapreduce.JobSubmitter: number of splits:1\n",
            "14/12/25 02:52:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1419326748056_0005\n",
            "14/12/25 02:52:31 INFO impl.YarnClientImpl: Submitted application application_1419326748056_0005\n",
            "14/12/25 02:52:31 INFO mapreduce.Job: The url to track the job: http://ec2-54-168-156-14.ap-northeast-1.compute.amazonaws.com:8088/proxy/application_1419326748056_0005/\n",
            "14/12/25 02:52:31 INFO mapreduce.Job: Running job: job_1419326748056_0005\n",
            "\n",
            "then hangs on, Similarity: 0.3508\n",
            "Summary & Description: fix myriad configuration filename correct doc myriaddevmd \n",
            " In Main.java, configuration filename is {{myriad-config-default.yml}}\n",
            "That mismatch makes somebody(like me) confused without any error messages printed., Similarity: 0.3781\n",
            "Summary & Description: support scale scale operations \n",
            " <h3> Scope for phase 1 </h3>\n",
            "  - Expose scale up/down commands via REST/UI (manual scaling).\n",
            "  - Make the scale up/down operations to be driven by configurable policies. e.g.: \n",
            "     * kill NMs with no/least number of AMs\n",
            "     * kill NMs with most recently launched containers\n",
            "     * kill enough NMs to free up \"X cpus, Y mem\" etc)\n",
            "  - Implement one of the above (most likely the first one above)\n",
            "  - Auto scaling (i.e. scale up when YARN has more tasks than resources and scale down when YARN has more resources than tasks)\n",
            "  - Allow only one scaling operation (auto/manual) at any given point of time\n",
            "\n",
            "<h3> Behavior of the scheduler (can be broken into sub-issues) </h3>\n",
            " - Scheduler receives a REST command to scale up/down (manual)\n",
            " - Scheduler 'detects' the need for scale up/down  (auto)\n",
            " - Scheduler uses a simple policy interface to obtain a list of NMs to be scaled up/down. The implementation is pluggable via configuration.\n",
            " - One of the policies should be implemented.\n",
            " - For each NM that needs to be scaled up/down, the scheduler passes a message to the executor running on that node with the new NM profile.\n",
            "\n",
            "<h3> Behavior of the executor  </h3>\n",
            " - Executor receives a message to scale up/down the Node Manager.\n",
            " - Executor receives the new \"NM Profile\" to apply for the Node Manager.\n",
            " - Executor modifies the \"cpu/mem\" resources in yarn-site.xml for the new NM profile and restarts NM., Similarity: 0.2145\n",
            "Summary & Description: allow admin specify mesos masters address \n",
            " One of the config properties in the myriad-config.yml file is the address (host/port) of the mesos master. Currently myriad-config.yml is embedded into myriad.jar. In order to make this file editable by admin we need to remove packaging this file into myriad.jar and allow it to be deployed into a directory that's on YARN's class path (.../etc/hadoop/ is a good location)., Similarity: 0.3464\n",
            "Summary & Description: executor launches nodemanager \n",
            " <h3> Assumptions </h3>\n",
            "  - Binaries needed for launching NM are pre-installed on all the nodes.\n",
            "\n",
            "<h3> Behavior of the scheduler (Embedded in RM) </h3>\n",
            "  - Scheduler launches the executor and subsequently assigns a task to the executor to launch NM.\n",
            "  - Scheduler exposes configuration options for the following:\n",
            "    * Full command to launch the NM\n",
            "    * Environment variables required for NM process (For e.g. HADOOP_HOME, YARN_HOME etc)\n",
            "    * \"user\" for the NM process\n",
            "    * Default NM profile to start the first NM (can be changed via REST interface during scale up/down)\n",
            "  - Scheduler passes the above configuration to the executor when NM is being launched as a 'task'.\n",
            "  \n",
            "<h3> Behavior of the executor </h3>\n",
            "  - The binaries needed to launch the executor are not assumed to be pre-installed (@mohitsoni: please correct me if you think otherwise)\n",
            "  - The executor updates the NM's cpu and mem capacities in yarn-site.xml. (To figure out the location of yarn-site.xml, the executor may have to take the approach outlined below in the next bullet) \n",
            "    - Configure {code:yarn}.nodemanager.resource.cpu-vcores{code} in {code:yarn}-site.xml{code}, to specify amount of cpus NodeManager should advertise to YARN ResourceManager.\n",
            "    - Configure {code:yarn}.nodemanager.resource.memory-mb{code} in {code:yarn}-site.xml{code}, to specify amount of memory NodeManager should advertise to YARN ResourceManager.\n",
            "    - Configure {code:yarn}.nodemanager.linux-container-executor.cgroups.hierarchy{code}, to mount YARN's cgroup hierarchy under the mesos-id for the NodeManager task. See [cgroups docs|https://github.com/mesos/myriad/blob/master/docs/cgroups.md] for more details.\n",
            "  - The executor launches NM as below:\n",
            "     * Try to launch the NM using \"sudo -H -u <user> bash -c '<NM_Launch_Command>'\" - i.e. inherit the user's environment from .bashrc.\n",
            "     * If the above fails, try to inject the environment variables passed in via Scheduler's configuration\n",
            "     * If both fail, error out.\n",
            "     * If one of them succeeds, remember which one succeeded and use that approach next time a NM needs to be launched (for e.g. during scale up/down)., Similarity: 0.3045\n",
            "Summary & Description: nodemanager executor \n",
            " Create a mesos executor for launching YARN's NodeManager. The executor should take care of following:\n",
            "* Configure {code:yarn}.nodemanager.resource.cpu-vcores{code} in {code:yarn}-site.xml{code}, to specify amount of cpus NodeManager should advertise to YARN ResourceManager.\n",
            "* Configure {code:yarn}.nodemanager.resource.memory-mb{code} in {code:yarn}-site.xml{code}, to specify amount of memory NodeManager should advertise to YARN ResourceManager.\n",
            "* Configure {code:yarn}.nodemanager.linux-container-executor.cgroups.hierarchy{code}, to mount YARN's cgroup hierarchy under the mesos-id for the NodeManager task. See [cgroups docs|https://github.com/mesos/myriad/blob/master/docs/cgroups.md] for more details.\n",
            "* Figure out strategy for accessing NodeManager binaries at runtime.\n",
            "  * Assume that NodeManager is pre-installed\n",
            "  * Download NodeManager binaries at runtime, using URI\n",
            "  * Consider Docker, Similarity: 0.2957\n",
            "Summary & Description: remove dependency application ioloop \n",
            " The IOLoop should be injected with a Procotol. (Will be an HttpProtocol in our case.), Similarity: 0.4834\n",
            "Summary & Description: make use fact javaniosocketchannel always writable underlaying socket write buffers full \n",
            " Like we did in deft 0.1.0 / 0.1.1. In HttpResponse.write we tried send data to the channel directly, instead of register for write io events.\n",
            "(if we cant send all data we still need to register for a write io event/callback), Similarity: 0.3820\n",
            "Summary & Description: support transferencoding chunked asynchronoushttpclient \n",
            " http://en.wikipedia.org/wiki/Chunked_transfer_encoding\n",
            "http://www.jmarshall.com/easy/http/#http1.1c2, Similarity: 0.4770\n",
            "Summary & Description: ambiguous httprequest httpresponse interfaces \n",
            " We have two HttpRequest and HttpResponse classes. One for the web server and one for the async http client.\n",
            "We should (1) investigate the possibility to have a common interface and (2) create two concrete implementations for the components above., Similarity: 0.3393\n",
            "Summary & Description: simple http get requestresponse \n",
            " Using e.g \"curl http://localhost:8080/\"\n",
            "response: \"hello world\", Similarity: 0.1809\n",
            "Summary & Description: supporting http 10 requests \n",
            " To be compatible with older browsers, HTTP 1.1 servers must support HTTP 1.0 requests. In particular, when a request uses HTTP 1.0 (as identified in the initial request line),\n",
            "\n",
            "    * don't require the Host: header, and\n",
            "    * don't send the \"100 Continue\" response. \n",
            "\n",
            "See: http://www.jmarshall.com/easy/http/#http1.1s8, Similarity: 0.3063\n",
            "Summary & Description: project name \n",
            " Ulme' makes me feel sick. Spam some proposals as comments in this thread, Similarity: 0.1394\n",
            "Summary & Description: timeout priorities \n",
            " facebook/tornado exerts itself to satify the timeouts added to the IOLoop.\n",
            "eg.\n",
            "while True:\n",
            "    poll_timeout = 0.2\n",
            "    [ ... ]\n",
            "    if self._timeouts:\n",
            "        now = time.time()\n",
            "        while self._timeouts and self._timeouts[0].deadline <= now:\n",
            "            timeout = self._timeouts.pop(0)\n",
            "            self._run_callback(timeout.callback)\n",
            "        if self._timeouts:\n",
            "            milliseconds = self._timeouts[0].deadline - now\n",
            "            poll_timeout = min(milliseconds, poll_timeout)\n",
            "\n",
            "the last row is interesting. the poll_timeout (TIMEOUT in deft) is modified so the next timeout will be executed as soon as possible., Similarity: 0.1703\n",
            "Summary & Description: return notfoundrequesthandler applicationgethandlerstring path \n",
            " In HPI; application.getHandler(request.getRequestedPath()); could return a \"default\" (Not Found) RequestHandler if no request handler is mapped to the given path.\n",
            "\n",
            "Code in HPI.handleRead could look much cleaner., Similarity: 0.4467\n",
            "Summary & Description: staticcontenthandler \n",
            " Implement requesthandler that delivers static content, Similarity: 0.3445\n",
            "Summary & Description: handle requestbody parsing request \n",
            " HttpRequest.of() must handle body part of request message, Similarity: 0.2474\n",
            "Summary & Description: wrong cachecontrol header sch \n",
            " current :response.setHeader(\"Cache-Control\", \"no-cache\");, Similarity: 0.2710\n",
            "Summary & Description: push third party libs \n",
            " Verify and upgrade:\n",
            "guava r08\n",
            "logback 0.9.28\n",
            "async-http-client 1.6.0 (for unit tests)\n",
            "httpclient 4.1 (for unit tests), Similarity: 0.3382\n",
            "Summary & Description: better looking 404page \n",
            " Fix content of 404 page, Similarity: 0.1661\n",
            "Summary & Description: date header static \n",
            " e.g. Date: Mon, 27 Sep 2010 16:30:38 GMT, Similarity: 0.1658\n",
            "Summary & Description: simple asynchronous http client \n",
            " The http client should run inside Deft's ioloop., Similarity: 0.4658\n",
            "Summary & Description: improve internals jctm \n",
            " The timeouts stored in JCTM (JMXConfigurableTimeoutManager) are not sorted. We should store the timeouts like this:\n",
            "    [T_1, T_2, ..., T_n] \n",
            "where \n",
            "    T_x is of type o.d.io.timeout.Timeout\n",
            "    timeout(T_x) is T_x.getTimeout()\n",
            "and\n",
            "    timeout(T_1) <= timeout(T_2) <= .. <= timeout(T_n)\n",
            " \n",
            "Would be trivial to stop the iteration (read timeout triggering)  if \n",
            "    timeout(T_x) > now, Similarity: 0.3543\n",
            "Summary & Description: exception handling \n",
            " How should exceptions be handled, which log should be written to etc., Similarity: 0.1704\n",
            "Summary & Description: chain support httpresponsewrite \n",
            " The last callback in an asynchronous callback chain will often look something like this\n",
            "response.write(result); \n",
            "response.finish(); \n",
            "\n",
            "If write \"returns this\" the above could be written:\n",
            "\n",
            "response.write(result).finish();, Similarity: 0.1404\n",
            "Summary & Description: fix issue 135 \n",
            " Implement #135 (java.io.IOException: Too many open files) (close #135) patch by ilmich review by rschildmeijer\n",
            "\n",
            "Sorry, the fastest way is do it all again:)\n",
            "\n",
            "Regards, Similarity: 0.4675\n",
            "Summary & Description: logging \n",
            " java.util.logging, slf4j, log4j..?, Similarity: 0.3739\n",
            "Summary & Description: dispatch correct method httpprotocolimplhandleread \n",
            " Right now it's assumed that it's the GET method.\n",
            "Need to check wheter it's GET/POST/HEAD etc. and then call corresponding method on RH, Similarity: 0.2711\n",
            "Summary & Description: reallocation glitch dynamicbytebuffer \n",
            " DynamicByteBuffer glitch mentioned by slemsle\n",
            "see https://github.com/slemesle/deft/blob/master/src/test/java/org/deftserver/io/buffer/DynamicByteBufferTest.java, Similarity: 0.3413\n",
            "Summary & Description: npe system tests windows vista \n",
            " Exception in thread \"I/O-LOOP\" java.lang.NullPointerException\n",
            "        at org.deftserver.web.IOLoop.start(IOLoop.java:61)\n",
            "        at org.deftserver.web.DeftSystemTest$1.run(DeftSystemTest.java:221)\n",
            "        at java.lang.Thread.run(Thread.java:619)\n",
            "\n",
            "NPE disappears if i remove the following line from our Closeables.closeQuietly\n",
            "    IOLoop.INSTANCE.removeHandler(channel);\n",
            "\n",
            "The test that fails is \n",
            "    DeftSystemTest.asynchronousRequestTest(), Similarity: 0.3355\n",
            "Summary & Description: expose nodejs tornado deft hello world code \n",
            " The charts on the deft web page (www.deftserver.org) visualizes some \"hello world\" request/response benchmarks. Make this code available (separate github project?), Similarity: 0.3790\n",
            "Summary & Description: expose writebuffersize \n",
            " Currently WRITE_BUFFER_SIZE is hard coded to 1500 (hint ~tcp packet)\n",
            "This knob should be adjustable/configurable by clients., Similarity: 0.2288\n",
            "Summary & Description: http get query parameters \n",
            " e.g. http://127.0.0.1:8080/person?name=roger&surname=schildmeijer\n",
            "\n",
            "API proposal: HttpRequest.getParameter(String parameterName);\n",
            "e.g String name = request.getParameter(\"name\");  // name == \"roger\", Similarity: 0.2149\n",
            "Summary & Description: dependency management \n",
            " (ant + ivy), maven or just ignore, Similarity: 0.2561\n",
            "Summary & Description: return 501 unimplemented methods \n",
            " Supporting the GET and HEAD methods\n",
            "\n",
            "To comply with HTTP 1.1, a server must support at least the GET and HEAD methods. If you're handling CGI scripts, you should probably support the POST method too.\n",
            "\n",
            "Four other methods (PUT, DELETE, OPTIONS, and TRACE) are defined in HTTP 1.1, but are rarely used. If a client requests a method you don't support, respond with \"501 Not Implemented\", like\n",
            "\n",
            "    HTTP/1.1 501 Not Implemented\n",
            "    [blank line here]\n",
            "\n",
            "See: http://www.jmarshall.com/easy/http/#http1.1s8, Similarity: 0.3834\n",
            "Summary & Description: post support \n",
            " Support for http method POST\n",
            "\n",
            "naive introduction to POST : http://www.jmarshall.com/easy/http/#postmethod, Similarity: 0.3706\n",
            "Summary & Description: prematurely closing selectablechannel \n",
            " github/williame pointed out that closing the channel (in AS) as soon as we read EOF is wrong. (We could have pending data (staged for write, waiting for handleWrite callback))\n",
            "\n",
            "Investigate this further..., Similarity: 0.2197\n",
            "Summary & Description: selector timeout manipulation \n",
            " The intention is that selectorTimeout (in IOLoop) (default 250ms) should be altered to fulfil ioloop timeouts and/or ioloop callbacks \n",
            "(i.e. minimize the \n",
            "   \"time-Timeout-was-executed\"  -  \"timeouts-timeout\"\n",
            "and/or execute a callback asap.).\n",
            "\n",
            "Currently the selectorTimeout is always 250ms., Similarity: 0.1954\n",
            "Summary & Description: remove obsolete example classes \n",
            " org.deftserver.example.{AsyncDbApi, AsyncDbHandler, HttpRequestPerformanceTest}\n",
            "\n",
            "AsyncDbApi - unused, misleading usage\n",
            "AsyncDbHandler - dont like the timeout usage to describe an @Asynchronous method\n",
            "HttpRequestPerformanceTest - Anyone using this any more?, Similarity: 0.3848\n",
            "Summary & Description: httprequest parse requestedpath correctly \n",
            " I think there is a problem with the Deft HttpRequest parsing, specifically with the value of the requestedPath attribute.\n",
            "I believe this value should be the URI up to but not including the query string. Currently, the return value for getRequestedPath returns the full request line, including the query string.\n",
            "\n",
            "For example:  /foo?a=XXX&y=ZZZ\n",
            "Currently Returns: /foo?a=XXX&y=ZZZ\n",
            "Should Return: /foo\n",
            "\n",
            "This has the secondary effect of breaking request handler mappings since any addition of a query string will result in a request handler for /foo not being found.\n",
            "\n",
            "I patched this locally as follows:\n",
            "\n",
            "    public HttpRequest(String requestLine, Map<String, String> headers) {\n",
            "        this.requestLine = requestLine;\n",
            "        String[] elements = requestLine.split(\" \");\n",
            "        method = HttpVerb.valueOf(elements[0]);\n",
            "        String[] pathFrags = elements[1].split(\"\\\\?\");\n",
            "        requestedPath = pathFrags[0];\n",
            "        version = elements[2];\n",
            "        this.headers = headers;   \n",
            "        body = null;\n",
            "        initKeepAlive();\n",
            "        parameters = parseParameters(elements[1]);\n",
            "    }, Similarity: 0.3161\n",
            "Summary & Description: add support http response status code \n",
            " eg. 301 Moved Permanently, Similarity: 0.2468\n",
            "Summary & Description: staticcontenthandler working \n",
            " #63 (Asynchronous writes) introduced a new regression regarding the SCH. Three UT (userDefinedStaticContentHandlerTest, pictureStaticFileRequestTest, staticFileRequestTest) are currently disabled because of this., Similarity: 0.2741\n",
            "Summary & Description: create maven release goallifecycle phase \n",
            " proposed structure:\n",
            "deft-x.x.x.zip\n",
            "  /lib (3rd part dep, e.g guava, logback, slf4j..etc)\n",
            "  LICENSE.txt\n",
            "  NEWS.txt\n",
            "  NOTICE.txt\n",
            "  README.md\n",
            "  deft-x.x.x.jar\n",
            "\n",
            "q: should we include the source?, Similarity: 0.4216\n",
            "Summary & Description: wrong groupid pomxml \n",
            " should be org.deftserver instead of org.deft, Similarity: 0.3770\n",
            "Summary & Description: config file \n",
            " Probably a good idea to extract some settings (Timeouts etc.) to a separate config-file, instead of hard coded values in code, Similarity: 0.3584\n",
            "Summary & Description: etag contentlength headers httpresponsefinish \n",
            " If no previous flush has been invoked during a finish() execution we could calculate an etag and the content-length and supply those as response headers., Similarity: 0.2437\n",
            "Summary & Description: expose keepalivetimeout \n",
            " We should make the keep-alive-timeout parameter available for \"clients\", Similarity: 0.1986\n",
            "Summary & Description: nonblocking asynchronous requests \n",
            " We need a way to override a RequestHandlers default behaviour, because we use a non-blocking I/O style. \n",
            "\n",
            "Default behaviour == the request is automatically finished.\n",
            "\n",
            "Overriding == want a request to remain open after the main request handler method returns.\n",
            "\n",
            "Detailed explanation and motivation: http://bit.ly/adRmia, Similarity: 0.2770\n",
            "Summary & Description: asynchronous socket \n",
            " To have better third party support (realised this during the impl of the async http client) we should offer something similar to Tornados iostream, which is basically an async (buffered) socket.\n",
            "\n",
            "impl proposal.\n",
            "The AsynchronousSocket should implement IOHandler and (initially) have methods like:\n",
            "    connect(String host, int port, AsyncCallback ccb)\n",
            "    close();\n",
            "    readUntil(String delimiter, AsyncResult<String> rcb)\n",
            "    write(String data, AsyncCallback wcb)\n",
            "\n",
            "we should probably add something like\n",
            "    readBytes(int n, AsyncResult<String> rcb)\n",
            "later on., Similarity: 0.4580\n",
            "Summary & Description: handle ifmodifiedsince \n",
            " To avoid sending resources that don't need to be sent, thus saving bandwidth, HTTP 1.1 defines the If-Modified-Since:  and If-Unmodified-Since: request headers. The former says \"only send the resource if it has changed since this date\"; the latter says the opposite. Clients aren't required to use them, but HTTP 1.1 servers are required to honor requests that do use them.\n",
            "\n",
            "Unfortunately, due to earlier HTTP versions, the date value may be in any of three possible formats:\n",
            "\n",
            "    If-Modified-Since:  Fri, 31 Dec 1999 23:59:59 GMT\n",
            "    If-Modified-Since:  Friday, 31-Dec-99 23:59:59 GMT\n",
            "    If-Modified-Since:  Fri Dec 31 23:59:59 1999\n",
            "\n",
            "Again, all time values in HTTP use Greenwich Mean Time (though try to be tolerant of non-GMT times). If a date with a two-digit year seems to be more than 50 years in the future, treat it as being in the past-- this helps with the millennium bug. In fact, do this with any date handling in HTTP 1.1.\n",
            "\n",
            "Although servers must accept all three date formats, HTTP 1.1 clients and servers must only generate the first kind.\n",
            "\n",
            "If the date in either of these headers is invalid, or is in the future, ignore the header.\n",
            "\n",
            "If, without the header, the request would result in an unsuccessful (non-200-level) status code, ignore the header and send the non-200-level response. In other words, only apply these headers when you know the resource would otherwise be sent.\n",
            "\n",
            "The If-Modified-Since: header is used with a GET request. If the requested resource has been modified since the given date, ignore the header and return the resource as you normally would. Otherwise, return a \"304 Not Modified\" response, including the Date: header and no message body, like\n",
            "\n",
            "    HTTP/1.1 304 Not Modified\n",
            "    Date: Fri, 31 Dec 1999 23:59:59 GMT\n",
            "    [blank line here]\n",
            "\n",
            "The If-Unmodified-Since: header is similar, but can be used with any method. If the requested resource has not been modified since the given date, ignore the header and return the resource as you normally would. Otherwise, return a \"412 Precondition Failed\" response, like\n",
            "\n",
            "    HTTP/1.1 412 Precondition Failed\n",
            "    [blank line here]\n",
            "\n",
            "\n",
            "See: http://www.jmarshall.com/easy/http/#http1.1s8, Similarity: 0.2479\n",
            "Summary & Description: verify host http header \n",
            " Because of the urgency of implementing the new Host: header, servers are not allowed to tolerate HTTP 1.1 requests without it. If a server receives such a request, it must return a \"400 Bad Request\" response, like\n",
            "\n",
            "    HTTP/1.1 400 Bad Request\n",
            "    Content-Type: text/html\n",
            "    Content-Length: 111\n",
            "\n",
            "    <html><body>\n",
            "    <h2>No Host: header received</h2>\n",
            "    HTTP 1.1 requests must include the Host: header.\n",
            "    </body></html>\n",
            "\n",
            "This requirement applies only to clients using HTTP 1.1, not any future version of HTTP. If the request uses an HTTP version later than 1.1, the server can accept an absolute URL instead of a Host: header (see next section). If the request uses HTTP 1.0, the server may accept the request without any host identification. \n",
            "\n",
            "See: http://www.jmarshall.com/easy/http/, Similarity: 0.1925\n",
            "Summary & Description: improve failure handling asynchronoushttpclient \n",
            " fetch(..) throws (connects to unexisting hostname (eg, http://tasdft.se/start/))\n",
            "\n",
            "    java.nio.channels.UnresolvedAddressException\n",
            "\n",
            "and if we connect to, eg. http://localhost/start (not listening on port 80), \n",
            "    21:56:42.778 [I/O-LOOP] ERROR org.deftserver.io.IOLoop - Exception received in IOLoop: {}\n",
            "    java.net.ConnectException: Connection refused\n",
            "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[na:1.6.0_22]\n",
            "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:574) ~[na:1.6.0_22]\n",
            "\tat org.deftserver.io.AsynchronousSocket.handleConnect(AsynchronousSocket.java:95) ~[classes/:na]\n",
            "\tat org.deftserver.io.IOLoop.start(IOLoop.java:79) ~[classes/:na]\n",
            "\tat org.deftserver.example.AsynchronousHttpClientExample.main(AsynchronousHttpClientExample.java:15) [classes/:na]\n",
            "\n",
            "is thrown, Similarity: 0.4578\n",
            "Summary & Description: optimize httputilcreateinitialline \n",
            " Remove String concatenation, Similarity: 0.2370\n",
            "Summary & Description: persistent connections \n",
            " Connection keep-alive\n",
            "http://bit.ly/VopwT, Similarity: 0.3323\n",
            "Summary & Description: issue 79 \n",
            " #79 (closed by mistake, is not finished, Similarity: 0.1080\n",
            "Summary & Description: native arrays inefficient java \n",
            " Its expensive to allocate a native array because of a constraint/rule (in JLS) that says that a newly allocated array, e.g. byte[], must have each of its elements default initialized. (0 for byte)    \n",
            "\n",
            "In org.deftserver.web.protocol.HttpResponse:\n",
            "    private final static int WRITE_BUFFER_SIZE = 1500;\t// in bytes\n",
            "    private DynamicByteBuffer responseData = DynamicByteBuffer.allocate(WRITE_BUFFER_SIZE);\n",
            "\n",
            "Changing this to 64/128 increased the performance (ab -k -c25 -n800000) by ~30%. (21 #/sec -> 27#sec, in 0.1.0/0.1.1 we used String concatenation, maybe thats why we saw that kind of performance)\n",
            "\n",
            "Did another quick try (with the changes mentiond above): \n",
            "In Application:\n",
            "    private int readBufferSize = 128;\t// in bytes\n",
            "\n",
            "gave: 33905.68 [#/sec] (mean) \n",
            "(same ab execution), Similarity: 0.2893\n",
            "Summary & Description: remove bytearrays httprequesttest \n",
            " Instead use new helper class: HttpRequestHelper, and create the corresponding requests, Similarity: 0.3710\n",
            "Summary & Description: fast timeouts \n",
            " assumption is that timeout management will become an increasing proportion of the time as the server scales; investigate timeouts and assure us we have a best-possible approach, Similarity: 0.1318\n",
            "Summary & Description: sourcetest package relationships \n",
            " The packages for test types are not in sync. with the source. For example, the type org.deftserver.web.http.HttpRequest is under test by the FQCN org.deftserver.web.HttpRequestTest. This should be corrected, with the test package being moved to match the source., Similarity: 0.4396\n",
            "Summary & Description: proper shutdown \n",
            " (Close all SelectableChannels during IOLoop.stop)\n",
            "\n",
            "Found this issue during multiple start-stop in integrations tests that uses deft as an embedded web server.\n",
            "\n",
            "The second time start was invoked a bind connection (port already in use) error appeared, Similarity: 0.3818\n",
            "Summary & Description: syntax highlighting \n",
            " The examples on deftserver.org should have syntax highlighting, Similarity: 0.2777\n",
            "Summary & Description: package rename \n",
            " org.deft -> org.deftserver, Similarity: 0.4062\n",
            "Summary & Description: make sure date set http headers response \n",
            " Caching is an important improvement in HTTP 1.1, and can't work without timestamped responses. So, servers must timestamp every response with a Date: header containing the current time, in the form\n",
            "\n",
            "    Date: Fri, 31 Dec 1999 23:59:59 GMT\n",
            "\n",
            "All responses except those with 100-level status (but including error responses) must include the Date: header.\n",
            "\n",
            "All time values in HTTP use Greenwich Mean Time. \n",
            "\n",
            "See: http://www.jmarshall.com/easy/http/#http1.1s8, Similarity: 0.2104\n",
            "Summary & Description: ioc \n",
            " Might be nice to use an \"IOC-container\", Spring Guice.., Similarity: 0.2698\n",
            "Summary & Description: endtoend system test asynchronoushttpclient \n",
            " Could do the http request against the running deft instance in the DeftSystemTest module.\n",
            "\n",
            "I could see the benefits of doing an out of bound http request against an external web server (eg. tt.se, google.com or github.com)...the drawback of this is that the \"system tests\" (read unit tests) would then require a valid internet connection. Bad practise?, Similarity: 0.3434\n",
            "Summary & Description: memory leaks \n",
            " HttpProtocol : The keys (SelectionKey) in stagedFiles is never removed. Should probably be removed in conjunction with closing of socket ( Closeables.closeQuietly(...); ), Similarity: 0.3412\n",
            "Summary & Description: improved mxbean registering \n",
            " Currently we need to specify an objectName (String) when we register an MXBean\n",
            "    MXBeanUtil.registerMXBean(Object self, String mbeanName)\n",
            "\n",
            "This is redudant. We could use\n",
            "    self.getClass().getPackage().getName();\n",
            "and\n",
            "    self.getClass().getSimpleName();\n",
            "\n",
            "to determine the 'objectName', e.g, see second argument below \n",
            "    MXBeanUtil.registerMXBean(this, \"org.deftserver.web:type=IOLoop\");, Similarity: 0.3316\n",
            "Summary & Description: timeout removal \n",
            " Add support for removal of (obsolete) timeouts. \n",
            "hint: IOLoop#removeTimeout(Timeout timeout), Similarity: 0.2829\n",
            "Summary & Description: serversocketchannel support asynchronoussocket \n",
            " Following throws IllegalArgumentException:\n",
            "      ServerSocketChannel server = ServerSocketChannel.open();\n",
            "      server.configureBlocking(false);\n",
            "      server.socket().bind(new InetSocketAddress(9090));\n",
            "      AsynchronousSocket socket = new AsynchronousSocket(server);\n",
            "      // use socket\n",
            "      IOLoop.INSTANCE.start();\n",
            "\n",
            "Currently the AS only support SocketChannel (connect). (i.e no support for eg. ServerSocketChannel (bind)).\n",
            "\n",
            "I did a quick test and added:  \n",
            "    else if (channel instanceof ServerSocketChannel) {\n",
            "       interestOps = SelectionKey.OP_ACCEPT;\n",
            "    }\n",
            "to the two parameters version of the AS ctor and that is probably a good start., Similarity: 0.4229\n",
            "Summary & Description: noconnectionpendingexception ut \n",
            " Hudson's output\n",
            "\n",
            "Running org.deftserver.io.AsynchronousSocketTest\n",
            "19:16:54.581 [I/O-LOOP] DEBUG org.deftserver.io.AsynchronousSocket - handle connect...\n",
            "    Exception in thread \"I/O-LOOP\" java.nio.channels.NoConnectionPendingException\n",
            "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:559)\n",
            "\tat org.deftserver.io.AsynchronousSocket.handleConnect(AsynchronousSocket.java:92)\n",
            "\tat org.deftserver.io.IOLoop.start(IOLoop.java:79)\n",
            "\tat org.deftserver.io.AsynchronousSocketTest$1.run(AsynchronousSocketTest.java:33)\n",
            "\tat java.lang.Thread.run(Thread.java:662)\n",
            "    waiting for client...\n",
            "    client connected..\n",
            "\n",
            "\n",
            "About NCPE:\n",
            "\"Unchecked exception thrown when the finishConnect method of a SocketChannel is invoked without first successfully invoking its connect method. \", Similarity: 0.4676\n",
            "Summary & Description: optimize bytebuffer usage critial write path \n",
            " #63 (Asynchronous write) introduced alot of ByteBuffer usage. Optimize this usage.\n",
            "\n",
            "Hint: (ByteBuffer usage in) HttpResponse.[write, flush, finish, ensureCapacity, allocate, prepend]\n",
            "\n",
            "BB reuse (e.g single bb used for both read and write), key methods: flip() // prepare bb for writing\n",
            "when write is done, if buffer has remaining => compact() // make room for more data be read in, Similarity: 0.2197\n",
            "Summary & Description: support multiple writes \n",
            " We should support multiple invocations to HttpResponse.write instead of the current limitation where we only support one single call to write. If another call is made a MultipleWritesException is thrown.\n",
            "\n",
            "Beginning of HttpResponse.write: \n",
            "    if (writeExecuted) {\n",
            "      throw new MultipleWritesException();\n",
            "    }\n",
            "\n",
            "We could introduce a new method called 'flush' which pretty much does what write does today (i.e write initial response line and headers and then send the data).\n",
            "\n",
            "write could buffer things up in memory until next flush invocation.\n",
            "\n",
            "finish could do a flush + close connection, Similarity: 0.2285\n",
            "Summary & Description: multithreaded deft multiple loadbalanced ioloop instance \n",
            " The main idea behind is to be able to have more than one IOLoop thread running in the JVM, so Defft can use every single core or CPU of the hosting system. I did something like that in my forked project.\n",
            "I see two orientation for this: \n",
            "- One infinite loop using a selector to listen for incoming request (accept) and pushing accepted sockets to one or more infinite thread loop. This is what I did in my fork :). The infinite thread loop use another selector to handle read, write and all other operations, so channel events are still executed in the same single thread.\n",
            "- One selector holding listening sockets is shared between multiple infinite IOLoop threads. Each IOLoop hold its own selector for read and write operations. There should be a lock on the shared selector but this may be easier to develop.\n",
            "\n",
            "My purpose is to allow Deft to execute on all available CPU cores without breaking the infinite loop philosophy., Similarity: 0.4162\n",
            "Summary & Description: deft web page \n",
            " Get a simple version of a web page for deft up and running.\n",
            "Create account on Google App Engine (GAE) and try to host it there, Similarity: 0.3591\n",
            "Summary & Description: premature closing request httpresponsefinish \n",
            " we are doing that (closeOrRegisterForRead) every time (no if condition). we are not sure that everything in responseData is sent to wire. Previously we could have registered for writing (because we could not send all data in flush(), write buffer was too small compared to the \"big\" responsedata.), Similarity: 0.2361\n",
            "Summary & Description: migrate timeoutfactory functionality timeout \n",
            " The only thing TimeoutFactory has is a single static factory method that could be moved to Timeout. \n",
            "\n",
            "Pros. \n",
            "  * Get rid of a util class\n",
            "  * .., Similarity: 0.2608\n",
            "Summary & Description: create non blocking system test \n",
            " Most (all?) system test (see DeftSystemTest) is using blocking http request using apache httpcomponents. Its possible to use non blocking http client with apache hc. Also, could be worth add some tests that use ngin (http://github.com/AsyncHttpClient/async-http-client) async http client. (wider test scoop), Similarity: 0.2817\n",
            "Summary & Description: timeout cancelled upon onfailure asynchronoushttpclient \n",
            " e,g\n",
            "Slightly modified AsynchronousHttpClientExample.java:\n",
            "\n",
            "\tpublic static void main(String[] args) {\n",
            "\t\tAsynchronousHttpClient client = new AsynchronousHttpClient();\n",
            "\t\tclient.fetch(\"http://tasdfadst.se/start/\", new ResultCallback());\n",
            "\t\tIOLoop.INSTANCE.start();\n",
            "\t}\n",
            "\t\n",
            "\tprivate static class ResultCallback implements AsyncResult<HttpResponse> {\n",
            "\n",
            "\t\t@Override public void onFailure(Throwable caught) { out.println(\"exception caught: \" + caught); }\n",
            "\n",
            "\t\t@Override public void onSuccess(HttpResponse response) { out.println(\"http resonse:\\n\" + response); }\n",
            "\t\t\n",
            "\t}\n",
            "\n",
            "Here we expect onFailure to be called with a\n",
            "    java.nio.channels.UnresolvedAddressException\n",
            "\n",
            "because of the unresolvable hostname. \n",
            "\n",
            "The problem is that we dont cancel the timeout (upon onFailure) that associated with the connect call, and hence, we will get another onFailure-callback after the timeout has reached its deadline (~15s). \n",
            "\n",
            "Solution: The timeout should be cancelled upon connect failure, Similarity: 0.4375\n",
            "Summary & Description: regular expressions capturing groups url mapping \n",
            " e.g \n",
            "    Application application = new Application(\n",
            "        new HashMap<String, RequestHandler>() \n",
            "            {{ put(\"/person/([0-9]+)\", new MyRequestHandler()); }}\n",
            "    );\n",
            "\n",
            "The number [0-9]+ is inside a capturing group and should be delivered to the associated RequestHandler, Similarity: 0.2520\n",
            "Summary & Description: remove obsolete doc unit test \n",
            " HttpResponse.write(File file) has obsolete documentation/javadoc. Remove.\n",
            "Create a system test that creates a user defined version of StaticContentHandler and try sending a file with HttpResponse.write(file)., Similarity: 0.4215\n",
            "Summary & Description: concurrentmodificationexception jmxdebuggabletimeoutmanager \n",
            " Exception in thread \"I/O-LOOP\" java.util.ConcurrentModificationException\n",
            "        at java.util.TreeMap$PrivateEntryIterator.nextEntry(TreeMap.java:1100)\n",
            "        at java.util.TreeMap$EntryIterator.next(TreeMap.java:1136)\n",
            "        at java.util.TreeMap$EntryIterator.next(TreeMap.java:1131)\n",
            "        at com.google.common.collect.AbstractMapBasedMultiset$EntrySet$1.next(Ab  stractMapBasedMultiset.java:112)\n",
            "        at com.google.common.collect.AbstractMapBasedMultiset$EntrySet$1.next(Ab  stractMapBasedMultiset.java:102)\n",
            "        at com.google.common.collect.Multisets.addAllImpl(Multisets.java:497)\n",
            "        at com.google.common.collect.AbstractMultiset.addAll(AbstractMultiset.ja  va:114)\n",
            "        at com.google.common.collect.TreeMultiset.addAll(TreeMultiset.java:51)\n",
            "        at com.google.common.collect.Iterables.addAll(Iterables.java:272)\n",
            "        at com.google.common.collect.TreeMultiset.create(TreeMultiset.java:104)\n",
            "        at org.deftserver.io.timeout.JMXDebuggableTimeoutManager.execute(JMXDebu  ggableTimeoutManager.java:55)\n",
            "        at org.deftserver.io.IOLoop.start(IOLoop.java:64)\n",
            "\n",
            "\n",
            "o_o, Similarity: 0.4496\n",
            "Summary & Description: authentication \n",
            " inspiration: http://www.tornadoweb.org/documentation#user-authentication, Similarity: 0.1724\n",
            "Summary & Description: timeouts added timeouts \n",
            " If a timeout is added during a timeout a CME will probably be thrown (?). Tornado and Loft solves this by doing a defensive copy, and iterate the copy.\n",
            "\n",
            "Look at Loft IOLoop for inspiration., Similarity: 0.1749\n",
            "Summary & Description: make parsing httprequest robust \n",
            " HttpRequest.of() must be able to handle \"non-standard\" formats.\n",
            "For instance header definitions could end with just LF instead of CRLF.\n",
            "It should also not crash if it receives garbage-data., Similarity: 0.3226\n",
            "Summary & Description: dont expose 3rd party apis eg guava \n",
            " Such code should be changed to return vanilla java objects instead.\n",
            "For instance: HttpRequest.getParameters();, Similarity: 0.2979\n",
            "Summary & Description: package structure \n",
            " we should have a session where we define a proper package structure.\n",
            "e.g protocol could be renamed to http. And some classes should probably be moved to another package (eg. IOHandler, IOLoop -> io package?), Similarity: 0.4238\n",
            "Summary & Description: timeout asynchronous http requests \n",
            " 30s?\n",
            "\n",
            "should probably be checked in the I/O loop., Similarity: 0.1412\n",
            "Summary & Description: default bytebuffer read size \n",
            " \"Ideally, an HTTP request should not go beyond 1 packet. The most widely used networks limit packets to approximately 1500 bytes, so if you can constrain each request to fewer than 1500 bytes, you can reduce the overhead of the request stream. HTTP request headers include:\"\n",
            "from: http://bit.ly/bkksUu, Similarity: 0.2519\n",
            "Summary & Description: build server \n",
            " Set up automatic build server. Hudson probably., Similarity: 0.3456\n",
            "Summary & Description: callback support ioloop \n",
            " It should be possible to add callbacks to the IOLoop. The callbacks are executed during the next ioloop iteration., Similarity: 0.4159\n",
            "Summary & Description: accepting absolute urls \n",
            " The Host: header is actually an interim solution to the problem of host identification. In future versions of HTTP, requests will use an absolute URL instead of a pathname, like\n",
            "\n",
            "    GET http://www.somehost.com/path/file.html HTTP/1.2\n",
            "\n",
            "To enable this protocol transition, HTTP 1.1 servers must accept this form of request, even though HTTP 1.1 clients won't send them. The server must still report an error if an HTTP 1.1 client leaves out the Host: header\n",
            "\n",
            "See: http://www.jmarshall.com/easy/http/#http1.1s8, Similarity: 0.2251\n",
            "Summary & Description: verify httpprotocolhandleread correct \n",
            " We have a potential bug when reading/parsing a request.\n",
            "If the clientChannel.read(buffer) is performed async, we cannot be sure that all data has been read when we start parsing the HttpRequest.\n",
            "Before we start the parsing, we need to make sure that all data is read, Similarity: 0.2770\n",
            "Summary & Description: http head support \n",
            " Add support for HTTP HEAD method.\n",
            "Should be implemented by StaticContentHandler, Similarity: 0.3971\n",
            "Summary & Description: header names caseinsensitive \n",
            " The header name should not be case-sensitive (though the value may be).\n",
            "We need to change methods like HttpRequest.getHeader(String name), Similarity: 0.2628\n",
            "Summary & Description: periodiccallbacks \n",
            " See Loft for inspiration, Similarity: 0.1491\n",
            "Summary & Description: default http headers \n",
            " In HttpUtil.createInitialLineAndHeaders we (currently) have two default headers -- Server and Date  \n",
            "\n",
            "Verify what http headers we should have as default., Similarity: 0.3080\n",
            "Summary & Description: get rid explicit staging mechanism \n",
            " Use SelectionKey attachment (attach a ByteBuffer) instead., Similarity: 0.2852\n",
            "Summary & Description: javaioioexception many open files \n",
            " Hi, during load test with static files I get this exception:\n",
            "\n",
            "java.io.IOException: Too many open files\n",
            "sun.nio.ch.ServerSocketChannelImpl.accept0 at (Native Method) ~ [na na]\n",
            "at sun.nio.ch.ServerSocketChannelImpl.accept (ServerSocketChannelImpl.java: 152) ~ [na na]\n",
            "at org.deftserver.web.http.HttpProtocol.handleAccept (HttpProtocol.java: 43) ~ [bin / na]\n",
            "at org.deftserver.io.IOLoop.start (IOLoop.java: 78) ~ [bin / na]\n",
            "at it.meebookto.webserver.MainServer.main (MainServer.java: 25)\n",
            "\n",
            "It seems that the method \n",
            "\n",
            "HttpResponse.write (File file) \n",
            "\n",
            "does not release resources after reading from the file system.\n",
            "Sorry for my bad english:), Similarity: 0.4912\n",
            "Summary & Description: xsltc compiltation error branch target offset large short \n",
            " When I am trying to compile a complex style sheet, I am getting the following \n",
            "error.\n",
            "Compiler error(s):\n",
            "  Branch target offset too large for short\n",
            "Without changing the XSL how to compile it?\n",
            "Is there any solution for this?, Similarity: 0.1431\n",
            "Summary & Description: avoid fsexists fsmkdirs call partitions abstracttablefilesystemview \n",
            " Avoid fs.exists() and fs.mkdirs() call to partitions in AbstractTablefileSystemView. \n",
            "\n",
            "This is supposed to be read only view. \n",
            "\n",
            "More details : [https://github.com/apache/hudi/commit/35111131c389704b2f5d4062c8ab73582f61ef13]\n",
            "\n",
            " , Similarity: 0.2962\n",
            "Summary & Description: address test failures enabling virtual keys support metadata table \n",
            " HUDI-2593 is bringing in virtual keys support for metadata table. There a quite a few test cases that don't build the write/client config properly and are leading to test failures. Few tests like compactor, clustering are genuinely failing as they are not passing in the right parameters or using the right interfaces when working on the metadata table. Need to address all these failures and fix the code as needed., Similarity: 0.3270\n",
            "Summary & Description: upgrade javaprometheusclient 312 4x \n",
            " Find more details here -> https://github.com/apache/hudi/issues/2774, Similarity: 0.4185\n",
            "Summary & Description: upgrade hbase dependencies hudi \n",
            " Bootstrap and metadata depend on hbase-server and hfile reader/writer for IO. Currently, Hudi is on 1.2.3 hbase version. We should upgrade to 2.4.x. There have been some significant changes since 1.2.3, especially the changes related to comparator. We need to fully certify the upgrade and also determine how it will affect users with readers and writers on different version., Similarity: 0.3608\n",
            "Summary & Description: fix broken relative links \n",
            " A few relative links were broken in last PR since new docs generated were not available in 0.9.0 release., Similarity: 0.3265\n",
            "Summary & Description: fix chinese docs \n",
            " Looks like the chinese localized docs did not get snapshotted for v0.9.0 and it requires user to go back to v0.8.0 to see localized docs., Similarity: 0.3379\n",
            "Summary & Description: clean concepts consolidate cwiki \n",
            "  [design & architecture|https://cwiki.apache.org/confluence/display/HUDI/Design+And+Architecture], Similarity: 0.4017\n",
            "Summary & Description: clustering fail generating unfinished replacecommit timeline \n",
            " When clustering fail, generating unfinished replacecommit.\n",
            " Restart job will generate delta commit. if the commit contain clustering group file, the task will fail.\n",
            " \"Not allowed to update the clustering file group %s\n",
            " For pending clustering operations, we are not going to support update for now.\"\n",
            " Need to ensure that the unfinished replacecommit file is deleted, or perform clustering first, and then generate delta commit., Similarity: 0.3348\n",
            "Summary & Description: move spark avro serialization class hudi repo \n",
            " in Spark 3.1.1, avro serialization-related class become private. We need to mvoe those classes into Hudi's repo., Similarity: 0.2521\n",
            "Summary & Description: multiwriter w deltastreamer spark datasource work \n",
            " Multi-writer w/ DeltaStreamer and Spark datasource does not work\n",
            "\n",
            " \n",
            "\n",
            "Subsequent commits in deltastreamer will fail.\n",
            "\n",
            " \n",
            "\n",
            "Related issue: https://github.com/apache/hudi/issues/3598, Similarity: 0.4159\n",
            "Summary & Description: disable metadata default flink java \n",
            " As of now, we have enabled metadata by default on the write path in master. but there are few engines and infra where we can't enable due to unavailability or due to not sufficient testing done.\n",
            "\n",
            " \n",
            "\n",
            "flink, java\n",
            "\n",
            "kafka connect. \n",
            "\n",
            " , Similarity: 0.4932\n",
            "Summary & Description: hudi external configuration file support \n",
            " Many big data applications like Hadoop, Hive have an XML configuration file that users can have a concentrated place to set all the parameters.\n",
            "\n",
            "Also to support Spark SQL, it might be easier for Hudi to have a configuration file which could avoid setting Hudi parameters inside Hive CLI or Spark SQL CLI.\n",
            "\n",
            "Here is an example:\n",
            "\n",
            "{{}}\n",
            "{code:java}\n",
            "# Enable optimistic concurrency control by default, to disable it, remove the following two configs\n",
            "hoodie.write.concurrency.mode           optimistic_concurrency_control\n",
            "hoodie.cleaner.policy.failed.writes     LAZY\n",
            "\n",
            "hoodie.write.lock.provider              org.apache.hudi.client.transaction.lock.ZookeeperBasedLockProvider\n",
            "hoodie.write.lock.zookeeper.url         ip-192-168-1-239.ec2.internal\n",
            "hoodie.write.lock.zookeeper.port        2181\n",
            "hoodie.write.lock.zookeeper.base_path   hudi_occ_lock\n",
            "\n",
            "hoodie.index.type                       BLOOM\n",
            "# Only applies if index type is HBASE\n",
            "hoodie.index.hbase.zkquorum             ip-192-168-1-239.ec2.internal\n",
            "hoodie.index.hbase.zkport               2181\n",
            "\n",
            "# Only applies if Hive sync is enable\n",
            "hoodie.datasource.hive_sync.jdbcurl     jdbc:hive2://ip-192-168-1-239.ec2.internal:10000\n",
            "{code}\n",
            "{{}}, Similarity: 0.3977\n",
            "Summary & Description: defaulthoodierecordpayload honor ordering value records within multiple log files merged \n",
            " While creating HoodieRecordPayloads from log files in case of MOR tables, the payloads are created without any orderingVal (even if specified while writing data). Due to this the precombine function could result in any payload irrespective of its orderingVal.\n",
            "\n",
            "Attaching a sample script to reproduce the issue.\n",
            "\n",
            "In this example, for key \"key1\", 1st insert is with ts=1000. Then we update with ts=2000. Thenn we updated with ts=500. Ideally after last update if we snnapshot query the table, we must get key1 with ts=2000 (since our ordering field is ts). However it shows entry of ts=1000 because from logs it ignores ts=2000 and only picks up ts=500.\n",
            "\n",
            "Also AFAIU, the same flow will be used while compaction and then we might lose data forever.\n",
            "\n",
            " \n",
            "\n",
            "More info: https://github.com/apache/hudi/issues/2756, Similarity: 0.3190\n",
            "Summary & Description: spark datasource tableshoodiefileindex issues merge read \n",
            " *Read as DataSource Tables* and *HoodieFileIndex* implementation that went in [https://github.com/apache/hudi/pull/2283] and [https://github.com/apache/hudi/pull/2651] has introduced a couple of major regressions for *Merge on Read* tables:\n",
            " * *_ro* *tables returning Snapshot results*: Since we are directly using Hudi DataSource now to query *_ro* and *_rt* MOR tables, the DataSource has no way to recognize the difference between read optimized and real time tables as it has no way to check for *table name*. In both these scenarios *{color:#172b4d}QUERY_TYPE_OPT_KEY{color}*{color:#172b4d} turns out to be *snapshot* by default, which is causing *MergeOnReadSnapshotRelation* to be used for querying thus returning snapshot results always.{color}\n",
            " * *{color:#172b4d}Partition pruning{color}* *{color:#172b4d}does not work{color}* *{color:#172b4d}for realtime queries{color}*{color:#172b4d}: The *MergeOnReadSnapshotRelation* is directly using *allFiles* to always fetch all the files without doing any partition pruning. This is a regression for Spark SQL real time queries because earlier partition pruning would work via InputFormat for these queries. Thus, it will have impact on rt queries performance.{color}, Similarity: 0.4238\n",
            "Summary & Description: hive sync always update lastcommittimesync \n",
            " In Hive Sync \n",
            "\n",
            "{{org.apache.hudi.hive.HiveSyncTool#syncHoodieTable()}}\n",
            "\n",
            "it includes schema update and partition update.\n",
            "\n",
            "Regardless of having update or not, the logic is to always update the table with a new timestamp for the last_commit_time_sync property.\n",
            "\n",
            "This will result in having new versions in AWS Glue tables for example, which will eventually lead to exceeding table version limit., Similarity: 0.2314\n",
            "Summary & Description: make separate release hudi sparkscala based packages scala 212 \n",
            " [https://github.com/apache/incubator-hudi/issues/881#issuecomment-528700749]\n",
            "\n",
            "Suspects: \n",
            "h3. Hudi utilities package \n",
            "\n",
            "bringing in spark-streaming-kafka-0.8* \n",
            "{code:java}\n",
            "[INFO] Scanning for projects...\n",
            "[INFO] \n",
            "[INFO] -------------------< org.apache.hudi:hudi-utilities >-------------------\n",
            "[INFO] Building hudi-utilities 0.5.0-SNAPSHOT\n",
            "[INFO] --------------------------------[ jar ]---------------------------------\n",
            "[INFO] \n",
            "[INFO] --- maven-dependency-plugin:3.1.1:tree (default-cli) @ hudi-utilities ---\n",
            "[INFO] org.apache.hudi:hudi-utilities:jar:0.5.0-SNAPSHOT\n",
            "[INFO] ...\n",
            "[INFO] +- org.apache.hudi:hudi-client:jar:0.5.0-SNAPSHOT:compile\n",
            "       ...\n",
            "[INFO] \n",
            "[INFO] +- org.apache.hudi:hudi-spark:jar:0.5.0-SNAPSHOT:compile\n",
            "[INFO] |  \\- org.scala-lang:scala-library:jar:2.11.8:compile\n",
            "[INFO] +- log4j:log4j:jar:1.2.17:compile\n",
            "       ...\n",
            "[INFO] +- org.apache.spark:spark-core_2.11:jar:2.1.0:provided\n",
            "[INFO] |  +- org.apache.avro:avro-mapred:jar:hadoop2:1.7.7:provided\n",
            "[INFO] |  |  +- org.apache.avro:avro-ipc:jar:1.7.7:provided\n",
            "[INFO] |  |  \\- org.apache.avro:avro-ipc:jar:tests:1.7.7:provided\n",
            "[INFO] |  +- com.twitter:chill_2.11:jar:0.8.0:provided\n",
            "[INFO] |  +- com.twitter:chill-java:jar:0.8.0:provided\n",
            "[INFO] |  +- org.apache.xbean:xbean-asm5-shaded:jar:4.4:provided\n",
            "[INFO] |  +- org.apache.spark:spark-launcher_2.11:jar:2.1.0:provided\n",
            "[INFO] |  +- org.apache.spark:spark-network-common_2.11:jar:2.1.0:provided\n",
            "[INFO] |  +- org.apache.spark:spark-network-shuffle_2.11:jar:2.1.0:provided\n",
            "[INFO] |  +- org.apache.spark:spark-unsafe_2.11:jar:2.1.0:provided\n",
            "[INFO] |  +- net.java.dev.jets3t:jets3t:jar:0.7.1:provided\n",
            "[INFO] |  +- org.apache.curator:curator-recipes:jar:2.4.0:provided\n",
            "[INFO] |  +- org.apache.commons:commons-lang3:jar:3.5:provided\n",
            "[INFO] |  +- org.apache.commons:commons-math3:jar:3.4.1:provided\n",
            "[INFO] |  +- com.google.code.findbugs:jsr305:jar:1.3.9:provided\n",
            "[INFO] |  +- org.slf4j:slf4j-api:jar:1.7.16:compile\n",
            "[INFO] |  +- org.slf4j:jul-to-slf4j:jar:1.7.16:provided\n",
            "[INFO] |  +- org.slf4j:jcl-over-slf4j:jar:1.7.16:provided\n",
            "[INFO] |  +- org.slf4j:slf4j-log4j12:jar:1.7.16:compile\n",
            "[INFO] |  +- com.ning:compress-lzf:jar:1.0.3:provided\n",
            "[INFO] |  +- org.xerial.snappy:snappy-java:jar:1.1.2.6:compile\n",
            "[INFO] |  +- net.jpountz.lz4:lz4:jar:1.3.0:compile\n",
            "[INFO] |  +- org.roaringbitmap:RoaringBitmap:jar:0.5.11:provided\n",
            "[INFO] |  +- commons-net:commons-net:jar:2.2:provided\n",
            "       ....\n",
            "[INFO] +- org.apache.spark:spark-sql_2.11:jar:2.1.0:provided\n",
            "[INFO] |  +- com.univocity:univocity-parsers:jar:2.2.1:provided\n",
            "[INFO] |  +- org.apache.spark:spark-sketch_2.11:jar:2.1.0:provided\n",
            "[INFO] |  \\- org.apache.spark:spark-catalyst_2.11:jar:2.1.0:provided\n",
            "[INFO] |     +- org.codehaus.janino:janino:jar:3.0.0:provided\n",
            "[INFO] |     +- org.codehaus.janino:commons-compiler:jar:3.0.0:provided\n",
            "[INFO] |     \\- org.antlr:antlr4-runtime:jar:4.5.3:provided\n",
            "[INFO] +- com.databricks:spark-avro_2.11:jar:4.0.0:provided\n",
            "[INFO] +- org.apache.spark:spark-streaming_2.11:jar:2.1.0:compile\n",
            "[INFO] +- org.apache.spark:spark-streaming-kafka-0-8_2.11:jar:2.1.0:compile\n",
            "[INFO] |  \\- org.apache.kafka:kafka_2.11:jar:0.8.2.1:compile\n",
            "[INFO] |     +- org.scala-lang.modules:scala-xml_2.11:jar:1.0.2:compile\n",
            "[INFO] |     +- org.scala-lang.modules:scala-parser-combinators_2.11:jar:1.0.2:compile\n",
            "[INFO] |     \\- org.apache.kafka:kafka-clients:jar:0.8.2.1:compile\n",
            "[INFO] +- io.dropwizard.metrics:metrics-core:jar:4.0.2:compile\n",
            "[INFO] +- org.antlr:stringtemplate:jar:4.0.2:compile\n",
            "[INFO] |  \\- org.antlr:antlr-runtime:jar:3.3:compile\n",
            "[INFO] +- com.beust:jcommander:jar:1.72:compile\n",
            "[INFO] +- com.twitter:bijection-avro_2.11:jar:0.9.2:compile\n",
            "[INFO] |  \\- com.twitter:bijection-core_2.11:jar:0.9.2:compile\n",
            "[INFO] +- io.confluent:kafka-avro-serializer:jar:3.0.0:compile\n",
            "[INFO] +- io.confluent:common-config:jar:3.0.0:compile\n",
            "[INFO] +- io.confluent:common-utils:jar:3.0.0:compile\n",
            "[INFO] |  \\- com.101tec:zkclient:jar:0.5:compile\n",
            "[INFO] +- io.confluent:kafka-schema-registry-client:jar:3.0.0:compile\n",
            "[INFO] \\- org.mockito:mockito-all:jar:1.10.19:test\n",
            "[INFO] ------------------------------------------------------------------------\n",
            "[INFO] BUILD SUCCESS\n",
            "[INFO] ------------------------------------------------------------------------\n",
            "[INFO] Total time:  2.211 s\n",
            "[INFO] Finished at: 2019-09-12T09:39:32-07:00\n",
            "[INFO] ------------------------------------------------------------------------\n",
            " {code}, Similarity: 0.3755\n",
            "Summary & Description: cutover old kmeans new kmeans remove old kmeans \n",
            " description pending, Similarity: 0.1012\n",
            "Summary & Description: nb regression memory \n",
            " After fix for MADLIB-744 we found a new regression:\n",
            "{code}\n",
            "SELECT madlibtestdata.test_calculate_accuracy\n",
            "                        ( $_valString$madlibtestdata.nb_p53$_valString$::text   --classify_source\n",
            "                        , $_valString$id$_valString$::text   --classify_key_column\n",
            "                        , $_valString$class$_valString$::text   --classify_class_column\n",
            "                        , $_valString$madlibtestresult.classified_result$_valString$::text   --classified_result_name\n",
            "                        );\n",
            "ExecutionResult:\n",
            "psql failed with error INFO:  SELECT count(*) FROM madlibtestdata.nb_p53;\n",
            "INFO:  SELECT count(*) FROM madlibtestdata.nb_p53 exp, madlibtestresult.classified_result act WHERE exp.id=act.key AND exp.class=act.nb_classification[1];\n",
            "ERROR:  Out of memory  (seg12 slice3 gpdb14.delta.sm.greenplum.com:40200 pid=20421)\n",
            "DETAIL:  VM Protect failed to allocate 8192 bytes, 0 MB available\n",
            "CONTEXT:  SQL statement \"SELECT count(*) FROM madlibtestdata.nb_p53 exp, madlibtestresult.classified_result act WHERE exp.id=act.key AND exp.class=act.nb_classification[1];\"\n",
            "PL/pgSQL function \"test_calculate_accuracy\" line 15 at execute statement\n",
            ".\n",
            "ExpectedResult:\n",
            "-[ RECORD 1 ]-----------+------\n",
            "test_calculate_accuracy | 0.685\n",
            "\n",
            "\n",
            "{code}\n",
            "\n",
            "Whole test case\n",
            "{code}\n",
            "SELECT madlibtestdata.test_create_nb_prepared_data_tables\n",
            "                        ( $_valString$madlibtestdata.nb_p53$_valString$::text   --training_source\n",
            "                        , $_valString$class$_valString$::text   --training_class_column\n",
            "                        , $_valString$attributes$_valString$::text   --training_attr_column\n",
            "                        , $_valString$madlibtestresult.trained_probs$_valString$::text   --trained_probs_name\n",
            "                        , $_valString$madlibtestresult.trained_priors$_valString$::text   --trained_priors_name\n",
            "                        );\n",
            "ExecutionResult:\n",
            "-[ RECORD 1 ]-----------------------+-\n",
            "test_create_nb_prepared_data_tables | \n",
            "ExpectedResult:\n",
            "-[ RECORD 1 ]-----------------------+-\n",
            "test_create_nb_prepared_data_tables | \n",
            "\n",
            "\n",
            "Itemname:nb_precompute_views_0_9_test_create_nb_classify_view_1\n",
            "Query:\n",
            "SELECT madlibtestdata.test_create_nb_classify_view\n",
            "                        ( $_valString$madlibtestresult.trained_probs$_valString$::text   --trained_probs_name\n",
            "                        , $_valString$madlibtestresult.trained_priors$_valString$::text   --trained_priors_name\n",
            "                        , $_valString$madlibtestdata.nb_p53$_valString$::text   --classify_source\n",
            "                        , $_valString$id$_valString$::text   --classify_key_column\n",
            "                        , $_valString$attributes$_valString$::text   --classify_attr_column\n",
            "                        , $_valString$madlibtestresult.classified_result$_valString$::text   --classified_result_name\n",
            "                        );\n",
            "\n",
            "Itemname:nb_precompute_views_0_9_test_create_nb_probs_view_2\n",
            "Query:\n",
            "SELECT madlibtestdata.test_create_nb_probs_view\n",
            "                        ( $_valString$madlibtestresult.trained_probs$_valString$::text   --trained_probs_name\n",
            "                        , $_valString$madlibtestresult.trained_priors$_valString$::text   --trained_priors_name\n",
            "                        , $_valString$madlibtestdata.nb_p53$_valString$::text   --classify_source\n",
            "                        , $_valString$id$_valString$::text   --classify_key_column\n",
            "                        , $_valString$attributes$_valString$::text   --classify_attr_column\n",
            "                        , $_valString$madlibtestresult.classified_probs$_valString$::text   --classified_probs_name\n",
            "                        );\n",
            "\n",
            "Itemname:nb_precompute_views_0_9_test_calculate_accuracy_3\n",
            "Query:\n",
            "SELECT madlibtestdata.test_calculate_accuracy\n",
            "                        ( $_valString$madlibtestdata.nb_p53$_valString$::text   --classify_source\n",
            "                        , $_valString$id$_valString$::text   --classify_key_column\n",
            "                        , $_valString$class$_valString$::text   --classify_class_column\n",
            "                        , $_valString$madlibtestresult.classified_result$_valString$::text   --classified_result_name\n",
            "                        );\n",
            "\n",
            "\n",
            "{code}\n",
            "\n",
            "For function definition, please refer to testsuite/dataset/DataModeling/SupervisedLearning/NaiveBayesClassification/nb_test_udf.sql \n",
            "\n",
            "For dataset , you can refer to converted data sets folder:  nb_p53, Similarity: 0.2516\n",
            "Summary & Description: nb regression error plpyspierror operator exist double precision integer plpythonc4648 \n",
            " ERROR:  plpy.SPIError: operator does not exist: double precision || integer[] (plpython.c:4648)\n",
            "\n",
            "{code}\n",
            "madlib=# SELECT madlib.create_nb_classify_view('madlibtestdata.nb_extra_values_training','class','attributes','madlibtestdata.nb_extra_values_classify','id','attributes',9000,'classified_result');\n",
            "ERROR:  plpy.SPIError: operator does not exist: double precision || integer[] (plpython.c:4648)\n",
            "LINE 24:     max(classify.value)::DOUBLE PRECISION ||\n",
            "                                                   ^\n",
            "HINT:  No operator matches the given name and argument type(s). You may need to add explicit type casts.\n",
            "QUERY:  \n",
            "        CREATE VIEW classified_result AS\n",
            "        SELECT\n",
            "            key,\n",
            "            madlib.argmax(class, log_prob) AS nb_classification\n",
            "        FROM (\n",
            "   SELECT t3.key as key, t3.class as class, log(max(t3.class_cnt)::DOUBLE PRECISION / max(t3.all_cnt)::DOUBLE PRECISION) + sum(t3.log_prob) as log_prob\n",
            "   FROM (\n",
            "\tSELECT\n",
            "\t\tt2.key,\n",
            "\t\tt2.class,\n",
            "\t\tt2.attr,\n",
            "\t\tt2.cvalue,\n",
            "\t\tmax(t2.fpValue) as fpValue, max(t2.fp_cnt) as fp_cnt,\n",
            "\t\tmax(t2.fp_attr_cnt) as fp_attr_cnt, t2.class_cnt, t2.all_cnt,\n",
            "\t\tlog((COALESCE(max(t2.fp_cnt),0) + 1)::DOUBLE PRECISION/(t2.class_cnt + 1 * max(t2.fp_attr_cnt))::DOUBLE PRECISION) as log_prob\n",
            "    FROM (\n",
            "\t\tSELECT t1.key, t1.class, t1.attr, t1.cvalue, unnest(t1.fpvalue) as fpValue, unnest(t1.fp_cnt) as fp_cnt, t1.fp_attr_cnt, t1.class_cnt, t1.all_cnt\n",
            "\t\tFROM (\n",
            "\t\t\tSELECT\n",
            "\t\t\t\tclassify.key,\n",
            "\t\t\t\tfeatureprobs.class,\n",
            "\t\t\t\tclassify.attr, max(classify.value) as cvalue,\n",
            "\t\t\t\tmax(classify.value)::DOUBLE PRECISION ||\n",
            "                    \n",
            "                    array_agg(featureprobs.value) as fpvalue,\n",
            "\t\t\t\t0::bigint ||\n",
            "                    \n",
            "                    array_agg(featureprobs.cnt) as fp_cnt,\n",
            "\t\t\t\tmax(featureprobs.attr_cnt) as fp_attr_cnt,\n",
            "\t\t\t\tclasspriors.class_cnt,\n",
            "\t\t\t\tclasspriors.all_cnt\n",
            "\t\t\tFROM\n",
            "\t\t\t\t\t(\n",
            "        SELECT * FROM\n",
            "            (\n",
            "            SELECT\n",
            "                trainingSource.class AS class,\n",
            "                count(*) AS class_cnt\n",
            "            FROM madlibtestdata.nb_extra_values_training AS trainingSource\n",
            "            GROUP BY trainingSource.class\n",
            "            ) l\n",
            "        CROSS JOIN\n",
            "            (\n",
            "            SELECT\n",
            "                count(*) AS all_cnt\n",
            "            FROM madlibtestdata.nb_extra_values_training AS trainingSource\n",
            "            ) m\n",
            "        ) AS classpriors,\n",
            "\t\t\t\t\t(\n",
            "        SELECT\n",
            "            class,\n",
            "            attr,\n",
            "            value,\n",
            "            coalesce(cnt, 0) AS cnt,\n",
            "            attr_cnt\n",
            "        FROM\n",
            "        (\n",
            "            SELECT *\n",
            "            FROM\n",
            "                (\n",
            "        SELECT * FROM\n",
            "            (\n",
            "            SELECT\n",
            "                trainingSource.class AS class,\n",
            "                count(*) AS class_cnt\n",
            "            FROM madlibtestdata.nb_extra_values_training AS trainingSource\n",
            "            GROUP BY trainingSource.class\n",
            "            ) l\n",
            "        CROSS JOIN\n",
            "            (\n",
            "            SELECT\n",
            "                count(*) AS all_cnt\n",
            "            FROM madlibtestdata.nb_extra_values_training AS trainingSource\n",
            "            ) m\n",
            "        ) AS classes\n",
            "            CROSS JOIN\n",
            "                (\n",
            "        SELECT\n",
            "            generate_series(1, 9000) AS attr,\n",
            "            unnest(trainingSource.attributes) AS value\n",
            "        FROM\n",
            "            madlibtestdata.nb_extra_values_training AS trainingSource\n",
            "        GROUP BY attr, value\n",
            "        ) AS attr_values\n",
            "        ) AS required_triples\n",
            "        LEFT OUTER JOIN\n",
            "        (\n",
            "            SELECT\n",
            "                trainingSource.class AS class,\n",
            "                generate_series(1, 9000) AS attr,\n",
            "                unnest(trainingSource.attributes) AS value,\n",
            "                count(*) AS cnt\n",
            "            FROM\n",
            "                madlibtestdata.nb_extra_values_training AS trainingSource\n",
            "            GROUP BY\n",
            "                class,\n",
            "                attr,\n",
            "                value\n",
            "        ) AS triple_counts\n",
            "        USING (class, attr, value)\n",
            "        INNER JOIN\n",
            "            (\n",
            "        SELECT\n",
            "            attr, count(value) AS attr_cnt\n",
            "        FROM\n",
            "        (\n",
            "            SELECT\n",
            "                attr, value\n",
            "            FROM (\n",
            "                SELECT\n",
            "                    generate_series(1, 9000) AS attr,\n",
            "                    unnest(trainingSource.attributes) AS value\n",
            "                FROM\n",
            "                    madlibtestdata.nb_extra_values_training AS trainingSource\n",
            "                ) l\n",
            "            GROUP BY attr, value\n",
            "        ) m\n",
            "        GROUP BY attr\n",
            "        ) AS attr_counts\n",
            "        USING (attr)\n",
            "        ) AS featureprobs,\n",
            "\t\t\t\t\t(\n",
            "\t\t\t\t\t\tSELECT\n",
            "\t\t\t\t\t\t\tclassifysource.id AS key,\n",
            "\t\t\t\t\t\t\tgenerate_series(1, 9000) AS attr,\n",
            "\t\t\t\t\t\t\tunnest(classifysource.attributes) AS value\n",
            "                        FROM\n",
            "\t\t\t\t\t\t\tmadlibtestdata.nb_extra_values_classify AS classifysource\n",
            "\t\t\t\t\t) AS classify\n",
            "            WHERE\n",
            "\t\t\t\t\tfeatureProbs.class = classPriors.class AND\n",
            "\t\t\t\t\tfeatureProbs.attr = classify.attr\n",
            "\t\t\tGROUP BY\n",
            "\t\t\t\t\tclassify.key, featureprobs.class, classify.attr, classpriors.class_cnt, classpriors.all_cnt\n",
            "\t\t) t1\n",
            "\t) t2\n",
            "\tWHERE\n",
            "\t\tt2.cvalue = t2.fpValue AND\n",
            "\t\t1 > 0 -- prevent division by 0\n",
            "\tGROUP BY t2.key, t2.class, t2.attr, t2.cvalue, t2.class_cnt, t2.all_cnt\n",
            "   ) t3\n",
            "   GROUP BY t3.key, t3.class\n",
            "    ) AS keys_and_nb_values\n",
            "        GROUP BY key\n",
            "        \n",
            "CONTEXT:  Traceback (most recent call last):\n",
            "  PL/Python function \"create_nb_classify_view\", line 24, in <module>\n",
            "    return bayes.create_classification_view(**globals())\n",
            "  PL/Python function \"create_nb_classify_view\", line 479, in create_classification_view\n",
            "  PL/Python function \"create_nb_classify_view\", line 559, in create_classification\n",
            "PL/Python function \"create_nb_classify_view\"\n",
            "\n",
            "{code}, Similarity: 0.1650\n",
            "Summary & Description: final release tasks madlib v05 \n",
            " Parent jira for final release tasks associated with the release:\n",
            "# All open jiras targetted for release resolved.\n",
            "# QA tests completed\n",
            "# Update Release Notes for v0.5\n",
            "# Update Version.yml for v0.5\n",
            "# Create new repository branch and tag in git\n",
            "# Add directory on madlib.net for v0.5 documentation\n",
            "# Upload new binary package to madlib.net/files\n",
            "# Update pgxn\n",
            "# Upload to subscribe.net\n",
            "# Update webpage to announce new version and update download links\n",
            "# Email interested parties and announce on mailing list, Similarity: 0.2622\n",
            "Summary & Description: kmeans canopy takes several hours fail space left device large dataset \n",
            " On large dataset, kmeans canopy takes several hours to fail with \"No space left on device\" error.\n",
            "\n",
            "1. Dataset: UCI dataset us_census_1990 which has 2458285 rows and 68 dimensions\n",
            "{noformat}\n",
            "madlib=# select count(*) from madlibtestdata.km_us_census_1990;\n",
            "  count  \n",
            "---------\n",
            " 2458285\n",
            "(1 row)\n",
            "\n",
            "madlib=# \\d madlibtestdata.km_us_census_1990\n",
            " Table \"madlibtestdata.km_us_census_1990\"\n",
            "  Column  |        Type        | Modifiers \n",
            "----------+--------------------+-----------\n",
            " pid      | bigint             | \n",
            " position | double precision[] | \n",
            "Distributed randomly\n",
            "{noformat}\n",
            "\n",
            "2. Kmeans canopy invocation\n",
            "{noformat}\n",
            "SELECT * FROM madlib.kmeans('madlibtestdata.km_us_census_1990', 'position', 'pid', 'canopy', 0.01, NULL, NULL, 'l2norm', 20, 0.0001, True, 'madlibtestresult.kmeans_canopy_baseline_out_points', 'madlibtestresult.kmeans_canopy_baseline_out_centroids', True, True) AS q;\n",
            "{noformat}                                                                                                                                       \n",
            "\n",
            "3. Test result\n",
            "{noformat}\n",
            "...\n",
            "eans_canopy_baseline_out_points  \n",
            " CONTEXT:  PL/Python function \"kmeans\"                                                                                                                                                \n",
            " INFO:   * output_centroids = madlibtestresult.kmeans_canopy_baseline_out_centroids                                                                                                   \n",
            " CONTEXT:  PL/Python function \"kmeans\"                                                                                                                                                \n",
            " INFO:   * verbose = True                                                                                                                                                             \n",
            " CONTEXT:  PL/Python function \"kmeans\"                                                                                                                                                \n",
            " INFO:  Input:                                                                                                                                                                        \n",
            " CONTEXT:  PL/Python function \"kmeans\"                                                                                                                                                \n",
            " INFO:  ... analyzing data points                                                                                                                                                     \n",
            " CONTEXT:  PL/Python function \"kmeans\"                                                                                                                                                \n",
            " INFO:   * points: 2458285 (68 dimensions), kept 2458285 after removing NULLs                                                                                                         \n",
            " CONTEXT:  PL/Python function \"kmeans\"                                                                                                                                                \n",
            " INFO:  ... generating initial centroids                                                                                                                                              \n",
            " CONTEXT:  PL/Python function \"kmeans\"                                                                                                                                                \n",
            " ERROR:  plpy.SPIError: could not write 32768 bytes to temporary file: No space left on device (buffile.c:501)  (seg2 gpdb2.delta.sm.greenplum.com:40002 pid=15985) (plpython.c:4700) \n",
            " CONTEXT:  Traceback (most recent call last):                                                                                                                                         \n",
            "   PL/Python function \"kmeans\", line 36, in <module>                                                                                                                                  \n",
            "     , verbose                                                                                                                                                                        \n",
            "   PL/Python function \"kmeans\", line 830, in kmeans                                                                                                                                   \n",
            "   PL/Python function \"kmeans\", line 459, in __init_canopy                                                                                                                            \n",
            " PL/Python function \"kmeans\"                                                                                                                                                          \n",
            " .\n",
            "(1 row)\n",
            "{noformat}, Similarity: 0.2535"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "I think the problem is in the following constructor, where instance level \"reflectionManager\" is not being initialized.\n",
            "\n",
            "\tprotected ClassValidator(\n",
            "\t\t\tXClass beanXClass, ResourceBundle resourceBundle, MessageInterpolator userInterpolator,\n",
            "\t\t\tMap<XClass, ClassValidator> childClassValidators, ReflectionManager reflectionManager\n",
            "\t) {\n",
            "\t\tthis.beanClass = reflectionManager.toClass( beanXClass );\n",
            "\t\tthis.messageBundle = resourceBundle == null ?\n",
            "\t\t\t\tgetDefaultResourceBundle() :\n",
            "\t\t\t\tresourceBundle;\n",
            "\t\tthis.defaultMessageBundle = ResourceBundle.getBundle( DEFAULT_VALIDATOR_MESSAGE );\n",
            "\t\tthis.userInterpolator = userInterpolator;\n",
            "\t\tthis.childClassValidators = childClassValidators;\n",
            "\t\tinitValidator( beanXClass, childClassValidators );\n",
            "\t}\n",
            "\n",
            "The other constructor initializes reflectionManager.\n",
            ", Similarity: 0.2323\n",
            "Summary & Description: creditcardnumber hibernate validator \n",
            " I just dicovered the existence of the Luhn algorithm ;-) Very cool.\n",
            "\n",
            "http://en.wikipedia.org/wiki/Luhn_algorithm\n",
            "\n",
            "Here is a Java impl:\n",
            "\n",
            "http://www.darkcanyongroup.com/code/luhn_algorithm.txt\n",
            "\n",
            "We should have a built-in validator for this., Similarity: 0.2506\n",
            "Summary & Description: digitsintegerdigits fractionaldigits \n",
            " @Digits(integerDigits=8, fractionalDigits=2)\n",
            "ensure that the number can be expressed with integerDigits digits and factionalDigits digits, Similarity: 0.1018\n",
            "Summary & Description: consider making validator framework truely independant hibernate core \n",
            " I'd like to use the validator framework, but without pulling hibernate in as a dependency.\n",
            "\n",
            "Currently, if I try to instantiate a ClassValidator, a org.hibernate.MappingException cannot be found.\n",
            "\n",
            "Consequently, the validator framework could also be independent of the rest of the annotations, and be distributed in its own jar.\n",
            ", Similarity: 0.3338\n",
            "Summary & Description: past validation annotation generates incorrect ddl oracle 8x \n",
            " The following validation code:\n",
            "\n",
            "    @Past\n",
            "    public Date getBirthDate()\n",
            "    {\n",
            "        return birthDate;\n",
            "    } \n",
            "\n",
            "produces the following DDL when using the OracleDialect:\n",
            "\n",
            "create table Person (party_id number(19,0) not null, birth_date date check (birth_date < current_date), primary key (party_id)) \n",
            "\n",
            "The \"current_date\" was introduced only in Oracle 9i and is not available in earlier Oracle versions and the following SQL exception is thrown:\n",
            "\n",
            "ORA-02438: Column check constraint cannot reference other columns \n",
            "\n",
            "According to Gavin, the current validation framework is not aware of Dialects. (http://forum.hibernate.org/viewtopic.php?t=943378), Similarity: 0.1665\n",
            "Summary & Description: create dedicated distribution documention module \n",
            " Align with Search and Validator. Dedicated modules are easier to manage., Similarity: 0.3704\n",
            "Summary & Description: separate test methods within test class \n",
            " Currently all test entities used by a test class are compiled in one go via a {{@BeforeClass}} method in {{CompilationTest}}. This causes all test methods of a given class to fail if there is an issue with a test entity only used by a single test method, making failures more complicated to analyze.\n",
            "\n",
            "As an alternative, the classes to be compiled could be specified on a per method base, e.g. like this:\n",
            "\n",
            "{code}\n",
            "@Test\n",
            "@WithClasses( { Foo.class, Bar.class } )\n",
            "public void testFoo() { ... }\n",
            "{code}, Similarity: 0.1771\n",
            "Summary & Description: consider make xml parsing failures failing build \n",
            " Currently any exceptions raised during the parsing of XML descriptors are reported using the {{WARN}} diagnostic kind and thus don't fail the build. We may consider to change this to use kind {{ERROR}} in order  to fail the build in this situation., Similarity: 0.1744\n",
            "Summary & Description: mappedsuperclasswithoutexplicitidtest failing certain operating systems \n",
            " Depending on the order in which the types are processed in {{JPAMetaModelEntityProcessor}}, the wrong access type may be derived for mapped super-classes., Similarity: 0.2561\n",
            "Summary & Description: wrong typed metamodel setattribute using implemented interface \n",
            " With the given test case (\"mvn compile\"), the generated Emb_ class is wrong.\n",
            "The second generic type of its SetAttribute is an interface, not the configured targetEntity., Similarity: 0.2268\n",
            "Summary & Description: generator exits discovering xmlmappingmetadatacomplete persistence unit \n",
            " I have several persistence units in persistence.xml, one of them uses <xml-mapping-metadata-complete/>. \n",
            "\n",
            "As soon as the metamodel generator discovers this unit, it stops processing any other persistence unit in the peristence.xml. Probably related to METAGEN-7 \n",
            "\n",
            "Workaround is ignoring persistence.xml: fullyAnnotationConfigured=true, Similarity: 0.2930\n",
            "Summary & Description: mixedconfigurationtest failing \n",
            " This bug is related to this thread of the mailing list: http://lists.jboss.org/pipermail/hibernate-dev/2012-March/007894.html\n",
            "\n",
            "From my original post:\n",
            "{quote}\n",
            "While working on Hibernate JPA Modelgen, I noticed that there are test failures in _MixedConfigurationTest_. I thought it was because of my own changes but I also have this problem with a fresh git clone from the official repo:\n",
            "{quote}\n",
            "\n",
            "{noformat}\n",
            "Running org.hibernate.jpamodelgen.test.mixedmode.MixedConfigurationTest\n",
            "Tests run: 4, Failures: 4, Errors: 0, Skipped: 0, Time elapsed: 2.494 sec <<< FAILURE!\n",
            "\n",
            "Results :\n",
            "\n",
            "Failed tests:\n",
            "testAccessTypeForXmlConfiguredEmbeddables(org.hibernate.jpamodelgen.test.mixedmode.MixedConfigurationTest): org.hibernate.jpamodelgen.test.mixedmode.Coordinates_ was not generated.\n",
            "  testDefaultAccessTypeApplied(org.hibernate.jpamodelgen.test.mixedmode.MixedConfigurationTest): org.hibernate.jpamodelgen.test.mixedmode.Vehicle_ was not generated.\n",
            "  testExplicitXmlConfiguredAccessTypeApplied(org.hibernate.jpamodelgen.test.mixedmode.MixedConfigurationTest): org.hibernate.jpamodelgen.test.mixedmode.Vehicle_ was not generated.\n",
            "  testMixedConfiguration(org.hibernate.jpamodelgen.test.mixedmode.MixedConfigurationTest): org.hibernate.jpamodelgen.test.mixedmode.RentalCar_ was not generated.\n",
            "\n",
            "Tests run: 4, Failures: 4, Errors: 0, Skipped: 0\n",
            "{noformat}\n",
            "\n",
            "From what I can see, there is at least a problem with _AnnotationMetaEntity.mergeInMembers_: the merged in members aren't really affected to the new entity as the hostingEntity of the attribute is still the original entity.\n",
            "\n",
            "In the case of the _ZeroCoordinates_ entity, it leads to a compilation error as the _SingularAttribute_ import isn't added to the right context (it's added to the original _XmlMetaEmbeddable_ context instead of the _AnnotationEmbeddable_ context this attribute is attached to at the end of the annotation processing). The content of the generated class is as follows:\n",
            "{code}\n",
            "package org.hibernate.jpamodelgen.test.mixedmode;\n",
            "\n",
            "import javax.annotation.Generated;\n",
            "import javax.persistence.metamodel.StaticMetamodel;\n",
            "\n",
            "@Generated(value = \"org.hibernate.jpamodelgen.JPAMetaModelEntityProcessor\")\n",
            "@StaticMetamodel(ZeroCoordinates.class)\n",
            "public abstract class ZeroCoordinates_ {\n",
            "        public static volatile SingularAttribute<ZeroCoordinates, Float> longitude;\n",
            "        public static volatile SingularAttribute<ZeroCoordinates, Float> latitude;\n",
            "}\n",
            "{code}\n",
            "\n",
            "I was wondering if providing the way to overwrite the hostingEntity (via removing the final and adding a setter) would be acceptable or not?\n",
            "\n",
            "Even if I do so (draft patch attached), I still have a test failing claiming that _ZeroCoordinates_ shouldn't have any attributes generated.\n",
            "\n",
            "IMHO, there are 2 problems here:\n",
            "* we need to decide if having the attributes generated for _ZeroCoordinates_ is the wanted behavior. Considering that they are explicitly declared in the XML mapping, I think so but, as there is an explicit test checking that they aren't, I'm not sure it's the expected behavior;\n",
            "* if we fix the above problem by removing the attributes from _ZeroCoordinates_, we need to write a test to show the problem of _AnnotationMetaEntity.mergeInMembers_ and fix it (either with the patch provided or with another one doing the same thing).\n",
            "\n",
            "Depending on what we decide, I can probably prepare a pull request for this problem if you want it.\n",
            " \n",
            "Guillaume, Similarity: 0.4383\n",
            "Summary & Description: upgrade version \n",
            " We should check and upgrade:\n",
            "\n",
            "* Maven plugin versions\n",
            "* JPA spec version\n",
            "* Hibernate ORM version, Similarity: 0.3295\n",
            "Summary & Description: inconsistencies way mappedsuperclass entities considered \n",
            " There are a few inconsistencies in the way @MappedSuperClass entities are considered: they are sometimes stored as MetaEntity and they are looked for as MetaEmbeddable in certain portions of the code.\n",
            "\n",
            "I don't think it's done on purpose as it's really inconsistent in a weird way.\n",
            "\n",
            "Pull request to follow., Similarity: 0.2580\n",
            "Summary & Description: embeddable entities dont inherit access type comes hierarchy containing class \n",
            " This is a followup from my post on the mailing list: we have @OneToOne relations on an @Embeddable object and they aren't present in the metamodel class generated for the @Embedded object.\n",
            "\n",
            "After a couple of hours of debugging/digging, I came to the conclusion that this is due to a missing updateEmbeddableAccessType() call in TypeUtils.determineAccessTypeForHierarchy(): if the containing class doesn't contain any information for the access type, the hierarchy of the containing class is scanned for access type information. Due to this missing call, in this specific case, the access type is not propagated to the @Embeddable entity via the @Embedded link. If by any chance, your @OneToOne annotations are on the methods in your @Embeddable entities, they are taken into account as it's the default access type. If they are positioned on the fields, they are ignored even if your @Id annotation is positioned on a field in the hierarchy.\n",
            "\n",
            "Pull request with a test case and the patch to follow., Similarity: 0.2738\n",
            "Summary & Description: inheritance metamodel classes \n",
            " If there is Inheritance structure like:\n",
            "@Entity                                     (No entity annotation)              @Entity\n",
            "public class Party  extends public abstract Timelimited extends public abstract Versioned\n",
            "String name                                 Long timelimitedId                  Long versionedId                  \n",
            "Date date\n",
            "Long partyId\n",
            "\n",
            "the model generator generates Party_ with only name date and partyid (no extends )\n",
            "then it generates Timelimited_ with timelimitedId , but also without any parents (no extends)                 \n",
            "and lastly a Versioned_  is generated with versionedId                  \n",
            "\n",
            "Now I would like to say Party_.versionedId , but i cant\n",
            "\n",
            "A workaround is to annotate the Timelimited class (which is in the middle of the hierarchy) with a @Entity\n",
            "\n",
            "then the Party_ extends Timelimited which extends Versioned and everything works as desired\n",
            "\n",
            "but JPA allows  to have non entity classes in the middle of a hierarchy :\n",
            "\n",
            "Both abstract and concrete classes can be entities. Both abstract and concrete classes can be annotated with the Entity annotation, mapped as entities, and queried for as entities.\n",
            "Entities can extend non-entity classes and non-entity classes can extend entity classes:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            ", Similarity: 0.1335\n",
            "Summary & Description: hashcode treated persistent attribute \n",
            " I got a class composite id class for a table with @Embeddable.\n",
            "It has two properties, and the equals and the hashCode methods.\n",
            "When hibernate-jpamodelgen 1.1.1.Final generates the metaclasses, I got a SingularAttribute with the name \"hashCode\" generated. But hashCode is not a property in the entity.\n",
            "\n",
            "\n",
            "entity:\n",
            "{code}\n",
            "/** by hbm2java */\n",
            "@Embeddable\n",
            "public class MyTableId  implements java.io.Serializable {\n",
            "\n",
            "    private String id;\n",
            "    private Integer memberId;\n",
            "\n",
            "    public MyTableId() {\n",
            "    }\n",
            "\n",
            "    public MyTableId(String id, Integer memberId) {\n",
            "       this.id = id;\n",
            "       this.memberId = memberId;\n",
            "    }\n",
            "\n",
            "    @Column(name=\"id\")\n",
            "    public String getId() {\n",
            "        return this.id;\n",
            "    }\n",
            "    public void setId(String id) {\n",
            "        this.id = id;\n",
            "    }\n",
            "\n",
            "    @Column(name=\"member_id\")\n",
            "    public Integer getMemberId() {\n",
            "        return this.memberId;\n",
            "    }\n",
            "    public void setMemberId(Integer memberId) {\n",
            "        this.memberId = memberId;\n",
            "    }\n",
            "\n",
            "   public boolean equals(Object other) {\n",
            "         if ( (this == other ) ) return true;\n",
            "         if ( (other == null ) ) return false;\n",
            "         if ( !(other instanceof MyTableId) ) return false;\n",
            "         MyTableId castOther = ( MyTableId ) other;\n",
            "\n",
            "         return ( (this.getId()==castOther.getId()) || ( this.getId()!=null && castOther.getId()!=null && this.getId().equals(castOther.getId()) ) )\n",
            " && ( (this.getMemberId()==castOther.getMemberId()) || ( this.getMemberId()!=null && castOther.getMemberId()!=null && this.getMemberId().equals(castOther.get\n",
            "MemberId()) ) );\n",
            "   }\n",
            "\n",
            "   public int hashCode() {\n",
            "         int result = 17;\n",
            "\n",
            "         result = 37 * result + ( getId() == null ? 0 : this.getId().hashCode() );\n",
            "         result = 37 * result + ( getMemberId() == null ? 0 : this.getMemberId().hashCode() );\n",
            "         return result;\n",
            "   }\n",
            "}\n",
            "{code}\n",
            "\n",
            "\n",
            "metaclass:\n",
            "{code}\n",
            "@StaticMetamodel(MyTableId.class)\n",
            "public abstract class MyTableId_ {\n",
            "   public static volatile SingularAttribute<MyTableId, String> id;\n",
            "   public static volatile SingularAttribute<MyTableId, Integer> hashCode;\n",
            "   public static volatile SingularAttribute<MyTableId, Integer> memberId;\n",
            "}\n",
            "{code}\n",
            ", Similarity: 0.2554\n",
            "Summary & Description: maven plugin jpa xml configuration path problem \n",
            " I have a problem with generating metamodel from JPA configuation \n",
            "\n",
            "I have JPA config like the following - there are a lot of ORM mapping in relative subdirectories\n",
            "\n",
            "<persistence-unit name=\"ApplicationDataSource\" transaction-type=\"RESOURCE_LOCAL\">\n",
            "    <description>Main persistence descriptor</description>\n",
            "    <mapping-file>configuration/model/jpa/mappings/base.xml</mapping-file>\n",
            "    <mapping-file>configuration/model/jpa/mappings/entities/employer.xml</mapping-file>\n",
            "    <mapping-file>configuration/model/jpa/mappings/entities/unit/unit.xml</mapping-file>\n",
            "    ...\n",
            "    <mapping-file>configuration/model/jpa/mappings/entities/unit/maintenance.xml</mapping-file>\n",
            "</persistence-unit>\n",
            "\n",
            "The problem is that processor is not able to find all these mappings without trailing slash. The following config works with metamodel processor\n",
            "\n",
            "<persistence-unit name=\"ApplicationDataSource\" transaction-type=\"RESOURCE_LOCAL\">\n",
            "    <!-- with trailing slash -->\n",
            "    <mapping-file>/configuration/model/jpa/mappings/base.xml</mapping-file> \n",
            "</persistence-unit>\n",
            "\n",
            "But the trailing slash doesn't allow the config to be loaded by Hibernate org.hibernate.ejb.Ejb3Configuration - Hibernate fails to load the config with trailing slash\n",
            "\n",
            ", Similarity: 0.6067\n",
            "Summary & Description: columncolumndefinition ignored unless placed get method \n",
            " >>>Not working: @Column is placed with variable definition.\n",
            "Column data is created in database as type tinyblob.\n",
            "Thus, @Column(columnDefinition = \"blob\") is ignored.\n",
            "\n",
            "@Entity\n",
            "public class File implements Serializable {\n",
            "private Long id;\n",
            "@NotNull @Column(columnDefinition = \"blob\")\n",
            "private byte [] data;\n",
            "\n",
            "@Id @GeneratedValue\n",
            "public Long getId() { return id; }\n",
            "public void setId(Long i) { id = i; }\n",
            "\n",
            "public byte [] getData() { return data; }\n",
            "public void setData(byte [] d) { data = d; }\n",
            "}\n",
            "##############################################################################\n",
            "\n",
            ">>>Workaround: @Column is placed with get method.\n",
            "Then, column data is created in database as type blob.\n",
            "\n",
            "@Entity\n",
            "public class File implements Serializable {\n",
            "private Long id;\n",
            "private byte [] data;\n",
            "\n",
            "@Id @GeneratedValue\n",
            "public Long getId() { return id; }\n",
            "public void setId(Long i) { id = i; }\n",
            "\n",
            "@NotNull @Column(columnDefinition = \"blob\")\n",
            "public byte [] getData() { return data; }\n",
            "public void setData(byte [] d) { data = d; }\n",
            "}\n",
            "\n",
            "\n",
            "\n",
            "##############################################################################\n",
            "Excerpt from: jboss-as-7.0.0.Final/standalone/configuration/standalone.xml\n",
            "\n",
            "<subsystem xmlns=\"urn:jboss:domain:datasources:1.0\">\n",
            "<datasources>\n",
            "<datasource jndi-name=\"java:jboss/datasources/MySqlDS\" pool-name=\"MySqlDS\" enabled=\"true\" jta=\"true\" use-java-context=\"true\" use-ccm=\"true\">\n",
            "<connection-url>\n",
            "jdbc:mysql://localhost:3306/jboss\n",
            "</connection-url>\n",
            "<driver>\n",
            "com.mysql\n",
            "</driver>\n",
            "<transaction-isolation>\n",
            "TRANSACTION_READ_COMMITTED\n",
            "</transaction-isolation>\n",
            "<pool>\n",
            "<min-pool-size>\n",
            "10\n",
            "</min-pool-size>\n",
            "<max-pool-size>\n",
            "100\n",
            "</max-pool-size>\n",
            "<prefill>\n",
            "true\n",
            "</prefill>\n",
            "<use-strict-min>\n",
            "false\n",
            "</use-strict-min>\n",
            "<flush-strategy>\n",
            "FailingConnectionOnly\n",
            "</flush-strategy>\n",
            "</pool>\n",
            "<security>\n",
            "<user-name>\n",
            "*************\n",
            "</user-name>\n",
            "<password>\n",
            "*************\n",
            "</password>\n",
            "</security>\n",
            "<statement>\n",
            "<prepared-statement-cache-size>\n",
            "32\n",
            "</prepared-statement-cache-size>\n",
            "<share-prepared-statements/>\n",
            "</statement>\n",
            "</datasource>\n",
            "<drivers>\n",
            "<driver name=\"com.mysql\" module=\"com.mysql\">\n",
            "<xa-datasource-class>\n",
            "com.mysql.jdbc.jdbc2.optional.MysqlXADataSource\n",
            "</xa-datasource-class>\n",
            "</driver>\n",
            "<driver name=\"h2\" module=\"com.h2database.h2\">\n",
            "<xa-datasource-class>\n",
            "org.h2.jdbcx.JdbcDataSource\n",
            "</xa-datasource-class>\n",
            "</driver>\n",
            "</drivers>\n",
            "</datasources>\n",
            "</subsystem>\n",
            "\n",
            "##############################################################################\n",
            "war jars:\n",
            "61504 Defl:N 56482 8% 2011-07-21 10:31 92d0520b WEB-INF/lib/i18nlog-1.0.10.jar\n",
            "358085 Defl:N 324832 9% 2011-04-04 11:37 8c574f28 WEB-INF/lib/log4j-1.2.12.jar\n",
            "47399 Defl:N 41460 13% 2011-07-21 10:31 ac044dbb WEB-INF/lib/jboss-logging-3.0.0.Beta5.jar\n",
            "204093 Defl:N 181695 11% 2011-07-07 12:54 ed9a2ff2 WEB-INF/lib/picketlink-idm-core-1.5.0.Alpha02.jar\n",
            "55966 Defl:N 44907 20% 2011-07-07 12:54 d81b0cc2 WEB-INF/lib/seam-international-3.0.0.Final.jar\n",
            "529064 Defl:N 490198 7% 2011-07-18 14:13 cb9a1aec WEB-INF/lib/quartz-2.0.1.jar\n",
            "1627515 Defl:N 1470306 10% 2011-07-07 12:54 e71d8ef4 WEB-INF/lib/primefaces-3.0.M2.jar\n",
            "231287 Defl:N 203688 12% 2011-07-21 10:31 76154858 WEB-INF/lib/jboss-marshalling-1.3.0.CR9.jar\n",
            "2479225 Defl:N 2249049 9% 2011-08-03 07:41 f775e5eb WEB-INF/lib/richfaces-components-ui-4.1.0-20110802.221239-82.jar\n",
            "543011 Defl:N 456324 16% 2011-07-12 14:02 f915bdef WEB-INF/lib/joda-time-1.6.1.jar\n",
            "80863 Defl:N 74890 7% 2011-07-21 10:31 1074f519 WEB-INF/lib/jboss-marshalling-river-1.3.0.CR9.jar\n",
            "153633 Defl:N 139858 9% 2011-07-18 08:58 267a0105 WEB-INF/lib/seam-security-impl-3.0.1-20110624.041853-12.jar\n",
            "546379 Defl:N 489412 10% 2011-07-21 10:38 7810d5c7 WEB-INF/lib/jboss-common-core-2.2.17.GA.jar\n",
            "161455 Defl:N 122304 24% 2011-07-12 15:10 55c0bc93 WEB-INF/lib/knowledge-api-5.2.0.Final.jar\n",
            "1902276 Defl:N 1719856 10% 2011-07-12 15:10 91eaa4f6 WEB-INF/lib/drools-core-5.2.0.Final.jar\n",
            "15071 Defl:N 12479 17% 2011-04-04 11:31 a1e02acb WEB-INF/lib/jta-1.1.jar\n",
            "7635 Defl:N 5428 29% 2011-07-21 10:31 ed71d5ec WEB-INF/lib/rhq-pluginAnnotations-3.0.1.jar\n",
            "897071 Defl:N 858346 4% 2011-07-12 15:16 a1635c95 WEB-INF/lib/antlr-3.3.jar\n",
            "91540 Defl:N 81205 11% 2011-07-25 08:27 6d5bdd9e WEB-INF/lib/seam-config-xml-3.0.1-20110723.041850-8.jar\n",
            "443432 Defl:N 420698 5% 2011-05-16 12:02 d108cdd2 WEB-INF/lib/antlr-2.7.6.jar\n",
            "1674737 Defl:N 1601274 4% 2011-07-07 12:55 b5de0b5f WEB-INF/lib/ecj-3.5.1.jar\n",
            "10899 Defl:N 7710 29% 2011-07-21 10:31 b580639d WEB-INF/lib/jboss-transaction-api-1.0.1.GA.jar\n",
            "15808 Defl:N 12066 24% 2011-07-07 12:54 cbb7cd31 WEB-INF/lib/sac-1.3.jar\n",
            "269014 Defl:N 245020 9% 2011-06-20 14:42 0d19c92a WEB-INF/lib/commons-net-3.0.1.jar\n",
            "1472606 Defl:N 1320427 10% 2011-07-21 10:31 0084c472 WEB-INF/lib/infinispan-core-5.0.0.CR7.jar\n",
            "7457 Defl:N 5972 20% 2011-07-18 14:13 cdac3310 WEB-INF/lib/quartz-jboss-2.0.1.jar\n",
            "713433 Defl:N 657365 8% 2011-07-12 15:10 3e88a598 WEB-INF/lib/mvel2-2.1.0.drools2.jar\n",
            "12623 Defl:N 10267 19% 2011-07-21 10:38 77d0c4ba WEB-INF/lib/jboss-logging-spi-2.1.0.GA.jar\n",
            "253950 Defl:N 241386 5% 2011-05-12 11:27 f758d70e WEB-INF/lib/cssparser-0.9.5.jar\n",
            "1114265 Defl:N 987976 11% 2011-05-12 11:27 57d773f1 WEB-INF/lib/guava-r08.jar\n",
            "25496 Defl:N 22183 13% 2011-07-14 12:55 1a95d60b WEB-INF/lib/slf4j-api-1.6.1.jar\n",
            "85262 Defl:N 64318 25% 2011-08-03 07:41 09f14670 WEB-INF/lib/richfaces-components-api-4.1.0-20110802.221059-82.jar\n",
            "119223 Defl:N 103690 13% 2011-07-18 08:58 fb1581b3 WEB-INF/lib/seam-persistence-3.0.1-20110711.040751-17.jar\n",
            "148627 Defl:N 138829 7% 2011-07-12 15:16 3e8b388d WEB-INF/lib/stringtemplate-3.2.1.jar\n",
            "397907 Defl:N 343667 14% 2011-07-07 12:54 7f34b227 WEB-INF/lib/seam-solder-3.0.0.Final.jar\n",
            "102661 Defl:N 80043 22% 2011-07-07 12:54 b67dd2a4 WEB-INF/lib/hibernate-jpa-2.0-api-1.0.1.Final.jar\n",
            "2135793 Defl:N 2028099 5% 2011-07-21 10:31 ade69d61 WEB-INF/lib/jgroups-2.12.0.Final.jar\n",
            "988489 Defl:N 902079 9% 2011-07-12 15:16 22c8db9d WEB-INF/lib/drools-compiler-5.2.0.Final.jar\n",
            "424253 Defl:N 391533 8% 2011-08-04 07:24 9a1f5dba WEB-INF/lib/richfaces-core-impl-4.1.0-20110803.165959-73.jar\n",
            "83291 Defl:N 68465 18% 2011-08-03 07:41 d9920651 WEB-INF/lib/seam-servlet-3.0.1-20110803.040537-7.jar\n",
            "33716 Defl:N 23689 30% 2011-07-18 08:58 3a591eab WEB-INF/lib/seam-security-api-3.0.1-20110624.041806-12.jar\n",
            "163650 Defl:N 149460 9% 2011-07-12 15:16 e8acd98f WEB-INF/lib/antlr-runtime-3.3.jar\n",
            "136498 Defl:N 115026 16% 2011-08-04 07:24 010242c6 WEB-INF/lib/richfaces-core-api-4.1.0-20110803.165751-75.jar\n",
            "608376 Defl:N 554163 9% 2011-07-14 12:55 4bb8e85b WEB-INF/lib/c3p0-0.9.1.1.jar\n",
            "23055 Defl:N 14694 36% 2011-07-07 12:54 5dfcdff2 WEB-INF/lib/picketlink-idm-spi-1.5.0.Alpha02.jar\n",
            "27714 Defl:N 18846 32% 2011-07-07 12:54 9718b1ca WEB-INF/lib/picketlink-idm-api-1.5.0.Alpha02.jar\n",
            "25717 Defl:N 20670 20% 2011-07-07 12:54 8473b909 WEB-INF/lib/picketlink-idm-common-1.5.0.Alpha02.jar, Similarity: 0.2632\n",
            "Summary & Description: refactoring generated annotation \n",
            " You will find as an attached file a patch to modify the Generated annotation of the JPA MetaModels.\n",
            "The value element of the annotation is now the name of the processor. \n",
            "If activated, the annotation as an element date which that indicates when the file has been generated. This element date may be a problem when you try to compare several generated files, so you can remove it with the option -AremoveDateFromGeneratedAnnotation=true.\n",
            "\n",
            "Hope this helps,\n",
            "\n",
            "--\n",
            "\n",
            "Théo, Similarity: 0.3521\n",
            "Summary & Description: basicattributevistor doesnt recognize subclasses javaioserializeable attributes \n",
            " Situation:\n",
            "Interface _UnitPersistentValueIF_ extends _PersistentValueIF_.\n",
            "Interface _PersistentValueIF_ extends _java.io.Serializable_.\n",
            "\n",
            "Result:\n",
            "The annotationprocessor creates attributes for element _PersistentValueIF_\n",
            "The annotationprocessor doesn't create attributes for element _UnitPersistentValueIF_\n",
            "\n",
            "Expected result:\n",
            "The annotationprocessor creates for both _PersistentValueIF_ and _UnitPersistentValueIF_ the attributes.\n",
            "\n",
            "I have debugged the annotationprocessor and this could be the solution:\n",
            "\n",
            "In BasicAttributeVisitor.java in method _visitDeclared(DeclaredType declaredType, Element element)_\n",
            "there is the following code:\n",
            "{code}\n",
            "  if ( \"java.io.Serializable\".equals( interfaceElement.getQualifiedName().toString() ) ) {\n",
            "{code}\n",
            "This code should also take into account its superclasses (or interfaces).\n",
            "\n",
            "Can this be done with 'java.lang.model' ?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            ", Similarity: 0.3617\n",
            "Summary & Description: root class hierarchy declare id default access type cannot resolved \n",
            " if we have\n",
            "{code}\n",
            "@MappedSuperClass Foo {}\n",
            "@Entity @Inheritance Bar extends Foo { @Id id }\n",
            "@Entity Baz extends Bar {}\n",
            "{code}\n",
            "\n",
            "Baz_ will not have any of Baz's bindings because while looking for access type the processor does not stop at Bar and continues to Foo which has default accesstype of null.\n",
            "\n",
            "Pull request with a test case incoming..., Similarity: 0.1626\n",
            "Summary & Description: documented options recognized namely ormxml addgeneratedannotation \n",
            " I use Hibernate 3.6.5.Final (depending on the version 1.0.0.Final of Metamodel Generator).\n",
            "When I use the following arg-file for javac\n",
            "{quote}\n",
            "{noformat}\n",
            "-d ../../../target/metamodel\n",
            "-s ../../../target/metamodel\n",
            "-ApersistenceXml=../../../../../integration/jpa-dao/src/main/resources/META-INF/fbs-persistence.xml\n",
            "-AormXml=../../../../../integration/jpa-dao/src/main/resources/META-INF/fbs-orm-mapping.xml\n",
            "-AaddGeneratedAnnotation=true\n",
            "-proc:only\n",
            "-cp .;W:/05_tools/.m2/repository/org/hibernate/javax/persistence/hibernate-jpa-2.0-api/1.0.0.Final/hibernate-jpa-2.0-api-1.0.0.Final.jar;W:/05_tools/.m2/repository/org/hibernate/hibernate-core/3.6.5.Final/hibernate-core-3.6.5.Final.jar;W:/05_tools/.m2/repository/org/hibernate/hibernate-envers/3.6.5.Final/hibernate-envers-3.6.5.Final.jar;W:/05_tools/.m2/repository/org/hibernate/hibernate-jpamodelgen/1.0.0.Final/hibernate-jpamodelgen-1.0.0.Final.jar;W:/01_workspace/FFEv2-fbs/bin;W:/05_tools/.m2/repository/commons-lang/commons-lang/2.4/commons-lang-2.4.jar;W:/01_workspace/FFEv2-common/bin\n",
            "{noformat}\n",
            "{quote}\n",
            "metamodel sources are successfully generated but the javac output looks as follows:\n",
            "{quote}\n",
            "{noformat}\n",
            "Note: Hibernate JPA 2 Static-Metamodel Generator 1.0.0.Final\n",
            "warning: The following options were not recognized by any processor: '[addGeneratedAnnotation, ormXml]'\n",
            "{noformat}\n",
            "{quote}\n",
            "Needless to say the @Generated is absent from the generated files, e.g.\n",
            "{code}\n",
            "package com.navteq.ncs.fbs.domain.persistence;\n",
            "\n",
            "import javax.persistence.metamodel.SingularAttribute;\n",
            "import javax.persistence.metamodel.StaticMetamodel;\n",
            "\n",
            "@StaticMetamodel(ActivationKeyAlgorithmPo.class)\n",
            "public abstract class ActivationKeyAlgorithmPo_ {\n",
            "\n",
            "\tpublic static volatile SingularAttribute<ActivationKeyAlgorithmPo, Long> id;\n",
            "\tpublic static volatile SingularAttribute<ActivationKeyAlgorithmPo, String> name;\n",
            "\n",
            "}\n",
            "\n",
            "\n",
            "{code}\n",
            "\n",
            "Both options are documented here http://docs.jboss.org/hibernate/stable/jpamodelgen/reference/en-US/html_single/#d0e349, Similarity: 0.3953\n",
            "Summary & Description: mappedsuperclass without id explicit access type dont inherit right hierachy access type \n",
            " all the @manytoone fields in a mappedsuperclass are absent in the generated metamodel., Similarity: 0.2594\n",
            "Summary & Description: xml based mapping embeddets mappedsuperclass ignored \n",
            " I use a Mapped Superclass, which refer to an (generic) Embeddded.\n",
            "Because this class is located in an different jar I needto map this class explicit in XML.\n",
            "But the Hibernate Model Generator does not create an field in the Meta Model of the Mapped Superclass that represent the Embedded.\n",
            "\n",
            "See the code for illustration.\n",
            "\n",
            "{code:title=Mapped Superclass(BusinessEntity<T>)}\n",
            "public abstract class BusinessEntity<T extends Serializable>\n",
            "                      implements Serializable {\n",
            "   private Long id;\n",
            "\n",
            "   private BusinessId<T> businessId;\n",
            " ...\n",
            "}\n",
            "{code}\n",
            "\n",
            "{code:title=Generic Embedded (BusinessId<T>)}\n",
            "public class BusinessId<T> implements Serializable {\n",
            "\n",
            "    private long businessId;\n",
            "  ...\n",
            "}\n",
            "{code}\n",
            "\n",
            "{code:title=orm.xml}\n",
            "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
            "<entity-mappings xmlns=\"http://java.sun.com/xml/ns/persistence/orm\"\n",
            "    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n",
            "    xsi:schemaLocation=\"http://java.sun.com/xml/ns/persistence/orm\n",
            "    http://java.sun.com/xml/ns/persistence/orm_2_0.xsd\"\n",
            "    version=\"2.0\">\n",
            "\n",
            "    <mapped-superclass class=\"BusinessEntity\"  \n",
            "            access=\"FIELD\">     \n",
            "        <attributes>            \n",
            "            <id name=\"id\">\n",
            "                <column nullable=\"false\"/>\n",
            "                <generated-value strategy=\"AUTO\"/>              \n",
            "            </id>\n",
            "            <embedded name=\"businessId\"/>\n",
            "        </attributes>       \n",
            "    </mapped-superclass>\n",
            "\n",
            "    <embeddable class=\"BusinessId\"\n",
            "            access=\"FIELD\">\n",
            "        <attributes>\n",
            "            <basic name=\"businessId\">\n",
            "                <column nullable=\"false\" unique=\"true\"/>\n",
            "            </basic>\n",
            "        </attributes>\n",
            "    </embeddable>   \n",
            "</entity-mappings>\n",
            "{code}\n",
            "\n",
            "{code:title=Generated Meta Model (BusinessEntity_)}\n",
            "import javax.persistence.metamodel.SingularAttribute;\n",
            "import javax.persistence.metamodel.StaticMetamodel;\n",
            "\n",
            "@StaticMetamodel(BusinessEntity.class)\n",
            "public abstract class BusinessEntity_ {\n",
            "\tpublic static volatile SingularAttribute<BusinessEntity, Long> id;\n",
            "}\n",
            "{code}\n",
            "\n",
            "{code:title=Generated Meta Model (BusinessId_)}\n",
            "import javax.persistence.metamodel.SingularAttribute;\n",
            "import javax.persistence.metamodel.StaticMetamodel;\n",
            "\n",
            "@StaticMetamodel(BusinessId.class)\n",
            "public abstract class BusinessId_ {\n",
            "\tpublic static volatile SingularAttribute<BusinessId, Long> businessId;\n",
            "}\n",
            "{code}\n",
            "\n",
            ", Similarity: 0.2929\n",
            "Summary & Description: normal class hierarchy breaks metamodel \n",
            " If an entity class extends a normal class which in turn extends another entity or a mapped superclass the generated meta model doesn't reflect this hierarchy.\n",
            ", Similarity: 0.0434\n",
            "Summary & Description: parameter additional entity mapping files ormxmllist ormxml \n",
            " In the \"Hibernate JPA 2 Metamodel Generator - Reference Guide\" 1.1.1.Final, the parameter to llows to specify additional entity mapping files is {{orm.xml}}.\n",
            "\n",
            "{quote}\n",
            "2.3. Processor specific options\n",
            "...\n",
            "|ormXml|Allows to specify additional entity mapping files. The specified value for this option is a comma separated string of mapping file names. Even when this option is specified /META-INF/orm.xml is implicit.|\n",
            "{quote}\n",
            "\n",
            "But in the code it is {{ormXmlList}}.\n",
            "{code:title=JPAMetaModelEntityProcessor line 77}\n",
            "public static final String ORM_XML_OPTION = \"ormXmlList\";\n",
            "{code}\n",
            "\n",
            "One of them should be changed so that documentation and code match., Similarity: 0.3731\n",
            "Summary & Description: sortedset attributes included metamodel \n",
            " SortedSet collections (with _@Sort_ etc.) are not included in generated metamodel. Is it the wanted behavior, even if collections are annotated with _@OneToMany_ resp. _@ManyToMany_?\n",
            "\n",
            "It produces the following error:\n",
            "{noformat}\n",
            "\"Unable to locate static metamodel field ...\"\n",
            "{noformat}, Similarity: 0.2134\n",
            "Summary & Description: embedded class implementing list interface leads missing identifier \n",
            " I have an embedded class which implements the _java.util.List_ interface when running the annotation processor for the JPA meta model it fails with the message \n",
            "{noformat}\n",
            "Note: Determining access type for ListOfString2\n",
            "    [javac] ListOfString2_.java:9: <identifier> expected\n",
            "    [javac] public static volatile SingularAttribute<ListOfString2, String> ;\n",
            "{noformat}\n",
            "when looking into the generated class the message makes sense because the identifier is indeed missing, question is how is that possible. See attachment for embedded object and generated output of the meta model class., Similarity: 0.4030\n",
            "Summary & Description: metadata created mapped superclasses directories \n",
            " my entites are in package A (directory src/main/java) and extend base-entities which are also in package A (but in src/generated/java). No metadata is produced for the base-entities. If i move the base-entities to the _src/main/java_ (to the same dir where the entities are), everything is working as expected. Attached is the relevant part of the maven pom.xml file, Similarity: 0.3891\n",
            "Summary & Description: subsequent processing rounds trying reprocess entities already processed causes error \n",
            " I have an entity named \"Car\" and another processor that creates another entity name \"CarAudit\".\n",
            "\n",
            "After the first round, the class \"Car_\" and class \"CarAudit\" are created, therefore causing a subsequent round of processing since \"CarAudit\" is marked with @Entity.\n",
            "\n",
            "However, the second round fails with the following error:\n",
            "\n",
            "\"diagnostic error: Problem with Filer: Attempt to recreate a file for type com.example.Car_\"\n",
            "\n",
            "This is due to not clearing the \"metaEntities\" list from the context object after every round. Each processing round will use the same processor and context object and try to create all of the meta entries listed in the context during each round.\n",
            "\n",
            "My proposed solution is to clear the metaEntities list from the context object after each round of processing.\n",
            "\n",
            "Sorry, I do not have a test case for this right now., Similarity: 0.2020\n",
            "Summary & Description: attributes generated embeddedid collections mapping defined ormxml mapping files \n",
            " To fix the collection problem l. 196 of _XmlMetaEntity_ (in the getCollectionTypes method):\n",
            "{code}\n",
            "if ( expectedElementKind.equals( elem.getKind() ) ) {\n",
            "{code}\n",
            "should be replaced by\n",
            "{code}\n",
            "if ( ! expectedElementKind.equals( elem.getKind() ) ) {\n",
            "{code}\n",
            "\n",
            "To fix the _EmbeddedId_ problem the following code should be inserted at l. 332 of _XmlMetaEntity_ (in the parseAttributes method):\n",
            "{code}\n",
            "if ( attributes.getEmbeddedId() != null) {\n",
            "\tEmbeddedId embeddedId = attributes.getEmbeddedId();\n",
            "\tElementKind elementKind = getElementKind( embeddedId.getAccess() );\n",
            "\tString type = getType( embeddedId.getName(), null, elementKind );\n",
            "\tif ( type != null ) {\n",
            "\t\tattribute = new XmlMetaSingleAttribute( this, embeddedId.getName(), type );\n",
            "\t\tmembers.add( attribute );\n",
            "\t}\n",
            "}\n",
            "{code}\n",
            ", Similarity: 0.2855\n",
            "Summary & Description: missing singular attribute import merging attributes \n",
            " I have failing testcases due to a missing import in the Generated ZeroCoordinates_.java.\n",
            "\n",
            "My analysis:\n",
            "The import \"import javax.persistence.metamodel.SingularAttribute;\" is not added to the file ZeroCoordinates_.java and will not compile due to this missing dependency.\n",
            "\n",
            "It is a mixed configuration: so in the class JPAMetaModelEntityProcessor (line 237) the call is made to \n",
            "\t\t\t\tmetaEntity.mergeInMembers( alreadyExistingMetaEntity.getMembers() );\n",
            "\n",
            "This basically means that the attributes of the already existing XML MetaEntity are placed in the attributesMap of the AnnotationMetaEntity.\n",
            "{code}\n",
            "public void mergeInMembers(Collection<MetaAttribute> attributes) {\n",
            "\tfor ( MetaAttribute attribute : attributes ) {\n",
            "\t\tmembers.put( attribute.getPropertyName(), attribute );\n",
            "\t}\n",
            "}\n",
            "{code}\n",
            "\n",
            "This means that the AnnotationEmbeddable has a Context, but the members (the merged in Xml-attributes) have a different context. (Do not understand why there are two contexts, can you enlighten me?)\n",
            "\n",
            "In the ClassWriter line 107:\n",
            "{code}\n",
            "for ( MetaAttribute metaMember : members ) {\n",
            "    pw.println( \"\t\" + metaMember.getDeclarationString() );\n",
            "}\n",
            "{code}\n",
            "\n",
            "the declaration string is printed. As the attributes are XMLMetaAttribute, their implementation of the getDeclarationString is\n",
            "{code}\n",
            "return \"public static volatile \" + hostingEntity.importType( getMetaType() )\n",
            "\t+ \"<\" + hostingEntity.importType( hostingEntity.getQualifiedName() )\n",
            "        + \", \" + hostingEntity.importType( getTypeDeclaration() )\n",
            "\t+ \"> \" + getPropertyName() + \";\";\n",
            "{code}\n",
            "\n",
            "The hosting entity of the attribute is still the XmlMetaEmbeddable and when the importType is added, it is added to the wrong context (the context of the XMLMetaEmbeddable and NOT the AnnotationMetaEmbeddable).\n",
            "\n",
            "Possible solution is to change the parent or create a new merged attribute (not ugly like I do below ;-))\n",
            "{code}\n",
            "            MetaAttribute mergedAttribute = new XmlMetaSingleAttribute(this, attribute.getPropertyName(), attribute.getMetaType());\n",
            "\t    members.put( attribute.getPropertyName(), mergedAttribute );\n",
            "{code}\n",
            "\n",
            "This resolves the problem with the missing import, but if it is better to have a single context for both annotation and xml elements this might be a cleaner solution. Attached is the 'ugly' solution, but this leaves two failing testcases:\n",
            "{noformat}\n",
            "  testAccessTypeForXmlConfiguredEmbeddables(org.hibernate.jpamodelgen.test.mixedmode.MixedConfigurationTest)\n",
            "  testMixedConfiguration(org.hibernate.jpamodelgen.test.mixedmode.MixedConfigurationTest)\n",
            "{noformat}\n",
            "The testMixedConfiguration could be a problem that the supplied solution is not yet the definitive answer ;-(:\n",
            "{noformat}\n",
            "=======================================================\n",
            "Types do not match: Wrong meta model type expected:<class org.hibernate.jpamodelgen.test.mixedmode.RentalCompany> but was:<interface javax.persistence.metamodel.SingularAttribute>\n",
            "\n",
            "org.testng.Assert.fail(Assert.java:84) \n",
            "at org.testng.Assert.failNotEquals(Assert.java:438) \n",
            "at org.testng.Assert.assertEquals(Assert.java:108) \n",
            "at org.hibernate.jpamodelgen.test.util.TestUtil.assertAttributeTypeInMetaModelFor(TestUtil.java:176) \n",
            "at org.hibernate.jpamodelgen.test.mixedmode.MixedConfigurationTest.testMixedConfiguration(MixedConfigurationTest.java:68) \n",
            "30 lines not shown\n",
            "=======================================================\n",
            "{noformat}\n",
            "The testAccessTypeForXmlConfiguredEmbbedables seems unreleated:\n",
            "{code}\n",
            "assertAbsenceOfFieldInMetamodelFor(\n",
            "\tZeroCoordinates.class,\n",
            "\t\"longitude\",\n",
            "\t\"Field access should be used, but ZeroCoordinates does not define fields\"\n",
            ");\n",
            "assertAbsenceOfFieldInMetamodelFor(\n",
            "\tZeroCoordinates.class,\n",
            "\t\"latitude\",\n",
            "\t\"Field access should be used, but ZeroCoordinates does not define fields\"\n",
            ");\n",
            "{code}\n",
            "as I am not completely sure that the asserts are correct. The access type of embeddables dependends on the enclosing entity, so ain't it true that the field AND properties should be generated?\n",
            "\n",
            "Regards,\n",
            "\n",
            "\n",
            "Martijn\n",
            ", Similarity: 0.4067\n",
            "Summary & Description: xml reference embeddable written \n",
            " No reference to an Embeddable included in the generated MetaModel class that used the embeddable.\n",
            "\n",
            "The embedded attributes were not written. Testcases and solution attached.\n",
            "\n",
            "Same comment apply as METAGEN-54, still had the 4 failing testcases I started with.\n",
            "\n",
            "Martijn Blankestijn, Similarity: 0.3575\n",
            "Summary & Description: xmlonly field access type set attribute generated \n",
            " I have a xml-only mapping with no target-entity attribute specified on collections. For the collections generics were used, so type information was available. The collections were not generated by the generator in the meta-model classes.\n",
            "\n",
            "I have checked out the current version of the source from Git and made the changes (testcases and solution). You find these files attached to this bugreport. It is not a very 'clean' solution yet, but I wanted to shared the bug and possible solution first.\n",
            "\n",
            "When I run maven just after checkout I had 4 failing testcases:\n",
            "* testAccessTypeForXmlConfiguredEmbeddables(org.hibernate.jpamodelgen.test.mixedmode.MixedConfigurationTest)\n",
            "* testDefaultAccessTypeApplied(org.hibernate.jpamodelgen.test.mixedmode.MixedConfigurationTest)\n",
            "* testExplicitXmlConfiguredAccessTypeApplied(org.hibernate.jpamodelgen.test.mixedmode.MixedConfigurationTest)\n",
            "* testMixedConfiguration(org.hibernate.jpamodelgen.test.mixedmode.MixedConfigurationTest)\n",
            "\n",
            "I still had these 4 failing testcase with my solution and I have not investigated this further.\n",
            "\n",
            "In my search for the answer (error in my mapping, incorrect understanding of the generator or a bug in the Generator) I found a couple of points I got confused about.\n",
            "\n",
            "First is that the access type on the XML entity was not set if it was specified only on the entity (not in the persistence unit default or on the collection itself). It then defaulted to METHOD (a.k.a. property access)\n",
            "\n",
            "In XmlMetaEntity (line 542)\n",
            "{code}\n",
            "   return TypeUtils.getElementKindForAccessType( accessTypeInfo.getDefaultAccessType() );\n",
            "{code}\n",
            "probably should be \n",
            "{code}\n",
            "   return TypeUtils.getElementKindForAccessType( accessTypeInfo.getAccessType() );\n",
            "{code}\n",
            "which was good because line 196 would lead the code to look for attributes (not methods) to compare to the property-name.\n",
            "If the element was not the same one as was expected, the loop would skip that element. This seemed strange to me.\n",
            "{code}\n",
            "\t\t\tif ( expectedElementKind.equals( elem.getKind() ) ) {\n",
            "\t\t\t\tcontinue;\n",
            "\t\t\t}\n",
            "{code}\n",
            "As I said, attached is my solution in which, I hope, will confirm to the JPA-specification ;-).\n",
            "\n",
            "Regards,\n",
            "\n",
            "Martijn Blankestijn, Similarity: 0.3943\n",
            "Summary & Description: suppress warnings \n",
            " Please consider adding a @SuppressWarnings(\"all\") annotation to the generated classes. Warnings in generated code are not helpful.\n",
            "\n",
            "In my case the warnings (driven by IDE settings) are caused by:\n",
            "\n",
            "1) Entities marked as @Deprecated.\n",
            "\n",
            "2) A custom Hibernate user type that maps a numeric SQL type into an EnumSet<T>. The generated SingularAttribute does not preserve the type of the set.\n",
            ", Similarity: 0.1622\n",
            "Summary & Description: jpametamodelentityprocessorcreatemetamodelclasses calls remove within foreach loop causing concurrentmodificationexception \n",
            " Running the annotation processor causes a ConcurrentModificationException.\n",
            "I'm using Maven and the maven-processor-plugin 1.3.7 but from looking into the sources I guess this bug occurs in any environment.\n",
            "JPAMetaModelEntityProcessor.createMetaModelClasses iterates of a Collection<MetaEntity> using a foreach loop and calls remove\n",
            "on the same collection which causes a ConcurrentModificationException.\n",
            "Obviously an iterator should be used instead.\n",
            "\n",
            "Here are the lines concerned:\n",
            "{code:java} \n",
            " Collection<MetaEntity> toProcessEntities = context.getMetaEmbeddables();\n",
            " while ( !toProcessEntities.isEmpty() ) {\n",
            "  Set<MetaEntity> processedEntities = new HashSet<MetaEntity>();\n",
            "  int toProcessCountBeforeLoop = toProcessEntities.size();\n",
            "  for ( MetaEntity entity : toProcessEntities ) {\n",
            "    // see METAGEN-36\n",
            "    if ( generatedModelClasses.contains( entity.getQualifiedName() ) ) {\n",
            "      toProcessEntities.remove( entity );  // XXX this causes a ConcurrentModificationException\n",
            "      continue;\n",
            "  }\n",
            " ...\n",
            "{code}\n",
            "Here is the stacktrace:\n",
            "{code}\n",
            "...\n",
            "[INFO] diagnostic Note: Hibernate JPA 2 Static-Metamodel Generator 1.1.0.Final\n",
            "An annotation processor threw an uncaught exception.\n",
            "Consult the following stack trace for details.\n",
            "java.util.ConcurrentModificationException\n",
            "\tat java.util.HashMap$HashIterator.nextEntry(HashMap.java:793)\n",
            "\tat java.util.HashMap$ValueIterator.next(HashMap.java:822)\n",
            "\tat org.hibernate.jpamodelgen.JPAMetaModelEntityProcessor.createMetaModelClasses(JPAMetaModelEntityProcessor.java:153)\n",
            "\tat org.hibernate.jpamodelgen.JPAMetaModelEntityProcessor.process(JPAMetaModelEntityProcessor.java:133)\n",
            "\tat com.sun.tools.javac.processing.JavacProcessingEnvironment.callProcessor(JavacProcessingEnvironment.java:625)\n",
            "\tat com.sun.tools.javac.processing.JavacProcessingEnvironment.discoverAndRunProcs(JavacProcessingEnvironment.java:554)\n",
            "\tat com.sun.tools.javac.processing.JavacProcessingEnvironment.doProcessing(JavacProcessingEnvironment.java:699)\n",
            "\tat com.sun.tools.javac.main.JavaCompiler.processAnnotations(JavaCompiler.java:981)\n",
            "\tat com.sun.tools.javac.main.JavaCompiler.compile(JavaCompiler.java:727)\n",
            "\tat com.sun.tools.javac.main.Main.compile(Main.java:353)\n",
            "\tat com.sun.tools.javac.api.JavacTaskImpl.call(JavacTaskImpl.java:115)\n",
            "\tat org.bsc.maven.plugin.processor.AbstractAnnotationProcessorMojo.executeWithExceptionsHandled(AbstractAnnotationProcessorMojo.java:261)\n",
            "\tat org.bsc.maven.plugin.processor.AbstractAnnotationProcessorMojo.execute(AbstractAnnotationProcessorMojo.java:129)\n",
            "\tat org.apache.maven.plugin.DefaultPluginManager.executeMojo(DefaultPluginManager.java:490)\n",
            "{code}, Similarity: 0.4064\n",
            "Summary & Description: generated metamodel sources compiled jdk 6 \n",
            " I tried to generate metamodel classes during maven build as described in the documentation (using automatic annotation processing in JDK 6) and noticed that metamodel source files are generated but not compiled. I also see the same problem when I try to configure metamodel generation in Eclipse as described in the documentation.\n",
            "\n",
            "Googling around showed that many people face the same problem in both maven and Eclipse.\n",
            "\n",
            "Further investigation showed that:\n",
            "\n",
            "* Generated sources are compiled by maven when version of maven-compiler-plugin is below 2.2, and not compiled otherwise.\n",
            "\n",
            "* This behaviour is related to {{TODO}} in {{org/hibernate/jpamodelgen/test/util/CompilationTest.java}} - if I remove the second compilation phase there, tests fail for the very same reason.\n",
            "\n",
            "* Currently annotation processor generates metamodel sources at the final round of annotation processing. However, when I modify {{org/hibernate/jpamodelgen/JPAMetaModelEntityProcessor.java}} to generate metamodel at the first round, tests pass and everything works fine in maven and Eclipse. It looks like sources generated at the final round are not compiled., Similarity: 0.4632\n",
            "Summary & Description: getting runtime error message ohemmetadatacontext unable locate static metamodel field \n",
            " I have a @MappedSuperClass declared as\n",
            "\n",
            "    @MappedSuperClass\n",
            "    public abstract class IdentifiableComponent<T extends EmbeddableId> extends RecordTimestamp2 implements Serializable\n",
            "\n",
            "and my Entity class declared as\n",
            "\n",
            "    @Entity\n",
            "    public class AppRegistration extends IdentifiableComponent<AppRegistrationId> \n",
            "\n",
            "and the Composite Id class declared as\n",
            "\n",
            "    @Embeddable\n",
            "    public class AppRegistrationId implements EmbeddableId\n",
            "\n",
            "The metamodel is generated properly, but at runtime I get the following error message\n",
            "\n",
            "    o.h.e.m.MetadataContext - Unable to locate static metamodel field : com.playspan.lookup.model.AppRegistration_#id\n",
            "\n",
            "\n",
            "I've tried adding @IdClass(AppRegistrationId) annotation to the AppRegistration Entity class, but still \n",
            "I get the same error message.\n",
            "\n",
            "Please tell me what I am doing wrong.  Thanx in advance.\n",
            "\n",
            "Attached is a complete sample buildable maven project with the above classes, Similarity: 0.3634\n",
            "Summary & Description: entity extending mappedsuperclass another package generate meta model properly \n",
            " I have a entity class SystemEvents which extends from Identifiable that is defined in another maven module. (see attached files).\n",
            "\n",
            "When I generate the META MODEL the generated meta model does not extend from Identifiable_ as documented\n",
            "\n",
            "{quote}\n",
            "If class X extends another class S, where S is the most derived managed class (i.e., entity or mapped superclass) extended by X, then class X_ must extend class S_, where S_ is the metamodel class created for S.\n",
            "{quote}\n",
            ", Similarity: 0.2524\n",
            "Summary & Description: mappedsuperclass type parameters result uncompilable metamodels \n",
            " The attached tgz illustrates the bug, run mvn compile.  The metamodel for the base class either needs a type param (and likewise the extends class on the sub-metamodel), or the base class needs to be generated with Object as the type \n",
            "\n",
            ", Similarity: 0.3272\n",
            "Summary & Description: attempt recreate file type \n",
            " When genearting model from entities I got error \n",
            "\n",
            "{code}\n",
            "\"error: Problem with Filer: Attempt to recreate a file for type ....\"\n",
            "{code}\n",
            "\n",
            "The problem looks like when mixing annotations {{@Embedable}} and {{@MappedSuperclass}}, removing one of those makes generation successful.\n",
            "\n",
            "Ant stack trace is as follow:\n",
            "{code}\n",
            " at org.apache.tools.ant.taskdefs.Javac.compile(Javac.java:1113)\n",
            "        at org.apache.tools.ant.taskdefs.Javac.execute(Javac.java:906)\n",
            "        at org.netbeans.modules.java.source.ant.JavacTask.execute(JavacTask.java:136)\n",
            "        at org.apache.tools.ant.UnknownElement.execute(UnknownElement.java:291)\n",
            "        at sun.reflect.GeneratedMethodAccessor480.invoke(Unknown Source)\n",
            "        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n",
            "        at java.lang.reflect.Method.invoke(Method.java:597)\n",
            "        at org.apache.tools.ant.dispatch.DispatchUtils.execute(DispatchUtils.java:106)\n",
            "        at org.apache.tools.ant.Task.perform(Task.java:348)\n",
            "        at org.apache.tools.ant.taskdefs.Sequential.execute(Sequential.java:68)\n",
            "        at org.apache.tools.ant.UnknownElement.execute(UnknownElement.java:291)\n",
            "        at sun.reflect.GeneratedMethodAccessor480.invoke(Unknown Source)\n",
            "        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n",
            "        at java.lang.reflect.Method.invoke(Method.java:597)\n",
            "        at org.apache.tools.ant.dispatch.DispatchUtils.execute(DispatchUtils.java:106)\n",
            "        at org.apache.tools.ant.Task.perform(Task.java:348)\n",
            "        at org.apache.tools.ant.taskdefs.MacroInstance.execute(MacroInstance.java:398)\n",
            "        at org.apache.tools.ant.UnknownElement.execute(UnknownElement.java:291)\n",
            "        at sun.reflect.GeneratedMethodAccessor480.invoke(Unknown Source)\n",
            "        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n",
            "        at java.lang.reflect.Method.invoke(Method.java:597)\n",
            "        at org.apache.tools.ant.dispatch.DispatchUtils.execute(DispatchUtils.java:106)\n",
            "        at org.apache.tools.ant.Task.perform(Task.java:348)\n",
            "        at org.apache.tools.ant.Target.execute(Target.java:390)\n",
            "        at org.apache.tools.ant.Target.performTasks(Target.java:411)\n",
            "        at org.apache.tools.ant.Project.executeSortedTargets(Project.java:1397)\n",
            "        at org.apache.tools.ant.Project.executeTarget(Project.java:1366)\n",
            "        at org.apache.tools.ant.helper.DefaultExecutor.executeTargets(DefaultExecutor.java:41)\n",
            "        at org.apache.tools.ant.Project.executeTargets(Project.java:1249)\n",
            "        at org.apache.tools.ant.module.bridge.impl.BridgeImpl.run(BridgeImpl.java:281)\n",
            "        at org.apache.tools.ant.module.run.TargetExecutor.run(TargetExecutor.java:539)\n",
            "        at org.netbeans.core.execution.RunClassThread.run(RunClassThread.java:154)\n",
            "{code}, Similarity: 0.3889\n",
            "Summary & Description: generated meta model classes extend super class meta model \n",
            " I'm currently using maven to build a project. I'm using org.bsc.maven.maven-processor-plugin plugin to generate the meta model. In my main source folder, I have a class annotated with @MappedSuperclass.\n",
            "\n",
            "{code}\n",
            "@MappedSuperclass\n",
            "public abstract class BaseEntity\n",
            "{\n",
            "    // Entity id\n",
            "    @Id\n",
            "    @GeneratedValue\n",
            "    private Long id;\n",
            "\n",
            "    // some more code\n",
            "}\n",
            "{code}\n",
            "\n",
            "In my test source folder, I have a class extending BaseEntity annotated with @Entity\n",
            "\n",
            "{code}\n",
            "@Entity()\n",
            "public class Book extends BaseEntity\n",
            "{\n",
            "    private String name;\n",
            "\n",
            "    @Column(unique = true)\n",
            "    private String isbn;\n",
            "\n",
            "    @ManyToOne(optional = false)\n",
            "    private Author author;\n",
            "    \n",
            "    // some more code\n",
            "}\n",
            "{code}\n",
            "\n",
            "When generating the meta model, the BaseEntity will generate BaseEntity_ and Book will generate Book_. The problem is that Book_ does not extend BaseEntity_\n",
            "\n",
            "Here is my config of the plugin\n",
            "\n",
            "{code:xml} \n",
            "<plugin>\n",
            "    <groupId>org.bsc.maven</groupId>\n",
            "    <artifactId>maven-processor-plugin</artifactId>\n",
            "    <version>1.3.6</version>\n",
            "    <executions>\n",
            "        <execution>\n",
            "            <id>process</id>\n",
            "            <goals>\n",
            "                <goal>process</goal>\n",
            "            </goals>\n",
            "            <phase>generate-sources</phase>\n",
            "            <configuration>\n",
            "                <!-- source output directory -->\n",
            "                <outputDirectory>${project.build.sourceDirectory}</outputDirectory>\n",
            "            </configuration>\n",
            "        </execution>\n",
            "        <execution>\n",
            "            <id>process-test</id>\n",
            "            <goals>\n",
            "                <goal>process-test</goal>\n",
            "            </goals>\n",
            "            <phase>generate-test-sources</phase>\n",
            "            <configuration>\n",
            "                <!-- source output directory -->\n",
            "                <outputDirectory>${project.build.testSourceDirectory}</outputDirectory>\n",
            "                <compilerArguments>-Adebug=true</compilerArguments>\n",
            "            </configuration>\n",
            "        </execution>\n",
            "    </executions>\n",
            "    <dependencies>\n",
            "        <dependency>\n",
            "            <groupId>org.hibernate</groupId>\n",
            "            <artifactId>hibernate-jpamodelgen</artifactId>\n",
            "            <version>1.0.0.Final-Genia</version>\n",
            "            <scope>compile</scope>\n",
            "        </dependency>\n",
            "    </dependencies>\n",
            "</plugin>\n",
            "{code} \n",
            "\n",
            "After looking at the code, the culprit seem to be org.hibernate.jpamodelgen.ClassWriter. In the method printClassDeclaration, we can see the following code:\n",
            "\n",
            "{code}\n",
            "if ( context.containsMetaEntity( superClassName )\n",
            "        || context.containsMetaEmbeddable( superClassName ) ) {\n",
            "    pw.print( \" extends \" + superClassName + \"_\" );\n",
            "}\n",
            "{code}\n",
            "\n",
            "It assume the the super class meta model is generated at the same time as the extending class, which is not the case for test-compile and compile. I also assume that it does not work if you extend a class coming from a jar where the meta model was already generated.\n",
            "\n",
            "To locally fix the problem, I changed the above code for:\n",
            "\n",
            "{code}\n",
            "if (((TypeElement) superClassElement).getAnnotation(Entity.class) != null\n",
            "        || ((TypeElement) superClassElement).getAnnotation(MappedSuperclass.class) != null)\n",
            "{\n",
            "    pw.print(\" extends \" + superClassName + \"_\");\n",
            "}\n",
            "{code}\n",
            "\n",
            "Since it's the first time I use annotation for code generation, I may not have fully understood the problem so feel free to correct me if the above fix is not the correct solution.\n",
            "\n",
            "Regard,\n",
            "Joel, Similarity: 0.3910\n",
            "Summary & Description: metamodel generated generated annotation \n",
            " The static meta model does not have a @Generated. This is probably the reason that avoids Eclipse compiling  of the derived classes (we must clean the project, or alter the generated class and save it). The eclipselink metamodel generator works fine, and the only difference between EclipseLink generator and hibernate generator is this annotation\n",
            "\n",
            "You can see that many users are being affected by this issue in the comments here:\n",
            "http://relation.to/Bloggers/HibernateStaticMetamodelGeneratorAnnotationProcessor\n",
            "\n",
            ", Similarity: 0.3810\n",
            "Summary & Description: target \n",
            " The jpamodelgen does not produce output for fields mapped using the @Embedded/@Target tags.\n",
            "\n",
            "ex:\n",
            "{code}\n",
            "@Entity\n",
            "class House\n",
            "{\n",
            "  @Embedded\n",
            "  @Target(acme.AddressImpl.class)\n",
            "  private Address address;\n",
            "}\n",
            "{code}\n",
            "\n",
            "It only works when the field is of type AddressImpl.\n",
            "\n",
            "Are there plans to support the hiberbate specific annotations?\n",
            "\n",
            "Any plans to support entity mapped using classic hbm.xml files?\n",
            "\n",
            "thanks\n",
            "jean-claude\n",
            "\n",
            ", Similarity: 0.4487\n",
            "Summary & Description: embedded generic types supported metamodel generator \n",
            " Scenario: I have a @MappedSuperclass defining an abstract entity. This class has a technical primary key and a business identity. The business identity is realized by means of a generic embeddable (e.g. for a Customer class there is a corresponding CustomerId class for its business identity).\n",
            "\n",
            "The JPAMetaModelEntityProcessor does generate the AbstractEntity_ class but does only include the primary key field but omits the generic field for the business identity (which leads to subsequent errors when accessing this field using a CriteriaBuilder).\n",
            "\n",
            "Attached a mini project with a test case which illustrates the problem. , Similarity: 0.2980\n",
            "Summary & Description: custom usertype supported hibernates static metamodel generator \n",
            " If an Entity has a custom Hibernate User type @Type it will not get generated in the static MetaModel class \"Item_\".\n",
            "\n",
            "This seems easy to fix by checking if the element being process has a @Type annotation then process it.\n",
            "\n",
            "{code}\n",
            "AnnotationMetaEntity.isBasicAttribute()\n",
            " ...\n",
            "   if(TypeUtils.containsAnnotation(element, Type.class)\n",
            "   {\n",
            "     return true;\n",
            "   }\n",
            "{code}\n",
            "\n",
            ", Similarity: 0.3177\n",
            "Summary & Description: review documentation \n",
            " * The copyright for the documentation should be: \"Red Hat, Inc.\"\n",
            "* Check why the example numbering is not working all the time, Similarity: 0.1411\n",
            "Summary & Description: create mechanism check whether xml files changed \n",
            " Since we cannot keep information between processor runs we will have to use some sort of file based mechanism. The processor could create a file when the xml files were parsed. The location of the the file could be passed as parameter or if not passed the VM tmp dir location is used. Each time the processor runs it checks whether any of the xml files is younger then the created tmp file. \n",
            "We could en- and dis-able this feature via another flag. , Similarity: 0.3040\n",
            "Summary & Description: handle idclass case \n",
            " in xml and annotation., Similarity: 0.2365\n",
            "Summary & Description: compiling hem tests raises error level log \n",
            " The error log raises from ClassWriter\n",
            "Problem with Processing Environment Filer: Attempt to recreate a file for type org.hibernate.ejb.test.ops.Widgets_\n",
            "\n",
            "Is that really to be considered an error? If yes, let's fix it. If not let's not display it., Similarity: 0.2665\n",
            "Summary & Description: output compiler meaninglessly verbose \n",
            " Ideally information level should be one line => modelgen processing entities\n",
            "\n",
            "Today we have meaningless things like\n",
            "annotations:[]\n",
            "last round false\n",
            "etc, Similarity: 0.1590\n",
            "Summary & Description: try find way able use supportedannotationtypesjavaxpersistenceentity jpametamodelentityprocessor \n",
            " At the moment we use @SupportedAnnotationTypes(\"*\"). Better would be to explicitly specify  @SupportedAnnotationTypes(\"javax.persistence.Entity\"). Then the processor would only be called if there are any entities annotated with @Entity. However, this also means that the processor is not getting called at all if there is no @Entity which could be the case if all configuration is done via xml. \n",
            "We would need a way to make sure that the processor is called at least once to ensure xml is parsed. Other than that only entities annotated with @Entity should be passed to the processor. \n",
            "At the moment I don't see how we can make this happen :(, Similarity: 0.4395\n",
            "Summary & Description: make logging output configurable \n",
            " Pass additional attribute to the processor to turn on/off the printing of debug statements via processingEnv.getMessager(), Similarity: 0.2538\n",
            "Summary & Description: document use processor different environments \n",
            " Include the documentation into the project (docbook?!) and blog about it., Similarity: 0.3264\n",
            "Summary & Description: handle byte \n",
            " http://fisheye.jboss.org/browse/Hibernate/core/trunk/entitymanager/src/test/java/org/hibernate/ejb/test/cascade/ExtractionDocument.java?r=15483#l23  ExtractionDocument defines a byte[] field.  The generator does not create any ExtractionDocument_ field for that attribute at all., Similarity: 0.3887\n",
            "Summary & Description: move defaultdatastorenames impl package stop sharing dialects \n",
            " From Emmanuel:\n",
            "\n",
            "{quote}\n",
            "* store is a bad name\n",
            "{quote}, Similarity: 0.2406\n",
            "Summary & Description: explore happens lock called \n",
            " {{EntityPersister}} exposes a {{lock}} operation. It uses a list of {{LockingStrategy}} s which are provided by {{GridDialect.getLockingStrategy}}.\n",
            "But this list is built by {{initLockers}} which is never called by {{OgmEntityPersister}}.\n",
            "\n",
            "We need to think about what will happen when callers of {{EntityPersister.lock}} are executed (is that a fair use in OGM?).\n",
            "And we need to clean up {{GridDialect}} implementation that sometimes return an implementation, sometimes throw an exception (seems wrong), sometimes return null.\n",
            "\n",
            "I *think* the right thing is to return a {{LockingStrategy}} that does throw an exception when called on a dialect not supporting locking.\n",
            "\n",
            "Should each involved dialect return an implementation of this {{ThrowUponLockLockingStrategy}} or should they return {{null}} and have the OGM engine build this strategy when {{null}} is returned.\n",
            "\n",
            "This needs some investigation and thinking.\n",
            "\n",
            "I am adding it to the final version as it would be cleaner but if really pressed we could delay that work., Similarity: 0.1475\n",
            "Summary & Description: provide billofmaterials pom matching versions ogm dependencies components \n",
            " We should provide a Bill-of-Materials POM which defines the versions of our components and dependencies. Users can refer to that BOM POM using the import scope in their dependency management configuration, thus giving them matching versions of all the artifacts listed in the BOM., Similarity: 0.3484\n",
            "Summary & Description: inject version number version maven plugin \n",
            " Search and validator (I guess) inject the version number in their {{Version}} class. OGM does not: it is hardcoded.\n",
            "I think [~accountid:557058:3972bcfe-a0fc-4e48-b575-4a991358f983] can guide whoever takes that task., Similarity: 0.3502\n",
            "Summary & Description: add properties relationship mapping intermediate table neo4j \n",
            " There is not a way in JPA to recognize an entity created to map additional properties to an intermediate table.\n",
            "\n",
            "In Neo4j, we could map this entities as relationships with properties (instead of nodes).\n",
            "\n",
            "This requires a discussion about the way a user could map this configuration., Similarity: 0.3176\n",
            "Summary & Description: add method griddialect allows get several entities \n",
            " There should be a method on {{GridDialect}} which allows to fetch several entities with one database round-trip:\n",
            "\n",
            "{code}\n",
            "ClosableIterator<Tuple> getTuples(List<EntityKey> keys, TupleContext tupleContext);\n",
            "{code}\n",
            "\n",
            "If supported by a specific store and configured by the user via {{@BatchSize}}, this  will allow to load all/several members of an association with one database access., Similarity: 0.3603\n",
            "Summary & Description: use natural format store maptyped properties mongodb \n",
            " Map-typed properties are currently persisted as follows in MongoDB and CouchDB:\n",
            "\n",
            "{code}\n",
            "{\n",
            "\t\"_id\" : \"7ab2aaa4-98ee-4eb1-95c9-655d0d040797\",\n",
            "\t\"addresses\" : [\n",
            "\t\t{\n",
            "\t\t\t\"nick\" : \"home\",\n",
            "\t\t\t\"addresses_id\" : \"6c0508fa-ab7f-4391-9887-ebc3a67d6a12\"\n",
            "\t\t},\n",
            "\t\t{\n",
            "\t\t\t\"nick\" : \"work\",\n",
            "\t\t\t\"addresses_id\" : \"680e11aa-c13d-4079-a8ce-2fcd32929c04\"\n",
            "\t\t}\n",
            "\t]\n",
            "}\n",
            "{code}\n",
            "\n",
            "It should be rather the following instead:\n",
            "\n",
            "{code}\n",
            "{\n",
            "\t\"_id\" : \"7ab2aaa4-98ee-4eb1-95c9-655d0d040797\",\n",
            "\t\"addresses\" : {\n",
            "\t\t\"home\" : \"6c0508fa-ab7f-4391-9887-ebc3a67d6a12\",\n",
            "\t\t\"work\" : \"680e11aa-c13d-4079-a8ce-2fcd32929c04\"\n",
            "\t}\n",
            "}\n",
            "{code}, Similarity: 0.3100\n",
            "Summary & Description: ogmsessionfactoryopensession return ogmsession \n",
            " In order to simplify retrieval of properly typed {{OgmSession}} objects, {{OgmSessionFactory#openSession()}} et al. should be overridden to return {{OgmSession}} rather than {{Session}}., Similarity: 0.3155\n",
            "Summary & Description: element collections properly persisted neo4j \n",
            " When working with {{@ElementCollection}} of an embeddable type, embedded node are wrongly labeled as TEMP_NODE. Also the \"embedded\" nodes are not deleted when removing the corresponding association; Only the relationship is removed, leaving the \"embedded\" node dangling behind., Similarity: 0.2826\n",
            "Summary & Description: avoid redundant association properties neo4j \n",
            " When a new relationship is created the columns of the RowKey are saved as properties of the relationship. This properties are usually redundant because they are already in the nodes connected by the relationship. We should only create the properties related to the association.\n",
            "\n",
            "Note that if we don't have the property on the relationship, it is not going to be possible to rebuild the RowKey when GridDialect#getAssociation(...) or to find the targetNode when GridDialect#createTupleAssociation(...) are called with the current available information in the AssociationKey, AssociationContext and RowKey.\n",
            "\n",
            "Let's take as an example BidirectionalManyToManyTest with AccountOwner and BankAccount, this is the information I have when Neo4jDialect#createTupleAssociation(...): is called:\n",
            "\n",
            "EntityKey{table='AccountOwner', columnNames=[id], columnValues=[...]}\n",
            "AssociationKey{table='AccountOwner_BankAccount', columnNames=[owners_id], columnValues=[...]}\n",
            "RowKey{table='AccountOwner_BankAccount', columnNames=[owners_id, bankAccounts_id], columnValues=[...]}\n",
            "\n",
            "What I want to obtain is the creation of a relationship like the following (I've omitted the type of the relationship and the properties):\n",
            "(AccountOwner) - [r] - (BankAccount)\n",
            "\n",
            "In this case the associationKey owner is AccountOwner and I can obtain the key to identify the corresponding node from AssociationKey#entityKey, what I'm missing is the metadata information to find the BankAccount node the relationship has to be connected with.\n",
            "With the current data I can extract the fact that the bankAccounts_id contains the id of target entity (BankAccount) but I don't know the name of the entity and which column contains the id.\n",
            "\n",
            "Note that removing the temp nodes is related to this issue because It is not possible to remove them without having some more information.\n",
            "\n",
            "\n",
            "\n",
            ", Similarity: 0.2785\n",
            "Summary & Description: provide public constants datastore provider short names \n",
            " When bootstrapping OGM programmatically, it would be useful if there were public constants for specifying the datastore provider via its short name:\n",
            "\n",
            "{code}\n",
            "Map<String, Object> props = new HashMap<String, Object>();\n",
            "props.put( OgmProperties.DATASTORE_PROVIDER, MongoDB.PROVIDER_NAME );\n",
            "Persistence.createEntityManagerFactory( \"myPu\", props );\n",
            "{code}\n",
            "\n",
            "Or even allow to pass in the dialect identifier type:\n",
            "\n",
            "\n",
            "{code}\n",
            "props.put( OgmProperties.DATASTORE_PROVIDER, MongoDB.class );\n",
            "{code}, Similarity: 0.4063\n",
            "Summary & Description: cache jpqlhql query plans \n",
            " (From the road map)\n",
            "\n",
            "Look at Hibernate ORM’s HQLQueryPlan which essentially caches results of a query translator which in term calls the entity loader. A similar design or even interface result is probably possible, Similarity: 0.2945\n",
            "Summary & Description: move proper ogmloader implementations \n",
            " (From the road map)\n",
            "\n",
            "Discuss how to properly load objects via the OgmLoader approach.\n",
            ", Similarity: 0.4385\n",
            "Summary & Description: verify correctness persistent data formats \n",
            " Before going final, we should check for all our dialects that the mappings of the different JPA constructs are sensible and correct., Similarity: 0.2389\n",
            "Summary & Description: embeddable stored separate nodes neo4j \n",
            " The following example:\n",
            "{code:java}\n",
            "@Entity\n",
            "class Account {\n",
            "        @Id\n",
            "\tString login;\n",
            "\tAddress homeAddress;\n",
            "}\n",
            "\n",
            "@Embeddable\n",
            "class Address {\n",
            "\tString street;\n",
            "\tString city;\n",
            "}\n",
            "{code}\n",
            "\n",
            "currently is mapped like:\n",
            "\n",
            "{code}\n",
            "(n:Account:ENTITY {login: '..', homeAddress.street1: '...', homeAddress.city: '...'})\n",
            "{code}\n",
            "\n",
            "but it could be:\n",
            "\n",
            "{code}\n",
            "(n:Account:ENTITY {login: '..'} -[:homeAddress] -> (:Address:EMBEDDABLE{street1: '...', city: '...'})\n",
            "{code}\n",
            ", Similarity: 0.2541\n",
            "Summary & Description: add support count function jpql mongodb \n",
            " From the [forum|https://forum.hibernate.org/viewtopic.php?f=31&t=1033703]:\n",
            "\n",
            "{quote}\n",
            "{code}\n",
            "@NamedQuery(name = \"blog_entry_count\", query = \"select count(be) from BlogEntry be\")\n",
            "{code}\n",
            "\n",
            "When the blog_entry_count query is exequted, the result is of BlogEntry type. I would expect it to be a number in this case. Does ogm supports aggregate functions and count() in particular in HQL?\n",
            "{quote}, Similarity: 0.3695\n",
            "Summary & Description: verify correctness griddialect central spi contracts \n",
            " * There are some methods marked as experimental. Are they proven ok by now?\n",
            "* {{executeBackendQuery()}} expects an array of entity key metadata. Is this correct for projections? (/)\n",
            "* Should we provide abstract base classes to derive from so to allow for the addition of methods where a reasonable default behavior exists in a compatible manner (not sure whether there are such cases)? (/)\n",
            "* Should we generally hide types from ORM in OGM contracts? Specifically, should we pass query parameters to {{executeBackendQuery()}} via something else than {{org.hibernate.engine.spi.QueryParameters}}? I think we should as it exposes some SQL specifics not matching for our case.\n",
            "* Is {{GridDialect#createTupleAssociation()}} really needed? It is implemented with a simple {{return new Tuple()}} in all but one cases (Neo4j). For Neo4j we could move the concerned logic to {{createAssociation()}}/{{updateAssociation()}} so that we could get rid of this method. (/)\n",
            "* Should {{GridDialect}} require a constructor with the datastore provider type or should there be a more generic solution (see discussion in {{GridDialectInitiator}})., Similarity: 0.2590\n",
            "Summary & Description: dont set session factory test skipped current dialect \n",
            " Using the {{@SkipByGridDialect}} annotation one can avoid execution of specific tests on given dialects. We'll still set up a session factory, though. This should not be done if a test is skipped completely on a given dialect, as already setting up the factory may be the reason for wishing to skip the test., Similarity: 0.1792\n",
            "Summary & Description: add support objectid mongodb \n",
            " MongoDB by default uses a 12-byte BSON type with a [special structure|http://docs.mongodb.org/manual/reference/object-id/] as document ids:\n",
            "\n",
            "{code}\n",
            "{\n",
            "    \"_id\" : ObjectId(\"537cc8f50fe960c16c350237\"), \n",
            "    \"name\" : \"foo\"\n",
            "}\n",
            "{code}\n",
            "\n",
            "This id is assigned during insert by the driver and comprises parts for timestamp, machine etc. We should support this as a) it is the \"natural\" way to represent ids in MongoDB and b) in order to facilitate integration with other applications relying on document ids being object ids.\n",
            "\n",
            "It should be possible to represent such id in entities as {{String}}, {{ObjectId}} and probably -{{Long}}- {{BigInteger}}., Similarity: 0.3985\n",
            "Summary & Description: allow users plug custom grid types \n",
            " It should be possible for a user to plug in custom grid types so they can store attributes of such types in their NoSQL store., Similarity: 0.2239\n",
            "Summary & Description: provide powerful syntax native mongodb queries \n",
            " Currently only find queries addressing a complete entity can expressed via native queries for MongoDB. One can not express projections nor insert or other update queries. As there is no canonical string-based query language in MongoDB, one way of achieving this is to allow for queries to be given as invocations of (a subset of) the MongoDB JavaScript API:\n",
            "\n",
            "{code}\n",
            "db.Order.find({name : \"lunar vehicle\"})\n",
            "db.Order.find({name : \"lunar vehicle\"}, { name : 1, price : 1})\n",
            "db.Order.insert({name : \"lunar vehicle\", price : 300})\n",
            "{code}\n",
            "\n",
            "A very simple sub-set of what's actually possible with the API would suffice, as most things can be expressed either as API call (e.g. sort()) or via special fields in the query object (e.g. \"$orderby\"). So we can start simple and evolve from there.\n",
            ", Similarity: 0.3017\n",
            "Summary & Description: cache reuse queries crud operations neo4j \n",
            " Where feasible, we should use parameterized queries for the CRUD operations in Neo4j and re-use them., Similarity: 0.2157\n",
            "Summary & Description: add support executing native update queries \n",
            " -When trying to execute a native update, we currently still run into an execution path from ORM and subsequently fail as the native NoSQL query can not be parsed by the ORM native query parsing routine.-\n",
            "\n",
            "We raise an {{UnsupportedOperationException}} in this case now., Similarity: 0.2469\n",
            "Summary & Description: integrate sort operator neo4j query parser backend \n",
            " {{ORDER BY}} clauses in JP-QL queries should be translated into the corresponding Cypher construct., Similarity: 0.2430\n",
            "Summary & Description: reconsider native queries expressed mongodb \n",
            " Currently native queries for MongoDB are expressed like this:\n",
            "\n",
            "{code}\n",
            "String nativeQuery = \"{ $and: [ { name : 'Portia' }, { author : 'Oscar Wilde' } ] }\";\n",
            "Query query = em.createNativeQuery( nativeQuery, OscarWildePoem.class );\n",
            "{code}\n",
            "\n",
            "While this works for basic cases, there are some limitations:\n",
            "\n",
            "* projections can't be expressed\n",
            "* offset/limit can't be expressed\n",
            "\n",
            "(The reason being that MongoDB has no \"full\" query language which would accept all required elements in one String, instead the different parts are to be passed as individual parameters to the driver API).\n",
            "\n",
            "This could be avoided by accepting an \"invocation\" of MongoDB's JS find() API:\n",
            "\n",
            "{code}\n",
            "String nativeQuery = \"db.Poem.find(\"\n",
            "    + \"{ $and: [ { name : 'Portia' }, { author : 'Oscar Wilde' } ] },\" //WHERE\n",
            "    + \"{_id : 1, name : 1}).\" // SELECT / projection\n",
            "    + \"skip(100).limit(100)\";\n",
            "{code}\n",
            "\n",
            "This would allow to retrieve the collection name from the actual query (today we derive it from the one and only entity result type set, which I believe gets semantics kind of backwards).\n",
            "\n",
            "Scalar values could be mapped via {{SqlResultSetMapping}}/{{ColumnResult}}., Similarity: 0.2985\n",
            "Summary & Description: deployment application using ogm orm fails eap 6 \n",
            " When deploying an application which uses data sources - one using a relational database via Hibernate ORM, and another one using a NoSQL datastore via Hibernate OGM - onto JBoss EAP 6, the following exception is raised:\n",
            "\n",
            "{quote}\n",
            "ERROR [org.jboss.msc.service.fail] (ServerService Thread Pool -- 49) MSC000001: Failed to start service jboss.persistenceunit.\"build-tracker.ear#relationdbPU\": org.jboss.msc.service.StartException in service jboss.persistenceunit.\"build-tracker.ear#relationdbPU\": java.util.ServiceConfigurationError: org.hibernate.integrator.spi.Integrator: Provider org.hibernate.search.hcore.impl.HibernateSearchIntegrator not a subtype\n",
            "\tat org.jboss.as.jpa.service.PersistenceUnitServiceImpl$1.run(PersistenceUnitServiceImpl.java:103) [jboss-as-jpa-7.3.0.Final-redhat-14.jar:7.3.0.Final-redhat-14]\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [rt.jar:1.7.0_45]\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [rt.jar:1.7.0_45]\n",
            "\tat java.lang.Thread.run(Thread.java:744) [rt.jar:1.7.0_45]\n",
            "\tat org.jboss.threads.JBossThread.run(JBossThread.java:122) [jboss-threads-2.1.1.Final-redhat-1.jar:2.1.1.Final-redhat-1]\n",
            "Caused by: java.util.ServiceConfigurationError: org.hibernate.integrator.spi.Integrator: Provider org.hibernate.search.hcore.impl.HibernateSearchIntegrator not a subtype\n",
            "\tat java.util.ServiceLoader.fail(ServiceLoader.java:231) [rt.jar:1.7.0_45]\n",
            "\tat java.util.ServiceLoader.access$300(ServiceLoader.java:181) [rt.jar:1.7.0_45]\n",
            "\tat java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:369) [rt.jar:1.7.0_45]\n",
            "\tat java.util.ServiceLoader$1.next(ServiceLoader.java:445) [rt.jar:1.7.0_45]\n",
            "\tat org.hibernate.service.classloading.internal.ClassLoaderServiceImpl.loadJavaServices(ClassLoaderServiceImpl.java:247)\n",
            "\tat org.hibernate.integrator.internal.IntegratorServiceImpl.<init>(IntegratorServiceImpl.java:53)\n",
            "\tat org.hibernate.service.BootstrapServiceRegistryBuilder.build(BootstrapServiceRegistryBuilder.java:158)\n",
            "\tat org.hibernate.ejb.Ejb3Configuration.buildLifecycleControledServiceRegistry(Ejb3Configuration.java:934)\n",
            "\tat org.hibernate.ejb.Ejb3Configuration.buildEntityManagerFactory(Ejb3Configuration.java:913)\n",
            "\tat org.hibernate.ejb.Ejb3Configuration.buildEntityManagerFactory(Ejb3Configuration.java:899)\n",
            "\tat org.hibernate.ejb.HibernatePersistence.createContainerEntityManagerFactory(HibernatePersistence.java:76)\n",
            "\tat org.jboss.as.jpa.service.PersistenceUnitServiceImpl.createContainerEntityManagerFactory(PersistenceUnitServiceImpl.java:200) [jboss-as-jpa-7.3.0.Final-redhat-14.jar:7.3.0.Final-redhat-14]\n",
            "\tat org.jboss.as.jpa.service.PersistenceUnitServiceImpl.access$600(PersistenceUnitServiceImpl.java:57) [jboss-as-jpa-7.3.0.Final-redhat-14.jar:7.3.0.Final-redhat-14]\n",
            "\tat org.jboss.as.jpa.service.PersistenceUnitServiceImpl$1.run(PersistenceUnitServiceImpl.java:99) [jboss-as-jpa-7.3.0.Final-redhat-14.jar:7.3.0.Final-redhat-14]\n",
            "\t... 4 more\n",
            "\n",
            "12:31:40,577 ERROR [org.jboss.as.server] (management-handler-thread - 11) JBAS015870: Deploy of deployment \"build-tracker.ear\" was rolled back with the following failure message:\n",
            "{\"JBAS014671: Failed services\" => {\"jboss.persistenceunit.\\\"build-tracker.ear#relationdbPU\\\"\" => \"org.jboss.msc.service.StartException in service jboss.persistenceunit.\\\"build-tracker.ear#relationdbPU\\\": java.util.ServiceConfigurationError: org.hibernate.integrator.spi.Integrator: Provider org.hibernate.search.hcore.impl.HibernateSearchIntegrator not a subtype\n",
            "    Caused by: java.util.ServiceConfigurationError: org.hibernate.integrator.spi.Integrator: Provider org.hibernate.search.hcore.impl.HibernateSearchIntegrator not a subtype\"}}\n",
            "{quote}\n",
            "\n",
            "I think this is due to two versions of Hibernate ORM being present here (4.1 as regular part of the application server and 4.3 which is brought in via the module ZIP from Hibernate OGM)., Similarity: 0.4146\n",
            "Summary & Description: support deployment osgi containers \n",
            " Would be nice to have some intergration tests with Apache Karaf; will probably need fixes in ORM too.\n",
            "Good to think about earlier rather than later as OSGi requires a specific package organization., Similarity: 0.3681\n",
            "Summary & Description: update ordered embedded collection element causes insert mongodb \n",
            " When performing an update to an existing element of an embedded collection in MongoDB, a new element is appended to the collection instead of updating the existing one., Similarity: 0.3398\n",
            "Summary & Description: update mavenreleaseplugin configuration \n",
            " The following parameters make the release simpler:\n",
            "\n",
            "{code:xml}\n",
            "<releaseProfiles>distro</releaseProfiles>\n",
            "{code}\n",
            "Select the right profile for the release \n",
            "\n",
            "{code:xml}                                                                                                                                           \n",
            "<arguments>-DskipTests</arguments>\n",
            "{code}\n",
            "Skip the tests (the builg should have benn already tested)\n",
            "\n",
            "{code:xml}                                                                                                                                                   \n",
            "<pushChanges>false</pushChanges>\n",
            "{code}\n",
            "The maven lugin won't push changes on the remote repository\n",
            "\n",
            "{code:xml}                                                                                                                                                    \n",
            "<localCheckout>true</localCheckout>\n",
            "{code}\n",
            "Use the local tag to perform the release \n",
            "\n",
            "{code:xml}                                                                                                                         \n",
            "<tagNameFormat>@{project.version}</tagNameFormat>\n",
            "{code} \n",
            "The name of the branch containing the new tag \n",
            "\n",
            "We aslo have to remove the following from the pom:\n",
            "{code:xml}\n",
            "                <configuration>                                                                                                                                                                                   \n",
            "                    <goals>assembly:assembly</goals>                                                                                                                                                       \n",
            "                </configuration>  \n",
            "{code}\n",
            "This causes an error performing the release since the assembly distribution file has been moved under the distribution folder, Similarity: 0.4382\n",
            "Summary & Description: documentation contain link datastores configuration \n",
            " When I run the build the documentation is missing the datastores configuration.\n",
            "\n",
            "The problem seems to be in datastore-providers.asciidoc, it works if I change\n",
            "{code}\n",
            "include::modules/infinispan.asciidoc[]\n",
            "{code}\n",
            "with\n",
            "{code}\n",
            "include::infinispan.asciidoc[]\n",
            "{code}\n",
            "\n",
            ", Similarity: 0.4821\n",
            "Summary & Description: followup todos jboss eap 6 module zip \n",
            " * -Use modules provided by RestEasy project instead of creating our owns-\n",
            "* Don't overwrite modules during integration test when running on an external JBoss EAP installation\n",
            "* Make EAP module usable on JBoss AS 7 and adapt wording in docs etc. accordingly (may be the doc changes only actually), Similarity: 0.4859\n",
            "Summary & Description: ogm doesnt work secured mongodb \n",
            " Hibernate OGM doesn't work when you use secured database, i.e. you provide username and password.\n",
            "\n",
            "# create a secured MongoDB database named \"ogm_test_database\", you can use e.g. mongolab.com\n",
            "# git clone https://github.com/ppitonak/hibernate-ogm.git\n",
            "# cd hibernate-ogm\n",
            "# git checkout secured_mongodb\n",
            "# export MONGODB_HOSTNAME=ds045027.mongolab.com\n",
            "# export MONGODB_PORT=45027\n",
            "# export MONGODB_USERNAME=someUsername\n",
            "# export MONGODB_PASSWORD=someP@ssw0rd\n",
            "# mvn clean install -s settings-example.xml -DuseExternalMongoDb -f integrationtest/pom.xml\n",
            "\n",
            "result: \n",
            "* failed test, connecting to database using Mongo shell works fine\n",
            "{quote}\n",
            "Caused by: java.lang.Exception: {\"JBAS014671: Failed services\" => {\"jboss.persistenceunit.\\\"MongoDBModuleMemberRegistrationIT.war#primary\\\"\" => \"org.jboss.msc.service.StartException in service jboss.persistenceunit.\\\"MongoDBModuleMemberRegistrationIT.war#primary\\\": javax.persistence.PersistenceException: \\[PersistenceUnit: primary] Unable to build Hibernate SessionFactory\n",
            "    Caused by: javax.persistence.PersistenceException: \\[PersistenceUnit: primary] Unable to build Hibernate SessionFactory\n",
            "    Caused by: org.hibernate.MappingException: Could not get constructor for org.hibernate.ogm.persister.SingleTableOgmEntityPersister\n",
            "    Caused by: org.hibernate.service.spi.ServiceException: Unable to create requested service \\[org.hibernate.ogm.dialect.GridDialect]\n",
            "    *Caused by: org.hibernate.HibernateException: OGM001213: MongoDB authentication failed with username \\[myUser]\"*}}\n",
            "        at org.jboss.as.controller.client.helpers.standalone.impl.ServerDeploymentPlanResultFuture.getActionResult(ServerDeploymentPlanResultFuture.java:134)\n",
            "        at org.jboss.as.controller.client.helpers.standalone.impl.ServerDeploymentPlanResultFuture.getResultFromNode(ServerDeploymentPlanResultFuture.java:123)\n",
            "        at org.jboss.as.controller.client.helpers.standalone.impl.ServerDeploymentPlanResultFuture.get(ServerDeploymentPlanResultFuture.java:85)\n",
            "        at org.jboss.as.controller.client.helpers.standalone.impl.ServerDeploymentPlanResultFuture.get(ServerDeploymentPlanResultFuture.java:42)\n",
            "        at org.jboss.as.controller.client.helpers.standalone.ServerDeploymentHelper.deploy(ServerDeploymentHelper.java:55)\n",
            "        at org.jboss.as.arquillian.container.ArchiveDeployer.deployInternal(ArchiveDeployer.java:77)\n",
            "        ... 96 more\n",
            "{quote}, Similarity: 0.3904\n",
            "Summary & Description: exception using mongodb queries containermanaged transaction \n",
            " When using a query with the MongoDB based parser backend, I'm getting the following exception upon the commit of the container-managed transaction:\n",
            "\n",
            "{code}\n",
            "Caused by: org.hibernate.HibernateException: Illegal attempt to associate a collection with two open sessions: [org.hibernate.ogm.hiking.model.Hike.sections#1]\n",
            "\tat org.hibernate.collection.internal.AbstractPersistentCollection.setCurrentSession(AbstractPersistentCollection.java:635) [hibernate-core-4.3.1.Final.jar:4.3.1.Final]\n",
            "\tat org.hibernate.event.internal.WrapVisitor.processCollection(WrapVisitor.java:66) [hibernate-core-4.3.1.Final.jar:4.3.1.Final]\n",
            "\tat org.hibernate.event.internal.AbstractVisitor.processValue(AbstractVisitor.java:121) [hibernate-core-4.3.1.Final.jar:4.3.1.Final]\n",
            "\tat org.hibernate.event.internal.WrapVisitor.processValue(WrapVisitor.java:125) [hibernate-core-4.3.1.Final.jar:4.3.1.Final]\n",
            "\tat org.hibernate.event.internal.AbstractVisitor.processEntityPropertyValues(AbstractVisitor.java:76) [hibernate-core-4.3.1.Final.jar:4.3.1.Final]\n",
            "\tat org.hibernate.event.internal.DefaultFlushEntityEventListener.wrapCollections(DefaultFlushEntityEventListener.java:220) [hibernate-core-4.3.1.Final.jar:4.3.1.Final]\n",
            "\tat org.hibernate.event.internal.DefaultFlushEntityEventListener.onFlushEntity(DefaultFlushEntityEventListener.java:157) [hibernate-core-4.3.1.Final.jar:4.3.1.Final]\n",
            "\tat org.hibernate.event.internal.AbstractFlushingEventListener.flushEntities(AbstractFlushingEventListener.java:231) [hibernate-core-4.3.1.Final.jar:4.3.1.Final]\n",
            "\tat org.hibernate.event.internal.AbstractFlushingEventListener.flushEverythingToExecutions(AbstractFlushingEventListener.java:102) [hibernate-core-4.3.1.Final.jar:4.3.1.Final]\n",
            "\tat org.hibernate.event.internal.DefaultFlushEventListener.onFlush(DefaultFlushEventListener.java:55) [hibernate-core-4.3.1.Final.jar:4.3.1.Final]\n",
            "\tat org.hibernate.ogm.service.impl.FlushBatchManagerEventListener.delegate(FlushBatchManagerEventListener.java:48) [hibernate-ogm-core-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]\n",
            "\tat org.hibernate.ogm.service.impl.FlushBatchManagerEventListener.delegate(FlushBatchManagerEventListener.java:35) [hibernate-ogm-core-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]\n",
            "\tat org.hibernate.ogm.service.impl.BatchManagerEventListener.onEvent(BatchManagerEventListener.java:55) [hibernate-ogm-core-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]\n",
            "\tat org.hibernate.ogm.service.impl.FlushBatchManagerEventListener.onFlush(FlushBatchManagerEventListener.java:43) [hibernate-ogm-core-4.1.0-SNAPSHOT.jar:4.1.0-SNAPSHOT]\n",
            "\tat org.hibernate.internal.SessionImpl.flush(SessionImpl.java:1218) [hibernate-core-4.3.1.Final.jar:4.3.1.Final]\n",
            "\tat org.hibernate.internal.SessionImpl.managedFlush(SessionImpl.java:421) [hibernate-core-4.3.1.Final.jar:4.3.1.Final]\n",
            "\tat org.hibernate.engine.transaction.synchronization.internal.SynchronizationCallbackCoordinatorNonTrackingImpl.beforeCompletion(SynchronizationCallbackCoordinatorNonTrackingImpl.java:110) [hibernate-core-4.3.1.Final.jar:4.3.1.Final]\n",
            "{code}\n",
            "\n",
            "I believe the reason is that we pass the {{OgmSession}} instead of the underlying {{SessionImpl}} into {{OgmLoader}} from within {{MongoDBQueryImpl$ObjectLoadingIterator#getAsManagedEntity()}}. The exception then is caused by comparing the {{OgmSession}} and {{SessionImpl}} in {{AbstractPersistentCollection#setCurrentSession()}}., Similarity: 0.3907\n",
            "Summary & Description: application using mongodb deployable also datastore isnt available \n",
            " When deploying an application using OGM with MongoDB onto WildFly, deployment fails in case the MongoDB server isn't started. Retrieval of the database in {{MongoDBDatastoreProvider}} should be done lazily to avoid this. This requires proper protection of the members as the provider is accessed concurrently., Similarity: 0.4942\n",
            "Summary & Description: update jpa collection annotated ordercolumn \n",
            " Hello,\n",
            "\n",
            "It seems that we can't update a collection when \"OrderColumn\" is used.\n",
            "\n",
            "{code:title=Order.java|borderStyle=solid}\n",
            "@Entity\n",
            "public class Order {\n",
            "...\n",
            "    @ElementCollection\n",
            "    @OrderColumn\n",
            "    public List<Product> getProducts() {\n",
            "        return products;\n",
            "    }\n",
            "...\n",
            "{code}\n",
            "\n",
            "{code:title=Product.java|borderStyle=solid}\n",
            "@Embeddable\n",
            "public class Product {\n",
            "...\n",
            "}\n",
            "{code}\n",
            "\n",
            "There is a test case attached.\n",
            "\n",
            "Regards,\n",
            "\n",
            "Arnaud, Similarity: 0.3303\n",
            "Summary & Description: column name given field honored \n",
            " When specifying a column name via {{@Column}} on the field level, it is not honored (unlike when the name is given on the property getter). Not sure whether that's an issue with ORM or OGM., Similarity: 0.1086\n",
            "Summary & Description: list read fails jpa ordercolumn used \n",
            " Hello,\n",
            "\n",
            "It seems that Lists are not correctly populated from Mongo when using @OrderColumn on collections; all elements are null:\n",
            "\n",
            "{code:title=Order.java|borderStyle=solid}\n",
            "@Entity\n",
            "public class Order {\n",
            "...\n",
            "  @ElementCollection\n",
            "  @OrderColumn\n",
            "  public List<Product> getProducts() { // ordered List (not a \"Bag\")\n",
            "        return products;\n",
            "  }\n",
            "...\n",
            "}\n",
            "{code}\n",
            "\n",
            "{code:title=Product.java|borderStyle=solid}\n",
            "@Embeddable\n",
            "public class Product {\n",
            "...\n",
            "}\n",
            "{code}\n",
            "\n",
            "Everything is OK without \"@OrderColumn\" though.\n",
            "You'll find a test case in attachment.\n",
            "\n",
            "Regards,\n",
            "\n",
            "Arnaud, Similarity: 0.3326\n",
            "Summary & Description: remove trigger access datastore log messages griddialectlogger class \n",
            " The comment is misleading since the dialect can actually access to the datastore, Similarity: 0.3049\n",
            "Summary & Description: add documentation textual representation elements saved neo4j \n",
            " Using the cypher syntax we can show how nodes, relationships and the links between them are stored in the DB., Similarity: 0.3747\n",
            "Summary & Description: verify validity datastore creation wiki page content delete unfixable \n",
            " Check that the content of https://community.jboss.org/wiki/HowToWriteADatastoreInHibernateOGM is good enough, fix it if needed. Or delete entirely if unrecoverable., Similarity: 0.4291\n",
            "Summary & Description: provide module jboss eap \n",
            " There should be a module distribution which allows to use the latest OGM release on JBoss EAP. This needs to update the ORM version as OGM requires ORM 4.3., Similarity: 0.4278\n",
            "Summary & Description: use concise format representing element collections basic types \n",
            " Instead of\n",
            "\n",
            "{code}\n",
            "{\n",
            "    \"_id\": \"17457a47-abfc-4fb7-955e-17acb0b49808\", \n",
            "    \"nicknames\": [\n",
            "        { \"nicknames\": \"idrA\" }, \n",
            "        { \"nicknames\": \"day[9]\" }\n",
            "    ]\n",
            "}\n",
            "{code}\n",
            "\n",
            "it would be nice to use the following persistent representation for an {{@ElementCollection}} of a basic type:\n",
            "\n",
            "{code}\n",
            "{\n",
            "    \"_id\": \"17457a47-abfc-4fb7-955e-17acb0b49808\", \n",
            "    \"nicknames\": [\n",
            "        \"idrA\", \n",
            "        \"day[9]\"\n",
            "    ]\n",
            "}\n",
            "{code}\n",
            "\n",
            "I'm not sure whether this relates to the MongoDB backend only or is an issue on the engine side., Similarity: 0.1742\n",
            "Summary & Description: support parameters native queries store supports \n",
            " Expose query parameters for native queries where supported by the datastore. Currently this is the case for Neo4j. We settled on using the native parameter syntax. If a datastore doesn't natively support query parameters, we're not going to emulate them for the time being., Similarity: 0.3223\n",
            "Summary & Description: wrong property used configuration neo4j tests \n",
            " In neo4j/src/test/hibernate.properties, we have\n",
            "\n",
            "{code}\n",
            "hibernate.ogm.neo4j.database.path\n",
            "{code}\n",
            "\n",
            "instead of\n",
            "\n",
            "{code}\n",
            "hibernate.ogm.neo4j.database_path\n",
            "{code}\n",
            "\n",
            "This cause the creation of the folder neo4j/null\n",
            ", Similarity: 0.3558\n",
            "Summary & Description: use hibernate search 5 \n",
            " Once Hibernate Search 5 is available in a stable version, we should update to it. This also requires the parser to be updated to 1.0.0.Alpha7. We should re-use the modules created with HSEARCH-1505.\n",
            "\n",
            "Some notes:\n",
            "\n",
            "* Neo4j depends on Lucene 3 via the \"legacy indexing\" mechanism; This probably can be replaced though by this: https://github.com/apatry/neo4j-lucene4-index, Similarity: 0.3175\n",
            "Summary & Description: avoid creation associations prior removal \n",
            " When trying to remove an association we temporarily create it in case it doesn't exist by invoking {{AssociationPersister#getAssociation()}}. This can be avoided by using {{getAssociationOrNull()}} instead., Similarity: 0.1931\n",
            "Summary & Description: fetch embedded associations getting hosting tuple mongodb \n",
            " When using the embedded mode for storing association information we can achieve a higher performance by reading the association information when getting the tuple embedding the association instead of doing another roundtrip to the database., Similarity: 0.4018\n",
            "Summary & Description: verify testsuite leak connections mongodb \n",
            " \n",
            "Gauillaume noticed these messages at  the end of the MongoDB tests:\n",
            "{quote}*WARNING: sendShutdown /127.0.0.1:27018 <http://127.0.0.1:27018>*\n",
            "*java.net.SocketException: Connection reset*{quote}\n",
            "\n",
            "We would need to at least verify if this is a test issue or a potential leak of our implementation., Similarity: 0.4201\n",
            "Summary & Description: perform mongodb collection updates single db call \n",
            " In {{MongoDBDialect#updateAssociation()}} we can achieve a better performance by writing all row updates to the store in a single {{update()}} call (see {{$each}}/{{$pushAll}}/{{$pullAll}})., Similarity: 0.3163\n",
            "Summary & Description: provide api retrieving log executedfailed operations transaction cycle \n",
            " When working with a non-transactional stores, there should be a way to find out about the executed and failed grid dialect operations of a transaction cycle. This allows to take appropriate action such as performing compensating operations, re-try the failed operations etc.\n",
            "\n",
            "Use cases:\n",
            "\n",
            "As a user of OGM, upon an exception during flush(),\n",
            "\n",
            "* UC-1.1: I want to *log* all operations applied so far and *abort* the processing of the flush cycle (/)\n",
            "    Example: Create a file with applied changes, and let someone manually take the required actions\n",
            "\n",
            "* UC-2.1: I want to *skip* the failed operation for certain exception types and *continue* further processing of the flush cycle (/)\n",
            "    Example: Ignore a duplicted record during importing a list of orders\n",
            "\n",
            "* UC-2.1.1: I want to skip the failed operation for certain exception types and entity types and continue further processing of the flush cycle (/)\n",
            "    Example: Ignore a duplicated order record but not a duplicated customer record, Similarity: 0.2616\n",
            "Summary & Description: remove threadlocal batchoperationsdelegator \n",
            " We batch the operations using an {{OperationsQueue}} that it is store in a {{ThreadLocal}} variable in {{BatchOperationsDelegator}}.\n",
            "\n",
            "We could remove the {{ThreadLocal}} variable and create the queue in the {{Session}}, Similarity: 0.3245\n",
            "Summary & Description: automate release process \n",
            " Releasing a new version of Hibernate OGM should be a quick and simple procedure, automated as far as feasible., Similarity: 0.2379\n",
            "Summary & Description: retrieve property changes without reread updates possible \n",
            " The CouchDB dialect makes use of the support for properties changed on the server side. The main use case for this is to re-read the revision property after updates and inserts.\n",
            "\n",
            "This case can be optimized by propagating the value which CouchDB returns from the write instead doing another read. Note that this will require an update to the {{GridDialect}} contract., Similarity: 0.1847\n",
            "Summary & Description: make infinispan store table dedicated cache \n",
            " Should we propose that option?\n",
            "Should it be the default?\n",
            "\n",
            "CC [~accountid:557058:99e61e65-956b-4a21-b29c-06057642e9ea], Similarity: 0.3107\n",
            "Summary & Description: perform insert entity embedded associations one operation mongodb \n",
            " Using the new batching mechanism it should be possible to insert (and update) MongoDB documents which contain in-entity associations in one go instead of first inserting the entity and then updating the document to insert the association rows as it's done atm., Similarity: 0.3719\n",
            "Summary & Description: verify efficient datastore roundtrips \n",
            " Make sure one more time that we don't do exceedingly stupid roundtrips for simple domain models with or without @EmebddableElement\n",
            "\n",
            "Then estimate the number of roundtrips on association loads.\n",
            "\n",
            "the next step will be denormalization and use of denormalized data but will ahve to come after the initial Final, Similarity: 0.3222\n",
            "Summary & Description: use wildfly 800final integration tests module baseline \n",
            " * Update version used in tests\n",
            "* Update docs (section 4.5)\n",
            "* Update module definitions, Similarity: 0.3497\n",
            "Summary & Description: ensure startstoppable implementations get passed completely set session factory \n",
            " Currently, {{StartStoppable}} implementations are invoked at a point of time at which the passed session factory is not yet completely set up (the call indirectly originates from the session factory constructor). Thus one can't access entity persisters from the factory etc.\n",
            "\n",
            "The contract would be more useful if implementations were invoked at a later time, where the factory is already completely set up. This could be realized using a a custom session factory observer (which itself is invoked when the factory bootstrap is complete) which gets all services from the factory that implement {{StartStoppable}} and invokes their start method., Similarity: 0.2163\n",
            "Summary & Description: align name access semantics properties representing external configuration files \n",
            " * {{EhcacheProperties.RESOURCE_NAME}} vs. {{InfinspanProperties.CONFIGURATION_RESOURCENAME}} vs. {{Neo4jProperties.CONFIGURATION_LOCATION}}\n",
            "* It's not consistent how the property is to be specified, as URL, String representing an a resource on the class path or absolute file path, Similarity: 0.3814\n",
            "Summary & Description: updates operations ehcache dialect applied memory \n",
            " The operations {{EhcacheDialect#updateTuple()}} and {{updateAssociation()}} propagate changes only to the in-memory map based representation of elements but don't update the actual cache entries.\n",
            "\n",
            "This works as long as records are read back from the heap (as they retain a reference to the originally modified map) but records which are read back from persistent storage represent the pre-update state., Similarity: 0.1630\n",
            "Summary & Description: remove unused naming strategy setting ogmintegrator \n",
            " This setting has no effect., Similarity: 0.2042\n",
            "Summary & Description: allow using ispn cache entities associations identifiers \n",
            " From Sanne:\n",
            "\n",
            "{quote}\n",
            "we should have at least one test using the same cache instance. I think we're using 3 to make the \"counting\" and various other assertions easier on us.\n",
            "{quote}, Similarity: 0.1931\n",
            "Summary & Description: use storeassigned ids generationtype identity mongodb \n",
            " For ids with generation type IDENTITY the capabilities of a store to assign ids \"inline\" when inserting records should be used (e.g. in MongoDB and CouchDB).\n",
            "\n",
            "If a store doesn't support this strategy in a meaningful way, an exception should be raised.\n",
            "\n",
            "ML discussion: http://lists.jboss.org/pipermail/hibernate-dev/2014-January/010826.html, Similarity: 0.2934\n",
            "Summary & Description: make key objects serializable \n",
            " To not be restricted by a persistent representation of the key types {{EntityKey}}, {{AssociationKey}} etc. these types themselves should not be {{Serializable}}, at least for the time being. Only Ehcache makes use of this right now. It should use its own serializable type instead., Similarity: 0.1654\n",
            "Summary & Description: never store elementcollection members association documents \n",
            " The document store backends should store the contents of {{@ElementCollection}} members always within the entity document, not taking the association storage setting into account.\n",
            "\n",
            "This has been the case for the MongoDB backend before, but has unintentionally been changed with [89030a2e|https://github.com/hibernate/hibernate-ogm/commit/89030a2e5c8d92cb5a46da680fd9834620224b0e]., Similarity: 0.3204\n",
            "Summary & Description: go version 41 move jpa 21 \n",
            " To clarify things, I'd like us to move OGM to 4.1 since we moved to JPA 2.1 ORM 4.3 support. It will be easier to explain things., Similarity: 0.2824\n",
            "Summary & Description: investigate means tying global options corresponding property closely together \n",
            " It'd be nice to have a way for making the relationship between a global option configured via the new option system and the corresponding property more obvious., Similarity: 0.2177\n",
            "Summary & Description: provide way marking test dialect dependent \n",
            " Some tests in _core_ don't depend on dialect specifics and thus don't need to be executed again and again for each dialect module.\n",
            "\n",
            "There should be a way to mark such tests so they are run only once as part of the _core_ module build but not again for each dialect., Similarity: 0.1883\n",
            "Summary & Description: queries dont return entries inserted current session \n",
            " As it seems, the query execution code path in OGM never triggers an auto-flush, thus entries inserted in the current session are not returned by queries. OTOH an auto-flush upon query execution may be unwanted at least for non-transactional stores, so maybe that's more a documentation issue., Similarity: 0.2379\n",
            "Summary & Description: adapt checkstyle rules allow imports used javadoc \n",
            " The readability of JavaDocs severely suffers when enforcing fully-qualified names for types not used in the actual source code. CheckStyle can be adapted to not raise an error if it detects such an \"unused\" import.\n",
            "\n",
            "We couldn't reach agreement on this in the whole team, but I'd still love to enable this at least for OGM. The referenced types are present at runtime in the very most - if not all - cases and even if they were not, imports per se are not reflected in class files (only the actual usage of types is baked into method signatures etc.), so I don't think there is any negative consequence to this., Similarity: 0.3776\n",
            "Summary & Description: add read preference option mongodb \n",
            " Users should be able to set the ReadPreference property: http://docs.mongodb.org/manual/core/read-preference/, Similarity: 0.3405\n",
            "Summary & Description: failure executing native query mongodb \n",
            " By executing the following native query to mongodb\n",
            "\n",
            "{code}\n",
            "List<Customer> result = session.createSQLQuery(\"{$and:[{username:'testUser'},{password:'testPwd'}]}\").addEntity(\"Customer\", Customer.class).list();\n",
            "{code}\n",
            "\n",
            "or JPA like\n",
            "\n",
            "{code}\n",
            "Customer c = (Customer) entityManager.createNativeQuery(\"{$and:[{username:'testUser'},{password:'testPwd'}]}\", Customer.class).getSingleResult();\n",
            "{code}\n",
            "\n",
            "I always get the following exception :\n",
            "\n",
            "{code}\n",
            "javax.ejb.EJBException: JBAS014580: Unexpected Error\n",
            "\tat org.jboss.as.ejb3.tx.CMTTxInterceptor.handleExceptionInOurTx(CMTTxInterceptor.java:187)\n",
            "\tat org.jboss.as.ejb3.tx.CMTTxInterceptor.invokeInOurTx(CMTTxInterceptor.java:275)\n",
            "\tat org.jboss.as.ejb3.tx.CMTTxInterceptor.required(CMTTxInterceptor.java:340)\n",
            "\tat org.jboss.as.ejb3.tx.CMTTxInterceptor.processInvocation(CMTTxInterceptor.java:239)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.as.ejb3.component.interceptors.CurrentInvocationContextInterceptor.processInvocation(CurrentInvocationContextInterceptor.java:41)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.as.ejb3.component.invocationmetrics.WaitTimeInterceptor.processInvocation(WaitTimeInterceptor.java:43)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.as.ejb3.security.SecurityContextInterceptor.processInvocation(SecurityContextInterceptor.java:95)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.as.ejb3.component.interceptors.ShutDownInterceptorFactory$1.processInvocation(ShutDownInterceptorFactory.java:64)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.as.ejb3.component.interceptors.LoggingInterceptor.processInvocation(LoggingInterceptor.java:59)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.as.ee.component.NamespaceContextInterceptor.processInvocation(NamespaceContextInterceptor.java:50)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.as.ejb3.component.interceptors.AdditionalSetupInterceptor.processInvocation(AdditionalSetupInterceptor.java:55)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.invocation.ContextClassLoaderInterceptor.processInvocation(ContextClassLoaderInterceptor.java:64)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.invocation.InterceptorContext.run(InterceptorContext.java:325)\n",
            "\tat org.wildfly.security.manager.WildFlySecurityManager.doChecked(WildFlySecurityManager.java:437)\n",
            "\tat org.jboss.invocation.AccessCheckingInterceptor.processInvocation(AccessCheckingInterceptor.java:61)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.invocation.InterceptorContext.run(InterceptorContext.java:325)\n",
            "\tat org.jboss.invocation.PrivilegedWithCombinerInterceptor.processInvocation(PrivilegedWithCombinerInterceptor.java:80)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.invocation.ChainedInterceptor.processInvocation(ChainedInterceptor.java:61)\n",
            "\tat org.jboss.as.ee.component.ViewService$View.invoke(ViewService.java:165)\n",
            "\tat org.jboss.as.ee.component.ViewDescription$1.processInvocation(ViewDescription.java:182)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.invocation.ChainedInterceptor.processInvocation(ChainedInterceptor.java:61)\n",
            "\tat org.jboss.as.ee.component.ProxyInvocationHandler.invoke(ProxyInvocationHandler.java:72)\n",
            "\tat it.telecomitalia.angel.ejb.TestEjb$$$view5.testNativeQuery(Unknown Source)\n",
            "\tat it.telecomitalia.angel.service.AuthenticationService.login(AuthenticationService.java:54)\n",
            "\tat it.telecomitalia.angel.service.AuthenticationService$Proxy$_$$_WeldClientProxy.login(Unknown Source)\n",
            "\tat it.telecomitalia.angel.api.rest.service.AuthenticationService.login(AuthenticationService.java:65)\n",
            "\tat it.telecomitalia.angel.api.rest.service.AuthenticationService$Proxy$_$$_WeldClientProxy.login(Unknown Source)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.lang.reflect.Method.invoke(Method.java:606)\n",
            "\tat org.jboss.resteasy.core.MethodInjectorImpl.invoke(MethodInjectorImpl.java:137)\n",
            "\tat org.jboss.resteasy.core.ResourceMethodInvoker.invokeOnTarget(ResourceMethodInvoker.java:280)\n",
            "\tat org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:234)\n",
            "\tat org.jboss.resteasy.core.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:221)\n",
            "\tat org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:356)\n",
            "\tat org.jboss.resteasy.core.SynchronousDispatcher.invoke(SynchronousDispatcher.java:179)\n",
            "\tat org.jboss.resteasy.plugins.server.servlet.ServletContainerDispatcher.service(ServletContainerDispatcher.java:220)\n",
            "\tat org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:56)\n",
            "\tat org.jboss.resteasy.plugins.server.servlet.HttpServletDispatcher.service(HttpServletDispatcher.java:51)\n",
            "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n",
            "\tat io.undertow.servlet.handlers.ServletHandler.handleRequest(ServletHandler.java:87)\n",
            "\tat io.undertow.servlet.handlers.security.ServletSecurityRoleHandler.handleRequest(ServletSecurityRoleHandler.java:59)\n",
            "\tat io.undertow.servlet.handlers.ServletDispatchingHandler.handleRequest(ServletDispatchingHandler.java:36)\n",
            "\tat org.wildfly.extension.undertow.security.SecurityContextAssociationHandler.handleRequest(SecurityContextAssociationHandler.java:81)\n",
            "\tat io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:25)\n",
            "\tat io.undertow.servlet.handlers.security.SSLInformationAssociationHandler.handleRequest(SSLInformationAssociationHandler.java:113)\n",
            "\tat io.undertow.security.handlers.AuthenticationCallHandler.handleRequest(AuthenticationCallHandler.java:52)\n",
            "\tat io.undertow.security.handlers.AbstractConfidentialityHandler.handleRequest(AbstractConfidentialityHandler.java:45)\n",
            "\tat io.undertow.servlet.handlers.security.CachedAuthenticatedSessionHandler.handleRequest(CachedAuthenticatedSessionHandler.java:65)\n",
            "\tat io.undertow.security.handlers.SecurityInitialHandler.handleRequest(SecurityInitialHandler.java:70)\n",
            "\tat io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:25)\n",
            "\tat io.undertow.server.handlers.PredicateHandler.handleRequest(PredicateHandler.java:25)\n",
            "\tat io.undertow.servlet.handlers.ServletInitialHandler.handleFirstRequest(ServletInitialHandler.java:218)\n",
            "\tat io.undertow.servlet.handlers.ServletInitialHandler.dispatchRequest(ServletInitialHandler.java:205)\n",
            "\tat io.undertow.servlet.handlers.ServletInitialHandler.access$000(ServletInitialHandler.java:69)\n",
            "\tat io.undertow.servlet.handlers.ServletInitialHandler$1.handleRequest(ServletInitialHandler.java:134)\n",
            "\tat io.undertow.server.HttpHandlers.executeRootHandler(HttpHandlers.java:36)\n",
            "\tat io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:619)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n",
            "\tat java.lang.Thread.run(Thread.java:744)\n",
            "Caused by: java.lang.IllegalAccessError: tried to access method org.hibernate.internal.SQLQueryImpl.<init>(Ljava/lang/String;Lorg/hibernate/engine/spi/SessionImplementor;Lorg/hibernate/engine/query/spi/ParameterMetadata;)V from class org.hibernate.internal.NoSQLQuery\n",
            "\tat org.hibernate.internal.NoSQLQuery.<init>(NoSQLQuery.java:39)\n",
            "\tat org.hibernate.ogm.hibernatecore.impl.OgmSession.createSQLQuery(OgmSession.java:179)\n",
            "\tat it.telecomitalia.angel.ejb.TestEjb.testNativeQuery(TestEjb.java:30)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.lang.reflect.Method.invoke(Method.java:606)\n",
            "\tat org.jboss.as.ee.component.ManagedReferenceMethodInterceptorFactory$ManagedReferenceMethodInterceptor.processInvocation(ManagedReferenceMethodInterceptorFactory.java:72)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.as.ee.concurrent.ConcurrentContextInterceptor.processInvocation(ConcurrentContextInterceptor.java:45)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.invocation.WeavedInterceptor.processInvocation(WeavedInterceptor.java:53)\n",
            "\tat org.jboss.as.ee.component.interceptors.UserInterceptorFactory$1.processInvocation(UserInterceptorFactory.java:63)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.invocation.InterceptorContext$Invocation.proceed(InterceptorContext.java:406)\n",
            "\tat org.jboss.as.weld.ejb.Jsr299BindingsInterceptor.doMethodInterception(Jsr299BindingsInterceptor.java:130)\n",
            "\tat org.jboss.as.weld.ejb.Jsr299BindingsInterceptor.processInvocation(Jsr299BindingsInterceptor.java:138)\n",
            "\tat org.jboss.as.ee.component.interceptors.UserInterceptorFactory$1.processInvocation(UserInterceptorFactory.java:63)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.invocation.WeavedInterceptor.processInvocation(WeavedInterceptor.java:53)\n",
            "\tat org.jboss.as.ee.component.interceptors.UserInterceptorFactory$1.processInvocation(UserInterceptorFactory.java:63)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.as.ejb3.component.invocationmetrics.ExecutionTimeInterceptor.processInvocation(ExecutionTimeInterceptor.java:43)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.as.jpa.interceptor.SBInvocationInterceptor.processInvocation(SBInvocationInterceptor.java:47)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.invocation.InterceptorContext$Invocation.proceed(InterceptorContext.java:406)\n",
            "\tat org.jboss.weld.ejb.AbstractEJBRequestScopeActivationInterceptor.aroundInvoke(AbstractEJBRequestScopeActivationInterceptor.java:46)\n",
            "\tat org.jboss.as.weld.ejb.EjbRequestScopeActivationInterceptor.processInvocation(EjbRequestScopeActivationInterceptor.java:84)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.invocation.InitialInterceptor.processInvocation(InitialInterceptor.java:21)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.invocation.ChainedInterceptor.processInvocation(ChainedInterceptor.java:61)\n",
            "\tat org.jboss.as.ee.component.interceptors.ComponentDispatcherInterceptor.processInvocation(ComponentDispatcherInterceptor.java:53)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.as.ejb3.component.pool.PooledInstanceInterceptor.processInvocation(PooledInstanceInterceptor.java:51)\n",
            "\tat org.jboss.invocation.InterceptorContext.proceed(InterceptorContext.java:309)\n",
            "\tat org.jboss.as.ejb3.tx.CMTTxInterceptor.invokeInOurTx(CMTTxInterceptor.java:273)\n",
            "\t... 72 more\n",
            "{code}, Similarity: 0.3440\n",
            "Summary & Description: stackoverflow using ogm orm pu time \n",
            " I'm trying to configure OGM with Infinispan + JPA loader.\n",
            "Here is my persistents.xml :\n",
            "\n",
            "Code:\n",
            "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
            "<persistence xmlns=\"http://java.sun.com/xml/ns/persistence\"\n",
            "             xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n",
            "             xsi:schemaLocation=\"http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_2_0.xsd\"\n",
            "             version=\"2.0\">\n",
            "\n",
            "    <persistence-unit name=\"DB\" transaction-type=\"RESOURCE_LOCAL\">\n",
            "        <provider>org.hibernate.ejb.HibernatePersistence</provider>\n",
            "        <class>db.generated.PackageEntity</class>\n",
            "        <properties  >\n",
            "            <property name=\"javax.persistence.jdbc.driver\" value=\"oracle.jdbc.OracleDriver\" />\n",
            "            <property name=\"javax.persistence.jdbc.url\" value=\"jdbc:oracle:thin:@10.1.5.81:1521:LDS\"/>\n",
            "            <property name=\"javax.persistence.jdbc.user\" value=\"***\" />\n",
            "            <property name=\"javax.persistence.jdbc.password\" value=\"****\" />\n",
            "            <property name=\"hibernate.transaction.jta.platform\" value=\"org.hibernate.service.jta.platform.internal.NoJtaPlatform\"/>\n",
            "        </properties>\n",
            "    </persistence-unit>\n",
            "\n",
            "    <persistence-unit name=\"IMDG\" transaction-type=\"RESOURCE_LOCAL\"  >\n",
            "        <provider>org.hibernate.ogm.jpa.HibernateOgmPersistence</provider>\n",
            "        <properties>\n",
            "            <property name=\"hibernate.ogm.datastore.provider\" value=\"infinispan\"/>\n",
            "            <property name=\"hibernate.ogm.infinispan.configuration_resourcename\"  value=\"infinispan.xml\"/>\n",
            "            <property name=\"hibernate.transaction.jta.platform\" value=\"org.hibernate.service.jta.platform.internal.NoJtaPlatform\"/>\n",
            "        </properties>\n",
            "    </persistence-unit>\n",
            "</persistence>\n",
            "\n",
            "Here is the infinispan.xml\n",
            "Code:\n",
            "<infinispan xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n",
            "            xsi:schemaLocation=\"urn:infinispan:config:5.1 http://www.infinispan.org/schemas/infinispan-config-5.1.xsd\"\n",
            "            xmlns=\"urn:infinispan:config:5.1\">\n",
            "\n",
            "      <global>\n",
            "      </global>\n",
            "\n",
            "    <default>\n",
            "    </default>\n",
            "\n",
            "    <namedCache name=\"ENTITIES\">\n",
            "        <loaders preload=\"true\"  passivation=\"false\" shared=\"true\" >\n",
            "            <loader class=\"org.infinispan.loaders.jpa.JpaCacheStore\"   fetchPersistentState=\"true\" purgeOnStartup=\"false\" ignoreModifications=\"true\" >\n",
            "                <properties>\n",
            "                    <property name=\"persistenceUnitName\" value=\"DB\" />\n",
            "                    <property name=\"entityClassName\" value=\"db.generated.PackageEntity\" />\n",
            "                </properties>\n",
            "            </loader>\n",
            "        </loaders>\n",
            "    </namedCache>\n",
            "\n",
            "    <namedCache name=\"ASSOCIATIONS\">\n",
            "    </namedCache>\n",
            "\n",
            "    <namedCache name=\"IDENTIFIERS\">\n",
            "    </namedCache>\n",
            "</infinispan>\n",
            "\n",
            "I'm gettting StackOverflowError when I booststrap JPA :\n",
            "Code:\n",
            "Persistence.createEntityManagerFactory(\"IMDG\")\n",
            "\n",
            "Please have a look at forum question :\n",
            "https://forum.hibernate.org/viewtopic.php?f=31&t=1029990&sid=99edcb329914d3c83859f391cadef097, Similarity: 0.5130\n",
            "Summary & Description: support authenticated access couchdb \n",
            " Currently, user name and password are not used when sending requests to CouchDB., Similarity: 0.1057\n",
            "Summary & Description: hook native query parser parameter substitution \n",
            " We had to disable query checks in OGM-363 because it fails for native queries.\n",
            "\n",
            "When this is fixed, reactivate the query check (see OgmConfiguration.reset())\n",
            "\n",
            "SessionFActoryImpl.checkNamedQueries()\n",
            "NamedQueryResolitory.checkNamedQueries (198)\n",
            "QueryCachePlan.getNativeSQLQueryPlan\n",
            "... down the rabbit hole\n",
            "\n",
            "SQLQueryParser is used to replace parameters with their value.\n",
            "that the parser fails.\n",
            "\n",
            "We need a way to hook our own parser\n",
            ", Similarity: 0.2871\n",
            "Summary & Description: make sure ogm pulses transaction coordinator like orm \n",
            " Hibernate ORM session and EM do call pulseTransactionCoordinator()\n",
            "It is used to enlist the session / EM synchronisation (for flush and co) to the current transaction if not done already.\n",
            "\n",
            "Assigning to Davide after the rule Finders keepers., Similarity: 0.1854\n",
            "Summary & Description: use common configurationpropertyreader accessing configuration values \n",
            " OGM-389 established a generic {{ConfigurationPropertyReader}} which provides the commonly used functionality of accessing a configuration property which can be given as instance, class object or class name (FQN or short alias). This reader class can now be used for other cases as well., Similarity: 0.3607\n",
            "Summary & Description: align classname hosting datastore provider properties names \n",
            " We seem to have the following patterns at least:\n",
            "\n",
            "- Environment\n",
            "- EhCacheConfiguration\n",
            "- CouchDB\n",
            "\n",
            "We should also decide in which package this should land:\n",
            "\n",
            "- org.hibernate.ogm.datastore.neo4j\n",
            "- org.hibernate.ogm.datastore.neo4j.configuration\n",
            "\n",
            "My personal preference is for:\n",
            "- org.hibernate.ogm.datastore.neo4j.Neo4J\n",
            "- org.hibernate.ogm.datastore.neo4j.Neo4JConfiguration (close second, I like the idea of a suffix).\n",
            "\n",
            "Thought [~accountid:557058:6a9959ae-3b15-4370-ad41-e78c978f4f7b] and [~accountid:557058:dc17d3f8-d34a-4a8a-a552-704e1902d0ae]?\n",
            "\n",
            "We also should move shared properties (e.g. \"create database\") to a common place., Similarity: 0.3804\n",
            "Summary & Description: builtintypetest sometimes fails timezone \n",
            " BuiltInType test fail on my machine when {code}Iso8601DateTypeDescriptor{code} is used to parse Date and the related field is mapped with {code}@Temporal.TIME{code}\n",
            ", Similarity: 0.2141\n",
            "Summary & Description: remove unnecessary repos dependency \n",
            " * Remove RedHat early access and deprecated JBoss repos from settings-example.xml\n",
            "* Remove superfluous dependency to org.hibernate:hibernate-testing, Similarity: 0.3784\n",
            "Summary & Description: store bytes numeric value couchdb calendardate iso8601 strings \n",
            " See Davide's comments on https://github.com/hibernate/hibernate-ogm/pull/253:\n",
            "\n",
            "* Shouldn't this use the TimeTypeDescriptor instead of the DateTypeDescriptor?\n",
            "* I'm pretty sure we can use StringDateTypeDescriptor.INSTANCE in this case. It can also be used for StandardBasicTypes.DATE and StandardBasicTypes.TIME I think., Similarity: 0.1495\n",
            "Summary & Description: create separate design documents production test views couchdb \n",
            " * Only create test views for tests\n",
            "* Move definition of test views to test source folder\n",
            "* Move methods required for tests only from dialect class into test helper, Similarity: 0.2999\n",
            "Summary & Description: add test optimistic locking \n",
            " Optimistic locking via {{@Version}} is supposed to be working in OGM, but as it seems there is no test for this functionality., Similarity: 0.2143\n",
            "Summary & Description: avoid test failures fail tests well \n",
            " If tests that opened a transaction fail, the pending transaction will cause the next test to be executed in the suite to fail as well as the TX is still associated with the thread., Similarity: 0.1392\n",
            "Summary & Description: make couchdb rev attribute usable entities \n",
            " CouchDB implicitely works with optimistic locking for all documents. For that purpose there is the _\\_rev_ attribute which is updated on the server side upon each write. When updating a document with a non-current revision, a HTTP 409 error is returned.\n",
            "\n",
            "As the attribute is maintained by the database, its value won't be up to date after inserts/updates atm. without manually reading back the entity. This can be addressed by adding support for _generated properties_ via the existing {{@Generated}} annotation (implement {{OgmEntityPersister#processInsertGeneratedProperties() and processUpdateGeneratedProperties()}}).\n",
            "\n",
            "In {{CouchDBDialect#updateTuple()}}, the entity currently is always read prior to the update, which would discard any previously read revision id. This needs to be changed to do the load only if the entity doesn't contain the original revision., Similarity: 0.1846\n",
            "Summary & Description: support entity embedded mode associations couchdb backend \n",
            " Similar to MongoDB, it should be configurable how to store associations in CouchDB, either embedded in the entity or in a separate document., Similarity: 0.4070\n",
            "Summary & Description: use natural format couchdb documents \n",
            " Currently CouchDB documents are structured like this:\n",
            "\n",
            "{code}\n",
            "{\n",
            "    \"_id\": \"Poem:id_:74d64d71-a996-4b2c-94c8-a5cea8287eb2_\",\n",
            "\n",
            "    [...]\n",
            "\n",
            "    \"columnNames\": [\n",
            "        \"id\",\n",
            "        \"name\"\n",
            "    ],\n",
            "    \"columnValues\": [\n",
            "        \"74d64d71-a996-4b2c-94c8-a5cea8287eb2\",\n",
            "        \"L'albatros\"\n",
            "    ]\n",
            "}\n",
            "{code}\n",
            "\n",
            "A more natural way would be this:\n",
            "\n",
            "{code}\n",
            "{\n",
            "    \"_id\" : \"74d64d71-a996-4b2c-94c8-a5cea8287eb2\", \n",
            "    \"name\" : \"L'albatros\" \n",
            "}\n",
            "{code}\n",
            "\n",
            "I'm also wondering why the type name is encoded in the id, as there is the separate \"table\" name attribute for this as well., Similarity: 0.1979\n",
            "Summary & Description: add rule check import hamcrest \n",
            " We should stick to plain JUnit and FEST assertions which we already use in other modules instead of also introducing Hamcrest matchers when adding unit tests., Similarity: 0.2130\n",
            "Summary & Description: make dependency hibernatesearchorm mandatory infinispan module \n",
            " The dependency\n",
            "\n",
            "{quote}\n",
            "<dependency>\n",
            "     <groupId>org.hibernate</groupId>\n",
            "     <artifactId>hibernate-search-orm</artifactId>\n",
            "     <optional>true</optional>\n",
            "</dependency\n",
            "{quote}\n",
            "\n",
            "in the OGM Infinispan module should not be optional since the {{InfinispanDatastoreProvider}} exposes the Search-based query parser implementation. So for ease of use the dependency to Search should be pulled in by default. Users who actually use another parser implemention could still exclude the dependency if they prefer., Similarity: 0.3871\n",
            "Summary & Description: griddialectexecutebackendquery return closeable iterator \n",
            " Some datastore like MongoDB return an object (DBCursor) that should be closed when we have finished to loop accross the results of a native query.\n",
            "\n",
            "Right now we are returning an {code}Iterable<Tuple>{code} but it should be something like\n",
            "{code}\n",
            "TupleCursor extends Iterable<Tuple>, Closeable\n",
            "{code}, Similarity: 0.2541\n",
            "Summary & Description: upgrade hibernate orm 430final \n",
            " * Refer to proper constant in {{EnvironmentTest}} (same to do in HSEARCH), Similarity: 0.1481\n",
            "Summary & Description: support neo4j queries \n",
            " * Transform HQL/JP-QL queries\n",
            "* Execute native (Cypher?) queries, Similarity: 0.3831\n",
            "Summary & Description: pass transaction manager current jtaplatform neo4j \n",
            " Currently we have a special {{JtaPlatform}} implementation which exposes the transaction manager from Neo4j to ORM/OGM. Instead we should try to pass the transaction manager from the current JTA platform to Neo4j. Neo4j has an SPI to make TM retrieval customizable ({{TransactionManagerProvider}} but this doesn't allow to pass in a given _instance_.\n",
            "\n",
            "ML reference: http://lists.jboss.org/pipermail/hibernate-dev/2013-October/010537.html, Similarity: 0.3967\n",
            "Summary & Description: support remote neo4j datastore \n",
            " This might be related to the blueprints integration\n",
            ", Similarity: 0.4680\n",
            "Summary & Description: move nosqlquery ogm namespace \n",
            " {{NoSQLQuery}} should live under {{org.hibernate.ogm.*}}. Currently it doesn't as needs to access some package private API from {{org.hibernate.internal}}., Similarity: 0.3418\n",
            "Summary & Description: update infinspan 6x \n",
            " WildFly 8.0.0.Beta1 uses Infinispan 6 already, causing our ISPN integration test to fail on WF due to moved classes., Similarity: 0.3623\n",
            "Summary & Description: remove started flag infinispandatastoreprovider \n",
            " HHH-7147 has been solved so the started flag should not be needed anymore, Similarity: 0.2369\n",
            "Summary & Description: update reference guide query capabilities \n",
            " We need to update the reference guide to describe the recently added querying capabilities:\n",
            "\n",
            "* It should be made clear per type of backend which JP-QL/HQL query constructs are supported.\n",
            "* Add example(s) for classic and JPA API\n",
            "* Native backend queries, Similarity: 0.3409\n",
            "Summary & Description: support stored procedures positional parameters mongodb \n",
            " Add support for {{EntityManager#createStoredProcedure()}} etc., Similarity: 0.4033\n",
            "Summary & Description: support object comparison jpql queries mongodb neo4j \n",
            " See comments below for various examples of queries which should be supported.\n",
            "\n",
            "Note that it only makes sense for MongoDB and Neo4j at the moment., Similarity: 0.3666\n",
            "Summary & Description: create hot rod remote infinispan griddialect \n",
            " It could be done using {{org.infinispan.AtomicMap}} or using the Grouping API. The main preference seems to be the Grouping API\n",
            "\n",
            "Both solutions are currently not supported by HotRod but there are two open issues:\n",
            "- https://issues.jboss.org/browse/ISPN-3732\n",
            "- https://issues.jboss.org/browse/ISPN-3733\n",
            "\n",
            "For the grouping API,\n",
            "we also need a method in the embedded interface, something like {{EmbeddedCache.getGroup(G)}}\n",
            "\n",
            "Methods needed in the {{RemoteCache}} should be: \n",
            "- {{RemoteClient.put(G g, K k, V v); //first param is the group}}\n",
            "- {{RemoteClinet.getGroup(G g) : Map<K,V>}};\n",
            "- {{RemoteClient.get(G g, K k)}}\n",
            "\n",
            "ML discussion: http://markmail.org/thread/z7pwchtcvijawxik, Similarity: 0.5103\n",
            "Summary & Description: blueprints integration \n",
            " From the homepage of http://www.tinkerpop.com/\n",
            "\"Blueprints is a property graph model interface with provided implementations. Databases that implement the Blueprints interfaces automatically support Blueprints-enabled applications\", Similarity: 0.4792\n",
            "Summary & Description: provide typesafe api accessing options \n",
            " {{OptionsContainer}} should provide type-safe APIs for accessing specific unique as well as non-unique options:\n",
            "\n",
            "{code}\n",
            "//unique option\n",
            "ForceOption force = optionsService.context().getGlobalOptions().getUnique(ForceOption.class);\n",
            "\n",
            "//non-unique\n",
            "Set<NamedQueryOption> namedQueries = optionsService.context().getEntityOptions(Giraffe.class).get(NamedQuery.class);\n",
            "{code}, Similarity: 0.3434\n",
            "Summary & Description: implement precedence configuration options given different levels \n",
            " With OGM-208 and OGM-338 it's possible now to define store-specific options on the global, entity and property level. It should be configurable per option type how to proceed if one option is given on more than one level. \n",
            "\n",
            "There are cases where a precedence of property over entity over global is useful, but there may be other cases as well. Maybe this should be configured via an annotion on the option type definition?, Similarity: 0.2621\n",
            "Summary & Description: queries selecting entire entity shouldnt return list arrays \n",
            " As [reported in the forum|https://forum.hibernate.org/viewtopic.php?f=31&t=1028833], this query\n",
            "\n",
            "{code}\n",
            "Query qry = sess.createQuery(\"select p from Person p where p.lastName = 'Smith'\");\n",
            "List<Object> people = qry.list();\n",
            "{code}\n",
            "\n",
            "returns a list of arrays instead of {{Person}} entities., Similarity: 0.0723\n",
            "Summary & Description: use javabeans property names optionscontext \n",
            " * In {{OptionsContext}} we should key meta-data against JavaBeans property names instead of actual field/getter names. (/)\n",
            "* Need to read annotation options from private fields (/)\n",
            "* Raise an exception in case a non-existent property is being configured via the API (/), Similarity: 0.4182\n",
            "Summary & Description: support polymorphic queries mongodb \n",
            " A query targetting a supertype should return matching subtype entities. At least for MongoDB this does not work at the moment when using the table-per-class strategy as only the collection of the addressed entity type is queried., Similarity: 0.2651\n",
            "Summary & Description: make mongodb write concern configurable per entity property \n",
            " With OGM-208 in place, we can make use of the new configuration facility and see how it works out in practice. A good candidate might be the write concern setting for which we already have the required option class and annotation.\n",
            "\n",
            "The MongoDB dialect should take the setting into account when executing writes. Given on the property level, the setting only makes sense for properties representing associations, which are stored in a separate association document., Similarity: 0.3951\n",
            "Summary & Description: update javadoc css enforce jdk 7 builds \n",
            " -OGM should be build using JDK 6.-\n",
            "-We should enforce it using the maven plugin.-\n",
            "\n",
            "In order to build OGM with Java 7 the JavaDoc CSS file needs to be updated to define the right classes. Java 7 or later needs to be enforced for builds once using the new stylesheet., Similarity: 0.4279\n",
            "Summary & Description: mapping context cached \n",
            " In MappingServiceImpl, a new MappingServiceContextImpl is created everytime the context() method is called.\n",
            ", Similarity: 0.3424\n",
            "Summary & Description: adapt changed parser api \n",
            " * Update to HSEARCH 4.4.0.Beta1\n",
            "* Update to HQLPARSER 1.0.0.Alpha 5 (The signature of {{PropertyHelper#convertToPropertyType()}} has changed in the course of HQLPARSER-28), Similarity: 0.3180\n",
            "Summary & Description: review improve infinispan mongodb documentation \n",
            " The Infinispan and MongoDB documentations are a bit hard to read. They need a review to improve the following points:\n",
            "\n",
            "- shorter sentences\n",
            "- less liaison words\n",
            "- focus on what is useful for the end user and less on how things are done, Similarity: 0.3496\n",
            "Summary & Description: technical fixes around javadoc \n",
            " * Some warnings occur when building the JavaDoc which should be removed:\n",
            "** wrong links/references\n",
            "** some \"unknown\" tags\n",
            "\n",
            "* -Enable the OGM JavaDocs to be built using Java 7; Due to changes in the CSS classes used by JavaDoc HTML pages between Java 6 and 7, the existing custom Hibernate JavaDoc CSS file can't be used when building the docs with Java 7. Instead, an updated file (as used in ORM and HV) needs to be used, which styles the correct CSS classes as referenced by JavaDocs built with Java 7.- (has been addressed with OGM-341 already), Similarity: 0.4252\n",
            "Summary & Description: add checkstyle check whitespaces type casts \n",
            " CS should make sure that there is a whitespace character after the closing brace of type casts:\n",
            "\n",
            "{code}\n",
            "//wrong\n",
            "int i = (bar)foo;\n",
            "\n",
            "//correct\n",
            "int i = (bar) foo;\n",
            "{code}, Similarity: 0.1122\n",
            "Summary & Description: simplify bit use docbook \n",
            " - Removing lineannotation element within programlisting\n",
            "- convert remark into tip as remark is not meant to be printed in a final document, Similarity: 0.2499\n",
            "Summary & Description: one javassist dependency \n",
            " Currently two different versions of Javassist are part of the classpath of _hibernate-ogm-core_:\n",
            "\n",
            "* org.javassist:javassist:jar:3.15.0-GA:compile (pulled in via ORM core)\n",
            "* javassist:javassist:jar:3.12.1.GA:test\n",
            "\n",
            "The latter should be removed., Similarity: 0.4654\n",
            "Summary & Description: specify type parameters jumap optionalserviceprovider \n",
            " To get rid of raw-type warnings (also in implementations), the type parameters for {{Map}} should be specified in the interface methods as {{Map<? , ?>}}., Similarity: 0.3297\n",
            "Summary & Description: convert jpql queries properties embeddable objects mongodb queries \n",
            " There should be support for referring to properties of {{@Embeddable}} objects in the WHERE clause of JP-QL queries:\n",
            "\n",
            "{code}\n",
            "@Entity\n",
            "@NamedQuery(name = \"PersonsByAddressLine\", query = \"FROM Person p WHERE p.address.line = :pAddressLine\")\n",
            "public class Person {\n",
            "\n",
            "\t@Id\n",
            "\tprivate Long id;\n",
            "\n",
            "\t@Embedded\n",
            "\tprivate Address address;\n",
            "\n",
            "\t//...\n",
            "}\n",
            "{code}, Similarity: 0.3083\n",
            "Summary & Description: extract separate module building distribution javadoc \n",
            " Create a separate sub-module which builds the documentation including JavaDoc, Similarity: 0.4143\n",
            "Summary & Description: onetoonetest completly clear datastore test finished \n",
            " When OneToOneTest has finished one entity is left in the DB and this may lead to problem with some other integration test checking the DB si empty.\n",
            "\n",
            "This problem does not always occur. It happens when tests are executed in a certain order., Similarity: 0.1717\n",
            "Summary & Description: add support like operators \n",
            " See HQLPARSER-17, Similarity: 0.3211\n",
            "Summary & Description: update hibernate search 44 \n",
            " Things to do when updating to Hibernate Search 4.4:\n",
            "\n",
            "* In {{SimpleQueriesTest}}, re-enable tests\n",
            "** {{testSimpleQueryOnUnindexedSuperType()}} (depends on HSEARCH-703)\n",
            "** {{testLessQuery()}}, {{testGreaterQuery()}} (depend on HSEARCH-1378), Similarity: 0.2054\n",
            "Summary & Description: explore capability lazily load unfrequently used properties \n",
            " Assuming a complex entity with many fields or properties, it is possible that there is a majority of use cases in which only a subset of these properties are actually used; there could be benefits in loading the remaining properties only on effective usage, and particularly storage benefits in not storing at all the tuple representing the property value.\n",
            "\n",
            "Two aspects:\n",
            " - avoid loading (null entries) and (unlikely needed entries)\n",
            " - avoid storing null entries\n",
            "\n",
            "Avoiding to load null entries is beneficial only in case there is no co-location (OGM-304) enabled, and would require some tracking anyway to store the information about properties which are defined vs. those which are not, so this aspect might not be too compelling., Similarity: 0.1944\n",
            "Summary & Description: maintain one ogmqueryloader per query plan \n",
            " Extract named parameter values from parser?, Similarity: 0.2036\n",
            "Summary & Description: tests fail embedded mongodb windows \n",
            " {quote}Waiting for Jenkins to finish collecting data\n",
            "mavenExecutionResult exceptions not empty\n",
            "message : Failed to execute goal org.codehaus.gmaven:gmaven-plugin:1.4:execute (log-info) on project hibernate-ogm-mongodb: startup failed, script1374585857064.groovy: 4: unexpected char: '\\' @ line 4, column 94.\n",
            "1 error\n",
            "\n",
            "cause : startup failed, script1374585857064.groovy: 4: unexpected char: '\\' @ line 4, column 94.\n",
            "1 error\n",
            "\n",
            "Stack trace : \n",
            "org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.codehaus.gmaven:gmaven-plugin:1.4:execute (log-info) on project hibernate-ogm-mongodb: startup failed, script1374585857064.groovy: 4: unexpected char: '\\' @ line 4, column 94.\n",
            "1 error\n",
            "\n",
            "\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:217)\n",
            "\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)\n",
            "\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)\n",
            "\tat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:84)\n",
            "\tat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:59)\n",
            "\tat org.apache.maven.lifecycle.internal.LifecycleStarter.singleThreadedBuild(LifecycleStarter.java:183)\n",
            "\tat org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:161)\n",
            "\tat org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:320)\n",
            "\tat org.apache.maven.DefaultMaven.execute(DefaultMaven.java:156)\n",
            "\tat org.jvnet.hudson.maven3.launcher.Maven3Launcher.main(Maven3Launcher.java:79)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n",
            "\tat java.lang.reflect.Method.invoke(Method.java:597)\n",
            "\tat org.codehaus.plexus.classworlds.launcher.Launcher.launchStandard(Launcher.java:329)\n",
            "\tat org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:239)\n",
            "\tat org.jvnet.hudson.maven3.agent.Maven3Main.launch(Maven3Main.java:158)\n",
            "\tat hudson.maven.Maven3Builder.call(Maven3Builder.java:98)\n",
            "\tat hudson.maven.Maven3Builder.call(Maven3Builder.java:64)\n",
            "\tat hudson.remoting.UserRequest.perform(UserRequest.java:118)\n",
            "\tat hudson.remoting.UserRequest.perform(UserRequest.java:48)\n",
            "\tat hudson.remoting.Request$2.run(Request.java:326)\n",
            "\tat hudson.remoting.InterceptingExecutorService$1.call(InterceptingExecutorService.java:72)\n",
            "\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n",
            "\tat java.util.concurrent.FutureTask.run(FutureTask.java:138)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)\n",
            "\tat java.lang.Thread.run(Thread.java:662)\n",
            "Caused by: org.apache.maven.plugin.MojoExecutionException: startup failed, script1374585857064.groovy: 4: unexpected char: '\\' @ line 4, column 94.\n",
            "1 error\n",
            "\n",
            "\tat org.codehaus.gmaven.plugin.MojoSupport.execute(MojoSupport.java:85)\n",
            "\tat org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:101)\n",
            "\tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:209)\n",
            "\t... 27 more\n",
            "Caused by: org.codehaus.groovy.control.MultipleCompilationErrorsException: startup failed, script1374585857064.groovy: 4: unexpected char: '\\' @ line 4, column 94.\n",
            "1 error\n",
            "\n",
            "\tat org.codehaus.groovy.control.ErrorCollector.failIfErrors(ErrorCollector.java:296)\n",
            "\tat org.codehaus.groovy.control.ErrorCollector.addFatalError(ErrorCollector.java:143)\n",
            "\tat org.codehaus.groovy.control.ErrorCollector.addError(ErrorCollector.java:113)\n",
            "\tat org.codehaus.groovy.control.ErrorCollector.addError(ErrorCollector.java:125)\n",
            "\tat org.codehaus.groovy.control.SourceUnit.addError(SourceUnit.java:353)\n",
            "\tat org.codehaus.groovy.antlr.AntlrParserPlugin.transformCSTIntoAST(AntlrParserPlugin.java:89)\n",
            "\tat org.codehaus.groovy.antlr.AntlrParserPlugin.parseCST(AntlrParserPlugin.java:61)\n",
            "\tat org.codehaus.groovy.control.SourceUnit.parse(SourceUnit.java:249)\n",
            "\tat org.codehaus.groovy.control.CompilationUnit$1.call(CompilationUnit.java:163)\n",
            "\tat org.codehaus.groovy.control.CompilationUnit.applyToSourceUnits(CompilationUnit.java:820)\n",
            "\tat org.codehaus.groovy.control.CompilationUnit.doPhaseOperation(CompilationUnit.java:513)\n",
            "\tat org.codehaus.groovy.control.CompilationUnit.processPhaseOperations(CompilationUnit.java:489)\n",
            "\tat org.codehaus.groovy.control.CompilationUnit.compile(CompilationUnit.java:466)\n",
            "\tat groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:279)\n",
            "\tat groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:250)\n",
            "\tat org.codehaus.gmaven.runtime.v1_6.ClassFactoryFeature$ClassFactoryImpl.create(ClassFactoryFeature.java:74)\n",
            "\tat org.codehaus.gmaven.runtime.support.ScriptExecutorSupport.execute(ScriptExecutorSupport.java:62)\n",
            "\tat org.codehaus.gmaven.plugin.execute.ExecuteMojo.process(ExecuteMojo.java:239)\n",
            "\tat org.codehaus.gmaven.plugin.ComponentMojoSupport.doExecute(ComponentMojoSupport.java:60)\n",
            "\tat org.codehaus.gmaven.plugin.MojoSupport.execute(MojoSupport.java:69)\n",
            "\t... 29 more\n",
            "channel stopped\n",
            "Email was triggered for: Failure{quote}, Similarity: 0.4009\n",
            "Summary & Description: set priority build order integration tests module projects using modules tag instead specify dependency \n",
            " The integration test project has the modules project as a dependency. This can be avoided changing the order of the modules in the parent pom, Similarity: 0.3199\n",
            "Summary & Description: make loadselectedcolumnscollectiontest run reliably jdk 7 \n",
            " The test {{LoadSelectedColumnsCollectionTest}} fails randomly on JDK 7 with the following exception:\n",
            "\n",
            "{quote}\n",
            "java.lang.NullPointerException\n",
            "\tat org.hibernate.ogm.test.mongodb.loading.LoadSelectedColumnsCollectionTest.getService(LoadSelectedColumnsCollectionTest.java:154)\n",
            "\tat org.hibernate.ogm.test.mongodb.loading.LoadSelectedColumnsCollectionTest.testLoadSelectedColumns(LoadSelectedColumnsCollectionTest.java:71)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.lang.reflect.Method.invoke(Method.java:601)\n",
            "\tat junit.framework.TestCase.runTest(TestCase.java:168)\n",
            "\tat org.hibernate.ogm.test.simpleentity.OgmTestCase.runTest(OgmTestCase.java:197)\n",
            "\tat org.hibernate.ogm.test.simpleentity.OgmTestCase.runBare(OgmTestCase.java:243)\n",
            "{quote}\n",
            "\n",
            "The issue occurs when the second test method in the file is executed before the first one. This can happen as of Java 7 since the order of methods retrieved via reflection is not deterministic any more. In this case the session factory will have been nulled by the {{tearDown()}} call after the second test method, causing the NPE when running the first test method afterwards., Similarity: 0.4438\n",
            "Summary & Description: use sessionfactoryserviceinitiator instead sessionfactoryaddobserver inject sessionfactory datastoreprovider \n",
            " In Hibernate ORM, there is the notion of SessionFactory aware services (SessionFactoryServiceInitiator). We did not use it in OGM because we could not find a way to add new service initiators to the SessionFactoryServiceRegistry. Instead we used a SessionFactory observer to listen to the SessionFactory creation and use that hook to create these SF aware services.\n",
            "\n",
            "There is a more standard way in Hibernate ORM. The trick is to override (in OgmIntegrator) SessionFactoryServiceRegistryFactoryInitiator like we do override others and change the list of services at will.\n",
            "\n",
            "This approach will also be useful for the metamodel work.\n",
            "\n",
            "Bonus point if we can devise an easier solution to register these SF aware ServiceInitiator. non SF aware service initiators can be registered by an Integrator implementing ServiceContributingIntegrator.\n",
            "We could imagine a SessionFactoryServiceContributingIntegrator. any better solution? A potential complex point is to see if the Integrator is still around when the SesisonFactoryServiceRegistry is created., Similarity: 0.3284\n",
            "Summary & Description: make property profile skip non compiletest related work builds \n",
            " When working on a feature, it is usual to run several mvn clean install which happen to create the doc, build the javadoc, run the checkstyle plugin and maybe other unrelated tasks.\n",
            "\n",
            "It would be nice to be able to exclude these peripheral tasks and save seconds during the quick iterative cycles.\n",
            "\n",
            "   mvn clean install -DtestOnly\n",
            "\n",
            "or something like that., Similarity: 0.3274\n",
            "Summary & Description: mongodbmodulememberregistrationit honor mongodbhostname \n",
            " I use MONGODB_HOSTNAME to point to an IP that is not 127.0.0.1 and the following test fails\n",
            "\n",
            "org.hibernate.ogm.test.integration.jbossas7.MongoDBModuleMemberRegistrationIT\n",
            "\n",
            "{code}\n",
            "[INFO]\n",
            "[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ hibernate-ogm-integrationtest-mongodb ---\n",
            "[WARNING] JAR will be empty - no content was marked for inclusion!\n",
            "[INFO] Building jar: /Users/emmanuel/Code/privatebuild/ogm/hibernate-ogm-integrationtest/hibernate-ogm-integrationtest-mongodb/target/hibernate-ogm-integrationtest-mongodb-4.0.0-SNAPSHOT.jar\n",
            "[INFO]\n",
            "[INFO] --- maven-jar-plugin:2.4:test-jar (build-test-jar) @ hibernate-ogm-integrationtest-mongodb ---\n",
            "[INFO] Building jar: /Users/emmanuel/Code/privatebuild/ogm/hibernate-ogm-integrationtest/hibernate-ogm-integrationtest-mongodb/target/hibernate-ogm-integrationtest-mongodb-4.0.0-SNAPSHOT-tests.jar\n",
            "[INFO]\n",
            "[INFO] --- maven-dependency-plugin:2.4:unpack (unpack) @ hibernate-ogm-integrationtest-mongodb ---\n",
            "[INFO] Configured Artifact: org.jboss.as:jboss-as-dist:7.2.0.Alpha1-redhat-4:zip\n",
            "[INFO] Configured Artifact: org.hibernate.ogm:hibernate-ogm-modules:jbossas-72-dist:4.0.0-SNAPSHOT:zip\n",
            "[INFO] Unpacking /Users/emmanuel/.m2/repository/org/jboss/as/jboss-as-dist/7.2.0.Alpha1-redhat-4/jboss-as-dist-7.2.0.Alpha1-redhat-4.zip to /Users/emmanuel/Code/privatebuild/ogm/hibernate-ogm-integrationtest/hibernate-ogm-integrationtest-mongodb/target with includes \"\" and excludes \"\"\n",
            "[INFO] Unpacking /Users/emmanuel/Code/privatebuild/ogm/hibernate-ogm-modules/target/hibernate-ogm-modules-4.0.0-SNAPSHOT-jbossas-72-dist.zip to /Users/emmanuel/Code/privatebuild/ogm/hibernate-ogm-integrationtest/hibernate-ogm-integrationtest-mongodb/target/jboss-eap-6.1/modules with includes \"\" and excludes \"\"\n",
            "[INFO]\n",
            "[INFO] --- maven-failsafe-plugin:2.12.4:integration-test (default) @ hibernate-ogm-integrationtest-mongodb ---\n",
            "[INFO] Failsafe report directory: /Users/emmanuel/Code/privatebuild/ogm/hibernate-ogm-integrationtest/hibernate-ogm-integrationtest-mongodb/target/failsafe-reports\n",
            "\n",
            "-------------------------------------------------------\n",
            " T E S T S\n",
            "-------------------------------------------------------\n",
            "Running org.hibernate.ogm.test.integration.jbossas7.MongoDBModuleMemberRegistrationIT\n",
            "Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 27.021 sec <<< FAILURE!\n",
            "org.hibernate.ogm.test.integration.jbossas7.MongoDBModuleMemberRegistrationIT  Time elapsed: 27.02 sec  <<< ERROR!\n",
            "org.jboss.arquillian.container.spi.client.container.DeploymentException: Cannot deploy: MongoDBModuleMemberRegistrationIT.war\n",
            "\tat org.jboss.as.arquillian.container.ArchiveDeployer.deployInternal(ArchiveDeployer.java:83)\n",
            "\tat org.jboss.as.arquillian.container.ArchiveDeployer.deployInternal(ArchiveDeployer.java:64)\n",
            "\tat org.jboss.as.arquillian.container.ArchiveDeployer.deploy(ArchiveDeployer.java:46)\n",
            "\tat org.jboss.as.arquillian.container.CommonDeployableContainer.deploy(CommonDeployableContainer.java:144)\n",
            "\tat org.jboss.arquillian.container.impl.client.container.ContainerDeployController$3.call(ContainerDeployController.java:161)\n",
            "\tat org.jboss.arquillian.container.impl.client.container.ContainerDeployController$3.call(ContainerDeployController.java:128)\n",
            "\tat org.jboss.arquillian.container.impl.client.container.ContainerDeployController.executeOperation(ContainerDeployController.java:271)\n",
            "\tat org.jboss.arquillian.container.impl.client.container.ContainerDeployController.deploy(ContainerDeployController.java:127)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.lang.reflect.Method.invoke(Method.java:601)\n",
            "\tat org.jboss.arquillian.core.impl.ObserverImpl.invoke(ObserverImpl.java:94)\n",
            "\tat org.jboss.arquillian.core.impl.EventContextImpl.invokeObservers(EventContextImpl.java:99)\n",
            "\tat org.jboss.arquillian.core.impl.EventContextImpl.proceed(EventContextImpl.java:81)\n",
            "\tat org.jboss.arquillian.container.impl.client.ContainerDeploymentContextHandler.createDeploymentContext(ContainerDeploymentContextHandler.java:78)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.lang.reflect.Method.invoke(Method.java:601)\n",
            "\tat org.jboss.arquillian.core.impl.ObserverImpl.invoke(ObserverImpl.java:94)\n",
            "\tat org.jboss.arquillian.core.impl.EventContextImpl.proceed(EventContextImpl.java:88)\n",
            "\tat org.jboss.arquillian.container.impl.client.ContainerDeploymentContextHandler.createContainerContext(ContainerDeploymentContextHandler.java:57)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.lang.reflect.Method.invoke(Method.java:601)\n",
            "\tat org.jboss.arquillian.core.impl.ObserverImpl.invoke(ObserverImpl.java:94)\n",
            "\tat org.jboss.arquillian.core.impl.EventContextImpl.proceed(EventContextImpl.java:88)\n",
            "\tat org.jboss.arquillian.container.impl.client.container.DeploymentExceptionHandler.verifyExpectedExceptionDuringDeploy(DeploymentExceptionHandler.java:50)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.lang.reflect.Method.invoke(Method.java:601)\n",
            "\tat org.jboss.arquillian.core.impl.ObserverImpl.invoke(ObserverImpl.java:94)\n",
            "\tat org.jboss.arquillian.core.impl.EventContextImpl.proceed(EventContextImpl.java:88)\n",
            "\tat org.jboss.arquillian.core.impl.ManagerImpl.fire(ManagerImpl.java:135)\n",
            "\tat org.jboss.arquillian.core.impl.ManagerImpl.fire(ManagerImpl.java:115)\n",
            "\tat org.jboss.arquillian.core.impl.EventImpl.fire(EventImpl.java:67)\n",
            "\tat org.jboss.arquillian.container.impl.client.container.ContainerDeployController$1.perform(ContainerDeployController.java:95)\n",
            "\tat org.jboss.arquillian.container.impl.client.container.ContainerDeployController$1.perform(ContainerDeployController.java:80)\n",
            "\tat org.jboss.arquillian.container.impl.client.container.ContainerDeployController.forEachDeployment(ContainerDeployController.java:263)\n",
            "\tat org.jboss.arquillian.container.impl.client.container.ContainerDeployController.forEachManagedDeployment(ContainerDeployController.java:239)\n",
            "\tat org.jboss.arquillian.container.impl.client.container.ContainerDeployController.deployManaged(ContainerDeployController.java:79)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.lang.reflect.Method.invoke(Method.java:601)\n",
            "\tat org.jboss.arquillian.core.impl.ObserverImpl.invoke(ObserverImpl.java:94)\n",
            "\tat org.jboss.arquillian.core.impl.EventContextImpl.invokeObservers(EventContextImpl.java:99)\n",
            "\tat org.jboss.arquillian.core.impl.EventContextImpl.proceed(EventContextImpl.java:81)\n",
            "\tat org.jboss.arquillian.core.impl.ManagerImpl.fire(ManagerImpl.java:135)\n",
            "\tat org.jboss.arquillian.core.impl.ManagerImpl.fire(ManagerImpl.java:115)\n",
            "\tat org.jboss.arquillian.core.impl.EventImpl.fire(EventImpl.java:67)\n",
            "\tat org.jboss.arquillian.container.test.impl.client.ContainerEventController.execute(ContainerEventController.java:101)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.lang.reflect.Method.invoke(Method.java:601)\n",
            "\tat org.jboss.arquillian.core.impl.ObserverImpl.invoke(ObserverImpl.java:94)\n",
            "\tat org.jboss.arquillian.core.impl.EventContextImpl.invokeObservers(EventContextImpl.java:99)\n",
            "\tat org.jboss.arquillian.core.impl.EventContextImpl.proceed(EventContextImpl.java:81)\n",
            "\tat org.jboss.arquillian.test.impl.TestContextHandler.createClassContext(TestContextHandler.java:75)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.lang.reflect.Method.invoke(Method.java:601)\n",
            "\tat org.jboss.arquillian.core.impl.ObserverImpl.invoke(ObserverImpl.java:94)\n",
            "\tat org.jboss.arquillian.core.impl.EventContextImpl.proceed(EventContextImpl.java:88)\n",
            "\tat org.jboss.arquillian.test.impl.TestContextHandler.createSuiteContext(TestContextHandler.java:60)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.lang.reflect.Method.invoke(Method.java:601)\n",
            "\tat org.jboss.arquillian.core.impl.ObserverImpl.invoke(ObserverImpl.java:94)\n",
            "\tat org.jboss.arquillian.core.impl.EventContextImpl.proceed(EventContextImpl.java:88)\n",
            "\tat org.jboss.arquillian.core.impl.ManagerImpl.fire(ManagerImpl.java:135)\n",
            "\tat org.jboss.arquillian.core.impl.ManagerImpl.fire(ManagerImpl.java:115)\n",
            "\tat org.jboss.arquillian.test.impl.EventTestRunnerAdaptor.beforeClass(EventTestRunnerAdaptor.java:80)\n",
            "\tat org.jboss.arquillian.junit.Arquillian$2.evaluate(Arquillian.java:182)\n",
            "\tat org.jboss.arquillian.junit.Arquillian.multiExecute(Arquillian.java:314)\n",
            "\tat org.jboss.arquillian.junit.Arquillian.access$100(Arquillian.java:46)\n",
            "\tat org.jboss.arquillian.junit.Arquillian$3.evaluate(Arquillian.java:199)\n",
            "\tat org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n",
            "\tat org.jboss.arquillian.junit.Arquillian.run(Arquillian.java:147)\n",
            "\tat org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)\n",
            "\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)\n",
            "\tat org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.lang.reflect.Method.invoke(Method.java:601)\n",
            "\tat org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)\n",
            "\tat org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)\n",
            "\tat org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)\n",
            "\tat org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)\n",
            "\tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)\n",
            "Caused by: java.lang.Exception: {\"JBAS014671: Failed services\" => {\"jboss.persistenceunit.\\\"MongoDBModuleMemberRegistrationIT.war#primary\\\"\" => \"org.jboss.msc.service.StartException in service jboss.persistenceunit.\\\"MongoDBModuleMemberRegistrationIT.war#primary\\\": javax.persistence.PersistenceException: [PersistenceUnit: primary] Unable to build EntityManagerFactory\n",
            "    Caused by: javax.persistence.PersistenceException: [PersistenceUnit: primary] Unable to build EntityManagerFactory\n",
            "    Caused by: org.hibernate.MappingException: Could not get constructor for org.hibernate.ogm.persister.SingleTableOgmEntityPersister\n",
            "    Caused by: org.hibernate.HibernateException: OGM001214: Unable to connect to MongoDB instance 127.0.0.1:27017\n",
            "    Caused by: com.mongodb.MongoException$Network: can't call something : /127.0.0.1:27017/admin\n",
            "    Caused by: java.io.IOException: couldn't connect to [/127.0.0.1:27017] bc:java.net.ConnectException: Connection refused\"}}\n",
            "\tat org.jboss.as.controller.client.helpers.standalone.impl.ServerDeploymentPlanResultFuture.getActionResult(ServerDeploymentPlanResultFuture.java:134)\n",
            "\tat org.jboss.as.controller.client.helpers.standalone.impl.ServerDeploymentPlanResultFuture.getResultFromNode(ServerDeploymentPlanResultFuture.java:123)\n",
            "\tat org.jboss.as.controller.client.helpers.standalone.impl.ServerDeploymentPlanResultFuture.get(ServerDeploymentPlanResultFuture.java:85)\n",
            "\tat org.jboss.as.controller.client.helpers.standalone.impl.ServerDeploymentPlanResultFuture.get(ServerDeploymentPlanResultFuture.java:42)\n",
            "\tat org.jboss.as.controller.client.helpers.standalone.ServerDeploymentHelper.deploy(ServerDeploymentHelper.java:50)\n",
            "\tat org.jboss.as.arquillian.container.ArchiveDeployer.deployInternal(ArchiveDeployer.java:77)\n",
            "\t... 96 more\n",
            "\n",
            "\n",
            "Results :\n",
            "\n",
            "Tests in error:\n",
            "  org.hibernate.ogm.test.integration.jbossas7.MongoDBModuleMemberRegistrationIT: Cannot deploy: MongoDBModuleMemberRegistrationIT.war\n",
            "\n",
            "Tests run: 1, Failures: 0, Errors: 1, Skipped: 0\n",
            "\n",
            "[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!\n",
            "[INFO]\n",
            "[INFO] --- maven-source-plugin:2.1.2:jar-no-fork (attach-sources) @ hibernate-ogm-integrationtest-mongodb ---\n",
            "[INFO] No sources in project. Archive not created.\n",
            "[INFO]\n",
            "[INFO] --- maven-failsafe-plugin:2.12.4:verify (default) @ hibernate-ogm-integrationtest-mongodb ---\n",
            "[INFO] Failsafe report directory: /Users/emmanuel/Code/privatebuild/ogm/hibernate-ogm-integrationtest/hibernate-ogm-integrationtest-mongodb/target/failsafe-reports\n",
            "[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!\n",
            "[INFO] ------------------------------------------------------------------------\n",
            "[INFO] Reactor Summary:\n",
            "[INFO]\n",
            "[INFO] Hibernate OGM Aggregator .......................... SUCCESS [6.146s]\n",
            "[INFO] Hibernate Object Grid Mapper ...................... SUCCESS [52.042s]\n",
            "[INFO] Hibernate OGM Ehcache integration ................. SUCCESS [20.105s]\n",
            "[INFO] Hibernate OGM Infinispan integration .............. SUCCESS [25.529s]\n",
            "[INFO] Hibernate OGM MongoDB integration ................. SUCCESS [2:04.289s]\n",
            "[INFO] Hibernate OGM Module .............................. SUCCESS [4.918s]\n",
            "[INFO] Hibernate OGM Integration and performance Tests ... SUCCESS [4.783s]\n",
            "[INFO] Hibernate OGM Integration Test case ............... SUCCESS [46.065s]\n",
            "[INFO] Hibernate OGM Integration Tests for MongoDB ....... FAILURE [45.576s]\n",
            "[INFO] ------------------------------------------------------------------------\n",
            "[INFO] BUILD FAILURE\n",
            "[INFO] ------------------------------------------------------------------------\n",
            "[INFO] Total time: 5:30.377s\n",
            "[INFO] Finished at: Thu Jul 04 19:00:29 CEST 2013\n",
            "[INFO] Final Memory: 117M/473M\n",
            "[INFO] ------------------------------------------------------------------------\n",
            "[ERROR] Failed to execute goal org.apache.maven.plugins:maven-failsafe-plugin:2.12.4:verify (default) on project hibernate-ogm-integrationtest-mongodb: There are test failures.\n",
            "[ERROR]\n",
            "[ERROR] Please refer to /Users/emmanuel/Code/privatebuild/ogm/hibernate-ogm-integrationtest/hibernate-ogm-integrationtest-mongodb/target/failsafe-reports for the individual test results.\n",
            "[ERROR] -> [Help 1]\n",
            "[ERROR]\n",
            "[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n",
            "[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n",
            "[ERROR]\n",
            "[ERROR] For more information about the errors and possible solutions, please read the following articles:\n",
            "[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\n",
            "[ERROR]\n",
            "[ERROR] After correcting the problems, you can resume the build with the command\n",
            "[ERROR]   mvn <goals> -rf :hibernate-ogm-integrationtest-mongodb\n",
            "FAILURE\n",
            "{code}, Similarity: 0.4652\n",
            "Summary & Description: reuse association data loaded main entity loading tuple \n",
            " Today the Tuple only represents the entity information and not the association information even if that data has been loaded by the native call.\n",
            "\n",
            "It would be nice to offer that data (via a fake resultset) and let it be reused by the OgmLoader. This will require to create this fake resultset but also to properly handle collection / association persisters whose handling I removed initially from OgmLoader., Similarity: 0.2563\n",
            "Summary & Description: reorganize ogm packages datastores \n",
            " At some point we need to clean the package hierarchy.\n",
            "\n",
            "- properly separate API / SPI and implementation packages\n",
            "- consider a nosql.{datastoreprovider|dialect|...} instead of {datastoreprovider|dialect|...}.nosql - not sure we should do it yet., Similarity: 0.3293\n",
            "Summary & Description: adapt current version parser project \n",
            " Adapt to renamed packages of parser, lexer and related classes in _hibernate-hql-parser_., Similarity: 0.2593\n",
            "Summary & Description: integration test parent module resource folder \n",
            " The parent integration-test folder should contain only the plugins configuration and not the plugin inclusion. It also should not have a resource folder.\n",
            "\n",
            "This cause some issues when integrated with eclipse and when running the tests and it also unpack and download an unecessary JBoss AS distribution., Similarity: 0.4531\n",
            "Summary & Description: integration tests test deployment using jbossdeploymentstructurexml \n",
            " Currently the deployment used in the integration tests is using the manifest to load the dependencies.\n",
            ", Similarity: 0.5197\n",
            "Summary & Description: configuration parsing \n",
            " The idea is to delegate the configuration parsing to a dedicated object and so to make it less coupled with the DatastoreProviders, Similarity: 0.3471\n",
            "Summary & Description: fix builtintypetestteststringmappedtypeserialisation \n",
            " <DavideD> emmanuel, one quick question about the TestHelper#extractEntityTuple\n",
            "<DavideD> Andrea is working on the couchDb implementation and he has a problem with the BuiltInTypeTest\n",
            "<DavideD> in the test BuiltinTypeTest#testStringMappedTypeSerialisation we check some values after the expected values has been converted to a Stirng and other values without converting them to string\n",
            "<DavideD> for example the userId\n",
            "<DavideD> If I'm correct the extractTuple should return values as String but the test fails because compares a String (actual value) with a Long (expected value) even if the String value of both is the same\n",
            "<DavideD> It seem an error in the test\n",
            "<emmanuel> DavideD: sorry got sidetracked by the internet\n",
            "<emmanuel> looking\n",
            "<emmanuel> DavideD: yes the test looks wrong\n",
            "<emmanuel> It was meant to only test built-in types that convert stuff into string\n",
            "<DavideD> is it ok if Andrea fix it by converting to String the expected and actual values?\n",
            "<emmanuel> Plus the extractTuple method should return Map<String,Object>\n",
            "<emmanuel> and not <String,String>\n",
            "<emmanuel> DavideD: no that does not look like a fix\n",
            "<DavideD> So the db should always remember the type of the object saved\n",
            "<emmanuel> DavideD: I would remove the test for userId and stockCount\n",
            "<emmanuel> these types are not meant to be strings\n",
            "<DavideD> Is The purpose of the test to assert values that should be saved as String in the db?\n",
            "<emmanuel> DavideD: I think so\n",
            "<emmanuel> but then dialects can override types so that's a bit of a mess\n",
            "<emmanuel> technicall we would only test the types and not necessarily how the NoSQL stores them\n",
            "<emmanuel> DavideD: the purpose is to test the string representation to be specific\n",
            "<emmanuel> but if a DB can store big decials in a native format\n",
            "<emmanuel> why not\n",
            "<emmanuel> can you open an issue to revisit this part of the tests?\n",
            "<emmanuel> In he mean time the lines 176 and 177 can go away\n",
            "<emmanuel> that's the ones posing problem I imagine, Similarity: 0.2509\n",
            "Summary & Description: offer ability load entities given table griddialect \n",
            " This is useful for the Hibernate Search mass indexer.\n",
            "\n",
            "This also means that we need a loader to build an entity based on a (list of) tuple., Similarity: 0.3118\n",
            "Summary & Description: fix basicgridextractor logging message \n",
            " The current trace output message is always \"found [$s] as column [$s]\" because [$s] occurences should be replaced by \"%1$s\" and \"%2$s\", Similarity: 0.2225\n",
            "Summary & Description: expose writeconcern settings configuration \n",
            " With the OGM-267 (upgrade mongodb java driver to 2.10.1) new WriteConcern settings are available.\n",
            "The complete list is here: http://api.mongodb.org/java/current/com/mongodb/WriteConcern.html\n",
            "The idea is to replace hibernate.ogm.mongodb.safe by hibernate.ogm.mongodb.writeconcern and then map values to WriteConcern.*\n",
            "\n",
            "So with hibernate.ogm.mongodb.writeconcern=\"NORMAL\" the WriteConcern.NORMAL setting will be used.\n",
            "So as the driver, the default value will be ACKNOWLEDGMENT\n",
            ", Similarity: 0.4149\n",
            "Summary & Description: upgrade mongodbjavadriver version 2101 \n",
            " Upgrage the version of the mongodb-java-driver used to 2.10.1 and to switch to the new client system (introduced into 2.10.0) which by default uses a WriteConcern set at Acknowledgement.\n",
            "\n",
            "So I think we can get rid of the default safe mode ?, Similarity: 0.3591\n",
            "Summary & Description: consider option use replica reads writes \n",
            " Today, we might read stuff after writes and return inconsistent results. We should add an option to force the dialect to use requestStart / requestDone\n",
            "See\n",
            "http://docs.mongodb.org/ecosystem/drivers/java-concurrency/, Similarity: 0.3416\n",
            "Summary & Description: mongodb throws exception updating entity inner class \n",
            " MongoDB throws the exception because the table field contains a $ signed in the name.\n",
            "\n",
            "{code}\n",
            "Caused by: com.mongodb.MongoException: cannot update reserved $ collection\n",
            "{code}\n",
            "\n",
            "Example:\n",
            "{code}\n",
            "@Entity\n",
            "@Inheritance(strategy = InheritanceType.TABLE_PER_CLASS)\n",
            "public class CommunityMember {\n",
            "\n",
            "\t@Id\n",
            "\tpublic String name;\n",
            "...\n",
            "\t@Entity\n",
            "\tpublic static class Employee extends CommunityMember {\n",
            "...\n",
            "\t}\n",
            "}\n",
            "{code}, Similarity: 0.3079\n",
            "Summary & Description: persistenttablebulkidstrategyexporttabledefinitions throws nullpointerexception ogm \n",
            " The org.hibernate.ogm.jdbc.NoopConnection methods return null, false, etc. values and the void methods are no-ops. Returning null references can cause problems when trying to use them later without null checks.\n",
            "\n",
            "Specifically, the NoopConnection.createStatement() methods also return null, so when trying to create an EntityManagerFactory, the PersistentTableBulkIdStrategy.exportTableDefinitions() method in hibernate-core is called and throwing a NullPointerException on line 164 when trying to close the statement.\n",
            "\n",
            "Either null checks should be included in PersistentTableBulkIdStrategy in hibernate-core or NOOP objects should be returned by NoopConnection hibernate-ogm-core, e.g. NoopStatement.\n",
            "\n",
            "The call causing the NPE:\n",
            "EntityManagerFactory emf = Persistence.createEntityManagerFactory(\"ogmsample\");\n",
            "\n",
            "Stack trace:\n",
            "javax.persistence.PersistenceException: Unable to build EntityManagerFactory\n",
            "\tat org.hibernate.ogm.jpa.HibernateOgmPersistence.createEntityManagerFactory(HibernateOgmPersistence.java:110)\n",
            "\tat javax.persistence.Persistence.createEntityManagerFactory(Persistence.java:63)\n",
            "\tat javax.persistence.Persistence.createEntityManagerFactory(Persistence.java:47)\n",
            "\tat com.example.HibernateOgmTester.main(HibernateOgmTester.java:42)\n",
            "Caused by: java.lang.NullPointerException\n",
            "\tat org.hibernate.hql.spi.PersistentTableBulkIdStrategy.exportTableDefinitions(PersistentTableBulkIdStrategy.java:164)\n",
            "\tat org.hibernate.hql.spi.PersistentTableBulkIdStrategy.prepare(PersistentTableBulkIdStrategy.java:102)\n",
            "\tat org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:488)\n",
            "\tat org.hibernate.cfg.Configuration.buildSessionFactory(Configuration.java:1750)\n",
            "\tat org.hibernate.ejb.EntityManagerFactoryImpl.<init>(EntityManagerFactoryImpl.java:94)\n",
            "\tat org.hibernate.ejb.Ejb3Configuration.buildEntityManagerFactory(Ejb3Configuration.java:905)\n",
            "\tat org.hibernate.ejb.Ejb3Configuration.buildEntityManagerFactory(Ejb3Configuration.java:890)\n",
            "\tat org.hibernate.ejb.HibernatePersistence.createEntityManagerFactory(HibernatePersistence.java:57)\n",
            "\tat org.hibernate.ogm.jpa.HibernateOgmPersistence.createEntityManagerFactory(HibernateOgmPersistence.java:92)\n",
            "\t... 3 more\n",
            "\n",
            "persistence.xml:\n",
            "\n",
            "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
            "<persistence version=\"2.0\" xmlns=\"http://java.sun.com/xml/ns/persistence\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_2_0.xsd\">\n",
            "    <persistence-unit name=\"ogmjtasample\" transaction-type=\"JTA\">\n",
            "        <provider>org.hibernate.ogm.jpa.HibernateOgmPersistence</provider>\n",
            "        <properties>\n",
            "            <property name=\"hibernate.transaction.jta.platform\"\n",
            "                      value=\"org.hibernate.service.jta.platform.spi.JtaPlatform\" />\n",
            "            <property name=\"hibernate.ogm.datastore.provider\"\n",
            "                      value=\"infinispan\" />\n",
            "            <property name=\"hibernate.ogm.infinispan.configuration_resourcename\"\n",
            "                      value=\"META-INF/ispn-config.xml\"/>\n",
            "        </properties>\n",
            "    </persistence-unit>\n",
            "</persistence>\n",
            "\n",
            "Maven dependencies:\n",
            "        <dependency>\n",
            "            <groupId>org.hibernate.ogm</groupId>\n",
            "            <artifactId>hibernate-ogm-core</artifactId>\n",
            "            <version>4.0.0-SNAPSHOT</version>\n",
            "        </dependency>\n",
            "        <dependency>\n",
            "            <groupId>org.hibernate.ogm</groupId>\n",
            "            <artifactId>hibernate-ogm-infinispan</artifactId>\n",
            "            <version>4.0.0-SNAPSHOT</version>\n",
            "        </dependency>\n",
            "        <dependency>\n",
            "            <groupId>org.hibernate</groupId>\n",
            "            <artifactId>hibernate-core</artifactId>\n",
            "            <version>4.1.8.Final</version>\n",
            "            <type>jar</type>\n",
            "        </dependency>\n",
            "        <dependency>\n",
            "            <groupId>org.hibernate</groupId>\n",
            "            <artifactId>hibernate-entitymanager</artifactId>\n",
            "            <version>4.1.8.Final</version>\n",
            "        </dependency>, Similarity: 0.3994\n",
            "Summary & Description: drop hibernateogm prefix module directories \n",
            " the prefix really doesn't help anything on the file system level. It is actually much easier to work with the project without the prefixes (see HV), Similarity: 0.3075\n",
            "Summary & Description: raise exception rollback backend support transactions \n",
            " To warn the user we could raise a transaction if rollback is called. But we need to make sure this does not have any side effect first., Similarity: 0.1241\n",
            "Summary & Description: detect unreasonable infinispan configuration \n",
            " There are combinations of settings in Infinispan which are perfectly legal for other use cases of Infinispan but are not tolerated by Hibernate OGM.\n",
            "\n",
            "Examples:\n",
            "- expiry of entries\n",
            "- eviction without passivation\n",
            "- ...?\n",
            "\n",
            "today I'm documenting that _though shall not do that_ but it would be nice to actively check for crazy combinations., Similarity: 0.1996\n",
            "Summary & Description: remove testsuite skip setting avoid ispn2149 \n",
            " The testsuite is disabling some Infinispan tests (currently just org.hibernate.ogm.test.associations.manytoone.ManyToOneTest) to workaround the Infinispan bug ISPN-2149.\n",
            "\n",
            "We should update Infinispan when this is fixed and remove the Skip setting., Similarity: 0.2779\n",
            "Summary & Description: ogm polymorphic \n",
            " OGM does not provide for polymorphism. The underlying problem is that ogm does not persist the subtypes table info.  From one of the unit tests (note both Hero and SuperHero have a table=Hero):\n",
            "\n",
            "\n",
            "08:01:42,770 TRACE ogm.datastore.access:78 - Reading Tuple with key EntityKey{table=&apos;Hero&apos;, columnNames=[name], columnValues=[Spartacus]} and context Tuple Context {}\n",
            "08:01:42,770 TRACE ogm.datastore.access:84 - Build Tuple object with key EntityKey{table=&apos;Hero&apos;, columnNames=[name], columnValues=[Spartacus]} (does not trigger access to the datastore)\n",
            "08:01:42,777 TRACE ogm.datastore.access:91 - Creating Tuple with key EntityKey{table=&apos;Hero&apos;, columnNames=[name], columnValues=[Spartacus]} in datastore\n",
            "08:01:42,782 TRACE ogm.datastore.access:78 - Reading Tuple with key EntityKey{table=&apos;Hero&apos;, columnNames=[name], columnValues=[Batman]} and context Tuple Context {specialPower}\n",
            "08:01:42,782 TRACE ogm.datastore.access:84 - Build Tuple object with key EntityKey{table=&apos;Hero&apos;, columnNames=[name], columnValues=[Batman]} (does not trigger access to the datastore)\n",
            "08:01:42,783 TRACE ogm.datastore.access:91 - Creating Tuple with key EntityKey{table=&apos;Hero&apos;, columnNames=[name], columnValues=[Batman]} in datastore\n",
            "\n",
            "This issue and OGM-230 are the same issue and OGM-230 should likely be merge into this issue.  I've added a Collection test and re-added the getReference  test as its behavior is also affected and does differ from hibernate-orm.  \n",
            "\n",
            "This is a show-stopper for me.\n",
            ", Similarity: 0.2139\n",
            "Summary & Description: make sure mutable attributes copied read infinispan \n",
            " After OGM-10, the verdict is that Infinispan might return the same instance for read values. We should check if this is a problem, and make sure all stored values which are exposed to the user are either using a copy or are immutable., Similarity: 0.1768\n",
            "Summary & Description: ogm emfind polymorphic \n",
            " OGM EntityManager.find() method is not polymorphic.  A unit test is attached and also available in pull request #131 as /hibernate-ogm/src/test/java/org/hibernate/ogm/test/jpa/JPAPolymorphismTest.java, Similarity: 0.3543\n",
            "Summary & Description: beef documentation around mongodb datastore \n",
            " our goal is to explain why / when MongoDB makes sense\n",
            "and explain how to get started and use it with OGM (ie the basic configuration options - possible even on the MongoDB side)\n",
            "\n",
            "And to polish things, a description on how things are stored on the MongoDB side\t\t\tso people understand we don't write blobs in the MongoDB but ueful data, Similarity: 0.3780\n",
            "Summary & Description: hibernate search massindexer work ogm \n",
            " As noticed on OGM-18 the MassIndexer component of Hibernate Search is currently not compatible with Hibernate OGM.\n",
            "\n",
            "A different approach to mass indexing is needed for OGM, and the GridDialect should at least provide a way to iterate efficiently on all entities; the definition of \"efficient\" varies from datastore to datastore, so the parameters would likely need to be different., Similarity: 0.2816\n",
            "Summary & Description: documentation build faster \n",
            " On my current machine, it takes between 3 and 4 minutes to build the documentation. Bean Validation for example takes less than a minute. The key difference is that Bean Validation embarks the DocBook dtd or xsd and locally reference them from the docbook xml files. \n",
            "\n",
            "Explore how to do that for Hibernate OGM (and Search and Vaidator). I suspect that since the docbook processing is a maven module, we won't be able to easily reuse that. But we could bring the dtd in our git repo and point them locally., Similarity: 0.4097\n",
            "Summary & Description: avoid table scan mongodb operations \n",
            " All tests should pass even when enabling the MongoDB server configuration option\n",
            "{code}notablescan = true{code}, Similarity: 0.3129\n",
            "Summary & Description: allow setting customize timeout mongodb connection reduce tests \n",
            " Today when the mongodb instance is not present, it takes a long time before the tests give up. We should reduce the timeout period., Similarity: 0.2746\n",
            "Summary & Description: limit redundancy storing association information non embedded way \n",
            " With the work done in IN_ENTITY (MongoDB), we now see that we don't really require to store as much data as we are doing today in regular Associations.\n",
            "Plus the structure is questionable redundancy wise (using MongoDB's example)\n",
            "\n",
            "{code}\n",
            "{\n",
            "    \"_id\" : ObjectId(\"4ff6c04fa8fa2db9fd76f34b\"),\n",
            "    \"columns\" : { \"Cloud_id\" : \"da3d8f5d-f024-4c6a-b813-81a7a643a08b\" },\n",
            "    \"rows\" : [ { \n",
            "            \"table\" : \"Cloud_SnowFlake\", \n",
            "            \"columns\" : { \n",
            "                \"Cloud_id\" : \"da3d8f5d-f024-4c6a-b813-81a7a643a08b\",\n",
            "                \"producedSnowFlakes_id\" : \"27b678d2-0f17-43bc-801e-2a714f1cca8c\"\n",
            "                },\n",
            "            \"tuple\" : { \n",
            "                \"Cloud_id\" : \"da3d8f5d-f024-4c6a-b813-81a7a643a08b\", \n",
            "                \"producedSnowFlakes_id\" : \"27b678d2-0f17-43bc-801e-2a714f1cca8c\"\n",
            "                }\n",
            "           },\n",
            "           {\n",
            "            \"table\" : \"Cloud_SnowFlake\",\n",
            "            \"columns\" : {\n",
            "                \"Cloud_id\" : \"da3d8f5d-f024-4c6a-b813-81a7a643a08b\",\n",
            "                \"producedSnowFlakes_id\" : \"cc80b5db-0db3-47a0-96fb-dbc70793c832\"\n",
            "                },\n",
            "            \"tuple\" : {\n",
            "                \"Cloud_id\" : \"da3d8f5d-f024-4c6a-b813-81a7a643a08b\",\n",
            "                \"producedSnowFlakes_id\" : \"cc80b5db-0db3-47a0-96fb-dbc70793c832\"\n",
            "                }\n",
            "        } ],\n",
            "    \"table\" : \"Cloud_SnowFlake\" \n",
            "}\n",
            "{code}\n",
            "\n",
            "We could rethink that to only store the relevant bits of information and use _id in a similar way as we do now for entities since OGM-174.\n",
            "The new structure could be\n",
            "\n",
            "{code}\n",
            "{\n",
            "    \"_id\" : \"da3d8f5d-f024-4c6a-b813-81a7a643a08b\", \n",
            "    // If a composite key, it would be\n",
            "    // \"_id\": {  \"Cloud_id\" : \"da3d8f5d-f024-4c6a-b813-81a7a643a08b\", \"foo_id\": 3}\n",
            "\n",
            "    //table is only present if we are not using GLOBAL_COLLECTION\n",
            "    \"table\" : \"Cloud_SnowFlake\",\n",
            "\n",
            "    \"rows\" : [ \n",
            "        { \n",
            "            \"producedSnowFlakes_id\" : \"27b678d2-0f17-43bc-801e-2a714f1cca8c\"\n",
            "        },\n",
            "        {\n",
            "            \"producedSnowFlakes_id\" : \"cc80b5db-0db3-47a0-96fb-dbc70793c832\"\n",
            "        } ]\n",
            "}\n",
            "{code}, Similarity: 0.3669\n",
            "Summary & Description: create facility ogm core dialects receive custom metadata annotation programmatic associated entities properties associations \n",
            " Typically we should be able to transfer the following metadata to the MongoDB driver\n",
            "\n",
            "{code}\n",
            "@Entity\n",
            "public class User {\n",
            "    @ManyToMany\n",
            "    @EmbeddedInDocument\n",
            "    public Set<Address> addresses;\n",
            "}\n",
            "{code}\n",
            "\n",
            "The facility should be extensible to make sure a driver can add any necessary custom metadata.\n",
            "A programmatic mapping API would be useful too., Similarity: 0.4934\n",
            "Summary & Description: make mongodbs association storage strategy available per association \n",
            " Using the new option mechanism, the association storage strategy should be configurable for the MongoDB dialect on a per entity/property base, via annotations and API.\n",
            "\n",
            "* Move the annotation, enum and programmatic APIs from _couchdb_ to _core_ (/)\n",
            "* Have only {{IN_ENTITY}} and {{AS_DOCUMENT}} on the enum in _core (/)\n",
            "* Provide {{@StoreAssociationsInSeparateCollection}} in MongoDB (/)\n",
            "* Implement association handling in {{MongoDBDialect}} based on the setting applying for a given association similar to {{CouchDBDialect}} (/)\n",
            "\n",
            "ML reference: http://lists.jboss.org/pipermail/hibernate-dev/2013-December/010741.html, Similarity: 0.4463\n",
            "Summary & Description: rename propertymetadataprovider local variables \n",
            " The name is inherited from the past. This class is really about using associations and maintaining consistency between sides, Similarity: 0.1564\n",
            "Summary & Description: offer shortcuts datastore providers \n",
            " Today, a user needs to set hibernate.ogm.datastore.provider and use the implementation class.\n",
            "I am not happy with that situation, I'd like to use shortnames instead:\n",
            "\n",
            "- they will be easier to setup\n",
            "- they will hide the fact that the class is in an impl package and hence should not be used by the user directly\n",
            "\n",
            "We could have:\n",
            "\n",
            "- infinispan\n",
            "- ehacache\n",
            "- mongodb, Similarity: 0.4285\n",
            "Summary & Description: updates mongodbdialect use id columns restriction \n",
            " I'm pretty sure that today we use the DBObject we load from MongoDB do be the filter query in the update operation.\n",
            "\n",
            "We should restrict it to the id column(s). Probably _id once OGM-174 is closed. Otherwise we might end up not updating the data by having a too restrictive query.\n",
            "\n",
            "Guillaume, does my analysis makes sense? Or does the MongoDB driver automatically filter by _id somehow and ignore the rest?, Similarity: 0.3248\n",
            "Summary & Description: support redis datastore \n",
            " Implement the datastore provider and dialect for Redis., Similarity: 0.3059\n",
            "Summary & Description: avoid tostring implementations use multi line formatting \n",
            " I'm having to examine quite long logs and this is making it hard to process, Similarity: 0.2290\n",
            "Summary & Description: persistentlistreadfrom method throws exception without workaround voldemort datastore provider \n",
            " On a test called org.hibernate.ogm.test.associations.collection.types.ListTest, OgmCollectionPersister.readIndex returns a Double instead of Integer. the readIndex method is called by PersistentList.readFrom method like below:\n",
            "\n",
            "{code:title=PersistentList.readFrom|borderStyle=solid}\n",
            "int index = \n",
            "     ( (Integer) persister.readIndex( rs, descriptor.getSuffixedIndexAliases(), getSession() ) ).intValue();\n",
            "{code}\n",
            "Since it tries to cast Double to Integer, it throws ClassCastException saying \"Double cannot be cast to Integer\". However, this happens with only the Voldemort datastore provider and other datatore providers don't need any workaround and don't have any issues with the method call. This is a bug on the Voldemort datastore provider. Need to be investigated and fixed without any workaround.\n",
            "\n",
            "The workaround currently used is like below:\n",
            "{code:title=Workaround in OgmCollectionPersister.readIndex|borderStyle=solid}\n",
            "\t\tfinal TupleAsMapResultSet resultset = rs\n",
            "                .unwrap(TupleAsMapResultSet.class);\n",
            "        final Tuple keyTuple = resultset.getTuple();\n",
            "        Object obj = indexGridType\n",
            "                .nullSafeGet(keyTuple, aliases, session, null);\n",
            "\n",
            "// workaround starts from here\n",
            "Object res = null;\n",
            "        try {\n",
            "            res = obj.getClass().getDeclaredMethod(\"intValue\").invoke(obj);\n",
            "        } catch (IllegalArgumentException e) {\n",
            "            throw new HibernateException(e);\n",
            "        } catch (SecurityException e) {\n",
            "            throw new HibernateException(e);\n",
            "        } catch (IllegalAccessException e) {\n",
            "            throw new HibernateException(e);\n",
            "        } catch (InvocationTargetException e) {\n",
            "            throw new HibernateException(e);\n",
            "        } catch (NoSuchMethodException e) {\n",
            "            return obj;\n",
            "        }\n",
            "        return res;\n",
            "// workaround ends\n",
            "{code}, Similarity: 0.3141\n",
            "Summary & Description: support embedded neo4j datastore \n",
            " Integrate Neo4J as a datastore for Hibernate OGM., Similarity: 0.4184\n",
            "Summary & Description: rework entitykeybuilder remove method called getcolumnmap \n",
            " To make Voldemort work with hibernate OGM, the implementation adds a method in EntityKeyBuilder called getColumnMap to get column names when fields use different names as its column names. The mapping seems required to deserialize JSON to an object with the correct type. However, it' not necessary to be there and also it only returns one column name as String which is not right.\n",
            "\n",
            "Rework EntityKeyBuilder to remove the method., Similarity: 0.2206\n",
            "Summary & Description: make mongodb safe option defaults true hibernate ogm \n",
            " I am now convinced that safe=false is a very very bad default and that we should override it. I'd rather see people forcing safe to false., Similarity: 0.2280\n",
            "Summary & Description: composite id fail mongodb mongodbdialect takes first id column account force id \n",
            " MongoDB dialect.getObject(EntityKey) does the following\n",
            "\n",
            "{code}DBObject searchObject = new BasicDBObject( ID_FIELDNAME, key.getColumnValues()[0] );{code}\n",
            "\n",
            "This cannot work in composite id environments. Same in createTuple(), Similarity: 0.3372\n",
            "Summary & Description: load necessary properties mongodb \n",
            " Today we load the whole MongoDB document. It can contain the association information wich might not be useful (lazy collections) and it can contain properties used by other apps but not mapped by Hibernate OGM.\n",
            "It would be better to explicitly select the list of properties we are interested in., Similarity: 0.4437\n",
            "Summary & Description: create indexes identifier columns id mongodb datastore \n",
            " At DatastoreProvider bootstrap we could make sure indexes exist or otherwise create them for all columns involved in a lookup. ie the identifier columns for entities, associations and sequences.\n",
            "\n",
            "This is related to OGM-156 and arguably a better approach., Similarity: 0.4089\n",
            "Summary & Description: make hibernate search query use findbyid instead query dont implement criteria \n",
            " The following default settings need to be done in {{OgmConfiguration}} and {{HibernateOgmPersistence}}:\n",
            "\n",
            "{code}\n",
            "hibernate.search.query.object_lookup_method = skip\n",
            "hibernate.search.query.database_retrieval_method = find_by_id\n",
            "{code}, Similarity: 0.2590\n",
            "Summary & Description: configurable wherehow associations stored mongodb dialect \n",
            " Add a configuration property which will allow user to choose where associations are stored:\n",
            "\n",
            "1) in a prefixed collection - eg. associations_Entity.\n",
            "2) in a global collection.\n",
            "3) in the same collection as the entity, in a separate document at the same level.\n",
            "\n",
            "I've done this, patch will follow., Similarity: 0.3772\n",
            "Summary & Description: add support safemode \n",
            " Use the org.hibernate.ogm.safemode (= true | false | no set) \n",
            "Should we provide more options to support Majority and Fsync_safe modes as well ?\n",
            "Here is there a description of each mode \n",
            "http://www.littlelostmanuals.com/2011/11/overview-of-basic-mongodb-java-write.html\n",
            ", Similarity: 0.3101\n",
            "Summary & Description: persistence provider specified emf creation taking persistenceunitinfo defaults ogm instead plain orm \n",
            " Basically the method\n",
            "org.hibernate.ogm.jpa.HibernateOgmPersistence.createContainerEntityManagerFactory(PersistenceUnitInfo, Map)\n",
            "\n",
            "when checking on {code}persistenceProviderClassName == null{code} should return null rather than attempt to start OGM.\n",
            "\n",
            "trivial fix but requires a test as this wasn't covered., Similarity: 0.4064\n",
            "Summary & Description: avoid using table scan mongodb nextvalue implementation \n",
            " I'm referring to the MongoDBDialect.nextValue implementation: when enabling the configuration option\n",
            "{code}notablescan = true{code}\n",
            "the tests using it fail., Similarity: 0.3681\n",
            "Summary & Description: timezone persisted \n",
            " TimeZone information from Calendar objects are not persisted in hibernate OGM because it use the org.hibernate.type.descriptor.java.CalendarDateTypeDescriptor class mapping only; dd MMMM yyyy \n",
            "\n",
            "The class org.hibernate.type.descriptor.java.TimeZoneTypeDescriptor.class from hibernate-core should be used as well possibly., Similarity: 0.2611\n",
            "Summary & Description: reduce memory consumption sharing metadata information key objects \n",
            " Today EntityKey, AssociationKey, RowKey are composed of a metadata part (table name and column names) and a data part (column values).\n",
            "Besides, AssociationKey also embeds collection role and owner's EntityKey.\n",
            "\n",
            "We could have a model where Key object receive a KeyMetadata object whose instances is shared and kept in Persister/Loader. This will reduce memory consumption.\n",
            "\n",
            "We can in addition consider putting non identifier metadata in a separate object (collection role and entity key owner information) and pass this object to the GridDialect. This object could even be specialized per datastore based on specific metadata hosted on entity / associations., Similarity: 0.2602\n",
            "Summary & Description: support types builtintypetest \n",
            " To help with new dialects like MongoDB add extra type coverage to the BuiltInType test., Similarity: 0.3167\n",
            "Summary & Description: expose collection type map set list etc underlying structure might smarter \n",
            " See https://hibernate.atlassian.net/browse/OGM-144?focusedCommentId=46123&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-46123, Similarity: 0.3873\n",
            "Summary & Description: support associations mongodb alan fitton \n",
            " h3. Proposal 1\n",
            "\n",
            "{code:javascript}\n",
            "{ \n",
            "    \"_id\" : ObjectId(\"4f7486c6318ca0fafa7761d0\"), \n",
            "    \"columnNames\" : [ \"addresses_id\" ], \n",
            "    \"columnValues\" : [ \"169e2d61-ce39-4bca-8300-185487df7119\" ], \n",
            "    \"rows\" : { \n",
            "        \"-387062339\" : { \n",
            "            \"table\" : \"User_Address\", \n",
            "            \"columnNames\" : [ \"User_id\", \"nick\" ], \n",
            "            \"columnValues\" : [ \"f11e01e8-7c2f-4795-81dc-94de7c4ba246\", \"home\" ] \n",
            "         } \n",
            "    }, \n",
            "    \"table\" : \"User_Address\" \n",
            "}\n",
            "{code}\t\n",
            "\n",
            "h3. Proposal 2\n",
            "\n",
            "{code:javascript}\n",
            "//example 2: closer to how entities are stored\n",
            "{ \n",
            "    \"_id\" : ObjectId(\"4f7486c6318ca0fafa7761d0\"), \n",
            "    \"table\" : \"User_Address\", \n",
            "    \"columnNames\" : [ \"addresses_id\" ], \n",
            "    \"columnValues\" : [ \"169e2d61-ce39-4bca-8300-185487df7119\" ], \n",
            "    \"rows\" : { \n",
            "        \"9d2386c6318ca0fafa32867ae\" : { \n",
            "            \"User_id\": \"f11e01e8-7c2f-4795-81dc-94de7c4ba246\",\n",
            "            \"nick\": \"home\"\n",
            "         } \n",
            "    }\n",
            "}\t\n",
            "{code}\n",
            "\n",
            "h3. Proposal 3 assuming MongoDB collection == table\n",
            "\n",
            "{code:javascript}\n",
            "//example 3: considering that MongoDB collections == tables\n",
            "// in collection \"User_Address\"\n",
            "{ \n",
            "    \"_id\" : ObjectId(\"4f7486c6318ca0fafa7761d0\"), \n",
            "    \"addresses_id\": \"169e2d61-ce39-4bca-8300-185487df7119\", \n",
            "    \"rows\" : { \n",
            "        \"9d2386c6318ca0fafa32867ae\" : { \n",
            "            \"User_id\": \"f11e01e8-7c2f-4795-81dc-94de7c4ba246\",\n",
            "            \"nick\": \"home\"\n",
            "         } \n",
            "    }\n",
            "}\t\n",
            "{code}, Similarity: 0.3438\n",
            "Summary & Description: implement dialectnextvalue mongodb \n",
            " MongoDB ha the notion of findAndModify operation that is perfect to map nextValue.\n",
            "\n",
            "http://www.mongodb.org/display/DOCS/findAndModify+Command\n",
            "\n",
            "What they call side counter method http://www.mongodb.org/display/DOCS/How+to+Make+an+Auto+Incrementing+Field, Similarity: 0.3868\n",
            "Summary & Description: tests dont cleanup failure \n",
            " Some tests are not cleaning up.\n",
            "When running the testsuite and having many failures (because of implementation problems) some errors show\n",
            "{quote}\n",
            "ARJUNA016051: thread is already associated with a transaction!\n",
            "{quote}\n",
            "While the test is opening it's first transaction. I guess some other test didn't close it., Similarity: 0.2263\n",
            "Summary & Description: refresh documentation next release \n",
            " Assigning this to Sanne to put pressure on him ;), Similarity: 0.1452\n",
            "Summary & Description: fix logs basicgridbinder \n",
            " From Guillaume\n",
            "\n",
            "I have noticed that the BasicGridBinder has a problem when it logs the\n",
            "bindding  ( BasicGridBinder.bind(Tuple, X, String[] ) method).\n",
            "Actually, the trace is \"binding [$s] to parameter(s) $s\" but it should be\n",
            "\"binding [thevalue] to parameter(s) theparameter\".\n",
            "It can be fixed easily by modifying the two calls to log.tracef() (line 70\n",
            "and 76) respectively like that:\n",
            "\n",
            "log.tracef( \"binding [null] to parameter [%1$s]\", name );\n",
            "and\n",
            "log.tracef( \"binding [%1$s] to parameter(s) %2$s\",\n",
            "javaDescriptor.extractLoggableRepresentation( value ), Arrays.toString(\n",
            "names ) );, Similarity: 0.4217\n",
            "Summary & Description: create table cassandra createdrop create set \n",
            " Today the keyspace is properly guarded but not the table creation, Similarity: 0.1341\n",
            "Summary & Description: unable find gridtype orghibernatetypeserializabletype \n",
            " When I try to retrieve an EntityManager via:\n",
            "EntityManagerFactory emf = Persistence.createEntityManagerFactory(\"mongoPU\");\n",
            "The mongoPU persistence unit is described in persistence.xml\n",
            "\n",
            "I got an expection which tells me \"Unable to build EntityManagerFactory\" and in the stack trace there is:\n",
            "Caused by: org.hibernate.HibernateException: Unable to find a GridType for org.hibernate.type.SerializableType\t\n",
            "at org.hibernate.ogm.type.impl.TypeTranslatorImpl.getType(TypeTranslatorImpl.java:110)\n",
            "\n",
            "So I looked into the TypeTranslatorImpl class and indeed there is no:\n",
            "typeConverter.put( SerializableTypeDescriptor.INSTANCE, SerializableType.INSTANCE );\n",
            "\n",
            "All files are in attachement.\n",
            ", Similarity: 0.3974\n",
            "Summary & Description: clarify doc jtaplatform option required \n",
            " This happens automatically for Hibernate Core, but currently OGM requires the option\n",
            "{code}\n",
            "hibernate.transaction.jta.platform = org.hibernate.service.jta.platform.internal.JBossAppServerJtaPlatform\n",
            "{code}\n",
            "\n",
            "or\n",
            "{code}<property name=\"jboss.as.jpa.adapterModule\" value=\"org.jboss.as.jpa.hibernate:4\"/>{code}\n",
            "as documented on https://docs.jboss.org/author/display/AS71/JPA+Reference+Guide, Similarity: 0.6004\n",
            "Summary & Description: ogm persistence provider fails build emf due missing datasource \n",
            " I'm trying to switch JBoss AS7 quickstart example Kitchensink (https://github.com/jbossas/quickstart/tree/master/kitchensink) to use Hibernate OGM.\n",
            "This is my modified example code: https://github.com/mlinhard/quickstart/commit/b027f7476bbb007e0477122d7672ef19ac110a90\n",
            "\n",
            "I'm using JBoss AS 7.1.0.Final.\n",
            "And Hibernate OGM 3.0.0-SNAPSHOT built from sources (https://github.com/hibernate/hibernate-ogm), last commit e6381d04b3d1a35b5c12aba40454124c20693ad5\n",
            "\n",
            "When I set up the needed modules in AS7 (see readme.md) and deploy the example using mvn jboss-as:deploy.\n",
            "I get an exception: see server.log, Similarity: 0.5373\n",
            "Summary & Description: concurrentmodificationexception loading associations load \n",
            " {quote}class: class java.util.ConcurrentModificationException\n",
            "cause: null\n",
            "java.util.ConcurrentModificationException\n",
            "\tat java.util.HashMap$HashIterator.nextEntry(HashMap.java:793)\n",
            "\tat java.util.HashMap$KeyIterator.next(HashMap.java:828)\n",
            "\tat java.util.AbstractCollection.addAll(AbstractCollection.java:305)\n",
            "\tat org.hibernate.ogm.datastore.spi.Association.getKeys(Association.java:132)\n",
            "\tat org.hibernate.ogm.loader.OgmLoader.getResultSet(OgmLoader.java:417)\n",
            "\tat org.hibernate.ogm.loader.OgmLoader.doQuery(OgmLoader.java:248)\n",
            "\tat org.hibernate.ogm.loader.OgmLoader.doQueryAndInitializeNonLazyCollections(OgmLoader.java:215)\n",
            "\tat org.hibernate.ogm.loader.OgmLoader.loadCollection(OgmLoader.java:185)\n",
            "\tat org.hibernate.ogm.loader.OgmBasicCollectionLoader.initialize(OgmBasicCollectionLoader.java:42)\n",
            "\tat org.hibernate.persister.collection.AbstractCollectionPersister.initialize(AbstractCollectionPersister.java:622)\n",
            "\tat org.hibernate.event.internal.DefaultInitializeCollectionEventListener.onInitializeCollection(DefaultInitializeCollectionEventListener.java:82)\n",
            "\tat org.hibernate.internal.SessionImpl.initializeCollection(SessionImpl.java:1606)\n",
            "\tat org.hibernate.collection.internal.AbstractPersistentCollection.initialize(AbstractPersistentCollection.java:379)\n",
            "\tat org.hibernate.collection.internal.AbstractPersistentCollection.read(AbstractPersistentCollection.java:112)\n",
            "\tat org.hibernate.collection.internal.PersistentSet.iterator(PersistentSet.java:180){quote}, Similarity: 0.4391\n",
            "Summary & Description: make hibernate ogm compile run tests using jdk 7 jdk 6 \n",
            " Three methods are missing from three classes.\n",
            "They are in abstract parent classes according to the stack trace and are required to be overridden.\n",
            "The output from maven is attached., Similarity: 0.3419\n",
            "Summary & Description: typo chapter 43 \n",
            " hiber*m*ate.format_sql, Similarity: 0.0488\n",
            "Summary & Description: nosuchmethoderror cachemanagerserviceprovidercreatecustomcachemanager \n",
            " method CacheManagerServiceProvider.createCustomCacheManager calls InfinispanConfiguration.newInfinispanConfiguration(\n",
            "\t\t\t\t\tString configFileName, String schemaFileName, ConfigurationValidatingVisitor cbv);\n",
            "\n",
            "InfinispanConfiguration configuration = InfinispanConfiguration.newInfinispanConfiguration(\n",
            "\t\t\t\t\tcfgName, InfinispanConfiguration.resolveSchemaPath(),\n",
            "\t\t\t\t\tnew ConfigurationValidatingVisitor());\n",
            "\n",
            "but the Infinispan API does not have this method as of 5.0.0 CR7\n",
            "\n",
            "the most similar method available in the Infinispan API is InfinispanConfiguration.newInfinispanConfiguration(String configFileName, String schemaFileName, ConfigurationBeanVisitor cbv, ClassLoader cl) \n",
            "\n",
            "\n",
            "Result is \n",
            "java.lang.NoSuchMethodError: org.infinispan.config.InfinispanConfiguration.newInfinispanConfiguration(Ljava/lang/String;Ljava/lang/String;Lorg/infinispan/config/ConfigurationBeanVisitor;)Lorg/infinispan/config/InfinispanConfiguration;\n",
            "\tat org.hibernate.ogm.datastore.infinispan.impl.CacheManagerServiceProvider.createCustomCacheManager(CacheManagerServiceProvider.java:126)\n",
            "\tat org.hibernate.ogm.datastore.infinispan.impl.CacheManagerServiceProvider.start(CacheManagerServiceProvider.java:80)\n",
            "\tat org.hibernate.ogm.metadata.GridMetadataManager.sessionFactoryCreated(GridMetadataManager.java:55)\n",
            "\tat org.hibernate.impl.SessionFactoryImpl.<init>(SessionFactoryImpl.java:478)\n",
            "\tat org.hibernate.cfg.Configuration.buildSessionFactory(Configuration.java:1845)\n",
            "\tat org.hibernate.ejb.Ejb3Configuration.buildEntityManagerFactory(Ejb3Configuration.java:906)\n",
            "\tat org.hibernate.ejb.HibernatePersistence.createContainerEntityManagerFactory(HibernatePersistence.java:74)\n",
            "\tat org.hibernate.ogm.jpa.HibernateOgmPersistence.createContainerEntityManagerFactory(HibernateOgmPersistence.java:142)\n",
            "\tat org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:225)\n",
            "\tat org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.afterPropertiesSet(AbstractEntityManagerFactoryBean.java:308)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1477)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1417)\n",
            "\t... 17 more, Similarity: 0.4638\n",
            "Summary & Description: simplify ogm configuration hibernate core native apis used wrap ogmsession davide dalto \n",
            " Yeah, it's in :), Similarity: 0.3032\n",
            "Summary & Description: abstract griddialect infinispans cache api \n",
            " See the discussion on this thread http://www.mailinglistarchive.com/html/hibernate-dev@lists.jboss.org/2011-05/msg00022.html\n",
            "and specifically this message http://www.mailinglistarchive.com/html/hibernate-dev@lists.jboss.org/2011-05/msg00044.html\n",
            "\n",
            "I think Datastore is the best we have so far, Similarity: 0.4640\n",
            "Summary & Description: think need embed column names keys \n",
            " Today keys embed table names and both column names and column values.\n",
            "this of course is not strictly needed, we could exclude column values, but is that a good or a bad thing?\n",
            "\n",
            "An alternative could be to not embed primary key columns in the tuple. That would also achieve the required compactness but it may make the implementation more complex. Maybe the expected Tuple object could hide this complexity., Similarity: 0.1396\n",
            "Summary & Description: infinispan configuration requires writeskewchecktrue \n",
            " The MVCC capabilities of Infinispan need to be explicitly enabled using the writeSkewCheck flag, Similarity: 0.3451\n",
            "Summary & Description: support pure infinispan client mode hibernate ogm \n",
            " There are several levels at play:\n",
            " - allow an OGM client to not join the grid as a full fledge node\n",
            " - support transactions over hotrod (including suspend and co)\n",
            " - support query over hotrod (ie ability to pass the Teiid query via HotRod and let Teiid nodes run on the Infinispan grid)\n",
            "\n",
            "The latest is not fleshed out though and will require refinement., Similarity: 0.3646\n",
            "Summary & Description: remove unused code branches unnecessary null checks \n",
            " I ran the FindBugs code analysis tool and noticed that there are some unnecessary null checks and unused code branches in Hibernate OGM Core module, like the following example from OgmLoader:\n",
            "\n",
            "{code:title=OgmLoader.java}\n",
            "//we don't load more than one instance per row, shortcircuiting it for the moment\n",
            "final int[] collectionOwners = null;\n",
            "\n",
            "for ( int i=0; i<collectionPersisters.length; i++ ) {\n",
            "\tfinal CollectionAliases[] descriptors = getCollectionAliases();\n",
            "\tfinal boolean hasCollectionOwners = collectionOwners !=null &&\n",
            "\t\t\tcollectionOwners[i] > -1;\n",
            "\t//true if this is a query and we are loading multiple instances of the same collection role\n",
            "\t//otherwise this is a CollectionInitializer and we are loading up a single collection or batch\n",
            "\n",
            "\tfinal Object owner = hasCollectionOwners ?\n",
            "\t\t\trow[ collectionOwners[i] ] :\n",
            "\t\t\tnull; //if null, owner will be retrieved from session\n",
            "\n",
            "\tfinal CollectionPersister collectionPersister = collectionPersisters[i];\n",
            "\tfinal Serializable key;\n",
            "\tif ( owner == null ) {\n",
            "\t\tkey = null;\n",
            "\t}\n",
            "\telse {\n",
            "\t\tkey = collectionPersister.getCollectionType().getKeyOfOwner( owner, session );\n",
            "\t\t//TODO: old version did not require hashmap lookup:\n",
            "\t\t//keys[collectionOwner].getIdentifier()\n",
            "\t}\n",
            "\n",
            "\treadCollectionElement(\n",
            "\t\t\towner,\n",
            "\t\t\tkey,\n",
            "\t\t\tcollectionPersister,\n",
            "\t\t\tdescriptors[i],\n",
            "\t\t\tresultSet, //TODO CURRENT must use the same instance across all calls\n",
            "\t\t\tsession\n",
            "\t\t);\n",
            "{code} \n",
            "\n",
            "Note that {{collectionOwners}} is always {{null}}. Thus, {{hasCollectionOwners}} is always {{false}}, causing {{owner}} to always be {{null}}. Then, the {{if ( owner == null ) }} will always be evaluated as true, turning the else part to be unnecessary. The above code can be rewritten as:\n",
            "\n",
            "{code:title=OgmLoader.java}\n",
            "final CollectionAliases[] descriptors = getCollectionAliases(); // this line was inside the for loop... it seems it can be outside\n",
            "for ( int i=0; i<collectionPersisters.length; i++ ) {\n",
            "\tfinal CollectionPersister collectionPersister = collectionPersisters[i];\n",
            "\n",
            "\treadCollectionElement(\n",
            "\t\t\tnull,\n",
            "\t\t\tnull,\n",
            "\t\t\tcollectionPersister,\n",
            "\t\t\tdescriptors[i],\n",
            "\t\t\tresultSet, //TODO CURRENT must use the same instance across all calls\n",
            "\t\t\tsession\n",
            "\t\t);\n",
            "}\n",
            "{code} \n",
            "\n",
            "This JIRA is to track similar issues to the example above. , Similarity: 0.3067\n",
            "Summary & Description: getting started infinispan doesnt needs explicitly added maven dependencies \n",
            " After Emmanuel's comment on pull request #7 about his surprise that Infinispan needed to be explicitly added to the maven dependency list, I decided to double check and, indeed, it doesn't. I removed it and the Getting Started code still works fine. , Similarity: 0.3554\n",
            "Summary & Description: provide full implementation getting started \n",
            " The information provided in the Getting Started is good enough for reading, but one has problems when trying to actually transform that into code. So, it would be nice to provide a full implementation, containing all the configuration files and all sources, to be used as a reference for readers trying to implement the Getting Started. , Similarity: 0.3309\n",
            "Summary & Description: getting started code doesnt compiles missing maven dependencies \n",
            " Most of the code in the Getting Started section in the documentation assumes that we are inside a test environment (src/test/java) and even mentions some testing API, but nowhere in the document it's mentioned that users should create the code as a test. As there are already plenty of examples in the test suite, the proposal is to improve the Getting Started to work as a standalone application. \n",
            "\n",
            "Another related issue is that some maven dependencies are not specified, and other are transitively resolved, but in the wrong scope. , Similarity: 0.3606\n",
            "Summary & Description: make ogm work explicit hibernate transaction demarcation \n",
            " Delegate to a JTA Transaction Manager underneath to get Infinispan behave transactionally. Use DummyTransactionManager initially as JBoss Tx would require another dependency for the user., Similarity: 0.3733\n",
            "Summary & Description: make sure test clean entries done \n",
            " This does not appear to be the case. When you open a second node, some entities remain when running the test suite., Similarity: 0.1594\n",
            "Summary & Description: rewrite ogmtestcase broken ways \n",
            " The sessionFactory handling (sessions) expect:\n",
            " - to reuse the same sessionFActory across test (good)\n",
            " - does not close the sessionfactory during the latest test\n",
            "\n",
            "this model works if everyone extends OgmTestCase but that's not true.\n",
            "=> the test suite fails when used in a cluster\n",
            "\n",
            "We should get rid of this session factory reuse code / assumption entirely:\n",
            " - done by closing and nullifying the sessions object on tearDown \n",
            "\n",
            "The code should be cleaned up though\n",
            "\n",
            ", Similarity: 0.2339\n",
            "Summary & Description: use externalizers serializable types infinispan \n",
            " http://infinispan.org/docs/6.0.x/user_guide/user_guide.html#_plugging_infinispan_with_user_defined_externalizers, Similarity: 0.4142\n",
            "Summary & Description: concurrentmodificationexception arraylist representing collection \n",
            " Several instances can access the collection and try and update things. Since the underlying implementation is a simple ArrayList, you can get ConcurrentModificationException if someone reads it while someone else update it.\n",
            "\n",
            "{code}\n",
            "Exception in thread \"pool-5-thread-2\" java.util.ConcurrentModificationException\n",
            "\tat java.util.AbstractList$Itr.checkForComodification(AbstractList.java:372)\n",
            "\tat java.util.AbstractList$Itr.next(AbstractList.java:343)\n",
            "\tat org.hibernate.ogm.util.impl.PropertyMetadataProvider.findMatchingTuple(PropertyMetadataProvider.java:137)\n",
            "\tat org.hibernate.ogm.persister.Dehydrator.doRemovePropertyMetadata(Dehydrator.java:219)\n",
            "\tat org.hibernate.ogm.persister.Dehydrator.dehydrate(Dehydrator.java:140)\n",
            "\tat org.hibernate.ogm.persister.OgmEntityPersister.dehydrate(OgmEntityPersister.java:784)\n",
            "\tat org.hibernate.ogm.persister.OgmEntityPersister.update(OgmEntityPersister.java:747)\n",
            "\tat org.hibernate.action.EntityUpdateAction.execute(EntityUpdateAction.java:113)\n",
            "\tat org.hibernate.engine.ActionQueue.execute(ActionQueue.java:273)\n",
            "\tat org.hibernate.engine.ActionQueue.executeActions(ActionQueue.java:265)\n",
            "\tat org.hibernate.engine.ActionQueue.executeActions(ActionQueue.java:185)\n",
            "\tat org.hibernate.event.def.AbstractFlushingEventListener.performExecutions(AbstractFlushingEventListener.java:321)\n",
            "\tat org.hibernate.event.def.DefaultFlushEventListener.onFlush(DefaultFlushEventListener.java:51)\n",
            "\tat org.hibernate.impl.SessionImpl.flush(SessionImpl.java:1216)\n",
            "\tat org.hibernate.impl.SessionImpl.managedFlush(SessionImpl.java:383)\n",
            "\tat org.hibernate.transaction.JDBCTransaction.commit(JDBCTransaction.java:133)\n",
            "\tat pt.ist.fenixframework.example.bankbench.hib.HibTxSystem.doIt(HibTxSystem.java:85)\n",
            "\tat pt.ist.fenixframework.example.bankbench.TxCommand.run(TxCommand.java:14)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n",
            "\tat java.lang.Thread.run(Thread.java:680)\n",
            "{code}\n",
            "\n",
            "Problem:\n",
            " - the collection should be copied on read and that's not the case\n",
            " - the proper approach is to wrap it as an AtomicMap to benefit from the \"diff\" change\n",
            " - longer term, we need the merge on conflict policy in Infinispan., Similarity: 0.2897\n",
            "Summary & Description: make sure hibernate ogm works fine seam \n",
            " injectable\n",
            "unwrap  / getDelegate() in particular unwrap(Session.class)  / SessionFactory\n",
            "HibernateEntityManager.getSessionFactory(), Similarity: 0.3838\n",
            "Summary & Description: implement referencablegetreference ogmsessionfactory davide dalto \n",
            " low priority, Similarity: 0.4210\n",
            "Summary & Description: support gridtypes \n",
            " Today we only support basic numeric and string types\n",
            "We should support other types like URL, BigDecimal etc, Similarity: 0.1815\n",
            "Summary & Description: discuss manik whether copy read necessary \n",
            " From what Manik said recently, they do marshal data when putting it in the map and thus a copy on read is not necessary.\n",
            "\n",
            "Clarify that and make sure mutable types do a proper copy on read if that's not the case., Similarity: 0.0662\n",
            "Summary & Description: add support lazy properties mostly ogmentitypersister \n",
            " This have very few interest as currently ISPN does load all the AtomicMap and not only a subset like select column1, column2 would do.\n",
            "\n",
            "Still one could:\n",
            " - ask for an ISPN improvement\n",
            " - reduce some memory consumption even if the full AtomicMap is retrieved., Similarity: 0.3088\n",
            "Summary & Description: make jpa work resourcelocal \n",
            " This probably will require to write a custom Hibernate Transaction implementation that use batch or something approaching., Similarity: 0.4657\n",
            "Summary & Description: write decent default infinispan configuration file \n",
            " So far the default config file is\n",
            "\n",
            "{code}<infinispan/>{code}\n",
            "\n",
            "I suspect it's not enough :), Similarity: 0.3927\n",
            "Summary & Description: spring boot upgrade 278 302 formula annotation working \n",
            " Hi Team, we recently upgraded our project from Spring boot 2.7.8 to 3.0.2. After this @Formula annotation is not working. Previously we use to see that in query but now only column value is retrieved without formula logic. Please need help on this. We DB2zDialect., Similarity: 0.3084\n",
            "Summary & Description: reflection use classloaderservice \n",
            " In a setup with [PF4J|https://pf4j.org/] with entities from multiple plugins, where each plugin has its own {{ClassLoader}}.\n",
            "\n",
            "After registering a {{ClassLoaderService}} with the service registry which knows about all these {{PluginClassLoader}} and adding the annotated entities through {{Configuration#addAnnotatedClass}} , the entities can be loaded just fine.\n",
            "\n",
            "Unfortunately, it is not possible to add a {{@ManyToOne}} annotation for classes from different classloaders: one of the plugins has a dependency on the other and I had hoped to use classes from the other plugin.\n",
            "\n",
            "But when adding that {{@ManyToOne}} annotation, a {{java.lang.NoClassDefFoundError}} is thrown.\n",
            "\n",
            "This seems to occur at {{org.hibernate.annotations.common.reflection.java.JavaXClass.getDeclaredMethodProperties(JavaXClass.java:97)}} where {{toClass().getDeclaredMethods()}} is invoked. This being a part of {{java.lang.Class}}, it doesn’t have access to the {{ClassLoaderService}} and has no chance to look up the associated class.\n",
            "\n",
            "This happens independently from the order in which classes were added with {{addAnnotatedClass}}: even if the first class has already been added and scanned successfully, the second class will fail to scan., Similarity: 0.5113\n",
            "Summary & Description: approximation parameterized type wrongly defaults object instead raw type \n",
            " While debugging the test for [https://hibernate.atlassian.net/browse/HHH-15822|https://hibernate.atlassian.net/browse/HHH-15822|smart-link] I realized that HCANN reports a wrong type for a property {{T prop}} where {{T extends Self<T>}}., Similarity: 0.2401\n",
            "Summary & Description: pageable query collection join fetches found entities loaded memory entities requested page could lead outofmemoryerror cases \n",
            " Duplicate of [https://hibernate.atlassian.net/browse/HHH-15852|https://hibernate.atlassian.net/browse/HHH-15852|smart-link]. I’ve created the bug in the wrong project., Similarity: 0.3636\n",
            "Summary & Description: generate sql error \n",
            " When I was doing ORM selection, I wrote some test codes as follows:\n",
            "\n",
            "\n",
            "{code:java}\n",
            "@Entity(name = \"t_log\")\n",
            "public class Log implements Serializable {\n",
            "  @Id\n",
            "  @GeneratedValue(strategy = GenerationType.IDENTITY)\n",
            "  @Column(columnDefinition = \"integer COMMENT 'No'\")\n",
            "  private Integer id;\n",
            "{code}\n",
            "\n",
            "\n",
            "But the Hibernate generated SQL doesn't work properly\n",
            "\n",
            "\n",
            "{code:sql}\n",
            "create table t_log (\n",
            "       id integer {color:red}COMMENT 'No' {color}generated by default as identity,\n",
            "        action varchar(30) COMMENT 'OP'\n",
            "        primary key (id)\n",
            "    )\n",
            "{code}\n",
            "\n",
            "This is because 'COMMENT' is not at the end of the sentence., Similarity: 0.1730\n",
            "Summary & Description: hibernateentitymanager fails initialise composite id \n",
            " all starts from here:\n",
            "https://stackoverflow.com/questions/59209739/org-hibernate-mappingexception-composite-id\n",
            "they solve the issue using @IdClass and it works !\n",
            "problem:\n",
            " it works with 5.4.10.Final:\n",
            "        <dependency>\n",
            "            <groupId>org.hibernate</groupId>\n",
            "            <artifactId>hibernate-entitymanager</artifactId>\n",
            "            <version>5.4.10.Final</version>\n",
            "        </dependency>\n",
            "but it definitely fails with 6.0.0.Alpha4:\n",
            "        <dependency>\n",
            "            <groupId>org.hibernate.orm</groupId>\n",
            "            <artifactId>hibernate-entitymanager</artifactId>\n",
            "            <version>6.0.0.Alpha4</version>\n",
            "        </dependency>\n",
            "\n",
            "\n",
            ", Similarity: 0.3276\n",
            "Summary & Description: hhh000270 type registration javautiluuid overrides previous orghibernatetypeuuidbinarytype2e9dcdd3 \n",
            " hii team \n",
            "I am getting stuck after this line \n",
            "HHH000270: Type registration [java.util.UUID] overrides previous : org.hibernate.type.UUIDBinaryType@2e9dcdd3\n",
            "\n",
            "please guide me through \n",
            "\n",
            "\n",
            "my dependencies are here and spring boot version is 2.1.6.RELEASE\n",
            "<dependencies>\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.springframework.boot</groupId>\n",
            "\t\t\t<artifactId>spring-boot-starter-web</artifactId>\n",
            "\t\t</dependency>\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.springframework.boot</groupId>\n",
            "\t\t\t<artifactId>spring-boot-starter-quartz</artifactId>\n",
            "\t\t</dependency>\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.springframework.boot</groupId>\n",
            "\t\t\t<artifactId>spring-boot-starter-aop</artifactId>\n",
            "\t\t\t<version>2.1.6.RELEASE</version>\n",
            "\t\t</dependency>\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.mongodb</groupId>\n",
            "\t\t\t<artifactId>mongo-java-driver</artifactId>\n",
            "\t\t\t<version>2.11.4</version>\n",
            "\t\t</dependency>\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.springframework.boot</groupId>\n",
            "\t\t\t<artifactId>spring-boot-starter-test</artifactId>\n",
            "\t\t\t<scope>test</scope>\n",
            "\t\t</dependency>\n",
            "\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>io.springfox</groupId>\n",
            "\t\t\t<artifactId>springfox-swagger2</artifactId>\n",
            "\t\t\t<version>${springfox-swagger2.version}</version>\n",
            "\t\t</dependency>\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>io.springfox</groupId>\n",
            "\t\t\t<artifactId>springfox-swagger-ui</artifactId>\n",
            "\t\t\t<version>${springfox-swagger2.version}</version>\n",
            "\t\t</dependency>\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>com.google.code.gson</groupId>\n",
            "\t\t\t<artifactId>gson</artifactId>\n",
            "\t\t\t<version>2.6.1</version>\n",
            "\t\t</dependency>\n",
            "\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.apache.commons</groupId>\n",
            "\t\t\t<artifactId>commons-lang3</artifactId>\n",
            "\t\t\t<version>3.1</version>\n",
            "\t\t</dependency>\n",
            "\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.postgresql</groupId>\n",
            "\t\t\t<artifactId>postgresql</artifactId>\n",
            "\t\t\t<scope>runtime</scope>\n",
            "\t\t</dependency>\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>javax.persistence</groupId>\n",
            "\t\t\t<artifactId>javax.persistence-api</artifactId>\n",
            "\t\t\t<version>2.2</version>\n",
            "\t\t</dependency>\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.springframework.data</groupId>\n",
            "\t\t\t<artifactId>spring-data-commons</artifactId>\n",
            "\t\t\t<version>2.1.5.RELEASE</version>\n",
            "\t\t</dependency>\n",
            "\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.springframework.boot</groupId>\n",
            "\t\t\t<artifactId>spring-boot-starter-data-jpa</artifactId>\n",
            "\t\t</dependency>\n",
            "\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>com.amazonaws</groupId>\n",
            "\t\t\t<artifactId>aws-java-sdk</artifactId>\n",
            "\t\t\t<version>1.11.589</version>\n",
            "\t\t</dependency>\n",
            "\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>javax.ws.rs</groupId>\n",
            "\t\t\t<artifactId>javax.ws.rs-api</artifactId>\n",
            "\t\t\t<version>2.0</version>\n",
            "\t\t</dependency>\n",
            "\n",
            "\t\t<!-- https://mvnrepository.com/artifact/org.keycloak/keycloak-authz-client -->\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.keycloak</groupId>\n",
            "\t\t\t<artifactId>keycloak-authz-client</artifactId>\n",
            "\t\t\t<version>6.0.0</version>\n",
            "\t\t</dependency>\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.keycloak</groupId>\n",
            "\t\t\t<artifactId>keycloak-admin-client</artifactId>\n",
            "\t\t\t<version>6.0.0</version>\n",
            "\t\t</dependency>\n",
            "\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.jboss.resteasy</groupId>\n",
            "\t\t\t<artifactId>resteasy-client</artifactId>\n",
            "\t\t\t<version>3.1.3.Final</version>\n",
            "\t\t</dependency>\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.jboss.resteasy</groupId>\n",
            "\t\t\t<artifactId>resteasy-jackson2-provider</artifactId>\n",
            "\t\t\t<version>3.1.3.Final</version>\n",
            "\t\t</dependency>\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>javax.activation</groupId>\n",
            "\t\t\t<artifactId>activation</artifactId>\n",
            "\t\t\t<version>1.1.1</version>\n",
            "\t\t</dependency>\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.springframework.boot</groupId>\n",
            "\t\t\t<artifactId>spring-boot-starter-actuator</artifactId>\n",
            "\t\t</dependency>\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.junit.jupiter</groupId>\n",
            "\t\t\t<artifactId>junit-jupiter</artifactId>\n",
            "\t\t\t<version>RELEASE</version>\n",
            "\t\t\t<scope>test</scope>\n",
            "\t\t</dependency>\n",
            "\n",
            "\t</dependencies>, Similarity: 0.3674\n",
            "Summary & Description: hibernate envers getting error restarting tomcat enverse audit table \n",
            " Hibernate: alter table user_details_AUD add constraint FKs3kmax48dhaox392n8nk3ac40 foreign key (REV) references REVINFO (REV)\n",
            "WARN [main] o.h.t.s.i.ExceptionHandlerLoggedImpl.handleException(27) | GenerationTarget encountered exception accepting command : Error executing DDL \"alter table user_details_AUD add constraint FKs3kmax48dhaox392n8nk3ac40 foreign key (REV) references REVINFO (REV)\" via JDBC Statement\n",
            "org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL \"alter table user_details_AUD add constraint FKs3kmax48dhaox392n8nk3ac40 foreign key (REV) references REVINFO (REV)\" via JDBC Statement\n",
            "\tat org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67)\n",
            "\tat org.hibernate.tool.schema.internal.AbstractSchemaMigrator.applySqlString(AbstractSchemaMigrator.java:559)\n",
            "\tat org.hibernate.tool.schema.internal.AbstractSchemaMigrator.applySqlStrings(AbstractSchemaMigrator.java:504)\n",
            "\tat org.hibernate.tool.schema.internal.AbstractSchemaMigrator.applyForeignKeys(AbstractSchemaMigrator.java:433)\n",
            "\tat org.hibernate.tool.schema.internal.AbstractSchemaMigrator.performMigration(AbstractSchemaMigrator.java:249)\n",
            "\tat org.hibernate.tool.schema.internal.AbstractSchemaMigrator.doMigration(AbstractSchemaMigrator.java:114)\n",
            "\tat org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:183)\n",
            "\tat org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:72)\n",
            "\tat org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:309)\n",
            "\tat org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:462)\n",
            "\tat org.hibernate.cfg.Configuration.buildSessionFactory(Configuration.java:708)\n",
            "\tat org.hibernate.cfg.Configuration.buildSessionFactory(Configuration.java:724)\n",
            "\tat org.springframework.orm.hibernate5.LocalSessionFactoryBean.buildSessionFactory(LocalSessionFactoryBean.java:615)\n",
            "\tat org.springframework.orm.hibernate5.LocalSessionFactoryBean.afterPropertiesSet(LocalSessionFactoryBean.java:599)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1804)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1741)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:576)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)\n",
            "\tat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)\n",
            "\tat org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:273)\n",
            "\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1239)\n",
            "\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1166)\n",
            "\tat org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:593)\n",
            "\tat org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)\n",
            "\tat org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1378)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:575)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)\n",
            "\tat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)\n",
            "\tat org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:273)\n",
            "\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1239)\n",
            "\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1166)\n",
            "\tat org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:593)\n",
            "\tat org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)\n",
            "\tat org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1378)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:575)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)\n",
            "\tat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)\n",
            "\tat org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:273)\n",
            "\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1239)\n",
            "\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1166)\n",
            "\tat org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:593)\n",
            "\tat org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)\n",
            "\tat org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1378)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:575)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)\n",
            "\tat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)\n",
            "\tat org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:273)\n",
            "\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1239)\n",
            "\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1166)\n",
            "\tat org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:593)\n",
            "\tat org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:90)\n",
            "\tat org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:374)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1378)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:575)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)\n",
            "\tat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)\n",
            "\tat org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:367)\n",
            "\tat org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:110)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1648)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1400)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:575)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)\n",
            "\tat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)\n",
            "\tat org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:367)\n",
            "\tat org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:110)\n",
            "\tat org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveManagedList(BeanDefinitionValueResolver.java:401)\n",
            "\tat org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:159)\n",
            "\tat org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:660)\n",
            "\tat org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:188)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1308)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1154)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:538)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)\n",
            "\tat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)\n",
            "\tat org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:367)\n",
            "\tat org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:110)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1648)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1400)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:575)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)\n",
            "\tat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)\n",
            "\tat org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:367)\n",
            "\tat org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:110)\n",
            "\tat org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveManagedList(BeanDefinitionValueResolver.java:401)\n",
            "\tat org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:159)\n",
            "\tat org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:660)\n",
            "\tat org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:188)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1308)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1154)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:538)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)\n",
            "\tat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)\n",
            "\tat org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:367)\n",
            "\tat org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:110)\n",
            "\tat org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveManagedList(BeanDefinitionValueResolver.java:401)\n",
            "\tat org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:159)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1648)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1400)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:575)\n",
            "\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:498)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320)\n",
            "\tat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318)\n",
            "\tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)\n",
            "\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:827)\n",
            "\tat org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:863)\n",
            "\tat org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:546)\n",
            "\tat org.springframework.web.context.ContextLoader.configureAndRefreshWebApplicationContext(ContextLoader.java:400)\n",
            "\tat org.springframework.web.context.ContextLoader.initWebApplicationContext(ContextLoader.java:291)\n",
            "\tat org.springframework.web.context.ContextLoaderListener.contextInitialized(ContextLoaderListener.java:103)\n",
            "\tat org.apache.catalina.core.StandardContext.listenerStart(StandardContext.java:4602)\n",
            "\tat org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5066)\n",
            "\tat org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183)\n",
            "\tat org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1427)\n",
            "\tat org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1417)\n",
            "\tat java.util.concurrent.FutureTask.run(Unknown Source)\n",
            "\tat org.apache.tomcat.util.threads.InlineExecutorService.execute(InlineExecutorService.java:75)\n",
            "\tat java.util.concurrent.AbstractExecutorService.submit(Unknown Source)\n",
            "\tat org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:943)\n",
            "\tat org.apache.catalina.core.StandardHost.startInternal(StandardHost.java:839)\n",
            "\tat org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183)\n",
            "\tat org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1427)\n",
            "\tat org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1417)\n",
            "\tat java.util.concurrent.FutureTask.run(Unknown Source)\n",
            "\tat org.apache.tomcat.util.threads.InlineExecutorService.execute(InlineExecutorService.java:75)\n",
            "\tat java.util.concurrent.AbstractExecutorService.submit(Unknown Source)\n",
            "\tat org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:943)\n",
            "\tat org.apache.catalina.core.StandardEngine.startInternal(StandardEngine.java:258)\n",
            "\tat org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183)\n",
            "\tat org.apache.catalina.core.StandardService.startInternal(StandardService.java:422)\n",
            "\tat org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183)\n",
            "\tat org.apache.catalina.core.StandardServer.startInternal(StandardServer.java:770)\n",
            "\tat org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:183)\n",
            "\tat org.apache.catalina.startup.Catalina.start(Catalina.java:682)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n",
            "\tat java.lang.reflect.Method.invoke(Unknown Source)\n",
            "\tat org.apache.catalina.startup.Bootstrap.start(Bootstrap.java:350)\n",
            "\tat org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:492)\n",
            "Caused by: java.sql.SQLIntegrityConstraintViolationException: Can't write; duplicate key in table '#sql-85c_15924a'\n",
            "\tat com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:115)\n",
            "\tat com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:95)\n",
            "\tat com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)\n",
            "\tat com.mysql.cj.jdbc.StatementImpl.executeInternal(StatementImpl.java:790)\n",
            "\tat com.mysql.cj.jdbc.StatementImpl.execute(StatementImpl.java:675)\n",
            "\tat com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)\n",
            "\tat org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54)\n",
            "\t... 169 common frames omitted, Similarity: 0.2221\n",
            "Summary & Description: hibernate manytomany relation infinite db calls \n",
            " In Many to Many bidirectional relation . When I try to get all the Entities from DB . I see infinite db calls to concerned tables.  More details \n",
            "http://stackoverflow.com/questions/42626306/hibernate-manytomany-mapping-infinite-db-calls?noredirect=1#comment72380595_42626306, Similarity: 0.2408\n",
            "Summary & Description: hibjpa21 able create 2 diff generators \n",
            " I was working on small POC, wanted to use 2 generator values in hbm.xml files using Hibernate 5.2.1+ Spring 4.3.1.\n",
            "\n",
            "*<hibernate-mapping>*\n",
            " *<class name=\"hibernate.test.Employee\" table=\"emptest2\">*\n",
            "\t\t*<id name=\"uid\">*\n",
            "\t\t\t*<generator class=\"uuid\"/>*\n",
            "\t\t*</id>*\n",
            "\t*<property name=\"name\" />*\n",
            " *</class>*\n",
            "*</hibernate-mapping>*\n",
            "\n",
            "I want to make it generic for different databases, for that I have to maintain 2 different hbm.xml files for different dbs. May be I need to pass Custom generator value like uuid2, guid for connectivity with 2 databases but seems not possible or don't have any idea on this or Needed to pass a classname which can check the dialect or something.\n",
            "\n",
            "When I see the code for DefaultIdentifierGeneratorFactory, here it registers generator (_register( \"uuid2\", UUIDGenerator.class );_) and maps to their relevant class file. I can't see any customized value or anything.\n",
            "\n",
            "Also, I see one comment here with this:\n",
            "\n",
            "*register( \"guid\", GUIDGenerator.class );*\n",
            "*// can be done with UUIDGenerator + strategy*\n",
            "\n",
            "which I was unable to understand that how can I make a GUIDGenerator from UUIDGenerator+strategy. Please let me know the solution., Similarity: 0.3544\n",
            "Summary & Description: field based javaxproperty creates unnecessary objects \n",
            " Current implementation of the Reflection API does not use the same caching as used for auto-boxing. This has been fixed in JDK 9 (see https://bugs.openjdk.java.net/browse/JDK-5043030 for details) but not in JDK 8 or 7. Therefore, when JavaXProperty reads for example a primitive field of the type \"boolean\", it creates every time a new object of type \"Boolean\". We can workaround this problem by using getter-methods of the Field class, which return primitive values, and wrapping the result using the valueOf-methods of the wrapper classes., Similarity: 0.5052\n",
            "Summary & Description: javalangnosuchmethoderror orgjbossloggingloggerdebugf \n",
            " Hi\n",
            "\n",
            "I don't know if this is correct section for this issue but i will try to drop it here :).\n",
            "I have problems with deployment of ear that contains Hibernate libs and it's dependencies, error is like follows:\n",
            "{noformat}\n",
            "<1449043276733> <[severity-value: 8] [rid: 0] [partition-id: 0] [partition-name: DOMAIN] > <BEA-240003> <Administration Console encountered the following error: weblogic.management.DeploymentException: java.lang.NoSuchMethodError: org.jboss.logging.Logger.debugf(Ljava/lang/String;I)V\n",
            "\tat weblogic.application.internal.BaseDeployment.throwAppException(BaseDeployment.java:131)\n",
            "\tat weblogic.application.internal.BaseDeployment.prepare(BaseDeployment.java:245)\n",
            "\tat weblogic.application.internal.EarDeployment.prepare(EarDeployment.java:67)\n",
            "\tat weblogic.application.internal.DeploymentStateChecker.prepare(DeploymentStateChecker.java:158)\n",
            "\tat weblogic.deploy.internal.targetserver.AppContainerInvoker.prepare(AppContainerInvoker.java:61)\n",
            "\tat weblogic.deploy.internal.targetserver.operations.ActivateOperation.createAndPrepareContainer(ActivateOperation.java:229)\n",
            "\tat weblogic.deploy.internal.targetserver.operations.ActivateOperation.doPrepare(ActivateOperation.java:103)\n",
            "\tat weblogic.deploy.internal.targetserver.operations.AbstractOperation.prepare(AbstractOperation.java:237)\n",
            "\tat weblogic.deploy.internal.targetserver.DeploymentManager.handleDeploymentPrepare(DeploymentManager.java:792)\n",
            "\tat weblogic.deploy.internal.targetserver.DeploymentManager.prepareDeploymentList(DeploymentManager.java:1306)\n",
            "\tat weblogic.deploy.internal.targetserver.DeploymentManager.handlePrepare(DeploymentManager.java:264)\n",
            "\tat weblogic.deploy.internal.targetserver.DeploymentServiceDispatcher.prepare(DeploymentServiceDispatcher.java:177)\n",
            "\tat weblogic.deploy.service.internal.targetserver.DeploymentReceiverCallbackDeliverer.doPrepareCallback(DeploymentReceiverCallbackDeliverer.java:171)\n",
            "\tat weblogic.deploy.service.internal.targetserver.DeploymentReceiverCallbackDeliverer.access$000(DeploymentReceiverCallbackDeliverer.java:13)\n",
            "\tat weblogic.deploy.service.internal.targetserver.DeploymentReceiverCallbackDeliverer$1.run(DeploymentReceiverCallbackDeliverer.java:46)\n",
            "\tat weblogic.work.SelfTuningWorkManagerImpl$WorkAdapterImpl.run(SelfTuningWorkManagerImpl.java:643)\n",
            "\tat weblogic.invocation.ComponentInvocationContextManager._runAs(ComponentInvocationContextManager.java:348)\n",
            "\tat weblogic.invocation.ComponentInvocationContextManager.runAs(ComponentInvocationContextManager.java:333)\n",
            "\tat weblogic.work.LivePartitionUtility.doRunWorkUnderContext(LivePartitionUtility.java:54)\n",
            "\tat weblogic.work.PartitionUtility.runWorkUnderContext(PartitionUtility.java:41)\n",
            "\tat weblogic.work.SelfTuningWorkManagerImpl.runWorkUnderContext(SelfTuningWorkManagerImpl.java:617)\n",
            "\tat weblogic.work.ExecuteThread.execute(ExecuteThread.java:397)\n",
            "\tat weblogic.work.ExecuteThread.run(ExecuteThread.java:346)\n",
            "Caused by: java.lang.NoSuchMethodError: org.jboss.logging.Logger.debugf(Ljava/lang/String;I)V\n",
            "\tat org.hibernate.internal.NamedQueryRepository.checkNamedQueries(NamedQueryRepository.java:149)\n",
            "\tat org.hibernate.internal.SessionFactoryImpl.checkNamedQueries(SessionFactoryImpl.java:764)\n",
            "\tat org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:495)\n",
            "\tat org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:444)\n",
            "\tat org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:802)\n",
            "\tat org.hibernate.jpa.HibernatePersistenceProvider.createContainerEntityManagerFactory(HibernatePersistenceProvider.java:135)\n",
            "\tat weblogic.persistence.BasePersistenceUnitInfo.initializeEntityManagerFactory(BasePersistenceUnitInfo.java:611)\n",
            "\tat weblogic.persistence.BasePersistenceUnitInfo.init(BasePersistenceUnitInfo.java:199)\n",
            "\tat weblogic.persistence.BaseJPAIntegrationProvider.createPersistenceUnitInfo(BaseJPAIntegrationProvider.java:54)\n",
            "\tat weblogic.persistence.AbstractPersistenceUnitRegistry.storeDescriptors(AbstractPersistenceUnitRegistry.java:422)\n",
            "\tat weblogic.persistence.EarPersistenceUnitRegistry.initialize(EarPersistenceUnitRegistry.java:72)\n",
            "\tat weblogic.persistence.PersistenceDeployment$PersistenceDeploymentExtension.prepare(PersistenceDeployment.java:67)\n",
            "\tat weblogic.application.internal.flow.AppDeploymentExtensionFlow.prepare(AppDeploymentExtensionFlow.java:25)\n",
            "\tat weblogic.application.internal.BaseDeployment$1.next(BaseDeployment.java:730)\n",
            "\tat weblogic.application.utils.StateMachineDriver.nextState(StateMachineDriver.java:45)\n",
            "\tat weblogic.application.internal.BaseDeployment.prepare(BaseDeployment.java:242\n",
            "{noformat}\n",
            "\n",
            "It's occurs during deployment - i looked into org.jboss.logging.Logger sources and - indeed - there is no method with only String parameter.\n",
            "\n",
            "jboss-logging is in version: 3.3.Final\n",
            "\n",
            "\n",
            "I've tried 5.0.0.Final and 5.0.4.Final with the same result., Similarity: 0.3316\n",
            "Summary & Description: polymorphismtype polymorphismtypeexplicit work expected \n",
            " According to the docs, using this annotation config should exclude the annotated type from queries using superclasses of its hierarchy but I'm unable to replicate this behavior., Similarity: 0.2069\n",
            "Summary & Description: better handling multiple matching getters stem name \n",
            " {code}\n",
            "\n",
            "\t@Entity\n",
            "\tpublic static class TheEntity {\n",
            "\t\tprivate Integer id;\n",
            "\n",
            "\t\tpublic boolean isId() {\n",
            "\t\t\treturn false;\n",
            "\t\t}\n",
            "\n",
            "\t\t@Id\n",
            "\t\tpublic Integer getId() {\n",
            "\t\t\treturn id;\n",
            "\t\t}\n",
            "\n",
            "\t\tpublic void setId(Integer id) {\n",
            "\t\t\tthis.id = id;\n",
            "\t\t}\n",
            "\t}\n",
            "{code}\n",
            "\n",
            "HCANN treats this class as having 2 attributes, one defined by the getId and another defined by the isId, both with the same \"attribute name\".\n",
            "\n",
            ", Similarity: 0.1856\n",
            "Summary & Description: depend beta version120beta1 orgjbossloggingjbossloggingannotations \n",
            " I want to know the reason of depend to 1.2.0.Bata1. (why not depend to 1.2.0.Final)\n",
            "\n",
            "If possible and no problem, i hope to depend on 1.2.0.Final. , Similarity: 0.3117\n",
            "Summary & Description: columnlengthn works field property \n",
            " If I use \"@Column(length=25)\" on a String field, it creates the field in the database at a length of 25 as expected.  If I move the annotation to the getter for the field, it appears to have no effect.  The generated SQL confirms that it uses the length limit in one case but not the other.  I have a program that re-creates the database from scratch when it runs; it runs fine in both cases with no error, but makes no use of the length in the second case that I can tell.\n",
            "\n",
            "I feel certain that there's something that I'm missing, that this can't possibly have gone unnoticed, but I cannot find anything to indicate that it's a known problem, or that there is something else that is supposed to be in the program that I don't have there.\n",
            "\n",
            "The program is run with a Derby running in server mode; the word \"create\" is passed on the command line (not case sensitive)`, Similarity: 0.1273\n",
            "Summary & Description: test failure java 8 \n",
            " Hi,\n",
            "\n",
            "There is a test failure when building hibernate-commons-annotations with Java 8:\n",
            "\n",
            "{code}\n",
            ":testClasses\n",
            ":test\n",
            "\n",
            "org.hibernate.annotations.common.test.annotationfactory.AnnotationFactoryTest > testCreatesProxyInstancesOfAnnotations FAILED\n",
            "    java.lang.RuntimeException at AnnotationFactoryTest.java:33\n",
            "        Caused by: java.lang.IllegalAccessException at AnnotationFactoryTest.java:33\n",
            "\n",
            "59 tests completed, 1 failed\n",
            ":test FAILED\n",
            "{code}, Similarity: 0.2889\n",
            "Summary & Description: collections arent declared using javautil interfaces recognized collections \n",
            " See HHH-4417 for a discussion.  Anything that implements java.util.Collection (or Map) should be recognized as a collection for the sake of annotations processing.  Hibernate ORM can prevent using such a collection if it's not able to bind it, but that should be up to it, but the type itself is a collection regardless.\n",
            "\n",
            "I'll be submitting a patch for ORM to actually handle the cases, but this will be a dependency of that.  Implementing this alone will just change the error that is received (making it more accurate, as it happens)., Similarity: 0.2909\n",
            "Summary & Description: property name beginning least two uppercase characters odd functionality hql \n",
            " When using annotated beans I found an instance where if you have a field name which then has a method name where that method name has 2 uppercase characters in a row, the Introspector.decapitalize() method will leave that property alone.  This then causes HQL to fail when you try to reference the actual field name (as we try to keep with the bean property format).  Example:\n",
            "\n",
            "{code}\n",
            "class Foo {\n",
            "  private String bAr = \"\";\n",
            "  @Column(name = \"bar\")\n",
            "  public String getBAr() { return this.bAr; }\n",
            "  public void setBAr(String bAr) { this.bAr = bAr; }\n",
            "}\n",
            "{code}\n",
            "\n",
            "When referencing \"Foo.bAr = \" in HQL it will fail saying that \"bAr\" doesn't exist.  In the logs, the field is actually referenced (by the AnnotationBinder) as \"Foo.BAr\"\n",
            "\n",
            "I'm not sure if this is intended, and I understand why (given the concept behind the Introspector.decapitalize() functionality) it works this way.  But if this is correct, then maybe there should be some documentation to at least indicate that this is how it works since it is not as simple as \"capitalize/decapitalize the first letter.\", Similarity: 0.1810\n",
            "Summary & Description: orghibernateannotationscommonutilstandardclassloaderdelegateimpl throws missingformatargumentexception \n",
            " I got the following Exception since using 4.3.0:\n",
            "\n",
            "java.util.MissingFormatArgumentException: Format specifier 's'\n",
            "       at java.util.Formatter.format(Formatter.java:2487)\n",
            "       at java.util.Formatter.format(Formatter.java:2423)\n",
            "       at java.lang.String.format(String.java:2797)\n",
            "       at org.jboss.logging.Slf4jLocationAwareLogger.doLogf(Slf4jLocationAwareLogger.java:81)\n",
            "       at org.jboss.logging.Logger.debugf(Logger.java:553)\n",
            "       at org.hibernate.annotations.common.util.StandardClassLoaderDelegateImpl.classForName(StandardClassLoaderDelegateImpl.java:53)\n",
            "       at org.hibernate.annotations.common.reflection.java.JavaReflectionManager.packageForName(JavaReflectionManager.java:147)\n",
            "       at org.hibernate.cfg.AnnotationBinder.bindPackage(AnnotationBinder.java:295)\n",
            "       at org.hibernate.cfg.Configuration.addPackage(Configuration.java:815)\n",
            "\n",
            ", Similarity: 0.3754\n",
            "Summary & Description: genericgenerators working 430cr2 \n",
            " I have this annotated entity code that's working in 4.2.0.Final but not in 4.3.0.CR2.\n",
            "\n",
            "{code}\n",
            "@Entity\n",
            "@Table(name = \"party_category_tax\", schema = \"ichibanmae_invo\")\n",
            "public class PartyTaxCategory implements java.io.Serializable {\n",
            "\n",
            "    private static final long serialVersionUID = -5119203949164267871L;\n",
            "\n",
            "    private PartyCategory partyCategory;\n",
            "    private String partyCategoryId;\n",
            "    \n",
            "    @Id \n",
            "    @GeneratedValue(generator = \"customSharedIdGenerator\")\n",
            "    @GenericGenerator(name = \"customSharedIdGenerator\", strategy = \"foreign\", parameters = @Parameter(name = \"property\", value = \"partyCategory\"))\n",
            "    @Column(name = \"party_category_id\", unique = true, nullable = false, length = 40) \n",
            "    public String getPartyCategoryId() {\n",
            "        return partyCategoryId;\n",
            "    }   \n",
            "\n",
            "    public void setPartyCategoryId(String partyCategoryId) {\n",
            "        this.partyCategoryId = partyCategoryId;\n",
            "    }\n",
            "....\n",
            "}\n",
            "{code}\n",
            "\n",
            "I get the following exception at deploy time when I try to deploy it against 4.3.0.CR2 libraries in JBoss eap 6.1, but deploys find against 4.2.0.Final libs which come bundled with jboss.\n",
            "\n",
            "{code}\n",
            "Caused by: org.hibernate.AnnotationException: Unknown Id.generator: customSharedIdGenerator\n",
            "    at org.hibernate.cfg.BinderHelper.makeIdGenerator(BinderHelper.java:640)\n",
            "    at org.hibernate.cfg.AnnotationBinder.processId(AnnotationBinder.java:2230)\n",
            "    at org.hibernate.cfg.AnnotationBinder.processElementAnnotations(AnnotationBinder.java:2136)\n",
            "    at org.hibernate.cfg.AnnotationBinder.processIdPropertiesIfNotAlready(AnnotationBinder.java:834)\n",
            "    at org.hibernate.cfg.AnnotationBinder.bindClass(AnnotationBinder.java:753)\n",
            "    at org.hibernate.cfg.Configuration$MetadataSourceQueue.processAnnotatedClassesQueue(Configuration.java:3762)\n",
            "    at org.hibernate.cfg.Configuration$MetadataSourceQueue.processMetadata(Configuration.java:3716)\n",
            "    at org.hibernate.cfg.Configuration.secondPassCompile(Configuration.java:1410)\n",
            "    at org.hibernate.cfg.Configuration.buildSessionFactory(Configuration.java:1844)\n",
            "    at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl$4.perform(EntityManagerFactoryBuilderImpl.java:850)\n",
            "    ... 11 more\n",
            "{code}\n",
            "\n",
            "I walked through the code in a debugger and found that in line 732 of AnnotationBinder.java\n",
            "{code}\n",
            "final InheritanceState.ElementsToProcess elementsToProcess = inheritanceState.getElementsToProcess();\n",
            "{code}\n",
            "\n",
            "getElementToProcess Is not returning the complete lets of annotations on the id method, in the failing case.\n",
            "\n",
            "Please find a test case attached., Similarity: 0.3321\n",
            "Summary & Description: expose declaring class xmember \n",
            " Initially thinking:\n",
            "{code}\n",
            "/**\n",
            " * Retrieve the XClass reference for the class which declares this property.\n",
            " * .. \n",
            " */\n",
            "public XClass getDeclaringClass();\n",
            "{code}\n",
            "\n",
            "Another option that would work for the use case I have would be:\n",
            "{code}\n",
            "/**\n",
            " * Determine whether the property is declared by the class represented by the given XClass.\n",
            " * .. \n",
            " */\n",
            "public boolean isDeclaredBy(XClass xClass);\n",
            "{code}\n",
            ", Similarity: 0.1326\n",
            "Summary & Description: add osgi metadata \n",
            " Hibernate core 4.3.0-Beta1 contains OSGi metadata yet one of its major dependencies does not.\n",
            "\n",
            "I am not able to deploy this into any OSGi container.\n",
            "\n",
            "{code}\n",
            "[2013-04-11T13:05:42.039-0400] [glassfish 4.0] [INFO] [] [] [tid: _ThreadID=87 _ThreadName=Thread-4] [timeMillis: 1365699942039] [levelValue: 800] [[\n",
            "  org.osgi.framework.BundleException: Unresolved constraint in bundle org.hibernate.core [381]: Unable to resolve 381.0: missing requirement [381.0] osgi.wiring.package; (osgi.wiring.package=org.hibernate.annotations.common)\n",
            "\tat org.apache.felix.framework.Felix.resolveBundleRevision(Felix.java:3974)\n",
            "\tat org.apache.felix.framework.Felix.startBundle(Felix.java:2037)\n",
            "\tat org.apache.felix.framework.BundleImpl.start(BundleImpl.java:955)\n",
            "\tat org.apache.felix.fileinstall.internal.DirectoryWatcher.process(DirectoryWatcher.java:1175)\n",
            "\tat org.apache.felix.fileinstall.internal.DirectoryWatcher.process(DirectoryWatcher.java:1153)\n",
            "\tat org.apache.felix.fileinstall.internal.DirectoryWatcher.processAllBundles(DirectoryWatcher.java:1146)\n",
            "\tat org.apache.felix.fileinstall.internal.DirectoryWatcher.process(DirectoryWatcher.java:456)\n",
            "\tat org.apache.felix.fileinstall.internal.DirectoryWatcher.run(DirectoryWatcher.java:263)]]\n",
            "{code}\n",
            ", Similarity: 0.4090\n",
            "Summary & Description: support osgi hibernatecommonsannotations \n",
            " HHH-7527 will need hibernate-commons-annotations to provide an OSGi manifest., Similarity: 0.2864\n",
            "Summary & Description: way specify names unique check constraints \n",
            " There is no way to specify names for unique constraints.\n",
            "\n",
            "For example, there is no way to specify a name for this constraint:\n",
            "\n",
            "@Column(unique=true)\n",
            "private String columnA;\n",
            "\n",
            "A way to solve this problem is to add a \"name\" attribute to @UniqueConstraint annotation., Similarity: 0.1506\n",
            "Summary & Description: formula failed quoted namingstrategy \n",
            " In my project I use specific NamingStrategy (org.hibernate.cfg.NamingStrategy).\n",
            "\n",
            "Each column name is wrapped by quotas - _dialect.openQuote() + columnName + _dialect.closeQuote().\n",
            "\n",
            "Then I try to use a @Formula with one of the property:\n",
            "\n",
            "@Formula(\"(select sum(s.\\\"prodCount\\\") from SensorEntry as s where s.\\\"job_id\\\" = \\\"id\\\")\")\n",
            "private Long value;\n",
            "\n",
            "This transforms into:\n",
            "select sum(s.job_.\"prodCount\") from SensorEntry as s where s.job_.\"job_id\" = job_.\"id\") as formula24_\n",
            "\n",
            "Which leads to exception:\n",
            "19:18:37,268  WARN main JDBCExceptionReporter:100 - SQL Error: 0, SQLState: 3F000\n",
            "19:18:37,269 ERROR main JDBCExceptionReporter:101 - ERROR: schema \"s\" does not exist\n",
            "19:18:37,270 ERROR main AbstractFlushingEventListener:324 - Could not synchronize database state with session\n",
            "org.hibernate.exception.GenericJDBCException: unable to select generated column values\n",
            "\tat org.hibernate.exception.SQLStateConverter.handledNonSpecificException(SQLStateConverter.java:126)\n",
            "\tat org.hibernate.exception.SQLStateConverter.convert(SQLStateConverter.java:114)\n",
            "\tat org.hibernate.exception.JDBCExceptionHelper.convert(JDBCExceptionHelper.java:66)\n",
            "\tat org.hibernate.persister.entity.AbstractEntityPersister.processGeneratedProperties(AbstractEntityPersister.java:3754)\n",
            "\tat org.hibernate.persister.entity.AbstractEntityPersister.processInsertGeneratedProperties(AbstractEntityPersister.java:3703)\n",
            "\tat org.hibernate.action.EntityInsertAction.execute(EntityInsertAction.java:89)\n",
            "\tat org.hibernate.engine.ActionQueue.execute(ActionQueue.java:279)\n",
            "\n",
            "I suppose that this is because quota literals don't escaped correctly by Hibernate., Similarity: 0.2527\n",
            "Summary & Description: annotationfactory allow use different classloder current context \n",
            " The method\n",
            "{code}org.hibernate.annotations.common.annotationfactory.AnnotationFactory.create(AnnotationDescriptor){code}\n",
            "needs to be overloaded, to allow special frameworks to pick a different ClassLoader., Similarity: 0.3699\n",
            "Summary & Description: change use jboss logging slf4j \n",
            " we need to move to jboss logging and get rid of slf4j, Similarity: 0.4529\n",
            "Summary & Description: index columns mappedsuperclasses dont work \n",
            " Indices in MappedSuperclass are not created in each child Entity, but only in one of them, as index names are global (at least in postgres), for the other Entites I get errors:\n",
            "\n",
            "10:00:17 ERROR [org.hibernate.tool.hbm2ddl.SchemaUpdate]: Unsuccessful: create index hash on B (hash)\n",
            "10:00:17 ERROR [org.hibernate.tool.hbm2ddl.SchemaUpdate]: ERROR: relation \"hash\" already exists\n",
            "\n",
            "\n",
            "{code:title=Root.java|borderStyle=solid}\n",
            "@MappedSuperclass\n",
            "abstract class Root {\n",
            "  @Column(nullable = false, unique = true)\n",
            "  @Index(name = \"hash\")\n",
            "  private String hash;\n",
            "\t\n",
            "  @Id\n",
            "  @GeneratedValue(strategy = GenerationType.IDENTITY)\n",
            "  private Long id;\n",
            "\n",
            "  // Getter, Setter, ...\n",
            "}\n",
            "{code}\n",
            "\n",
            "{code:title=A.java|borderStyle=solid}\n",
            "@Entity\n",
            "public class A extends Root {\n",
            "  // Getter, Setter, ...\n",
            "}\n",
            "{code}\n",
            "\n",
            "{code:title=B.java|borderStyle=solid}\n",
            "@Entity\n",
            "public class B extends Root {\n",
            "  // Getter, Setter, ...\n",
            "}\n",
            "{code}, Similarity: 0.2773\n",
            "Summary & Description: discriminator single table per class hierarchy 2242 optional \n",
            " If a Single table per class inheritance is used for cases as shown in the documentation, this makes perfect sense to need a Discriminator column.\n",
            "\n",
            "However, in many scenarios, no Discriminator is needed as there will only different represenations of the same object.\n",
            "\n",
            "Example:\n",
            "\n",
            "One library defines a User entity.\n",
            "\n",
            "In order to separate different Security implementations from each other, another library can extend this User Object, e.g.\n",
            "as an ExtendedUser.\n",
            "\n",
            "Some classes will query the table with less columns and call it \"User\" - some will query the same table in parallel as \"ExtendendUser\" - so no discriminator is needed - and adding an additional column makes now sense.\n",
            "\n",
            "The colunns needed are already defined in the entities themselves., Similarity: 0.0907\n",
            "Summary & Description: entitybinder incorrect warn message dynamicupdate entity used non root entity ignored \n",
            " This my first bug so please excuse any mistakes I make in filing it, and help me correct them.\n",
            "\n",
            "I'm using PostgreSQL.  I have a bunch of domain objects.  Some of them are small class hierarchies.  I chose to map each class hierarchy to a single table using a discriminator column.  Here's one example where I have a base class (Note) and a subclass (TaskNote)...\n",
            "\n",
            "@Entity\n",
            "@org.hibernate.annotations.Entity(dynamicUpdate = true)\n",
            "@Table(name = \"notes\")\n",
            "@SequenceGenerator(name = \"notes_note_id_seq\", sequenceName = \"notes_note_id_seq\", allocationSize = 1)\n",
            "@Proxy(lazy = true)\n",
            "@Inheritance(strategy=InheritanceType.SINGLE_TABLE)\n",
            "@SQLDelete(sql=\"update notes set removed = true where note_id = ?\")\n",
            "@DiscriminatorColumn(\n",
            "    name=Note.noteTypeColumnName,\n",
            "    discriminatorType=DiscriminatorType.INTEGER\n",
            ")\n",
            "public abstract class Note implements Persistable {\n",
            "...\n",
            "}\n",
            "\n",
            "@Entity\n",
            "@org.hibernate.annotations.Entity(dynamicUpdate = true)\n",
            "@Proxy(lazy = true)\n",
            "@DiscriminatorValue(\"1\")\n",
            "public class TaskNote extends Note {\n",
            "...\n",
            "}\n",
            "\n",
            "Notice that I added the following annotation to both: @org.hibernate.annotations.Entity(dynamicUpdate = true)\n",
            "\n",
            "I did this because I want to keep my updates lean.\n",
            "\n",
            "After adding this annotation I started seeing warnings in my log:\n",
            "\n",
            "2010-11-01 10:03:22,210 WARN  org.hibernate.cfg.annotations.EntityBinder @org.hibernate.annotations.Entity used on a non root entity: ignored for redfin.core.domain.TaskNote\n",
            "\n",
            "I spent some time experimenting with this annotation to understand how it works with class hierarchies.  I discovered that:\n",
            "\n",
            "* If I put the annotation on the child class and not on the parent class, then I get the WARN but dynamicUpdate still works\n",
            "* If I put the annotation on the parent class and not the child class, then the WARN goes away but dynamicUpdate does not work\n",
            "* If I put the annotation on both, then the WARN is there and dynamicUpdate works\n",
            "\n",
            "To me this implies that the WARN is incorrect.  Do you agree?\n",
            "\n",
            "I believe this is the code that is generating the message:\n",
            "http://www.docjar.com/html/api/org/hibernate/cfg/annotations/EntityBinder.java.html\n",
            "\n",
            "Here are the particular versions of the various hibernate libraries that I'm using:\n",
            "\n",
            "            <dependency>\n",
            "                <groupId>org.hibernate</groupId>\n",
            "                <artifactId>hibernate-validator</artifactId>\n",
            "                <version>3.0.0.ga</version>\n",
            "            </dependency>\n",
            "            <dependency>\n",
            "                <groupId>org.hibernate</groupId>\n",
            "                <artifactId>hibernate</artifactId>\n",
            "                <version>3.2.7.ga</version>\n",
            "            </dependency>\n",
            "            <dependency>\n",
            "                <groupId>org.hibernate</groupId>\n",
            "                <artifactId>hibernate-annotations</artifactId>\n",
            "                <version>3.3.0.ga</version>\n",
            "            </dependency>\n",
            "            <dependency>\n",
            "                <groupId>org.hibernate</groupId>\n",
            "                <artifactId>hibernate-commons-annotations</artifactId>\n",
            "                <version>3.3.0.ga</version>\n",
            "            </dependency>\n",
            "            <dependency>\n",
            "                <groupId>org.hibernate</groupId>\n",
            "                <artifactId>antlr</artifactId>\n",
            "                <version>2.7.5H3</version>\n",
            "            </dependency>\n",
            ", Similarity: 0.2760\n",
            "Summary & Description: polymorphic query named field using inheritancestrategyinheritancetypejoined \n",
            " Using a Joined table strategy and annotation definitions, Hibernate does not respect the name parameter from a column annotation, as in @Column(name = \"ES_CELL_LINE\"), in the generation of a polymorphic query on the parent type.\n",
            "\n",
            "@Entity\n",
            "@Table(name = \"GENOTYPE\")\n",
            "@Inheritance(strategy=InheritanceType.JOINED)\n",
            "public class Genotype implements java.io.Serializable {\n",
            "\tprivate int genotypeKey;\n",
            "...\n",
            "}\n",
            "\n",
            "@Entity\n",
            "@Table(name = \"GENOTYPE_TARGETED\")\n",
            "public class GenotypeTargeted extends Genotype {\n",
            "\n",
            "    private String ESCellLine;\n",
            "\n",
            "    @Column(name = \"ES_CELL_LINE\", length = 32)\n",
            "    @Length(max = 32)\n",
            "    public void setESCellLine(String eSCellLine) {\n",
            "    \tESCellLine = eSCellLine;\n",
            "    }\n",
            "    public String getESCellLine() {\n",
            "    \treturn ESCellLine;\n",
            "    }\n",
            "}\n",
            "\n",
            "\n",
            "Using the query \"select distinct g from Genotype g\" produces a query containing \"genotype4_1_.ESCellLine as ESCellLine69_3_,\" rather than \"genotype4_1_.ES_CELL_LINE as ESCellLine69_3_,\" as would be expected. All named fields from the parent class are correct, while all named fields from the subclasses use the field name rather than the value of the name parameter., Similarity: 0.1787\n",
            "Summary & Description: audited class embeddedid manytoone relationship \n",
            " Hi,\n",
            "\n",
            "there is a problem when a class is @Audited and this has an @EmbeddedId (only when the Embeddable class has ManyToOne relationship).\n",
            "\n",
            "Example code:\n",
            "\n",
            "persistence.xml:\n",
            "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
            "<persistence version=\"1.0\" xmlns=\"http://java.sun.com/xml/ns/persistence\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/persistence http://java.sun.com/xml/ns/persistence/persistence_1_0.xsd\">\n",
            "  <persistence-unit name=\"TestAuditPU\" transaction-type=\"RESOURCE_LOCAL\">\n",
            "    <provider>org.hibernate.ejb.HibernatePersistence</provider>\n",
            "    <properties>\n",
            "      <property name=\"hibernate.dialect\" value=\"org.hibernate.dialect.MySQLInnoDBDialect\"/>\n",
            "      <property name=\"hibernate.hbm2ddl.auto\" value=\"create-drop\"/>\n",
            "      <property name=\"hibernate.connection.username\" value=\"root\"/>\n",
            "      <property name=\"hibernate.connection.driver_class\" value=\"com.mysql.jdbc.Driver\"/>\n",
            "      <property name=\"hibernate.connection.password\" value=\"\"/>\n",
            "      <property name=\"hibernate.connection.url\" value=\"jdbc:mysql://192.168.0.6:3306/idm\"/>\n",
            "      <property name=\"hibernate.ejb.event.post-insert\"\n",
            "                  value=\"org.hibernate.ejb.event.EJB3PostInsertEventListener,org.hibernate.envers.event.AuditEventListener\" />\n",
            "        <property name=\"hibernate.ejb.event.post-update\"\n",
            "                  value=\"org.hibernate.ejb.event.EJB3PostUpdateEventListener,org.hibernate.envers.event.AuditEventListener\" />\n",
            "        <property name=\"hibernate.ejb.event.post-delete\"\n",
            "                  value=\"org.hibernate.ejb.event.EJB3PostDeleteEventListener,org.hibernate.envers.event.AuditEventListener\" />\n",
            "        <property name=\"hibernate.ejb.event.pre-collection-update\"\n",
            "                  value=\"org.hibernate.envers.event.AuditEventListener\" />\n",
            "        <property name=\"hibernate.ejb.event.pre-collection-remove\"\n",
            "                  value=\"org.hibernate.envers.event.AuditEventListener\" />\n",
            "        <property name=\"hibernate.ejb.event.post-collection-recreate\"\n",
            "                  value=\"org.hibernate.envers.event.AuditEventListener\" />\n",
            "    </properties>\n",
            "  </persistence-unit>\n",
            "</persistence>\n",
            "\n",
            "Class A:\n",
            "/*\n",
            "* To change this template, choose Tools | Templates\n",
            "* and open the template in the editor.\n",
            "*/\n",
            "\n",
            "package testaudit;\n",
            "\n",
            "import java.io.Serializable;\n",
            "import javax.persistence.*;\n",
            "import org.hibernate.envers.Audited;\n",
            "\n",
            "/**\n",
            "*\n",
            "* @author heir\n",
            "*/\n",
            "@Entity\n",
            "@Table(name=\"tblA\")\n",
            "@Audited\n",
            "public class A implements Serializable {\n",
            "    @Id\n",
            "    private String name;\n",
            "\n",
            "    @OneToMany(mappedBy=\"bpk.a\")\n",
            "    private java.util.List<B> bs;\n",
            "\n",
            "    public A()\n",
            "    {\n",
            "\n",
            "    }\n",
            "\n",
            "    /**\n",
            "     * @return the name\n",
            "     */\n",
            "    public String getName() {\n",
            "        return name;\n",
            "    }\n",
            "\n",
            "    /**\n",
            "     * @param name the name to set\n",
            "     */\n",
            "    public void setName(String name) {\n",
            "        this.name = name;\n",
            "    }\n",
            "\n",
            "    /**\n",
            "     * @return the bs\n",
            "     */\n",
            "    public java.util.List<B> getBs() {\n",
            "        return bs;\n",
            "    }\n",
            "\n",
            "    /**\n",
            "     * @param bs the bs to set\n",
            "     */\n",
            "    public void setBs(java.util.List<B> bs) {\n",
            "        this.bs = bs;\n",
            "    }\n",
            "}\n",
            "\n",
            "Class B:\n",
            "\n",
            "@Entity\n",
            "@Table(name=\"tblB\")\n",
            "@Audited\n",
            "public class B implements Serializable {\n",
            "\n",
            "    @Id\n",
            "    private BPK bpk;\n",
            "\n",
            "    public B()\n",
            "    {\n",
            "\n",
            "    }\n",
            "\n",
            "    /**\n",
            "     * @return the bpk\n",
            "     */\n",
            "    public BPK getBpk() {\n",
            "        return bpk;\n",
            "    }\n",
            "\n",
            "    /**\n",
            "     * @param bpk the bpk to set\n",
            "     */\n",
            "    public void setBpk(BPK bpk) {\n",
            "        this.bpk = bpk;\n",
            "    }\n",
            "\n",
            "}\n",
            "\n",
            "Class BPK:\n",
            "\n",
            "@Embeddable\n",
            "public class BPK implements Serializable {\n",
            "\n",
            "    private String name;\n",
            "    @ManyToOne(targetEntity=testaudit.A.class,\n",
            "        cascade={CascadeType.ALL})\n",
            "    @JoinColumn(name=\"strAName\")\n",
            "    private A a;\n",
            "\n",
            "    public BPK()\n",
            "    {\n",
            "       \n",
            "    }\n",
            "\n",
            "    /**\n",
            "     * @return the name\n",
            "     */\n",
            "    public String getName() {\n",
            "        return name;\n",
            "    }\n",
            "\n",
            "    /**\n",
            "     * @param name the name to set\n",
            "     */\n",
            "    public void setName(String name) {\n",
            "        this.name = name;\n",
            "    }\n",
            "\n",
            "    /**\n",
            "     * @return the a\n",
            "     */\n",
            "    public A getA() {\n",
            "        return a;\n",
            "    }\n",
            "\n",
            "    /**\n",
            "     * @param a the a to set\n",
            "     */\n",
            "    public void setA(A a) {\n",
            "        this.a = a;\n",
            "    }\n",
            "}\n",
            "\n",
            "Exception:\n",
            "\n",
            "Exception in thread \"main\" javax.persistence.PersistenceException: [PersistenceUnit: TestAuditPU] Unable to build EntityManagerFactory\n",
            "        at org.hibernate.ejb.Ejb3Configuration.buildEntityManagerFactory(Ejb3Configuration.java:900)\n",
            "        at org.hibernate.ejb.HibernatePersistence.createEntityManagerFactory(HibernatePersistence.java:57)\n",
            "        at javax.persistence.Persistence.createEntityManagerFactory(Persistence.java:48)\n",
            "        at javax.persistence.Persistence.createEntityManagerFactory(Persistence.java:32)\n",
            "        at testaudit.Main.main(Main.java:23)\n",
            "Caused by: org.hibernate.HibernateException: could not init listeners\n",
            "        at org.hibernate.event.EventListeners.initializeListeners(EventListeners.java:205)\n",
            "        at org.hibernate.cfg.Configuration.getInitializedEventListeners(Configuration.java:1396)\n",
            "        at org.hibernate.cfg.Configuration.buildSessionFactory(Configuration.java:1385)\n",
            "        at org.hibernate.cfg.AnnotationConfiguration.buildSessionFactory(AnnotationConfiguration.java:954)\n",
            "        at org.hibernate.ejb.Ejb3Configuration.buildEntityManagerFactory(Ejb3Configuration.java:891)\n",
            "        ... 4 more\n",
            "Caused by: org.hibernate.MappingException: Type not supported: org.hibernate.type.ManyToOneType\n",
            "        at org.hibernate.envers.configuration.metadata.IdMetadataGenerator.addIdProperties(IdMetadataGenerator.java:75)\n",
            "        at org.hibernate.envers.configuration.metadata.IdMetadataGenerator.addId(IdMetadataGenerator.java:120)\n",
            "        at org.hibernate.envers.configuration.metadata.AuditMetadataGenerator.generateFirstPass(AuditMetadataGenerator.java:374)\n",
            "        at org.hibernate.envers.configuration.EntitiesConfigurator.configure(EntitiesConfigurator.java:100)\n",
            "        at org.hibernate.envers.configuration.AuditConfiguration.<init>(AuditConfiguration.java:86)\n",
            "        at org.hibernate.envers.configuration.AuditConfiguration.getFor(AuditConfiguration.java:99)\n",
            "        at org.hibernate.envers.event.AuditEventListener.initialize(AuditEventListener.java:334)\n",
            "        at org.hibernate.event.EventListeners$1.processListener(EventListeners.java:198)\n",
            "        at org.hibernate.event.EventListeners.processListeners(EventListeners.java:181)\n",
            "        at org.hibernate.event.EventListeners.initializeListeners(EventListeners.java:194)\n",
            "        ... 8 more\n",
            "Java Result: 1\n",
            "\n",
            "Thanks\n",
            "\n",
            "Heinen Rino\n",
            "\n",
            ", Similarity: 0.2945\n",
            "Summary & Description: primarykeyjoincolumn foreignkeyname foreignfoobar dont work inheritancetypejoined \n",
            " I've got an example where I have two classes: Customer, ValuedCustomer, where ValuedCustomer inherits from Customer. As InheritanceType.JOINED is used here, hibernate will generate a primary key in ValuedCustomer as well as all integrity constraints for that (I use Oracle10g dialect). I would like to give a name to that foreign key in ValuedCustomer (which is also a primary key there), but it's not possible.\n",
            "In ValuedCustomer I use @PrimaryKeyJoinColumn annotation and @org.hibernate.annotations.Table with foreignKey property set in it. I would like that hibernate hbm2ddl generate foreign key constraint name as indicated in @ForeignKey annotation but it doesn't. It generates random constraint name instead. \n",
            "\n",
            "I'm attaching example java project and generated schema file., Similarity: 0.2269\n",
            "Summary & Description: issue column annotation \n",
            " We all know that when we don't map a attribute with column in the DB using @Column() annotation, hibernate by default splits the variable based on the words and constructs the column name to be mapped.\n",
            "\n",
            "Example \n",
            "\n",
            "if I have something like \n",
            "\n",
            "private BigDecimal netLiqPercent; \n",
            "\n",
            "then hibernate constructs the column name as net_liq_percent.\n",
            "\n",
            "But when we use \n",
            "\n",
            "\t@Column(name =\"Account_NetLiq_Percent\", nullable=true, updatable=true, insertable=true)\t\n",
            "\tprivate BigDecimal netLiqPercent; \n",
            "\n",
            "Hibernate should not try to resolve / construct column, instead it should use whatever the column name is being specified.\n",
            "\n",
            "However its not so! In the above case hibernate tries to look for column \"account_net_liq_percent\" and gives unknown column exception.\n",
            "\n",
            "I believe when we explicitly map the column hibernate should use it.\n",
            "\n",
            "but it works if I change column name to all CAPS..!\n",
            "\n",
            "I think this needs to be addressed.\n",
            " \n",
            ", Similarity: 0.2153\n",
            "Summary & Description: avoid chocking weird types property marked transient transient \n",
            " The following source:\n",
            "\n",
            "\n",
            "@javax.persistence.Entity\n",
            "public class TestEntity {\n",
            "        \n",
            "        @javax.persistence.Id\n",
            "        public int Id;\n",
            "        \n",
            "        public java.util.ArrayList<Object[]> badMethod() { return null; }\n",
            "\n",
            "        public static void main(String args[]) {\n",
            "                        new org.hibernate.cfg.AnnotationConfiguration().addAnnotatedClass(TestEntity\n",
            ".class).configure().buildSessionFactory();\n",
            "  }\n",
            "\n",
            "}\n",
            "\n",
            "will cause:\n",
            "\n",
            "java.lang.IllegalArgumentException: No PropertyTypeExtractor available for type void\n",
            "at org.hibernate.annotations.common.reflection.java.JavaReflectionManager.toXType(JavaReflectionManager.java:164)^M\n",
            "at org.hibernate.annotations.common.reflection.java.JavaXMethod.create(JavaXMethod.java:18)\n",
            "at org.hibernate.annotations.common.reflection.java.JavaReflectionManager.getXMethod(JavaReflectionManager.java:128)\n",
            "at org.hibernate.annotations.common.reflection.java.JavaXClass.getDeclaredMethods(JavaXClass.java:114)\n",
            "at org.hibernate.validator.ClassValidator.initValidator(ClassValidator.java:214)\n",
            "at org.hibernate.validator.ClassValidator.<init>(ClassValidator.java:133)\n",
            "at org.hibernate.validator.event.ValidateEventListener.initialize(ValidateEventListener.java:91)\n",
            "at org.hibernate.event.EventListeners.initializeListeners(EventListeners.java:356)\n",
            "at org.hibernate.cfg.Configuration.getInitializedEventListeners(Configuration.java:1304)\n",
            "at org.hibernate.cfg.Configuration.buildSessionFactory(Configuration.java:1294) \n",
            "\n",
            "\n",
            "Changing the return type to List<Object[]> avoids the bug.\n",
            "\n",
            "Attached is a tgz of an ant-buildable project; typing \"ant run\" will illustrate the bug.\n",
            ", Similarity: 0.3340\n",
            "Summary & Description: update neo4j version 3411 \n",
            " With upgrading the neo4j dependency version from 3.4.*10* to 3.4.*11*, *four* unit-tests are failing.\n",
            "* DuplicateIdDetectionTest\n",
            "* JtaRollbackTest\n",
            "* ResourceLocalRollbackTest\n",
            "* CompensationSpiTest\n",
            "\n",
            "Comparing the neo4j git tags to see what has changed among those version numbers, it seems a change was introduced, how building the \"cause chain\" for the exception query-execution.\n",
            "\n",
            "The git diff of neo4j version 3.4.10 - 3.4.11 is\n",
            "https://github.com/neo4j/neo4j/compare/3.4.10...3.4.11\n",
            "\n",
            "The isolated commits which had changed the behavior\n",
            "\n",
            "* https://github.com/neo4j/neo4j/commit/25bd77e8524bcd60ae8418f96da46d840e1de5f6\n",
            "\n",
            "* https://github.com/neo4j/neo4j/commit/aa0ab5548b8279949b7881505208484e81f9fe06\n",
            "\n",
            "* https://github.com/neo4j/neo4j/commit/a14accb8ef658250de2d7b8cb055cf660b19e57a\n",
            "\n",
            "To enable compatibility with neo4j 3.4.11 the class *EmbeddedNeo4jDialect*\n",
            "has to be modified.\n",
            "\n",
            "*The exception has to get changed from \"UniquePropertyValueValidation\" to \"IndexEntryConflict.\"*, Similarity: 0.3616\n",
            "Summary & Description: update mongodb java driver version 3112 \n",
            " Update Mongo Java Driver - 3.9.1 => 3.11.2, Similarity: 0.3947\n",
            "Summary & Description: mysql document store support \n",
            " hi,\n",
            "i'm eager to know if hibernate supports MySql document store queries on json. i have been searching for this feature but i still haven't found anything about it. I must work on a spring mvc project using hibernate and mysql document store. I need to query json fields of this document store or insert data into it. but I can't find a way to do that. I appreciate if you could help me about this.\n",
            "thanks, Similarity: 0.3341\n",
            "Summary & Description: mongodbdialect uses shared parboiled parser across multiple threads parser thread safe \n",
            " When executing multiple (same) native queries against MongoDB (using createNativeQuery), following error happens easily:\n",
            "\n",
            "java.lang.IllegalArgumentException: Cannot peek beyond the bottom of the stack\n",
            "        at org.parboiled.MatcherContext.runMatcher(MatcherContext.java:367) ~[parboiled-core-1.1.8.jar:1.1.8]\n",
            "        at org.parboiled.matchers.SequenceMatcher.match(SequenceMatcher.java:46) ~[parboiled-core-1.1.8.jar:1.1.8]\n",
            "        at org.parboiled.parserunners.BasicParseRunner.match(BasicParseRunner.java:77) ~[parboiled-core-1.1.8.jar:1.1.8]\n",
            "\n",
            "Parboiled parsers are *not* thread safe - https://github.com/sirthias/parboiled/wiki/Thread-Safety\n",
            "\n",
            "Yet the [MongoDialect|https://github.com/hibernate/hibernate-ogm/blob/master/mongodb/src/main/java/org/hibernate/ogm/datastore/mongodb/MongoDBDialect.java#L215] uses shared, static parser for native queries:\n",
            "\n",
            "{code:java}\n",
            "\tprivate static final NativeQueryParser NATIVE_QUERY_PARSER = Parboiled.createParser( NativeQueryParser.class );\n",
            "{code}\n",
            "\n",
            "The access to this property is not synchronized.\n",
            "\n",
            "Wrapping query execution (in the app) in synchronized (globalLock) mitigates this issue instantly and completely - but it hurts performance a lot as no queries can be executed in parallel. \n",
            "\n",
            ", Similarity: 0.3787\n",
            "Summary & Description: upgrade jackson 295 \n",
            " Due to a security issue fixed by the version 2.8.11., Similarity: 0.2104\n",
            "Summary & Description: upgrade integration tests wildfly 1400final \n",
            " Since Wildfly 14 the JPA version is 2.2 by default, so we can also cleanup the integration tests: no longer needing {{-Dee8.preview.mode=true}}, Similarity: 0.4163\n",
            "Summary & Description: run hibernate ogm without provider persistence property \n",
            " Make no longer mandatory setting the persistence property `provider` to `org.hibernate.ogm.jpa.Hibernate Persistence` in order to run Hibernate OGM.\n",
            "\n",
            "We decided to enable OGM implicitly when a JDBC connection URL, a datasource and a dialect are not provided. The user can still decide not to enable OGM by setting the `hibernate.ogm.enabled property` to false., Similarity: 0.3823\n",
            "Summary & Description: join columns might keep reference previously associated deleted entities \n",
            " In case of @OneToMany bidirectional associations, without any definitions of cascade. When we delete the entity owner, it might happen that the associates entities would still keep the reference to the, now deleted, entity owner.\n",
            "Thus, if we try to create another entity owner, recycling the id owned by the former, we could have associations, between the latter and associated entities, never defined by the user.\n",
            "\n",
            "This seems affect only grid and document dialects, such as MongoDB or Infinispan. On the other hand, graph dialects, like Neo4j, have no issue. Probabily because the latters do not need to handle the inverses of bidirectional associations.\n",
            "Test case: [^CleanJoinColumnsAfterDeleteReferencedEntitiesTest.patch] \n",
            "\n",
            ", Similarity: 0.2008\n",
            "Summary & Description: flush operation cascade delete could prejudice commit \n",
            " With Infinispan remote dialect, a large cascade delete on a bidirectional association and a subsequent flush could bring persistence context in an inconsistent state, causing in turn this error on commit operation:\n",
            "\n",
            "`javax.persistence.RollbackException: Error while committing the transaction\n",
            "        at org.hibernate.ogm.backendtck.inheritance.singletable.family.SingleTableInheritancePersistTest.testFlushAndCommitAfterCascadeDelete(SingleTableInheritancePersistTest.java:192)\n",
            "Caused by: java.lang.IllegalStateException: org.hibernate.TransientPropertyValueException: object references an unsaved transient instance - save the transient instance before flushing : org.hibernate.ogm.backendtck.inheritance.singletable.family.Woman.familyName -> org.hibernate.ogm.backendtck.inheritance.singletable.family.Family\n",
            "        at org.hibernate.ogm.backendtck.inheritance.singletable.family.SingleTableInheritancePersistTest.testFlushAndCommitAfterCascadeDelete(SingleTableInheritancePersistTest.java:192)\n",
            "Caused by: org.hibernate.TransientPropertyValueException: object references an unsaved transient instance - save the transient instance before flushing : org.hibernate.ogm.backendtck.inheritance.singletable.family.Woman.familyName -> org.hibernate.ogm.backendtck.inheritance.singletable.family.Family\n",
            "`\n",
            "Test case is here:\n",
            "[^Test_flush_and_commit_after_a_cascade_delete_on_bidirectional_association.patch] , Similarity: 0.3093\n",
            "Summary & Description: improve message user mongodb like index unique constraint field \n",
            "  Currently when a user attempts to define a unique constraint and an index on the same field in MongoDB an exception stack trace is displayed.\n",
            " Instead of a stack trace a WARNING message would be better.\n",
            "\n",
            "This has been discussed in a forum thread \n",
            "\n",
            "https://discourse.hibernate.org/t/using-unique-constraint-and-index-on-field-with-mongodb/888, Similarity: 0.3315\n",
            "Summary & Description: infinispan remote support local hotrod transaction \n",
            " With Infinispan 9.3.x, local transactions over HotRot client are supported by the datastore.\n",
            "It is a very nice and critical feature, that we want to offer also to the users of Infinispan Server that use Hibernate OGM as a client., Similarity: 0.4318\n",
            "Summary & Description: review strategies loading enhanced classes configurationcontextimpl \n",
            " The loading of the newly defined classes should not happen via _.load( classloader )_ as this breaks depending on different Byte Buddy versions / JDK versions.\n",
            "\n",
            "We introduced an helper for the same problem in Hibernate ORM called {{org.hibernate.bytecode.internal.bytebuddy.ByteBuddyState#resolveClassLoadingStrategy}}.\n",
            "\n",
            "This was meant as an internal contract for ORM though, so maybe we want to promote it as SPI?\n",
            "\n",
            "Also this method was only just introduced in ORM {{5.3.1.Final}} so it would require a dependency upgrade if we wanted to use it as-is in OGM., Similarity: 0.4364\n",
            "Summary & Description: infinispan remote support jointable association type use cases \n",
            " Currently Infinispan remote dialect is not capable of implement a join table strategy to map associations to datastore caches.\n",
            "Join table is used, speaking of Hibernate ORM 5.3.0.Final, also for OneToMany association if a @JoinColumn annotation is not defined on field and if the association is unidirectional. Futhermore join table strategy is used of course also to implement all ManyToMany associations.\n",
            "If the dialect try to implement  JoinTable an OGM001711 error message is risen, showing the text: \"This domain model would cause table '%s' to be generated without a primary key. This is not supported on an Infinispan Remote dialect: check that your embedded collections have a proper ordering definition.\".\n",
            "In this issue we want to remove this limitation, allowing Infinispan Remote dialect to handle join column mapping on association, for all use cases that require this mapping., Similarity: 0.3945\n",
            "Summary & Description: support property selections projection queries jpql apache ignite \n",
            " E. g.: \n",
            "{{select h.id, h.description from Hypothesis h}}\n",
            "which can be translated into Ignite SQL as:\n",
            "{{select h._KEY, h.description from HYPOTHESIS h}}\n",
            "without need of fetching whole entities, but only properties participating in projection., Similarity: 0.3420\n",
            "Summary & Description: define infinispan remote protobuf schema providing final file \n",
            " Currently Hibernate OGM can generate the Protobuf schema or the user can define an alternative implementation using the property **hibernate.ogm.infinispan_remote.schema_override_service**.\n",
            "\n",
            "We want provide a way to define the schema just providing the final file in resource folder., Similarity: 0.4150\n",
            "Summary & Description: remove dependency javassist \n",
            " We're phasing out the usage of Javassist in Hibernate ORM, mainly so to not have problems on newer JDK versions.\n",
            "\n",
            "Similarly OGM should no longer depend on Javassist., Similarity: 0.3838\n",
            "Summary & Description: update integration tests use wildfly 1300beta1 \n",
            " WildFly 13.0.0.Beta1 being available, we can avoid needing to patch Wildfly to update the JPA specification.\n",
            "\n",
            "Incidentally, it also includes the Hibernate ORM and Hibernate Search versions we mean to currently use in Hibernate OGM, however, this being just a coincidence I would not remove the infrastructure we have in place to pick an alternative version - that will still be useful in the future., Similarity: 0.4149\n",
            "Summary & Description: support standard functional expressions jpql queries ignite \n",
            " Standard functions allowed in JPQL: \n",
            "https://docs.jboss.org/hibernate/orm/4.3/devguide/en-US/html/ch11.html#ql-exp-functions\n",
            "\n",
            "All these functions are supported by Ignite SQL, so can be used in queries. \n",
            "https://apacheignite-sql.readme.io/docs/numeric-functions\n",
            "https://apacheignite-sql.readme.io/docs/sql-function\n",
            "\n",
            "Note that operands may contain other expressions, e.g. \n",
            "{{where length(trim(h.author.name)) > 0 and mod(length(trim(h.author.name)), 2) = 0}}\n",
            ", Similarity: 0.3909\n",
            "Summary & Description: wrong type resolution association keys embedded cache init \n",
            " * if a column holds association key, its type should be set to associated entity key type (currently, it is wrongly resolved as associated entity class in *-to-one and `java.util.String` in many-to-many associations)\n",
            "* if a column holds part of embedded property, its type should be set to actual type of that part (currently resolved as embeded property class itself), Similarity: 0.2045\n",
            "Summary & Description: support merge refresh loaders ogmentitypersister \n",
            " I don't know exactly what's necessary to fix:\n",
            "https://github.com/hibernate/hibernate-ogm/blob/master/core/src/main/java/org/hibernate/ogm/persister/impl/OgmEntityPersister.java#L912\n",
            "but it would be nice if we could fix it so that we benefit from the recent improvements of the ORM {{AbstractEntityPersister}} {{createLoaders()}} method., Similarity: 0.4674\n",
            "Summary & Description: support indexes neo4j \n",
            " See the tests in this package in the MongoDB module: org.hibernate.ogm.datastore.mongodb.test.index\n",
            "\n",
            "MongoDB indexes are more advance than the Neo4j ones. We need to check which use cases work with Neo4j and update the tests accordingly.\n",
            ", Similarity: 0.3645\n",
            "Summary & Description: upgrade hibernate orm 530final \n",
            " Hibernate ORM version {{5.3.0.Final}} is now available in Maven Central, and includes the JBoss _feature pack_ .\n",
            "\n",
            "See also https://github.com/hibernate/hibernate-search/commit/134ff5c6d5f253d9dd49543151ac13ec8a3072ad, Similarity: 0.3008\n",
            "Summary & Description: infinispan remote query support query byte field \n",
            " Follow up of [OGM-1457|https://hibernate.atlassian.net/browse/OGM-1457].\n",
            "A strange Parsing exception is risen when we try to perform a query on Infinispan server on a bytes Protobuf field.\n",
            "When we've found the reason of the issue, we will support query on Byte type field too., Similarity: 0.2921\n",
            "Summary & Description: infinispan remote query support character boolean parameters \n",
            " Follow up of [OGM-1426|https://hibernate.atlassian.net/browse/OGM-1426].\n",
            ", Similarity: 0.2699\n",
            "Summary & Description: error neo4j tests java 9 \n",
            " There is NullPointerException in EmbeddedGraphDatabaseFactoryTest, because method neo4jPropertiesUrl returns null. \n",
            "Probably it's because of method uses jdk.internal.loader.ClassLoaders$AppClassLoader with java 9. With java 8 uses sun.misc.Launcher$AppClassLoader.\n",
            ", Similarity: 0.3870\n",
            "Summary & Description: support server tasks infinispan remote \n",
            " see http://infinispan.org/docs/stable/user_guide/user_guide.html#server_tasks, Similarity: 0.4284\n",
            "Summary & Description: support run java code embedded mode \n",
            " See http://infinispan.org/docs/stable/user_guide/user_guide.html#executing_code_in_the_grid, Similarity: 0.4768\n",
            "Summary & Description: infinispan remote stored procedure remote task support \n",
            " Enabling JPA StoredProcedureQuery support for Infinispan remote dialect. The application with Hiberante OGM will be capable of executing and binding input and outparameter to an Infinispan Remote Task. , Similarity: 0.4154\n",
            "Summary & Description: mapping tests tableperclass inheritance type mongodb \n",
            " At the moment, we only test the native mapping of inheritance via org.hibernate.ogm.datastore.mongodb.test.inheritance.SingleTableInheritanceTest\n",
            "\n",
            "What we need to do is:\n",
            "# 1st commit: Move the classes under `org.hibernate.ogm.datastore.mongodb.test.inheritance` to a new package `org.hibernate.ogm.datastore.mongodb.test.inheritance.singletable`\n",
            "#  2nd commit Basically copy test and entities related to SingleTableInheritanceTest and create a new test class TablePerClassInheritanceTest under the package `org.hibernate.ogm.datastore.mongodb.test.inheritance.tableperclass` , Similarity: 0.3801\n",
            "Summary & Description: elementcollection doesnt retrieve mongodb array \n",
            " *UPDATE*: It turns out that this is not a bug, but I still want to add a couple of additional tests \n",
            "\n",
            "Refers to Stackoverflow error:\n",
            "\n",
            "[JBoss WildFly 11, Hibernate ORM 5.2, OGM 5.3 and MongoDB - zero length array of Objects|http://stackoverflow.com/questions/49232318/jboss-wildfly-11-hibernate-orm-5-2-ogm-5-3-and-mongodb-zero-length-array-of?noredirect=1#comment85510037_49232318]\n",
            "\n",
            "@ElementCollection doesn't retrieve MongoDB array as a collection of Embedded Entities.\n",
            "\n",
            ", Similarity: 0.4591\n",
            "Summary & Description: orghibernatepropertyaccessexception mongodb native query null assigned primitve \n",
            " When a primitive type is used for an Entity field, performing a partial Entity MongoDB native query could lead to an org.hibernate.PropertyAccessException.\n",
            "It happens when the primitive field type is not included in the Projection set of the partial query.\n",
            "\n",
            "{code:java}\n",
            "@Entity\n",
            "public class OscarWildePoem {\n",
            "        @Id\n",
            "\tprivate Long id;\n",
            "\tprivate String name;\n",
            "\tprivate String author;\n",
            "\tprivate byte rating;\n",
            "}\n",
            "{code}\n",
            "\n",
            "{code:java}\n",
            "@Test\n",
            "\tpublic void nativeQueryProjectionExcludingPrimitive() {\n",
            "\t\tfinal String nativeQuery = \"db.WILDE_POEM.find({ 'name' : 'Portia' }, { 'author' : 1, 'copiesSold' : 1 } )\";\n",
            "\n",
            "\t\tinTransaction( session -> {\n",
            "\t\t\tQuery query = session.createNativeQuery( nativeQuery ).addEntity( OscarWildePoem.class );\n",
            "\t\t\tOscarWildePoem result = (OscarWildePoem) query.uniqueResult();\n",
            "\n",
            "\t\t\tassertThat( result.getId() ).isEqualTo( new Long( 1l ) );\n",
            "\t\t\tassertThat( result.getName() ).isNull();\n",
            "\t\t\tassertThat( result.getAuthor() ).isEqualTo( portia.getAuthor() );\n",
            "\t\t\tassertTrue( result.getRating() == 0 );\n",
            "\t\t\tassertThat( result.getCopiesSold() ).isEqualTo( portia.getCopiesSold() );\n",
            "\t\t} );\n",
            "\t}\n",
            "{code}\n",
            "\n",
            "Exception mesage:\n",
            "{noformat}\n",
            "org.hibernate.PropertyAccessException: Null value was assigned to a property of primitive type setter of org.hibernate.ogm.datastore.mongodb.test.query.nativequery.OscarWildePoem.rating\n",
            "{noformat}\n",
            "\n",
            ", Similarity: 0.2798\n",
            "Summary & Description: documentation states wildfly 10 whereas 11 soon 12 \n",
            " The documentation states that it's about WF 10 (\"How to package Hibernate OGM applications for WildFly 10\").\n",
            "https://docs.jboss.org/hibernate/stable/ogm/reference/en-US/html_single/#ogm-configuration-jbossmodule\n",
            "\n",
            "We should use a variable so that it's updated automatically.\n",
            "\n",
            "Might be a good idea to backport it to a 5.3 branch if we do a maintenance release soon., Similarity: 0.5116\n",
            "Summary & Description: support cypher queries positional parameters neo4j throw clear exception user tries run \n",
            " We should at least throw a clear exception with a message that explain that this is not working at the moment.\n",
            "MongoDB already does that.\n",
            "\n",
            "It should be possible to implement this for Cypher queries with Neo4j becaus ecypher queries accept parameters in the form of {code}{0}, {1} {code} and so on.\n",
            "\n",
            "If the work on this issues is done after the update to Hibernate ORM 5.3 we also need to keep track of the property in sessionFactory.getSessionFactoryOptions().jdbcStyleParamsZeroBased() as in ParamLocationRecognizer.parseLocations, Similarity: 0.2907\n",
            "Summary & Description: choosing default template configuration new caches infinispan remote dialect \n",
            " Give the user the possibility to use a predefined cache as a template to configure all caches created by the dialect.\n",
            "This could be done by configuring a suitable property of the dialect and maybe a default value (ex: \"default\").\n",
            "Before applying the configuration, it will be up to the dialect to check if the template cache exists and if not, throwing an appropriate exception.\n",
            "\n",
            ", Similarity: 0.3071\n",
            "Summary & Description: investigate possible apply remote task execution infinispan remote dialect \n",
            " On OGM Infinispan Remote dialect check the feasibility of executing batch operations on the remote server using the Infinispan feature: Remote Task Execution.\n",
            "\n",
            "We've discovered an actual limitation on Remote Task Execution, see https://issues.jboss.org/browse/ISPN-8020.\n",
            "\n",
            "The issue talk about Script Task, not about Remote Task, but the problem it would seem to be the same, also on Remote Task Execution: it is not possible using Protostream marshaller for Remote Task invocation.\n",
            "\n",
            "The workaround suggested: using 2 RemoteCacheManager (one for cache with Protostream marshaller, another one for task only with default marshaller) seems to work.\n",
            "Compatibility mode of course will be mandatory in this case, to allow different marshaller to operate on the same caches.\n",
            "\n",
            ", Similarity: 0.3318\n",
            "Summary & Description: check warnings infinispan remote build \n",
            " There are a lot of warning during Infinispan tests:\n",
            "\n",
            "{quote} WARN  [org.infinispan.server.hotrod.Decoder2x] (HotRod-ServerWorker-3-2) ISPN006011: Operation 'REPLACE_IF_UNMODIFIED' forced to return previous value should be used on transactional caches, otherwise data inconsistency issues could arise under failure situations\n",
            "155 WARN  [org.infinispan.server.hotrod.Decoder2x] (HotRod-ServerWorker-3-2) ISPN006011: Operation 'PUT_IF_ABSENT' forced to return previous value should be used on transactional caches, otherwise data inconsistency issues could arise under failure situations\n",
            "157 WARN  [org.infinispan.server.hotrod.Decoder2x] (HotRod-ServerWorker-3-2) ISPN006011: Operation 'REMOVE' forced to return previous value should be used on transactional caches, otherwise data inconsistency issues could arise under failure situations\n",
            "{quote}, Similarity: 0.3015\n",
            "Summary & Description: storage infinispan counters need storagepersistent \n",
            " See {{ClusteredCounterCommand:55}}, Similarity: 0.3009\n",
            "Summary & Description: create wildfly module apache ignite \n",
            " Same as we do for the core project, we need to create the module so that we can launch integration tests on WildFly as well, Similarity: 0.4411\n",
            "Summary & Description: create integration test module apache ignite \n",
            " There is a folder right now but It is skipped, we need to make it work following the work we do in core, Similarity: 0.4475\n",
            "Summary & Description: create counters start infinispan embedded \n",
            " Similar to what we do for Neo4j we could create the counters at start up if it doesn't exists already.\n",
            "This way we don't need to check if the counter already exist every time we need to increment the sequence.\n",
            "\n",
            "The improvement will affect only SequenceGenerator strategy counters., Similarity: 0.2026\n",
            "Summary & Description: shouldnt create partial entities native query \n",
            " When converting the result of a native query to an entity, Hibernate OGM does not check that all the fields are present, this leads to an Entity that does not contain all the values.\n",
            "\n",
            "Here a testcase to add in the class `MongoDBSessionCLIQueryTest`:\n",
            "\n",
            "{code}\n",
            "\t@Test\n",
            "\tpublic void testPartialCreationOfEntity() throws Exception {\n",
            "\t\ttry ( OgmSession session = openSession() ) {\n",
            "\t\t\tTransaction transaction = session.beginTransaction();\n",
            "\n",
            "\t\t\tString nativeQuery = \"db.\" + OscarWildePoem.TABLE_NAME + \".find({ 'name' : '\" + portia.getName() + \"' }, {'name': 1, 'rating':1})\";\n",
            "\t\t\tQuery query = session.createNativeQuery( nativeQuery ).addEntity( OscarWildePoem.class );\n",
            "\t\t\tOscarWildePoem result = (OscarWildePoem) query.uniqueResult();\n",
            "\n",
            "\t\t\tassertThat( result.getAuthor() ).isEqualTo( portia.getAuthor() );\n",
            "\t\t\tassertThat( result.getCopiesSold() ).isEqualTo( portia.getCopiesSold() );\n",
            "\n",
            "\t\t\ttransaction.commit();\n",
            "\t\t}\n",
            "\t}\n",
            "{code}\n",
            "\n",
            "This is a problem because the value gets cached and can result in unexpected results when running subsequent queries.\n",
            "\n",
            "I guess we should check what Hibernate ORM does, I suppose an exception should be thrown in this scenario.\n",
            "\n",
            "See this link to stack overflow: https://stackoverflow.com/questions/48294248/hibernate-ogm-with-mongodb-result-of-2nd-query-on-same-table-dependent-on-result\n",
            "\n",
            "We should check if the same behavior happens for the other dialects and for HQL queries., Similarity: 0.2513\n",
            "Summary & Description: build failing consistently travis \n",
            " Starting recently, we have the Travis build failing consistently with an error while running the Neo4j tests.\n",
            "\n",
            "For instance: https://travis-ci.org/gsmet/hibernate-ogm/builds/318675676#L5467\n",
            "\n",
            "{quote}\n",
            "[ERROR] Tests run: 4, Failures: 4, Errors: 0, Skipped: 0, Time elapsed: 2.159 s <<< FAILURE! - in org.hibernate.ogm.backendtck.associations.collection.types.ListTest\n",
            "[ERROR] testRemovalOfElementFromOrderedListIsApplied(org.hibernate.ogm.backendtck.associations.collection.types.ListTest)  Time elapsed: 0.448 s  <<< FAILURE!\n",
            "org.junit.ComparisonFailure: expected:<['L[eia]']> but was:<['L[uke]']>\n",
            "\tat org.hibernate.ogm.backendtck.associations.collection.types.ListTest.testRemovalOfElementFromOrderedListIsApplied(ListTest.java:131)\n",
            "[ERROR] testOrderedListAndCompositeId(org.hibernate.ogm.backendtck.associations.collection.types.ListTest)  Time elapsed: 0.784 s  <<< FAILURE!\n",
            "org.junit.ComparisonFailure: [Entity cache should be empty] expected:<[0]> but was:<[3]>\n",
            "\tat org.hibernate.ogm.backendtck.associations.collection.types.ListTest.testOrderedListAndCompositeId(ListTest.java:172)\n",
            "[ERROR] testUpdateToElementOfOrderedListIsApplied(org.hibernate.ogm.backendtck.associations.collection.types.ListTest)  Time elapsed: 0.258 s  <<< FAILURE!\n",
            "org.junit.ComparisonFailure: expected:<['L[isa]', 'Leia']> but was:<['L[uke]', 'Leia']>\n",
            "\tat org.hibernate.ogm.backendtck.associations.collection.types.ListTest.testUpdateToElementOfOrderedListIsApplied(ListTest.java:94)\n",
            "[ERROR] testOrderedList(org.hibernate.ogm.backendtck.associations.collection.types.ListTest)  Time elapsed: 0.543 s  <<< FAILURE!\n",
            "org.junit.ComparisonFailure: [Entity cache should be empty] expected:<[0]> but was:<[7]>\n",
            "\tat org.hibernate.ogm.backendtck.associations.collection.types.ListTest.testOrderedList(ListTest.java:62)\n",
            "{quote}, Similarity: 0.2687\n",
            "Summary & Description: support stored procedures neo4j \n",
            " Add support stored procedures in Neo4j dialect.\n",
            "\n",
            "Example of implementations released in dialect for MongoDB (https://hibernate.atlassian.net/browse/OGM-359), Similarity: 0.4408\n",
            "Summary & Description: mongodb add geometrycollection spatial support \n",
            " We currently support all the unit geometry type but it would be nice if we could add support for:\n",
            "https://docs.mongodb.com/manual/reference/geojson/#geometrycollection\n",
            "\n",
            "See https://github.com/hibernate/hibernate-ogm/pull/902 for more information about how to do it. All the infrastructure is there, what's still needed is mostly to implement the objects <-> json machinery., Similarity: 0.4770\n",
            "Summary & Description: inefficient query retrieving embedded nodes neo4j \n",
            " When accessing the Neo4j datastore via hibernate.ogm.datastore.provider=neo4j_bolt, the runtime complexity of the query for BoltNeo4jEntityQueries.getFindEntityQuery() depends on how many nodes are reachable in the overall graph by following the outgoing relations of the searched node. This bad runtime complexity seems to be caused by the query pattern that is added to the findEntityQuery by BaseNeo4jEntityQueries.appendOptionalMatchOwnerEmbeddedNodes().\n",
            "\n",
            "Given the following Entity class\n",
            "\n",
            "{code:java}\n",
            "@Entity\n",
            "public class Node {\n",
            "\n",
            "    @Id\n",
            "    private UUID uuid;\n",
            "\n",
            "    @OneToOne(fetch = FetchType.LAZY)\n",
            "    private Node previousNode;\n",
            "\n",
            "    @OneToOne(mappedBy = \"previousNode\")\n",
            "    private Node nextNode;\n",
            "\n",
            "    //getter, setter ...\n",
            "{code}\n",
            "\n",
            "the findEntityQuery in BoltNeo4jEntityQueries is as follows:\n",
            "\n",
            "{noformat}\n",
            "MATCH (owner:ENTITY:Node {uuid: {0}}) OPTIONAL MATCH (owner) -[r*]-> emb:EMBEDDED) RETURN owner, r\n",
            "{noformat}\n",
            "\n",
            "The runtime complexity of this query depends on how many nodes can be reached from the node with {{uuid: \\{0\\}}} by following the previousNode relationship because the pattern {{(owner) \\-[r*]\\-> emb:EMBEDDED)}} potentially expands all those previous nodes. \n",
            "\n",
            "For example, if we are using the Node entity for basically saving a linked list of nodes, e.g. node1 <- previousNode - node2 <- previousNode - node3 ..., then Neo4J is using the following query plan during executing the findEntityQuery:\n",
            "\n",
            " !queryplan.PNG|thumbnail! \n",
            "\n",
            "This query plan becomes more and more inefficient, the more nodes are matched by the subpattern {{(owner)\\-[r*]\\->(emb)}}. In case of a linked list of several thousand nodes, when trying to retrieve the last node of the linked list via its uuid, this may lead to query times of the findEntityQuery of several seconds.\n",
            ", Similarity: 0.3846\n",
            "Summary & Description: supports dialectspecific query hints \n",
            " We want to be able to specify query hints that are specific for a particular dialect.\n",
            "\n",
            "For example, in Apache Ignite is possible to specify that a query should run only on the node even if the data is distributed.\n",
            "\n",
            ", Similarity: 0.2781\n",
            "Summary & Description: module core build jdk 9 \n",
            " Module 'core' not build by JDK 9.\n",
            "Reason is:\n",
            "ERROR] /C:/projects/hibernate-ogm/core/src/test/java/org/hibernate/ogm/utils/TestHelper.java:[49,32] cannot find symbol\n",
            "  symbol:   class ServiceLoader\n",
            "  location: package com.sun.tools.javac.util\n",
            "\n",
            ", Similarity: 0.4981\n",
            "Summary & Description: hibernateogm support apachecassandra129 jdk6 \n",
            " Provide Hibernate OGM library for apache-cassandra-1.2.9 with jdk-6, Similarity: 0.4786\n",
            "Summary & Description: add annotation select template configuration cache \n",
            " At the moment Hibernate OGM can create caches but only if a default configuration is defined on the Infinispan Server. We need to provide something to allow some customization.\n",
            "\n",
            "A few examples of what I'm thinking:\n",
            "{code}\n",
            "@Entity\n",
            "@CacheTemplate(\"transactional_confg\")\n",
            "public class Entity {\n",
            "...\n",
            "}\n",
            "{code}\n",
            "\n",
            "or\n",
            "\n",
            "{code}\n",
            "@Entity\n",
            "@CacheTemplate(name = \"transactional_confg\")\n",
            "public class Entity {\n",
            "...\n",
            "}\n",
            "{code}\n",
            "\n",
            "The value is what we need to pass to the method:\n",
            "{code}\n",
            "hotrodClient.administration().createCache( cacheName, cacheTemplate );\n",
            "{code}\n",
            "\n",
            "Currently we pass null, see org.hibernate.ogm.datastore.infinispanremote.impl.InfinispanRemoteDatastoreProvider#startAndValidateCaches()\n",
            "\n",
            "Tests can be run using maven or via InfinispanRemoteBackendTckHelper.\n",
            ", Similarity: 0.4422\n",
            "Summary & Description: add example associations entities class \n",
            " We already have a test for this: RecursiveAssociationsTest\n",
            "\n",
            "Or we could add a simpler one with Siblings (similar to wife/husband)\n",
            "\n",
            "See the link to the question on Stackoverflow: https://stackoverflow.com/questions/46317336/hibernate-neo4j-create-relationships-from-one-class, Similarity: 0.2541\n",
            "Summary & Description: add support operation insertmany \n",
            " need support operation 'insertMany', Similarity: 0.2566\n",
            "Summary & Description: add support operation insertone \n",
            " need support operation 'insertOne', Similarity: 0.2780\n",
            "Summary & Description: remote neo4j npe transaction commit dealing inverse relations \n",
            " BoltNeo4jDialect runs into NPE in getAssociation() (line 409) during a commit of a transaction after persisting of an object graph with bidirectional and polymorphic associations.\n",
            "\n",
            "Corresponding test case can be found in https://github.com/dadrus/jpa-unit/blob/13-neo4j-support/integration-test/base/src/main/java/eu/drus/jpa/unit/test/AbstractCleanupTest.java (test1(), line 37). It can be started using https://github.com/dadrus/jpa-unit/blob/13-neo4j-support/integration-test/jpa-neo4j-hibernate-ogm-test/src/test/java/eu/drus/jpa/unit/test/CleanupTest.java (@Ignore on a class level needs to be removed). Prerequisite to run the test is a running Neo4j instance (see https://github.com/dadrus/jpa-unit/blob/13-neo4j-support/integration-test/jpa-neo4j-hibernate-ogm-test/src/test/resources/META-INF/persistence.xml for further settings).\n",
            "\n",
            "Is the given object graph not supported by design or did I run indeed into a bug?, Similarity: 0.3574\n",
            "Summary & Description: improve error reporting mongodb nativequeryparser \n",
            " When using the client syntax (so using a query like {{db.something.find(...)}}) with a ill formed JSON query, we have an obscure error about using {{db}} instead of a valid JSON, whereas the issue is not about the db part.\n",
            "\n",
            "We should try to improve the parser so that it reports an understandable error in the following cases:\n",
            " * the command used is not supported (command as in {{find}})\n",
            " * the JSON query is not valid (but it does not make the db part invalid)\n",
            "\n",
            "Some more thoughts that might provide some useful guidance. Note that I didn't play with it so it's just rough ideas for now.\n",
            "\n",
            "The {{Operation()}} rule is one of the interesting ones. Basically, we have the current behavior right now: either you have exactly the right command and the right format or it considers that it will be not be a {{db.xxx.yyy()}} command at all.\n",
            "\n",
            "So to give a few examples of what could be done:\n",
            "- the parser keeps the state pushed to the builder, so the idea is to push as much information as possible in the builder, so that it is able to properly make decisions and provide useful error reports\n",
            "- for instance, we could change the db() rule to be:\n",
            "{code}\n",
            "        @SuppressNode\n",
            "\tpublic Rule Db() {\n",
            "\t\treturn Sequence( ZeroOrMore( WhiteSpace() ), \"db \", Separator(), builder.setCliQuery( true ) );\n",
            "\t}\n",
            "{code}\n",
            "allowing the builder to know we are dealing with a cliQuery.\n",
            "- then I would add a last choice to the Operation() rule with an operation composed of any alphabetical characters so that later we could report it as an unsupported command\n",
            "- I also think each Operation() (find for instance) should be built differently e.g. we should set the operation type as soon as we find the right command but have a flag saying the operation is complete/valid at the end of the command parsing\n",
            "so basically:\n",
            "{code}\n",
            "Sequence( Find(), builder.setOperationValid( true ) ), // <--- we say the command is valid instead of setting the operation type\n",
            "{code}\n",
            "and:\n",
            "{code}\n",
            "       public Rule Find() {\n",
            "\t\treturn Sequence(\n",
            "\t\t\t\tSeparator(),\n",
            "\t\t\t\t\"find \",\n",
            "\t\t\t\t\"( \",\n",
            "                                builder.setOperation( Operation.FIND ), // <----- this is new\n",
            "\t\t\t\tJsonObject(), builder.setCriteria( match() ),\n",
            "\t\t\t\tOptional( Sequence( \", \", JsonObject(), builder.setProjection( match() ) ) ),\n",
            "\t\t\t\t\") \"\n",
            "\t\t);\n",
            "\t}\n",
            "{code}\n",
            "- we should also check if we can make the CriteriaOnlyFindQuery() a bit more restrictive (but we should check that MongoDB doesn't accept all sorts of weird syntaxes for this JSON)\n",
            "\n",
            "Then the idea is to use all this information we collect to improve {{MongoDBQueryDescriptorBuilder#build()}} to make educated decisions about what this query is and return proper error message if the query is not valid., Similarity: 0.3770\n",
            "Summary & Description: mongodb properties child object inheritance hierarchies loaded coming relation \n",
            " In a polymorphic relation with an entity hierarchy using SINGLE_TABLE inheritance type, the properties of subclasses (which do not exist in the parent class) are not loaded if the query to retrieve the required objects acts on a parent class. It looks like the selector, created by Hibernate OGM for MongoDB extension, considers properties of a base class only. This works without any issue with any JPA provider for RDBMS databases.\n",
            "\n",
            "E.g.\n",
            "\n",
            "{code:java}\n",
            "@Entity\n",
            "@Inheritance(strategy = InheritanceType.SINGLE_TABLE)\n",
            "@DiscriminatorColumn(name = \"TYPE\")\n",
            "public abstract class BaseClass {\n",
            "    private String baseClassProperty;\n",
            "}\n",
            "\n",
            "@Entity\n",
            "@DiscriminatorValue(value = \"A\")\n",
            "public class SubClassA extends BaseClass {\n",
            "   private String subClassAProperty;\n",
            "   \n",
            "   // further properties and methods ...\n",
            "}\n",
            "\n",
            "@Entity\n",
            "@DiscriminatorValue(value = \"B\")\n",
            "public class SubClassB extends BaseClass {\n",
            "   private String subClassBProperty;\n",
            "\n",
            "   // further properties and methods ...\n",
            "}\n",
            "\n",
            "@Entity\n",
            "public class BaseClassUser {\n",
            "   @Id\n",
            "   private Long id;\n",
            "   \n",
            "   @OneToMany(cascade = CascadeType.ALL, orphanRemoval = true, fetch = FetchType.EAGER)\n",
            "   private Set<BaseClass> values= new HashSet<>();\n",
            "}\n",
            "\n",
            "// from a e.g. test and having multiple corresponding documents in the DB, the following query will return the proper objects in the values relation of the loaded BaseClassUser object, but the subClass*Property will be null in all cases.\n",
            "\n",
            "final TypedQuery<BaseClassUser> query = manager.createQuery(\"SELECT u FROM BaseClassUser u WHERE u.='1'\", BaseClassUser.class);\n",
            "{code}\n",
            "\n",
            "You can find a fully working example in https://github.com/dadrus/jpa-unit to reproduce this issue. The affected test case is in https://github.com/dadrus/jpa-unit/blob/master/integration-test/base/src/main/java/eu/drus/jpa/unit/test/AbstractApplyCustomScripsTest.java (test1() method; line 70) With Hibernate OGM and MongoDB it can be run using https://github.com/dadrus/jpa-unit/blob/master/integration-test/jpa-mongodb-hibernate-ogm-test/src/test/java/eu/drus/jpa/unit/test/ApplyCustomScripsTest.java. The aforementioned line is disabled because of this issue. If enabled NPE is thrown with Hibernate OGM and MongoDB.\n",
            "\n",
            "If you run the same test but for a RDBMS (e.g. from https://github.com/dadrus/jpa-unit/blob/master/integration-test/jpa2.1-hibernate-test/src/test/java/eu/drus/jpa/unit/test/ApplyCustomScripsTest.java) everything is fine.\n",
            "\n",
            ", Similarity: 0.3188\n",
            "Summary & Description: create property look native nosql connection via jndi \n",
            " This will help the integration with WildFly swarm.\n",
            "\n",
            "An extract form a conversation on HipChat:\n",
            "\n",
            "{quote}\n",
            "[3:43 PM] Scott Marlow: There was a wildfly-swarm user asking how they could use ogm, the answer was to just use it, but still, it was difficult for them.  We recently updated the wildfly-nosql feature packs to not include the native NoSQL drvers, instead, we updated the Swarm NoSQL fractions to expect the application pom.xml to specify the NoSQL driver dependencies (apps bring their own NoSQL driver, the same way that apps bring their own JDBC driver).\n",
            "[3:44 PM] Scott Marlow: I think that once we integrate OGM + wildfly-nosql, it should be easier for wildfly-swarm users to use ogm\n",
            "[3:46 PM] Scott Marlow: Swarm is looking to move to use WildFly 11 as its base, around June (which was mentioned in their google groups forum),I'd like to release an initial wildfly-nosql (alpha perhaps) and wildfly-swarm fractions around then (time permitting).\n",
            "[3:47 PM] Scott Marlow: so that we can start getting community feedback.\n",
            "{quote}\n",
            "\n",
            "Something else to keep in mind:\n",
            "{quote}\n",
            "[4:19 PM] Sanne Grinovero: we could start with JNDI but I had the impression that JNDI would not be available in all server editions, thinking e.g. a slim version of thorntail\n",
            "[4:20 PM] Sanne Grinovero: but let's just do it to begin with :)\n",
            "remember there's a jipijapa adaptor in the OGM tree. Start there to keep it easy?\n",
            "{quote}\n",
            ", Similarity: 0.4557\n",
            "Summary & Description: readmemd file hibernate ogm repository incorrect links \n",
            " The https://github.com/hibernate/hibernate-ogm/blob/master/README.md file in Hibernate OGM repository points to incorrect links for Cassandra, CouchDB,EhCache and Redis.\n",
            "\n",
            "On Searching for the following projects, i found the following links, but these are not updated anywhere.\n",
            "https://github.com/DavideD/hibernate-ogm-redis\n",
            "https://github.com/DavideD/hibernate-ogm-ehcache\n",
            "https://github.com/DavideD/hibernate-ogm-couchdb\n",
            "https://github.com/DavideD/hibernate-ogm-cassandra, Similarity: 0.3669\n",
            "Summary & Description: infinispan configuration handling making caches transactional sideeffect \n",
            " The injection of the {{TransactionManagerLookup}} delegate into the Infinispan Cache is flipping the configuration flag making non-transactional caches transactional as a side effect.\n",
            "\n",
            "This leads to caches being wrongly configured with optimistic locking transaction, yet no write-skew checks are being enabled. Also the Cache won't have Repeatable Read isolation nor actual entry versioning, so this breaks all CAS operations.\n",
            "\n",
            "This doesn't affect transactional caches., Similarity: 0.2891\n",
            "Summary & Description: upgrade infinispan 911final \n",
            " Marking as a blocker as it the goal of our roadmap for version 5.3.\n",
            "\n",
            "We will also need this version to implement several missing features, such as\n",
            "* OGM-1170 Infinispan Remote dialect could create the Remote Cache(s) it needs automatically\n",
            "* OGM-1171\n",
            "Implement JP-QL support for Infinispan Remote, Similarity: 0.3988\n",
            "Summary & Description: add new operations native cli mongodb \n",
            " Since 3.2 there are some new operations that the user can execute:\n",
            "\n",
            "* insertOne, insertMany\n",
            "* deleteOne, deleteMany\n",
            "* updateOne, updateMany, replaceOne\n",
            "\n",
            "It should easy to add them to the currently supported operations but if it's too complex, we can split this JIRA in subtasks., Similarity: 0.3269\n",
            "Summary & Description: elementcollection store duplicates add test documentation \n",
            " The problem  is that two identical embedded in an association have the same RowKey.\n",
            "The RowKey is used as key in maps and when we create the map  the last RowKey overrides the previous one.\n",
            "\n",
            "Is it possible to check adding this test to EmbeddableExtraTest:\n",
            "\n",
            "{code}\n",
            "\t@Test\n",
            "\tpublic void testPersistWithDuplicatesInEmbeddedList() throws Exception {\n",
            "\t\ttry ( final Session session = openSession() ) {\n",
            "\t\t\tTransaction transaction = session.beginTransaction();\n",
            "\t\t\tfinal String ALTERNATIVE_NUMBER = \"+1-202-555-0333\";\n",
            "\t\t\tList<String> alternativePhones = Arrays.asList( ALTERNATIVE_NUMBER, ALTERNATIVE_NUMBER );\n",
            "\t\t\tAccountWithPhone account = new AccountWithPhone( \"222\", \"Mobile account 222\" );\n",
            "\t\t\taccount.setPhoneNumber( new PhoneNumber( \"+1-222-555-0111\", alternativePhones ) );\n",
            "\n",
            "\t\t\tsession.persist( account );\n",
            "\t\t\ttransaction.commit();\n",
            "\t\t\tsession.clear();\n",
            "\n",
            "\t\t\ttransaction = session.beginTransaction();\n",
            "\t\t\tAccountWithPhone loadedUser = (AccountWithPhone) session.get( AccountWithPhone.class, account.getId() );\n",
            "\t\t\tassertThat( loadedUser ).as( \"Cannot load persisted object with nested embeddables\" ).isNotNull();\n",
            "\t\t\tassertThat( loadedUser.getPhoneNumber() ).isNotNull();\n",
            "\t\t\tassertThat( loadedUser.getPhoneNumber().getMain() ).isEqualTo( account.getPhoneNumber().getMain() );\n",
            "\t\t\tassertThat( loadedUser.getPhoneNumber().getAlternatives() ).containsExactly(\n",
            "\t\t\t\t\talternativePhones.toArray(\n",
            "\t\t\t\t\t\t\tnew Object[alternativePhones.size()] ) );\n",
            "\n",
            "\t\t\tsession.delete( loadedUser );\n",
            "\t\t\ttransaction.commit();\n",
            "\t\t\tsession.clear();\n",
            "\n",
            "\t\t\ttransaction = session.beginTransaction();\n",
            "\t\t\tassertThat( session.get( AccountWithPhone.class, account.getId() ) ).isNull();\n",
            "\t\t\ttransaction.commit();\n",
            "\t\t}\n",
            "\t}\n",
            "{code}, Similarity: 0.2914\n",
            "Summary & Description: exception id generation used table per concrete class strategy \n",
            " If the following mapping is used:\n",
            "\n",
            "{code}\n",
            "@Entity\n",
            "@Inheritance(strategy = InheritanceType.TABLE_PER_CLASS)\n",
            "public abstract class BaseEntity {\n",
            "    protected UUID id;\n",
            "\n",
            "    @Id\n",
            "    @GeneratedValue(generator = \"uuid\")\n",
            "    @GenericGenerator(name = \"uuid\", strategy = \"uuid2\")\n",
            "    public UUID getId() {\n",
            "        return id;\n",
            "    }\n",
            "...\n",
            "}\n",
            "{code}\n",
            "\n",
            "The user sees the following exception:\n",
            "\n",
            "{code}\n",
            "Caused by: org.hibernate.MappingException: No Dialect mapping for JDBC type: -2\n",
            "{code}\n",
            "\n",
            "It seems the error is caused by the fact that Hibernate ORM creates an additional table for this mapping containing the ids generated. We should try to solve the issue or improve the error message and update the documentation., Similarity: 0.1451"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "{code:java} ... {\"range\":{\"createdAt\":{\"gte\":1.478789928E12}}} ... {code}\n",
            "\n",
            "Elasticsearch then fails with this error:\n",
            "{code:java} {\"type\":\"parse_exception\",\"reason\":\"failed to parse date field [1.478789928E12] with format [strict_date_optional_time||epoch_millis]\"} {code}\n",
            "\n",
            "Tested with Elasticsearch 2.3.5 and 2.4.1, Similarity: 0.1099\n",
            "Summary & Description: prevent mappings assign multiple types single field \n",
            " We should prevent the situation described in HSEARCH-2448 to arise regardless of the indexing service. , Similarity: 0.1072\n",
            "Summary & Description: drop support indexedembeddedindexnullas \n",
            " Elasticsearch doesn't support \"null_value\" for object fields, and does not support setting a string value (our null token) to an object field either, so I don't see how we can get the same kind of queries we had with the Lucene backend (\"path.to.embedded:__null__\") working.\n",
            "\n",
            "Let's give up on this feature, and implement \"exists\" predicates for object fields (HSEARCH-2389) instead.\n",
            ", Similarity: 0.3270\n",
            "Summary & Description: avoid nontrivial computation accessing metadata \n",
            " Currently, some metadata getters, such as {{TypeMetadata.getDocumentFieldMetadataFor}}, trigger a tree traversal through embedded types metadata.\n",
            "We probably want to cache such things, maybe by initializing a flattened view of all embedded metadata upon metadata generation., Similarity: 0.3973\n",
            "Summary & Description: split internal metadata two agnostic metadata indexing service specific metadata \n",
            " We want to make it as easy as possible for users to switch between indexing services (Lucene, Elasticsearch).\n",
            "\n",
            "To that end, we would isolate as much as possible the mapping from the indexing services specifics.\n",
            "This means in particular that field bridges would no longer give access to Lucene-specific features (such as SortedDocValuesFields), but would only serve the purpose of transforming the data from the entity model to a generic document model. Then we'd have another layer (maybe customizable) that would transform the data from the generic document model to a document model that would be specific to an indexing \n",
            "\n",
            "So we'd have:\n",
            "\n",
            "Entity ====[Field bridge]===> Generic Document ====[Indexing service specific bridge]===> Indexing service specific document\n",
            "\n",
            "Note that the indexing service specific bridge might only be a standard, non-customizable singleton (on contrary to field bridges): this is yet to be determined.\n",
            "\n",
            "We'd likely require a reverse process when extracting query results:\n",
            "\n",
            "Entity <====[Field bridge]=== Generic Document <====[Indexing service specific bridge]=== Indexing service specific document\n",
            "\n",
            "See HSEARCH-2055 for discussions about this \"FieldBridge 2.0\" API.\n",
            "\n",
            "The purpose of this ticket is to discuss required changes to the metadata. Indeed, to support this process, we'd need metadata about the generic document model: which fields are supposed to be sortable, what are their types, their expected formats (for dates in particular), etc., so that the indexing service specific bridge would know how to interpret the generic document.\n",
            "Before starting the actual work, we'll probably need to enumerate the required metadata., Similarity: 0.3551\n",
            "Summary & Description: apispi overhaul hs 60 \n",
            " The current APIs and SPIs rely heavily on Lucene types, and this will have to change now that we support alternative indexing services (Elasticsearch, and maybe later Solr, or others).\n",
            "\n",
            "Also, there are known weaknesses in field bridges, and we might as well make use of that opportunity to overhaul the way field bridges are registered/executed., Similarity: 0.3914\n",
            "Summary & Description: prevent field bridges bypassing indexedembedded prefixes \n",
            " Currently, field bridges can define whatever name they want for their fields, and this name is used exactly as is.\n",
            "\n",
            "Two issues arise from this situation:\n",
            "\n",
            " 1. It's not easy for field bridge implementors to override the default field name (prefix + java property name) properly: they are only given the default field name, with no indication whatsoever on what is the prefix and what is the name. Even with string manipulation, it may be impossible to tell one from the other (when the prefix is overridden, for instance). Most of the time, the easiest solution is to only add a suffix to the default field name, which is probably the sanest choice anyway.\n",
            " 2. Field bridge implementors can easily bypass the prefix and add a field to the root of the document, which is a dubious practice at best.\n",
            "\n",
            "When we design the FieldBridge 2.0, we might want to tacle this (especially the second issue)., Similarity: 0.2750\n",
            "Summary & Description: reuse containedinrecursioncontext code parsing annotations \n",
            " We have code responsible for keeping track of the recursion limits when taking ContainedIn into account at runtime:\n",
            "\n",
            " * {{org.hibernate.search.engine.spi.ContainedInRecursionContext}}\n",
            " * {{org.hibernate.search.engine.spi.AbstractDocumentBuilder.updateContainedInRecursionContext(Object, ContainedInMetadata, ContainedInRecursionContext)}}\n",
            "\n",
            "As it happens, the process of generating metadata requires similar code, but is currently implemented differently with:\n",
            "\n",
            " * {{org.hibernate.search.engine.metadata.impl.ParseContext}} and more specifically its methods {{isMaxLevelReached()}}, {{getMaxLevel()}}, {{setMaxLevel(int)}}, {{getLevel()}}, {{incrementLevel()}} and {{decrementLevel()}}\n",
            " * {{org.hibernate.search.engine.metadata.impl.PathsContext}} (which seems to also have an error-tracking purpose in {{org.hibernate.search.engine.metadata.impl.AnnotationMetadataProvider.validateAllPathsEncountered(XProperty, PathsContext, IndexedEmbedded)}})\n",
            " * {{org.hibernate.search.engine.metadata.impl.AnnotationMetadataProvider.checkForIndexedEmbedded(XProperty, Builder, String, boolean, Builder, ConfigContext, PathsContext, ParseContext)}}\n",
            " * {{org.hibernate.search.engine.metadata.impl.AnnotationMetadataProvider.updatePaths(String, PathsContext, IndexedEmbedded)}}\n",
            " * org.hibernate.search.engine.metadata.impl.AnnotationMetadataProvider.isInPath(String, PathsContext, IndexedEmbedded)\n",
            "\n",
            "It may be a good idea to factor in these two implementations if they are indeed achieving a similar purpose. Especially since the {{ContainedInRecursionContext}} implementation seems simpler., Similarity: 0.3150\n",
            "Summary & Description: report incomplete metadata issues elasticsearch mapping generation \n",
            " Issue spotted here: https://github.com/hibernate/hibernate-search/pull/1217/commits/dfc7f199358808397d144d79d89f7915851db222#r87074164\n",
            "\n",
            "Right now, we're only logging debug messages when failing to add a property/field to the ES mapping:\n",
            "\n",
            "\n",
            "{code:file=DefaultElasticsearchSchemaTranslator.java}\n",
            "\t\t// normal document fields\n",
            "\t\tfor ( DocumentFieldMetadata fieldMetadata : typeMetadata.getNonEmbeddedDocumentFieldMetadata() ) {\n",
            "\t\t\ttry {\n",
            "\t\t\t\taddPropertyMapping( mappingBuilder, fieldMetadata );\n",
            "\t\t\t}\n",
            "\t\t\tcatch (IncompleteDataException e) {\n",
            "\t\t\t\tLOG.debug( \"Not adding a mapping for field \" + fieldMetadata.getAbsoluteName() + \" because of incomplete data\", e );\n",
            "\t\t\t}\n",
            "\t\t}\n",
            "\n",
            "\t\t// bridge-defined fields\n",
            "\t\tfor ( BridgeDefinedField bridgeDefinedField : getNonEmbeddedBridgeDefinedFields( typeMetadata ) ) {\n",
            "\t\t\ttry {\n",
            "\t\t\t\taddPropertyMapping( mappingBuilder, bridgeDefinedField );\n",
            "\t\t\t}\n",
            "\t\t\tcatch (IncompleteDataException e) {\n",
            "\t\t\t\tLOG.debug( \"Not adding a mapping for field \" + bridgeDefinedField.getAbsoluteName() + \" because of incomplete data\", e );\n",
            "\t\t\t}\n",
            "\t\t}\n",
            "\n",
            "....\n",
            "\n",
            "\n",
            "\t\tfor ( FacetMetadata facetMetadata : fieldMetadata.getFacetMetadata() ) {\n",
            "\t\t\ttry {\n",
            "\t\t\t\taddFieldMapping( propertyMapping, mappingBuilder, facetMetadata );\n",
            "\t\t\t}\n",
            "\t\t\tcatch (IncompleteDataException e) {\n",
            "\t\t\t\tLOG.debug( \"Not adding a mapping for facet \" + facetMetadata.getAbsoluteName() + \" because of incomplete data\", e );\n",
            "\t\t\t}\n",
            "\t\t}\n",
            "{code}\n",
            "\n",
            "The only way to get IncompleteDataException can be found in {{addTypeOptions}}:\n",
            "\n",
            "{code}\n",
            "...\n",
            "\t\t\t\tbreak;\n",
            "\t\t\tcase UNKNOWN_NUMERIC:\n",
            "\t\t\t\t// Likely a custom field bridge which does not expose the type of the given field; either correctly\n",
            "\t\t\t\t// so (because the given name is the default field and this bridge does not wish to use that field\n",
            "\t\t\t\t// name as is) or incorrectly; The field will not be added to the mapping, causing an exception at\n",
            "\t\t\t\t// runtime if the bridge writes that field nevertheless\n",
            "\t\t\t\telasticsearchType = null;\n",
            "\t\t\t\tbreak;\n",
            "\t\t\tcase STRING:\n",
            "\t\t\tcase UNKNOWN:\n",
            "\t\t\tdefault:\n",
            "\t\t\t\telasticsearchType = DataType.STRING;\n",
            "\t\t\t\tbreak;\n",
            "\t\t}\n",
            "\n",
            "\t\tif ( elasticsearchType == null ) {\n",
            "\t\t\tthrow new IncompleteDataException( \"Field type could not be determined\" );\n",
            "\t\t}\n",
            "{code}\n",
            "\n",
            "While I understand that we might not want to make the mapping generation fail completely (so that users may test more easily), at least we should issue a warning. Or maybe even log an error.\n",
            "\n",
            "Something to be considered: [~accountid:557058:99e61e65-956b-4a21-b29c-06057642e9ea] expressed concerned about issuing warnings, since in some enterprises they are considered blocking when putting applications in production.\n",
            "\n",
            "I feel like one of the purposes of warnings is to inform users about potential error, and leave it to the user to decide if it's bad or not. So in this case, it would be exactly what we need. Now, if it's blocking for some users...\n",
            "\n",
            "[~accountid:557058:71e31052-f0d7-46e3-a9d7-8b9acd6998d8], [~accountid:557058:99e61e65-956b-4a21-b29c-06057642e9ea], WDYT?, Similarity: 0.4189\n",
            "Summary & Description: wait index status raise exception \n",
            " Hi there\n",
            "\n",
            "I'm doing some tests with Elasticsearch 2.4.1.\n",
            "Empty and fresh new elasticsearch.\n",
            "\n",
            "Running tests as described at: https://github.com/dadoonet/hsearch-es-demo/tree/02-hibernatesearch\n",
            "\n",
            "{code:xml}\n",
            "<persistence \n",
            "  xmlns=\"http://xmlns.jcp.org/xml/ns/persistence\"\n",
            "  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n",
            "  xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/persistence http://xmlns.jcp.org/xml/ns/persistence/persistence_2_1.xsd\"\n",
            "  version=\"2.1\">\n",
            "\n",
            "  <persistence-unit name=\"videoGamePu\" transaction-type=\"RESOURCE_LOCAL\">\n",
            "\n",
            "    <description>Persistence Unit of the Video Game Manager App</description>\n",
            "    <provider>org.hibernate.jpa.HibernatePersistenceProvider</provider>\n",
            "\n",
            "    <properties>\n",
            "      <property name=\"hibernate.connection.url\" value=\"jdbc:h2:mem:db1;DB_CLOSE_DELAY=-1\" />\n",
            "      <property name=\"hibernate.connection.username\" value=\"sa\" />\n",
            "\n",
            "      <property name=\"hibernate.show_sql\" value=\"false\" />\n",
            "      <property name=\"hibernate.hbm2ddl.auto\" value=\"create-drop\" />\n",
            "      \n",
            "      <property name=\"hibernate.search.default.indexmanager\" value=\"elasticsearch\"/>\n",
            "      <property name=\"hibernate.search.default.elasticsearch.host\" value=\"http://127.0.0.1:9200\"/>\n",
            "      <property name=\"hibernate.search.default.elasticsearch.index_schema_management_strategy\" value=\"CREATE\"/>\n",
            "\n",
            "    </properties>\n",
            "\n",
            "  </persistence-unit>\n",
            "</persistence>\n",
            "{code}\n",
            "\n",
            "Only one node running. So the index status is yellow.\n",
            "\n",
            "\n",
            "{code}\n",
            "$ curl localhost:9200/_cat/indices?v\n",
            "health status index                                        pri rep docs.count docs.deleted store.size pri.store.size \n",
            "yellow open   org.hibernate.demos.hswithes.model.videogame   5   1          3            0     10.2kb         10.2kb \n",
            "{code}\n",
            "\n",
            "[According to the code|https://github.com/hibernate/hibernate-search/blob/master/elasticsearch/src/main/java/org/hibernate/search/elasticsearch/impl/ElasticsearchIndexManager.java#L262-L281], it should fail with an exception but apparently it does not.\n",
            "\n",
            "I wonder if actually you are passing the timeout value with a unit. If you don't this raise an exception which is not 408.\n",
            "\n",
            "{code}\n",
            "$ curl -XGET 'http://localhost:9200/_cluster/health/org.hibernate.demos.hswithes.model.videogame?wait_for_status=green&timeout=10000' -v\n",
            "*   Trying ::1...\n",
            "* Connected to localhost (::1) port 9200 (#0)\n",
            "> GET /_cluster/health/org.hibernate.demos.hswithes.model.videogame?wait_for_status=green&timeout=10000 HTTP/1.1\n",
            "> Host: localhost:9200\n",
            "> User-Agent: curl/7.43.0\n",
            "> Accept: */*\n",
            "> \n",
            "< HTTP/1.1 400 Bad Request\n",
            "< Content-Type: application/json; charset=UTF-8\n",
            "< Content-Length: 317\n",
            "< \n",
            "* Connection #0 to host localhost left intact\n",
            "{\"error\":{\"root_cause\":[{\"type\":\"parse_exception\",\"reason\":\"Failed to parse setting [timeout] with value [10000] as a time value: unit is missing or unrecognized\"}],\"type\":\"parse_exception\",\"reason\":\"Failed to parse setting [timeout] with value [10000] as a time value: unit is missing or unrecognized\"},\"status\":400}\n",
            "{code}\n",
            "\n",
            "But with a correct time unit, it waits and fails.\n",
            "\n",
            "{code}\n",
            "$ curl -XGET 'http://localhost:9200/_cluster/health/org.hibernate.demos.hswithes.model.videogame?wait_for_status=green&timeout=1s' -v\n",
            "*   Trying ::1...\n",
            "* Connected to localhost (::1) port 9200 (#0)\n",
            "> GET /_cluster/health/org.hibernate.demos.hswithes.model.videogame?wait_for_status=green&timeout=1s HTTP/1.1\n",
            "> Host: localhost:9200\n",
            "> User-Agent: curl/7.43.0\n",
            "> Accept: */*\n",
            "> \n",
            "< HTTP/1.1 408 Request Timeout\n",
            "< Content-Type: application/json; charset=UTF-8\n",
            "< Content-Length: 388\n",
            "< \n",
            "* Connection #0 to host localhost left intact\n",
            "{\"cluster_name\":\"elasticsearch\",\"status\":\"yellow\",\"timed_out\":true,\"number_of_nodes\":1,\"number_of_data_nodes\":1,\"active_primary_shards\":5,\"active_shards\":5,\"relocating_shards\":0,\"initializing_shards\":0,\"unassigned_shards\":5,\"delayed_unassigned_shards\":0,\"number_of_pending_tasks\":0,\"number_of_in_flight_fetch\":0,\"task_max_waiting_in_queue_millis\":0,\"active_shards_percent_as_number\":50.0}\n",
            "{code}\n",
            "\n",
            "Let me know if you need more details. I can try to work on a PR later next week.\n",
            ", Similarity: 0.2949\n",
            "Summary & Description: add support multifields elasticsearch map property several fields \n",
            " Today we map them into separate fields but Elasticsearch has the notion of subfields\n",
            "\n",
            "https://www.elastic.co/guide/en/elasticsearch/reference/5.0/multi-fields.html\n",
            "\n",
            "So the JSON doc would have the field value only once., Similarity: 0.3307\n",
            "Summary & Description: add ability pass several ips elasticsearch host \n",
            " Alternatively or in addition is to add discoveryEnabled option of JEST\n",
            "\n",
            "This is necessary to get fail over support., Similarity: 0.3806\n",
            "Summary & Description: throw exceptions clear messages field type conflicts elasticsearch \n",
            " With the Lucene backend, we used to allow using a specific path as both a composite object and a concrete object (string, long, etc). For instance, if we have something like this:\n",
            "\n",
            "{code}\n",
            "myComposite.leaf=foo\n",
            "myComposite=bar\n",
            "{code}\n",
            "\n",
            "Then {{myComposite}} may hold both a concrete value (\"bar\") *and* sub-fields ({{myComposite.leaf}}).\n",
            "\n",
            "A concrete case when this could happen is when you have a property annotated with both {{@Field}} and {{@IndexedEmbedded}}:\n",
            "\n",
            "{code:java}\n",
            "@IndexedEmbedded(prefix = \"myComposite.\")\n",
            "@Field(name = \"myComposite\")\n",
            "private MyComposite myComposite;\n",
            "{code}\n",
            "\n",
            "This works alright with Lucene, because there is no such thing as a composite object: the data is flattened and stored as a big bag of key/value pairs.\n",
            "But with Elasticsearch, this is not the case, at least not when interacting through the APIs: composite object have dedicated types (the {{object}} and {{nested}} datatypes), and those do not allow storing concrete values (only sub-fields).\n",
            "\n",
            "Currently though, we do not check for such cases, and when an error happens, it's rather cryptic because it comes from Elasticsearch and does not have much context.\n",
            "\n",
            "We should make sure that we throw clear exceptions:\n",
            "\n",
            " * when generating the mapping, we should throw an exception with a clear message when an ES property has multiple types (object and something else). Currently, the last encountered wins, and we may end up with properties with the {{long}} datatype (for instance) that also have their own properties, which will make ES cry.\n",
            " * when mapping generation is disabled, we should make sure to throw an exception anyway. We may do this at runtime (when using conflicting fields in projections, sorts or queries) or when boostrapping, whichever is easier.\n",
            "\n",
            "The limitations have already been documented as part of HSEARCH-2396., Similarity: 0.2667\n",
            "Summary & Description: make easier add sortable fields custom field bridges \n",
            " See https://github.com/hibernate/hibernate-search/pull/1212#discussion_r86206665\n",
            "\n",
            "Custom field bridges which provide sortable fields don't have their doc values added automatically, because we prevent that explicitly in {{org.hibernate.search.engine.spi.DocumentBuilderIndexedEntity.addSortFieldDocValues(Document, PropertyMetadata, float, Object)}}. That behavior is documented:\n",
            "\n",
            "{quote}Fields added through class-level bridges or custom field-level bridges (when not using the default field name) cannot\n",
            "be marked as sortable by means of the `@SortableField` annotation. Instead the field bridge itself has to add the\n",
            "required doc value fields, in addition to the document fields it adds. Furthermore such bridge needs to implement the\n",
            "`MetadataProvidingFieldBridge` interface which defines a method `configureFieldMetadata()` for marking the fields\n",
            "created by this bridge as sortable:\n",
            "{quote}\n",
            "\n",
            "We should do something to make that easier.\n",
            "\n",
            "One solution would be to provide methods in LuceneOptions to add sortable fields (internally, we'd add the docvalues along with the standard field).\n",
            "\n",
            "Another solution would be to simply remove the requirement for field bridges to provide the doc values field themselves: we could do that for them. It seems it would be easy enough as long as the custom field bridge adds a standard field (IntField, DoubleField, etc.) with the value to sort on.\n",
            "\n",
            "However, I just checked: the {{sortable()}} thing in custom field bridges has been added in 5.5.1 / 5.6.0: HSEARCH-2021. So the second solution would mean introducing breaking changes..., Similarity: 0.4133\n",
            "Summary & Description: improve error handling \n",
            " Currently it's possible to set an error handler at search integration level, by using the property {{hibernate.search.error_handler}} pointing to a implementation class. The error handler is a callback that presents the exception and an {{org.hibernate.search.exception.ErrorContext}} that contains the works that failed and the {{Throwable}}\n",
            "\n",
            "On a particular Infinispan index manager, sometimes it may be desirable to retry some indexing operations when a particular exception happens in the backend, and the current mechanism poses some challenges:\n",
            "\n",
            "* The error handler is at {{SearchIntegrator}} level, so all shards (index managers) share the same error handler; \n",
            "* There's no indication of which index manager that the error occurred;\n",
            "* It's not possible to compose multiple error handlers into one, which would allow to first do a RetryErrorHandler and then delegate it to the LogErrorHandler if it fails.\n",
            "\n",
            "\n",
            "\n",
            ", Similarity: 0.2957\n",
            "Summary & Description: hibernate search pom leads incorrect dependencies used client project \n",
            " I found a usability issue while working on a demo.\n",
            "\n",
            "Here is my POM\n",
            "\n",
            "{code:xml}\n",
            "\t<properties>\n",
            "\t\t<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n",
            "\t\t<project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>\n",
            "\t\t<maven.compiler.source>1.8</maven.compiler.source>\n",
            "\t\t<maven.compiler.target>1.8</maven.compiler.target>\n",
            "\n",
            "\t\t<version.org.hibernate.orm>5.1.2.Final</version.org.hibernate.orm>\n",
            "\t\t<version.org.hibernate.search>5.6.0.Beta3</version.org.hibernate.search>\n",
            "\t\t<slf4jVersion>1.6.4</slf4jVersion>\n",
            "\t</properties>\n",
            "\n",
            "\t<dependencies>\n",
            "\t\t<!-- Compile -->\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.hibernate</groupId>\n",
            "\t\t\t<artifactId>hibernate-search-orm</artifactId>\n",
            "\t\t\t<version>${version.org.hibernate.search}</version>\n",
            "\t\t</dependency>\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.hibernate</groupId>\n",
            "\t\t\t<artifactId>hibernate-search-elasticsearch</artifactId>\n",
            "\t\t\t<version>${version.org.hibernate.search}</version>\n",
            "\t\t</dependency>\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.hibernate</groupId>\n",
            "\t\t\t<artifactId>hibernate-entitymanager</artifactId>\n",
            "\t\t\t<version>${version.org.hibernate.orm}</version>\n",
            "\t\t</dependency>\n",
            "{code}\n",
            "\n",
            "But in the runtime logs, I see that ORM 5.1.0 is used (the version selected by Hibernate Search's POM).\n",
            "\n",
            "{code}\n",
            "[2016-11-02 08:43:38,485][INFO ][org.hibernate.Version    ] HHH000412: Hibernate Core {5.1.0.Final}\n",
            "{code}\n",
            "\n",
            "One way out is to do\n",
            "\n",
            "{code:xml}\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.hibernate</groupId>\n",
            "\t\t\t<artifactId>hibernate-search-elasticsearch</artifactId>\n",
            "\t\t\t<version>${version.org.hibernate.search}</version>\n",
            "\t\t\t<exclusions>\n",
            "\t\t\t\t<exclusion>\n",
            "\t\t\t\t\t<groupId>org.hibernate</groupId>\n",
            "\t\t\t\t\t<artifactId>hibernate-core</artifactId>\n",
            "\t\t\t\t\t<artifactId>hibernate-entitymanager</artifactId>\n",
            "\t\t\t\t</exclusion>\n",
            "\t\t\t</exclusions>\n",
            "\t\t</dependency>\n",
            "{code}\n",
            "\n",
            "But that is not very nice for users.\n",
            "\n",
            "Is there anything we could do? Maybe making {{hibernate-entitymanager}} and {{hibernate-core}} optional dependencies in {{hibernate-search-orm}}?, Similarity: 0.4362\n",
            "Summary & Description: asyncexecutor blocks forever shutdown \n",
            " We have a situation on Infinispan where closing an index backend blocks forever with the stack trace attached. We are not sure of the reason why since it is blocking on \n",
            "\n",
            "{noformat}\n",
            "at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1465)\n",
            "at org.hibernate.search.backend.impl.lucene.LuceneBackendResources.flushCloseExecutor(LuceneBackendResources.java:125)\n",
            "{noformat}\n",
            "\n",
            "but there are not threads running called \"Index updates queue processor for index ...\".\n",
            ", Similarity: 0.3325\n",
            "Summary & Description: consider support nested objects parent child \n",
            " Elasticsearch has two interesting features mapping wise\n",
            "\n",
            "* nested objects https://www.elastic.co/guide/en/elasticsearch/guide/current/nested-objects.html\n",
            "* parent child https://www.elastic.co/guide/en/elasticsearch/guide/current/parent-child.html\n",
            "\n",
            "We should offer the option for a user to chose when an @IndexedEmbedded is mapped as manual denormalization, nested object or parent child.\n",
            "\n",
            "We can orthogonally add support for this in the Lucene backend., Similarity: 0.2191\n",
            "Summary & Description: add support elasticsearch 5 \n",
            " Adding a ticket, since I'm working on it. I will update the required changes below as I find new ones.\n",
            "\n",
            "Potential blockers:\n",
            "\n",
            " * Support for specifying analyzers in elasticsearch.yml has been removed: https://www.elastic.co/guide/en/elasticsearch/reference/5.x/analysis-custom-analyzer.html: we have to use the Rest API to declare analyzers (see HSEARCH-2219)\n",
            " * Analyzer definitions are now index-scoped so you can't declare global analyzers and have to declare the analyzers for each index (more or less each Hibernate root entity); this is highly inconvenient. This makes solving HSEARCH-2219 all the more important: expecting users to declare analyzers themselves on the Elasticsearch server is now a no-no (see comments on this ticket).\n",
            "\n",
            "External work required:\n",
            "\n",
            " * The elasticsearch-maven-plugin is not compatible with ES 5; I set up a branch with the minimal required changes and opened a PR: https://github.com/alexcojocaru/elasticsearch-maven-plugin/pull/19\n",
            " * Elastic only released the core Elasticsearch artifact on maven central, and some modules, but not the groovy module (https://github.com/elastic/elasticsearch/tree/master/modules/lang-groovy). The classes are not part of the core artifact, either (they could have been due to some Gradle magic). *Thus*, running our Elasticsearch integration tests with an embedded instance of Elasticsearch may prove impossible (at least for those which need Groovy). Oddly enough, their own language \"Painless\" suffers from the exact same issue: http://search.maven.org/#search%7Cga%7C1%7Cg%3Aorg.elasticsearch%20AND%20v%3A5.0.0\n",
            "   **UPDATE**: actually, it's on purpose. They only want to publish ZIPs, so I guess elasticsearch-maven-plugin is a dead-end, at least as it is now: https://github.com/elastic/elasticsearch/issues/18131#issuecomment-222105133\n",
            " * The Optimize API has been removed in favor of the newer ForceMerge API, which is almost identical (except its name). Jest only supports the Optimize API in its current version. Note that the ForceMerge API wasn't available in ES 2.0, it appeared in ES 2.1... I opened a PR to add the ForceMerge command anyway: https://github.com/searchbox-io/Jest/pull/408\n",
            "   See also https://www.elastic.co/guide/en/elasticsearch/reference/5.0/breaking_50_rest_api_changes.html#_literal__optimize_literal_endpoint_removed\n",
            "\n",
            "Changes that would require to drop support for 2.0 (or to introduce dialects):\n",
            "\n",
            " * The {{string}} datatype disappeared and has been replaced by {{text}} and {{keyword}}. What we need is probably {{text}}, except for non-anlyzed fields that must be {{keyword}} s (as {{text}} fields *have* to be analyzed).\n",
            " * {{null_value}} is no longer supported on the {{text}} datatype: we currently use it for the {{indexNullAs}} feature\n",
            " * sorting on text fields now requires enabling [data loading|https://www.elastic.co/guide/en/elasticsearch/reference/5.0/fielddata.html] in the mapping\n",
            " * DeleteByQuery is a core feature again, with its own API. The plugin has been removed.\n",
            " * The default scripting language is now Painless, which is very similar to Groovy (only script parameters must be prefixed with {{params.}})\n",
            " * For projections, the \"fields\" keyword when querying is now \"stored_fields\" and using \"_source\" in there is disallowed. Source filtering must be used to access the _source. e.g. {{?_source_include=foo}}\n",
            " * {{arcDistanceInKm}} has been renamed to {{arcDistance}} and now returns meters: https://www.elastic.co/guide/en/elasticsearch/reference/5.0/breaking_50_scripting.html#_geopoint_scripts\n",
            "\n",
            "Changes that will probably also work with ES 2.x (see HSEARCH-2437):\n",
            "\n",
            " * -\"filtered\" queries are no longer supported and must be replaced by \"bool\" queries with a \"must\" and a \"filter\"-\n",
            " * -the \"queryString\" keyword for query string queries does not work anymore, we must use \"query_string\" (I wonder why we didn't in the first place)-\n",
            " * -The syntax we used with ES 2 for search scripts- ({{\"script_fields:\"\\{\"_distance\":\\{\"params\": \\{...\\}, \"script\": \"...\"\\}\\} }}) -seems off with the documentation and doesn't work in ES 5.-\n",
            " * -the {{size}} parameter in bucket aggregation queries (used for facetting) used to accept a 0 value, meaning \"Integer.MAX_VALUE\". It was a deprecated feature and it's not possible anymore.- See https://www.elastic.co/guide/en/elasticsearch/reference/2.4/search-aggregations-bucket-terms-aggregation.html#_size\n",
            " * HSEARCH-2414 affects Elasticsearch 5.0 too (not only 2.4.1).\n",
            "\n",
            "See my branch where I'm poking around to see what needs to be done: https://github.com/yrodiere/hibernate-search/tree/HSEARCH-2434, Similarity: 0.3531\n",
            "Summary & Description: assertionfailure providedid embeddeds \n",
            " This started after integration of HSEARCH-2397 apparently, building the SearchFactory started throwing an exception on Infinispan:\n",
            "\n",
            "{noformat}\n",
            "org.hibernate.search.exception.AssertionFailure: The path 'providedId' is not contained within 'addresses.'\n",
            "\n",
            "\tat org.hibernate.search.elasticsearch.impl.PathComponentExtractor.makeRelative(PathComponentExtractor.java:58)\n",
            "\tat org.hibernate.search.elasticsearch.impl.ElasticsearchMappingBuilder.setPropertyAbsolute(ElasticsearchMappingBuilder.java:114)\n",
            "\tat org.hibernate.search.elasticsearch.impl.ElasticsearchIndexManager.addFieldMapping(ElasticsearchIndexManager.java:417)\n",
            "\tat org.hibernate.search.elasticsearch.impl.ElasticsearchIndexManager.addMappings(ElasticsearchIndexManager.java:372)\n",
            "\tat org.hibernate.search.elasticsearch.impl.ElasticsearchIndexManager.addMappings(ElasticsearchIndexManager.java:392)\n",
            "\tat org.hibernate.search.elasticsearch.impl.ElasticsearchIndexManager.createIndexMappings(ElasticsearchIndexManager.java:343)\n",
            "\tat org.hibernate.search.elasticsearch.impl.ElasticsearchIndexManager.initializeIndex(ElasticsearchIndexManager.java:231)\n",
            "\tat org.hibernate.search.elasticsearch.impl.ElasticsearchIndexManager.setSearchFactory(ElasticsearchIndexManager.java:222)\n",
            "\tat org.hibernate.search.indexes.impl.IndexManagerHolder.setActiveSearchIntegrator(IndexManagerHolder.java:190)\n",
            "\tat org.hibernate.search.engine.impl.MutableSearchFactoryState.setActiveSearchIntegrator(MutableSearchFactoryState.java:227)\n",
            "\tat org.hibernate.search.spi.SearchIntegratorBuilder.buildNewSearchFactory(SearchIntegratorBuilder.java:228)\n",
            "\tat org.hibernate.search.spi.SearchIntegratorBuilder.buildSearchIntegrator(SearchIntegratorBuilder.java:118)\n",
            "\tat org.infinispan.query.impl.LifecycleManager.getSearchFactory(LifecycleManager.java:317)\n",
            "{noformat}\n",
            "\n",
            "\n",
            "Here's the partial mapping for reference:\n",
            "{code:java}\n",
            "@Indexed\n",
            "public class User  {\n",
            "\n",
            "   @Field(store = Store.YES, analyze = Analyze.NO)\n",
            "   @SortableField\n",
            "   private int id;\n",
            "\n",
            "   @IndexedEmbedded(targetElement = Address.class, indexNullAs = Field.DEFAULT_NULL_TOKEN)\n",
            "   private List<Address> addresses;\n",
            "\n",
            "}\n",
            "\n",
            "public class Address  {\n",
            "\n",
            "   @Field(store = Store.YES, analyze = Analyze.NO)\n",
            "   private String street;\n",
            "\n",
            "   @Field(store = Store.YES, analyze = Analyze.NO)\n",
            "   private String postCode;\n",
            "\n",
            "   @Field(store = Store.YES, analyze = Analyze.NO)\n",
            "   private int number;\n",
            "}\n",
            "\n",
            "{code}\n",
            "\n",
            "We have a {{SearchConfiguration}} with {{isIdProvidedImplicit}} true\n",
            ", Similarity: 0.3756\n",
            "Summary & Description: entity ids containing underscore lost querying \n",
            " We have a test case on Infinispan where the entity id is \"user_2\". The Elasticsearch backend erroneously considers \"user\" as the tenant id and returns id \"2\" in the query, Similarity: 0.1112\n",
            "Summary & Description: analyzers classbridge ignored elasticsearch \n",
            " This is because the {{ElasticsearchIndexManager}} relies on {{org.hibernate.search.engine.metadata.impl.DocumentFieldMetadata.getAnalyzerReference()}} to determine the analyzer, and {{org.hibernate.search.engine.metadata.impl.AnnotationMetadataProvider.bindClassBridgeAnnotation(String, Builder, ClassBridge, FieldBridge, ConfigContext, ParseContext)}} does not initialize the analyzer reference on the {{DocumentFieldMetadata}} (no call to {{builder.analyzerReference}}).\n",
            "\n",
            "There might be other metadata that are not initialized properly, so it may be worth it to compare standard field metadata building with class bridge metadata building.\n",
            "\n",
            "Note: there are disabled tests that should be re-enabled if we implement this feature or marked as definitively disabled if we decide otherwise. Search in the codebase for references to this ticket's key., Similarity: 0.3843\n",
            "Summary & Description: provide alternative orghibernatesearchanalyzerdiscriminator elasticsearch \n",
            " {{org.hibernate.search.analyzer.Discriminator}} allows to dynamically choose the analyzer to use on each field based on the value of one entity property.\n",
            "This can't be done on Elasticsearch, as analyzers are defined by the mapping, and cannot be specified when indexing.\n",
            "\n",
            "We should either:\n",
            "\n",
            " * Find a way to implement this (unlikely).\n",
            " * Provide an alternative to Elasticsearch backend users. The Elasticsearch doc advises to use {{fields}} to address a similar use case: https://www.elastic.co/guide/en/elasticsearch/reference/2.4/multi-fields.html#_multi_fields_with_multiple_analyzers ; see HSEARCH-2454\n",
            " * Or at the very least, document the lack of support and the fact that it will stay that way. This is currently documented as a temporary limitation as part of HSEARCH-2393.\n",
            "\n",
            "Note: there are disabled tests that should be re-enabled if we implement this feature or marked as definitively disabled if we decide otherwise. Search for the string {{HSEARCH-2428}} in the codebase., Similarity: 0.2819\n",
            "Summary & Description: specifying analyzer apply elasticsearch field mapping \n",
            " I have an analyzer defined in my elasticsearch.yml conf file.\n",
            "\n",
            "{code}\n",
            "index.analysis :\n",
            "    analyzer :\n",
            "        hsanalyzer :\n",
            "            type: custom\n",
            "            tokenizer : standard\n",
            "            filter : [lowercase, autocomplete_filter]\n",
            "    filter :\n",
            "        autocomplete_filter :\n",
            "            type: edge_ngram\n",
            "            min_gram: 1\n",
            "            max_gram: 20\n",
            "{code}\n",
            "\n",
            "This analyzer allows an autocomplete search.\n",
            "\n",
            "My domain object attribute is defined as\n",
            "\n",
            "{code:java}\n",
            "@NotNull\n",
            "@Column(name = \"title\", nullable = false)\n",
            "@Field(index = Index.YES, store = Store.YES, analyze = Analyze.YES, analyzer = @Analyzer(definition = \"hsanalyzer\"))\n",
            "private String title;\n",
            "{code}\n",
            "\n",
            "When the ES mapping is created, the analyzer is not specified for the title field. So my ES mapping is the following:\n",
            "{code}\n",
            "\"title\": {\n",
            "\"type\": \"string\"\n",
            "}\n",
            "{code}\n",
            "\n",
            "instead of\n",
            "\n",
            "{code}\n",
            "\"title\": {\n",
            "\"analyzer\": \"hsanalyzer\",\n",
            "\"type\": \"string\"\n",
            "}\n",
            "{code}\n",
            "\n",
            "and consequently without the analyzer defined in the mapping the autocomplete does not work., Similarity: 0.3597\n",
            "Summary & Description: projecting unstored field raise exception elasticsearch \n",
            " Currently projecting an unstored fields works with Elasticsearch, because we use the \"_source\" for extracting the results anyway. So the field storage is never used, actually. See HSEARCH-2358 for details.\n",
            "\n",
            "Anyway, I think we should enforce storing those fields, be it only to shield us from a future issue with the current retrieval method, that would force us to do it the \"right\" way.\n",
            "\n",
            "A test case is provided in {{org.hibernate.search.test.query.ProjectionQueryTest}}: {{projectingUnstoredField}}. The test was disabled as part of HSEARCH-2406, but it should be re-enabled when this issue ({{HSEARCH-2423}}) has been fixed., Similarity: 0.3061\n",
            "Summary & Description: support statistics elasticsearch \n",
            " Some tests fail because of the lack of support for statistics with Elasticsearch.\n",
            "\n",
            "In particular:\n",
            "\n",
            " * {{org.hibernate.search.test.jmx.IndexControlMBeanTest.testIndexAndPurge()}}\n",
            " * {{org.hibernate.search.test.configuration.mutablefactory.MutableFactoryTest.testAddingClassSimpleAPIwithJMX()}}\n",
            " * ... ?\n",
            "\n",
            "Please do a search in the code for this ticket ({{HSEARCH-2421}}) when solving the issue., Similarity: 0.3091\n",
            "Summary & Description: tenant ids containing underscores supported es \n",
            " See {{DocumentIdHelper}}: if the tenant ID contains an underscore, it is likely that only the part before the underscore will be interpreted as the tenant ID, the remaining part being interpreted as the beginning of the entity ID.\n",
            "\n",
            "We should escape underscore in the tenant ID, and take these escape into account when extracting back the entity ID.\n",
            "Also, we should check whether there are other places where we should take this escaping into account (most notably queries)., Similarity: 0.0560\n",
            "Summary & Description: allow registering analyzer definitions bootstrap via extension point \n",
            " Currently the Analyzers are being looked up by name, but the name map is built by Hibernate Search itself according to its configuration and {{@AnalyzerDef}} annotations.\n",
            "\n",
            "Other frameworks, _Infinispan Query_ as a concrete case, might want to provide additional means for defining analyzers. We decided at a face to face meeting that the simplest solution would be to make our \"Analyzer Map\" a {{Service}} contract, so that they can inject their own instance to override the current one, which would be promoted to \"default implementation\".\n",
            "\n",
            "The interface definition looks like trivial; we need to make sure however that we consistently use this and keep in mind that the Map is a concurrent service, which might be updated by external parties at runtime.\n",
            "\n",
            "I suspect - and hope - that we'll be able to agree that such updates can only be additive: i.e. adding a new name/analyzer couple would be fine, but changing or removing the mapping of a previously defined name is more problematic without introducing some locking mechanism.\n",
            ", Similarity: 0.3905\n",
            "Summary & Description: allow definition elasticsearch analyzers hibernate search \n",
            " It seems there is an API allowing to define analyzers remotely in ES: https://www.elastic.co/guide/en/elasticsearch/reference/2.4/indices-update-settings.html\n",
            "\n",
            "Maybe we could use that to push analyzers along with the mappings?, Similarity: 0.2528\n",
            "Summary & Description: zoneddatetime cannot indexed elasticsearch 241 \n",
            " {code}\n",
            "14:11:06,974 (main) ERROR LogErrorHandler:67 - HSEARCH000058: Exception occurred org.hibernate.search.exception.SearchException: HSEARCH400007: Elasticsearch request failed.\n",
            " Request:\n",
            "========\n",
            "Operation: Index\n",
            "Index: org.hibernate.search.elasticsearch.test.elasticsearchjavatimeit$sample\n",
            "Type: org.hibernate.search.elasticsearch.test.ElasticsearchJavaTimeIT$Sample\n",
            "Id: 1\n",
            "Data:\n",
            "{\"zonedDateTime\":\"2011-10-30T02:50:00.007+01:00[CET]\",\"description\":\"ZonedDateTime example\"}\n",
            "Response:\n",
            "=========\n",
            "Status: 400\n",
            "Error message: {\"root_cause\":[{\"type\":\"mapper_parsing_exception\",\"reason\":\"failed to parse [zonedDateTime]\"}],\"type\":\"mapper_parsing_exception\",\"reason\":\"failed to parse [zonedDateTime]\",\"caused_by\":{\"type\":\"illegal_argument_exception\",\"reason\":\"Invalid format: \\\"2011-10-30T02:50:00.007+01:00[CET]\\\" is malformed at \\\"CET]\\\"\"}}\n",
            "Cluster name: null\n",
            "Cluster status: 400\n",
            "\n",
            "\n",
            "Primary Failure:\n",
            "\tEntity org.hibernate.search.elasticsearch.test.ElasticsearchJavaTimeIT$Sample  Id 1  Work Type  org.hibernate.search.backend.AddLuceneWork\n",
            "Subsequent failures:\n",
            "\tEntity org.hibernate.search.elasticsearch.test.ElasticsearchJavaTimeIT$Sample  Id 1  Work Type  org.hibernate.search.backend.AddLuceneWork\n",
            "{code}, Similarity: 0.2982\n",
            "Summary & Description: update elasticsearch version used tests 241 \n",
            " Will be useful to dismiss incompatibility issues with Elasticsearch 2.4. Would help for HSEARCH-2388, notably., Similarity: 0.1996\n",
            "Summary & Description: track ultimately drop hsearchexperimental flags stable features \n",
            " We have @hsearch.experimental flags on some relatively old features:\n",
            "\n",
            " * {{@Facet}}/{{@Facets}} (2015-05)\n",
            " * DeleteByQuery (2015-03)\n",
            " * {{@Indexed.interceptor}} and {{EntityIndexingInterceptor}} (2014-11)\n",
            " * {{DocumentExtractor.getTopDocs}} (2014-03)\n",
            " * Methods to pass instances in programmatic mappings (2013-09)\n",
            " * {{ShardIdentifierProvider}} (2013-09)\n",
            " * {{ProjectionConstants.DOCUMENT_ID}} (2013-04)\n",
            " * Every spatial-related annotation (2012-06)\n",
            " * {{IndexControlMBean}} (2010-08)\n",
            "\n",
            "We should consider either adding tickets about improving these features (if they are not satisfying as they are now) or dropping the experimental flag.\n",
            "\n",
            "Also, we have these flags on relatively new features, but no information in the code as to when the flag will be dropped or when the API will be reviewed:\n",
            "\n",
            " * {{MetadataProvidingFieldBridge}}, {{FieldMetadataBuilder}} et al. (2015-11)\n",
            " * {{IgnoreAnalyzerBridge}} (2016-04)\n",
            " * {{IndexManagerTypeSpecificBridgeProvider}} (2016-04)\n",
            " * {{AnalyzerExecutionStrategy}} (2016-05)\n",
            "\n",
            "Maybe adding a JIRA key next to every {{@hsearch.experimental}} flag (and next to every one we add in the future) would help tracking those?, Similarity: 0.3611\n",
            "Summary & Description: indexedembeddedprefix depth etc dont work elementcollection anymore \n",
            " The cause is probably HSEARCH-2046 (https://github.com/hibernate/hibernate-search/commit/c1db5107a86222727c2be9535570891fdfb48be3).\n",
            "\n",
            "The thing is, {{@ElementCollection}} may not only be used on primitive types, but also on {{@Embeddables}}, where a prefix, or even a depth to avoid infinite recursion, make a lot of sense.\n",
            "\n",
            "Also, @IndexedEmbedded doesn't even work on collections of primitive type. This makes sense to me, as the annotation is intended to index *properties* of a given field, and primitive types don't have any.\n",
            "I think there was a confusion when solving HSEARCH-2046, due to the fact that in this test, there is an @IndexedEmbedded and a @Field on a collection property, with both having the same field name... So when we saw elements in the index, they were generated by the field, and when we saw null tokens, they were generated by the @IndexedEmbedded., Similarity: 0.2199\n",
            "Summary & Description: support caching filters elasticsearch \n",
            " For now, the Elasticsearch backend does not support caching of the Filter instances as the caching API is based on Lucene filters.\n",
            "\n",
            "Note: there are tests that should pass when this ticket is resolved, and that are currently disabled using the ElasticsearchSupportInProgress category. Those tests will be (or have been) outlined as part of HSEARCH-2390., Similarity: 0.3286\n",
            "Summary & Description: enable collectionupdateeventtest elasticsearch \n",
            " The test seems to fail for no particular reason when ran in a full test suite, while passing when executed as a single test...\n",
            "\n",
            "Note: there are tests that should pass when this ticket is resolved, and that are currently disabled in the pom.xml of the Elasticsearch module. Those tests will be (or have been) outlined as part of HSEARCH-2390., Similarity: 0.2465\n",
            "Summary & Description: implement timeouts elasticsearch backend \n",
            " Note: there are tests that should pass when this ticket is resolved, and that are currently disabled in the pom.xml of the Elasticsearch module. Those tests will be (or have been) outlined as part of HSEARCH-2390., Similarity: 0.2457\n",
            "Summary & Description: improve field nametype validation querying elasticsearch backend \n",
            " Note: there are tests that should pass when this ticket is resolved, and that are currently disabled in the pom.xml of the Elasticsearch module. Those tests will be (or have been) outlined as part of HSEARCH-2390.\n",
            "Also, some relevant tests are disabled using the ElasticsearchSupportInProgress category., Similarity: 0.3286\n",
            "Summary & Description: support exists predicate indexedembedded \n",
            " We're removing support for {{@IndexedEmbedded.indexNullAs}} in HSEARCH-2465.\n",
            "\n",
            "As a result, users are no longer able to search for documents that have an object field present/missing.\n",
            "\n",
            "We should support the *concept* of \"exists\" queries for object fields, or at least nested fields.\n",
            "\n",
            "See https://www.elastic.co/guide/en/elasticsearch/guide/current/_dealing_with_null_values.html\n",
            "\n",
            "Note: there are Search 5 tests that should pass when this ticket is resolved, and that are currently disabled in the pom.xml of the Elasticsearch module. Those tests will be (or have been) outlined as part of HSEARCH-2390.\n",
            "Also, some relevant tests are disabled using the {{ElasticsearchSupportInProgress}} category., Similarity: 0.2913\n",
            "Summary & Description: deletebyquery phase massindexer operation fails solved deletebyquery plugin wasnt running \n",
            " When performing full reindexing (org.hibernate.search.MassIndexer#purgeAllOnStart, org.hibernate.search.MassIndexer#start)\n",
            "I am having  exceptions:\n",
            "{code}\n",
            " Request:\n",
            "========\n",
            "Operation: DeleteByQuery\n",
            "Data:\n",
            "{ \"query\" : { \"constant_score\" : { \"filter\" : { \"match_all\" : { } } } } }\n",
            "Response:\n",
            "=========\n",
            "Status: 404\n",
            "Error message: 404 Not Found\n",
            "Cluster name: null\n",
            "Cluster status: null\n",
            "\n",
            "\n",
            "Primary Failure:\n",
            "\tEntity com.peopleinsite.ugc.service.ChangeSet  Id null  Work Type  org.hibernate.search.backend.PurgeAllLuceneWork\n",
            "Subsequent failures:\n",
            "\tEntity com.peopleinsite.ugc.service.ChangeSet  Id null  Work Type  org.hibernate.search.backend.PurgeAllLuceneWork\n",
            "{code}\n",
            "\n",
            "Although it doesn't look like affecting reindexing process (indexes are created successfully and fully searchable) I couldn't find the obvious reason for that exceptions.\n",
            "\n",
            "Not sure if that is a bug or something is not properly configured at my ES(version 2.4.1) environment.\n",
            "\n",
            "P.S. installing https://www.elastic.co/blog/core-delete-by-query-is-a-plugin didn't help.\n",
            "\n",
            "Thanks,\n",
            "Alex\n",
            "\n",
            "\n",
            ", Similarity: 0.2744\n",
            "Summary & Description: configurable dynamic mapping settings \n",
            " At the moment org.hibernate.search.elasticsearch.impl.ElasticsearchIndexManager#createIndexMappings *dynamic* setting is set to *strinct* and there is no way to change it (apart from setting elasticsearch.index_schema_management_strategy=NONE (which was default for 5.6.0.Beta2) and then dynamic setting defaults  to true, which what i need).\n",
            "\n",
            "I think it whould be benefitial to have all options available for dynamic mappings\n",
            "https://www.elastic.co/guide/en/elasticsearch/guide/current/dynamic-mapping.html .\n",
            "\n",
            "Thanks,\n",
            "Alex\n",
            "\n",
            "---\n",
            "Note ([~accountid:557058:58fa1ced-171a-4c00-97e8-5d70d442cc4b]): Some tests have been disabled because of this lack of support. Please search for this ticket's code ({{HSEARCH-2387}}) in the source and re-enabled them when this issue has been fixed.\n",
            ", Similarity: 0.3180\n",
            "Summary & Description: create separate backend testing projects \n",
            " Currently, we are testing the Elasticsearch backend by executing tests extracted from test-jars created in both -engine and -orm.\n",
            "\n",
            "That works great most of the time, but we do have some issues related to transitive dependencies not being handled by Maven for test-jars (see https://maven.apache.org/plugins/maven-jar-plugin/examples/create-test-jar.html).\n",
            "\n",
            "The most straightforward solution would be to move all the tests we want to execute on multiple backends to separate projects that would be specifically designed to allow their execution against a backend specified as a parameter (think of this as some kind of TCK).\n",
            "But since it's a rather drastic move, we'd have to discuss this first.\n",
            "Note that in some cases, if we don't want to move the tests, we could also try reversing the dependencies, configuring tests in -orm for instance to execute once for each backend., Similarity: 0.4552\n",
            "Summary & Description: make elasticsearch version used integration tests build parameter \n",
            " The goal is to setup multiple CI jobs to verify a certain range of ES versions is actually compatible, and keep this compatibility monitored., Similarity: 0.2971\n",
            "Summary & Description: serialization doesnt handle builtin lucene attributes \n",
            " First, some interfaces are not supported:\n",
            "\n",
            " * {{org.apache.lucene.search.BoostAttribute}}\n",
            " * {{org.apache.lucene.search.FuzzyTermsEnum.LevenshteinAutomataAttribute}}\n",
            " * {{org.apache.lucene.search.MaxNonCompetitiveBoostAttribute}}\n",
            " * {{org.apache.lucene.analysis.NumericTokenStream.NumericTermAttribute}}\n",
            " * {{org.apache.lucene.analysis.tokenattributes.PositionLengthAttribute}}\n",
            " * {{org.apache.lucene.analysis.tokenattributes.TermToBytesRefAttribute}}\n",
            " * {{org.apache.lucene.analysis.tokenattributes.BytesTermAttribute}}\n",
            "\n",
            "Second, attributes implementing multiple interfaces are not supported, because the serializer assumes only one interface is implemented. This is the case of {{org.apache.lucene.analysis.tokenattributes.PackedTokenAttributeImpl}} for instance. We should make it possible for one attribute in Java to generate multiple attributes in the message.\n",
            "\n",
            "And finally, polymorphism is being ignored. {{org.apache.lucene.collation.tokenattributes.CollatedTermAttributeImpl}} for instance extends {{org.apache.lucene.analysis.tokenattributes.CharTermAttributeImpl}} without implementing additional interfaces, but simply overrides a method. Simply solving the first two issue should solve the problem, though, provided every Attribute method is simply a getter., Similarity: 0.4986\n",
            "Summary & Description: avoid logging warnings caused internal usage legacy criteria api \n",
            " Hibernate ORM deprecated the old Criteria API in favour of the JPA Criteria API.\n",
            "\n",
            "Hibernate Search uses the old one internally; not least this might generate warnings at runtime which can't be avoided by the end user., Similarity: 0.2883\n",
            "Summary & Description: unable sort string non case sensitive order \n",
            " I can't sort a string field in a way that should be consistent for me: I mean with a non case sensitive ordering.\n",
            "\n",
            "A [similar issue|http://stackoverflow.com/questions/38472164/how-to-do-case-insensitive-sorting-using-hibernate-lucene-search] was reported on Stack Overflow, but it was concerning HSearch 3.6.2 and I currently use the analyzer given as response.\n",
            "\n",
            "I realised a short test case here : https://github.com/rjoly/testcase-hibernate-search-sort, Similarity: 0.2272\n",
            "Summary & Description: using searchintegratorprovided querydescriptor require passing targeted entities twice \n",
            " When using {{org.hibernate.search.engine.impl.ImmutableSearchFactory.createQueryDescriptor(Query, Class<?>...)}}, we provide the targeted entities so that we can determine the correct backend to use. But those targeted entities are not saved, so when using {{org.hibernate.search.FullTextSession.createFullTextQuery(QueryDescriptor, Class<?>...)}} later to create the actual query, we have to provide the targeted entities again...\n",
            "\n",
            "This feels wrong, and we should do something to avoid it., Similarity: 0.2522\n",
            "Summary & Description: document use querydescriptor \n",
            " QueryDescriptor (returned by ElasticsearchQueries in particular) may prove confusing.\n",
            "\n",
            "We should ensure there's a clear documentation about how to use this class (i.e. {{org.hibernate.search.FullTextSession.createFullTextQuery(QueryDescriptor, Class<?>...)}}), and that everywhere we return such an object, we add a link pointing to this documentation., Similarity: 0.2466\n",
            "Summary & Description: hsquerytargetedentitieslistclass wont always work using multiple backends \n",
            " It seems we have a API design issue with the introduction of QueryDescriptor.\n",
            "\n",
            "The QueryDescriptor implementation defines which backend will be used for a query (there's an implementation for each backend). Thus it's created based on which entities we're targeting (in {{org.hibernate.search.engine.impl.ImmutableSearchFactory.createQueryDescriptor(Query, Class<?>...)}}).\n",
            "\n",
            "But:\n",
            "\n",
            "1. These targeted entities are just used for backend determination, and not saved for use on query execution (see HSEARCH-2367)\n",
            "2. (that's the issue to address here) The HSQuery interface allows for later change of the targeted entities... Which could then be entities that are indexed in another backend. This would probably fail miserably at some point., Similarity: 0.3553\n",
            "Summary & Description: indexnotfoundexception query elasticsearch \n",
            " I am using a {{SearchIntegrator}} pre-configured with two entities, {{TestEntity}} and {{AnotherTestEntity}}, using index names {{indexa}} and {{indexb}} respectively. \n",
            "\n",
            "Initially only entries of type {{TestEntity}} are indexed, and when querying the following exception is thrown:\n",
            "\n",
            "{noformat}\n",
            " Request:\n",
            "========\n",
            "Operation: Search\n",
            "Data:\n",
            "{\"query\":{\"filtered\":{\"query\":{\"term\":{\"name\":{\"value\":\"ISPN-1949\"}}},\"filter\":{\"bool\":{\"should\":[{\"type\":{\"value\":\"org.infinispan.query.api.TestEntity\"}},{\"type\":{\"value\":\"org.infinispan.query.api.AnotherTestEntity\"}}]}}}}}\n",
            "Response:\n",
            "=========\n",
            "Status: 404\n",
            "Error message: {\"root_cause\":[{\"type\":\"index_not_found_exception\",\"reason\":\"no such index\",\"resource.type\":\"index_or_alias\",\"resource.id\":\"indexb\",\"index\":\"indexb\"}],\"type\":\"index_not_found_exception\",\"reason\":\"no such index\",\"resource.type\":\"index_or_alias\",\"resource.id\":\"indexb\",\"index\":\"indexb\"}[TestSuiteProgress] Tests succeeded: 54, failed: 1, skipped: 0\n",
            "\n",
            "{noformat}\n",
            "\n",
            "By default the Elasticsearch is considering all indexes when querying but apparently only one index was created, Similarity: 0.2314\n",
            "Summary & Description: querydescriptors ignore targetentities \n",
            " I'm porting the following code to take advantage of the Elasticsearch backend and the Lucene query translation:\n",
            "\n",
            "{noformat}\n",
            "  hSearchQuery = searchFactory.createHSQuery();\n",
            "      hSearchQuery\n",
            "         .luceneQuery(luceneQuery)\n",
            "         .targetedEntities(Arrays.asList(classes));\n",
            "{noformat}\n",
            "\n",
            "The migrated version looks like:\n",
            "\n",
            "{noformat}\n",
            "ExtendedSearchIntegrator extendedIntegrator =\n",
            "       searchFactory.unwrap(ExtendedSearchIntegrator.class);\n",
            "\n",
            "hSearchQuery = searchFactory\n",
            "      .createQueryDescriptor(luceneQuery, classes)\n",
            "      .createHSQuery(extendedIntegrator);\n",
            "{noformat}\n",
            "\n",
            "This causes NPE when the index manager is *not* elasticsearch since the {{LuceneQueryDescriptor}} does not use the list of indexed classes:\n",
            "\n",
            "{noformat}\n",
            "java.lang.NullPointerException\n",
            "\tat org.hibernate.search.query.engine.impl.LuceneHSQuery.buildSearcher(LuceneHSQuery.java:401)\n",
            "\tat org.hibernate.search.query.engine.impl.LuceneHSQuery.buildSearcher(LuceneHSQuery.java:380)\n",
            "\tat org.hibernate.search.query.engine.impl.LuceneHSQuery.queryEntityInfos(LuceneHSQuery.java:138)\n",
            "{noformat}, Similarity: 0.3414\n",
            "Summary & Description: add elasticsearch mapping export tool \n",
            " The tool would allow to export a Hibernate Search-generated mapping so that users may use it in scripts or compare it to their existing Elasticsearch mapping. \n",
            "\n",
            "-The main issue was that such a tool should not have to connect to an Elasticsearch instance: we just want it to export the schema based on a configuration and a set of jars. Yet HSearch's metamodel creation and index manager creation/startup seem intertwined, and we cannot execute one without the other. So in order for the tool to exist, we need to bring some changes to HSearch's startup process.-\n",
            "-See there for more details about the issue:- [https://hibernate.atlassian.net/browse/HSEARCH-2260?focusedCommentId=84220&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-84220|https://hibernate.atlassian.net/browse/HSEARCH-2260?focusedCommentId=84220&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-84220] => This is no longer true in Hibernate Search 6; you can start it offline; see [https://docs.jboss.org/hibernate/stable/search/reference/en-US/html_single/#backend-elasticsearch-configuration-version|https://docs.jboss.org/hibernate/stable/search/reference/en-US/html_single/#backend-elasticsearch-configuration-version|smart-link]  and [https://docs.jboss.org/hibernate/stable/search/reference/en-US/html_single/#mapper-orm-schema-management-strategy|https://docs.jboss.org/hibernate/stable/search/reference/en-US/html_single/#mapper-orm-schema-management-strategy|smart-link] , Similarity: 0.3643\n",
            "Summary & Description: fully asynchronous automatic indexing \n",
            " *Important:* See \"Approach 2: entity change events\" in [https://hibernate.atlassian.net/browse/HSEARCH-3281|https://hibernate.atlassian.net/browse/HSEARCH-3281|smart-link] .\n",
            "\n",
            "As highlighted but the use case here:\n",
            "\n",
            "* [http://stackoverflow.com/questions/39273444/asynchronous-indexing-by-hibernate-search-hs-after-transaction-commit/39766800#39766800|http://stackoverflow.com/questions/39273444/asynchronous-indexing-by-hibernate-search-hs-after-transaction-commit/39766800#39766800]\n",
            "\n",
            "Our \"async\" worker is delegating to a background thread the write-to-index aspect, but it still has to gather all data in the application thread synchronously.\n",
            "\n",
            "This is not the first time such a thing is asked, and we might be able to batch some operations in the background work? For example we have plans to have the MassIndexer hinted on how to optimally load associations for a given type, the same hints could be applied here.\n",
            "\n",
            "It could be in in all effects implemented by simply feeding the queue of an always available MassIndexer.\n",
            "\n",
            "Note that one important aspect of this would be persistence of entity change events: if the server crashes after the transaction is committed, we need to be aware of the entities that still need reindexing., Similarity: 0.2800\n",
            "Summary & Description: zoneddatetimebridge stores time ambiguous representation \n",
            " The bridge stores time as a timestamp + the zone ID. Unfortunately, this representation is ambiguous for some timestamps, in particular when clocks are set back due to switching daylight saving time. For instance \"2011-10-30 2:50:00 CET\" may point to either \"2011-10-30 2:50:00+01:00\" or \"2011-10-30 2:50:00+02:00\".\n",
            "A safer string representation would be something like what's done in {{java.time.format.DateTimeFormatter.ISO_ZONED_DATE_TIME}}, where both the offset and the zone ID are explicitly stored (something like \"2011-10-30 2:50:00+01:00[CET]\")\n",
            "\n",
            "Some strategy will have to be chosen to handle previously stored {{ZonedDateTimes}}, since we'll have to change the storing format and cannot assume that users will reindex everything.\n",
            "\n",
            "Attached is a patch adding a test case (but no fix yet)., Similarity: 0.1340\n",
            "Summary & Description: use field storage instead source document projections \n",
            " From what I can see in {{org.hibernate.search.elasticsearch.impl.ElasticsearchHSQueryImpl.IndexSearcher.getFieldValue(EntityIndexBinding, JsonObject, String)}}, when projecting on a field, this field's value is extracted from the \"_source\" attribute, instead of using [Elasticsearch's own projection feature|https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-fields.html].\n",
            "That last one should be preferred for stored fields, since it will always return the value in the same format, independently of how the value was submitted. For instance, if a date field has the default format ({{strict_date_optional_time||epoch_millis}}), and if a document value has been submitted using the epoch format, then the \"_source\" attribute will contain the value in this epoch format, but when using Elasticsearch's projection feature, we'll still get the value in the {{strict_date_optional_time}} format.\n",
            "\n",
            "This issue is not critical, since most of the time, the index content is added by Hibernate Search itself, but it might help in some cases, for instance when users migrate big, old indexes and don't want to reindex everything right away., Similarity: 0.4795\n",
            "Summary & Description: add support norms elasticsearch 5 \n",
            " When generating the index mapping, the {{Field.Index}} is only used to determine the index type:\n",
            "\n",
            "{code}\n",
            "\tprivate String getIndexValue(Field.Index index) {\n",
            "\t\tswitch ( index ) {\n",
            "\t\t\tcase ANALYZED:\n",
            "\t\t\tcase ANALYZED_NO_NORMS:\n",
            "\t\t\t\treturn ANALYZED;\n",
            "\t\t\tcase NOT_ANALYZED:\n",
            "\t\t\tcase NOT_ANALYZED_NO_NORMS:\n",
            "\t\t\t\treturn NOT_ANALYZED;\n",
            "\t\t\tcase NO:\n",
            "\t\t\t\treturn \"no\";\n",
            "\t\t\tdefault:\n",
            "\t\t\t\tthrow new AssertionFailure( \"Unexpected index type: \" + index );\n",
            "\t\t}\n",
            "\t}\n",
            "{code}\n",
            "\n",
            "But as we can see, the \"norms\" aspect is being ignored, and ES [{{norm}} attribute|https://www.elastic.co/guide/en/elasticsearch/reference/2.4/norms.html] is never populated.\n",
            "\n",
            "The bug is not feature-breaking, but may impact performance., Similarity: 0.2620\n",
            "Summary & Description: prefixquery apache lucene query type automatically translated json \n",
            " Would nice to have org.apache.lucene.search.PrefixQuery\n",
            "automatically translated to elasticsearch json request. Currently it's not supported., Similarity: 0.4341\n",
            "Summary & Description: improve logging elasticsearch integration \n",
            " Keen to see translated(from Apache Lucene queries) json search requests to elasticsearch (hibernate-search-backend-elasticsearch-5.6.0.Alpha3) currently they are not logged, Similarity: 0.4129\n",
            "Summary & Description: simplify configuration dynamic analyser selection allow use existing analysers eg englishanalyzer \n",
            " strategy for determining analyser based on the contents of the entity:\n",
            "\n",
            "public interface AnalyzerProvider {\n",
            "\n",
            "  Analyzer getAnalyzerForIndexedEntity(Object entity);\n",
            "}\n",
            ", Similarity: 0.3136\n",
            "Summary & Description: support sharing resources among different index managers \n",
            " Current the index backends are divided in two categories: sync and async.\n",
            "Sync involves keeping a dedicated thread to apply changesets to the index, while async involves an executor to apply changes plus a periodic commit thread.\n",
            "\n",
            "Threading above are maintained on a per index manager basis, meaning the resource usage grows linearly as the number of index managers grows.\n",
            ", Similarity: 0.3099\n",
            "Summary & Description: current timezone handling generates inconsistent elasticsearch indices \n",
            " It seems that dates from the JVM are interpreted as UTC dates and stored in Elasticsearch as such, independently of the JVM's default time zone.\n",
            "\n",
            "h2. TL;DR\n",
            "\n",
            "The current behavior has the main advantage of allowing to write simple JSON queries more easily, because dates without timezones will be interpreted as if they had a default timezone matching the JVM's default timezone.\n",
            "\n",
            "But on the other hand, this behavior completely screws anyone wanting to do queries with explicit timezones, since the dates are stored with the wrong timezone.\n",
            "\n",
            "h2. Full explanation\n",
            "\n",
            "To be more specific, if you have a {{Date}} object representing {{2016-01-02T00:00}}, with the implicit (default) time zone being {{+01:00}}, HS will store this in Elasticsearch as {{2016-01-02T00:00+00:00}}. Notice how the timezone got erased. (for information, it's done in {{org.hibernate.search.elasticsearch.util.impl.ElasticsearchDateHelper.dateToString(Date)}})\n",
            "\n",
            "When querying through the DSL, everything will work fine, since HS will once again act as if the {{Date}} object provided to the {{match}} method was encoded for the UTC time zone.\n",
            "\n",
            "When building your own JSON query and asking HS to execute it as it is, things start to be a bit weird. This query string:\n",
            "{code}\n",
            "  dateOfBirth:2016-01-02\n",
            "{code}\n",
            "... will match. It should not, according to [Elasticsearch's documentation|https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-range-query.html#_time_zone_in_range_queries], since dates without time zones are intepreted as UTC dates.\n",
            "Well, whatever, we can say that's just a change of default timezone.\n",
            "\n",
            "But then you start working with multiple time zones, or with explicit time zones, and then you're screwed. The following query won't match, even though it uses the exact same date we previously had inside the JVM:\n",
            "{code}\n",
            "  dateOfBirth:2016-01-02T00:00:00+01:00\n",
            "{code}\n",
            "Which is normal from ES's perspective, since we stored {{2016-01-02T00:00:00+00:00}}, which is {{2016-01-02T01:00:00+01:00}} and does not match the query. But it's certainly not normal from a user's perspective., Similarity: 0.2161\n",
            "Summary & Description: offer better support onmissingvalueuseobject sort dsl \n",
            " Providing a replacement for missing values in the sort DSL currently has two limitations:\n",
            "\n",
            " 1. One can only use it with numeric values, because {{org.apache.lucene.search.SortField.setMissingValue(Object)}} does not accept replacements for String values, and a {{SortField}} is what we return ultimately.\n",
            " 2. Field bridges are ignored, because:\n",
            "   * Field bridges cannot convert an object to a numeric value (the most they can do is provide a String value by implementing {{StringBridge}}), but {{org.apache.lucene.search.SortField.setMissingValue(Object)}} expects numeric values for numeric fields, and a {{SortField}} is what we return ultimately. Note that {{setMissingValue}} won't break right away, but {{org.apache.lucene.search.SortField.getComparator(int, int)}} (called before sorting) will.\n",
            "   * String values are irrelevant (see 1. above)\n",
            "\n",
            "These limitations should go away when dropping the reliance on the Lucene API in HS 6.0. Allowing to use field bridges on numeric fields might require some more work, though., Similarity: 0.2616\n",
            "Summary & Description: enable creating querybuilder multientity scope \n",
            " From HSEARCH-1872 comments:\n",
            "\n",
            "{quote}\n",
            "When querying multiple indices \\[hence multiple entities\\] at once, it may happen that some field we're sorting on is absent from one of the indices. In that case, ElasticSearch requires that type information be provided.\n",
            "So in that case, we may have to retrieve type information from the metamodel. Problem: the QueryBuilder, from which we start building the sort, is only aware of one entity we're working on. This might be something to fix, because queries built this way may (and will) still be ran against multiple indices.\n",
            "So, let's say the user is querying two indices: A(fields: z, a1, a2), B (fields: z, b1, b2), and he wants to sort on z, then a1, then b1. The user won't be able to build his sort with the QueryBuilder, since whichever entity he chooses to bind his QueryBuilder to, there would be some missing type information at some point (for either the a1 field or the b1 field).\n",
            "{quote}\n",
            "\n",
            "The idea would be to enable creation of a QueryBuilder with a scope covering multiple entities. When retrieving metadata, this builder would try retrieving from the first entity, then (if not found) fall back to the second, and so on.\n",
            "We would implicitly consider that if a field exists on one entity, on every other entity of the scope the metadata for this field are the same or the field doesn't exist., Similarity: 0.2163\n",
            "Summary & Description: metadataprovidingfieldbridge cannot override metadata annotationgenerated field \n",
            " MetadataProvidingFieldBridge's metadata is ignored when the metadata concerns an already-existing (Hibernate Search-generated) field.\n",
            "For instance, when a user wants to define a field bridge that will turn a bean to a sortable numeric field, they cannot use the name of the field carrying the field bridge and must hack away by adding a suffix to the sortable numeric field name. That's a shame, because the field generated by Hibernate Search is missing metadata anyway: in particular, even with an @Numeric annotaton, Hibernate Search cannot guess the actual numeric encoding type (int, double, ...) and thus cannot guess the correct sort type in the sort API (see HSEARCH-2325, HSEARCH-1872)., Similarity: 0.3903\n",
            "Summary & Description: provide support distance units \n",
            " The Unit enum has only one value so far: KM.\n",
            "It's a bit pointless as it is. Maybe we could extend it with at least \"M\"/\"METER\"?, Similarity: 0.0085\n",
            "Summary & Description: code examples documentations automatically checked correctness \n",
            " I just stumbled upon some code example that still used {{SortField.STRING}}, which doesn't exist anymore, instead of the newer {{SortField.Type.STRING}}. I'm fixing it right now, but the real issue is that this kind of problem is hard to spot, and we can't be sure there aren't others in the documentation.\n",
            "\n",
            "The thing is, code examples provided in the documentation are never compiled, thus when they become obsolete and do not compile, or do not run, anymore, we simply don't know.\n",
            "\n",
            "The Hibernate Validator project uses a nice approach to solve this issue: they write code examples in JUnit tests, apply tags (with java comments) to the portions to be included in the documentation, and refer to these tags from the documentation.\n",
            "That way, code example are assured to always compile, and even (if we define proper assertions) to always run as expected.\n",
            "\n",
            "An example:\n",
            "\n",
            "In the asciiDoc:\n",
            "{code}\n",
            "[[example-constraint-mapping]]\n",
            ".Programmatic constraint declaration\n",
            "====\n",
            "[source, JAVA, indent=0]\n",
            "----\n",
            "include::{sourcedir}/org/hibernate/validator/referenceguide/chapter11/constraintapi/ConstraintApiTest.java[tags=constraintMapping]\n",
            "----\n",
            "====\n",
            "{code}\n",
            "\n",
            "And in the test (notice the comment with {{tag::}} and {{end::}}):\n",
            "\n",
            "{code}\n",
            "public class ConstraintApiTest {\n",
            "\n",
            "\t@Test\n",
            "\tpublic void constraintMapping() {\n",
            "\t\t//tag::constraintMapping[]\n",
            "\t\tHibernateValidatorConfiguration configuration = Validation\n",
            "\t\t\t\t.byProvider( HibernateValidator.class )\n",
            "\t\t\t\t.configure();\n",
            "\n",
            "\t\tConstraintMapping constraintMapping = configuration.createConstraintMapping();\n",
            "\n",
            "\t\tconstraintMapping\n",
            "\t\t\t.type( Car.class )\n",
            "\t\t\t\t.property( \"manufacturer\", FIELD )\n",
            "\t\t\t\t\t.constraint( new NotNullDef() )\n",
            "\t\t\t\t.property( \"licensePlate\", FIELD )\n",
            "\t\t\t\t\t.ignoreAnnotations()\n",
            "\t\t\t\t\t.constraint( new NotNullDef() )\n",
            "\t\t\t\t\t.constraint( new SizeDef().min( 2 ).max( 14 ) )\n",
            "\t\t\t.type( RentalCar.class )\n",
            "\t\t\t\t.property( \"rentalStation\", METHOD )\n",
            "\t\t\t\t\t.constraint( new NotNullDef() );\n",
            "\n",
            "\t\tValidator validator = configuration.addMapping( constraintMapping )\n",
            "\t\t\t\t.buildValidatorFactory()\n",
            "\t\t\t\t.getValidator();\n",
            "\t\t//end::constraintMapping[]\n",
            "\t}\n",
            "}\n",
            "{code}, Similarity: 0.2609\n",
            "Summary & Description: default unit spatial distance projection es documented lucenes \n",
            " See https://hibernate.atlassian.net/browse/HSEARCH-1872?focusedCommentId=82458&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-82458 (line starting with \"Should we keep in(Unit)\"), Similarity: 0.3397\n",
            "Summary & Description: distance computation inconsistent lucene elasticsearch backend \n",
            " *When fixed*, adapt the last commit of https://github.com/hibernate/hibernate-search/pull/1136\n",
            "\n",
            "When querying on distance to reference coordinates, and when some document misses a value for the location field:\n",
            "\n",
            "* the Lucene backend computes the distance between the reference coordinates and (0,0)\n",
            "* the ElasticSearch backend simply returns a distance of {{Double.MAX_VALUE}} (~1*10^308)\n",
            "\n",
            "This is illustrated by this commit, where I had to adapt a test in order to take into account the inconsistency between the two backends: https://github.com/hibernate/hibernate-search/pull/1136/commits/e41b842704b581b5a93ba24a6020436d85573378\n",
            "\n",
            "I think we should make the behavior consistent.\n",
            "IMO, the ElasticSearch backend's behavior is more sensible. Changing the Lucene backend's behavior could be considered as a breaking change. On the other hand, changing the behavior of ES might prove difficult., Similarity: 0.2911\n",
            "Summary & Description: add specific sorts sort dsl \n",
            " In HSEARCH-1872, a sort DSL is being introduced. This DSL will have to be extended with elements that were excluded from the initial work (caution, some ideas are yet to be validated):\n",
            "\n",
            "* a {{withComparator()}} method for building a sort that will use a java.util.Comparator\n",
            "* a {{treatMultiValuedAs(mode)}} method for instructions about how multi-valued fields should be sorted.\n",
            "* a {{byNative()}} method for injecting implementation-dependent sorts inside a DSL-built sort (such as a JSON string for ElasticSearch, or a SortField for a local Lucene index)\n",
            "* a {{onMissingValue()}} method for distance sort (at least first/last as for field sorts, or even substitue value if possible)\n",
            "* a {{withComputeMethod()}} method for distance sort\n",
            "* a {{byDistanceFromSpatialQuery(Query)}} method for distance sort\n",
            "\n",
            "Emmanuel Bernard had started working on some of these subjects, and this work had to be reverted in order to reduce the scope. Please find tags for those reverts below. The idea is that if you revert the reverts, you'll end up with a start of an implementation.\n",
            "\n",
            "* https://github.com/yrodiere/hibernate-search/releases/tag/HSEARCH-2320-distance-withComputeMethod-torevert\n",
            "* https://github.com/yrodiere/hibernate-search/releases/tag/HSEARCH-2320-withComparator-torevert\n",
            "* https://github.com/yrodiere/hibernate-search/releases/tag/HSEARCH-2320-distance-onMissingValue-torevert\n",
            "* https://github.com/yrodiere/hibernate-search/releases/tag/HSEARCH-2320-treatMultiValuedAs-torevert\n",
            "* https://github.com/yrodiere/hibernate-search/releases/tag/HSEARCH-2320-distance-byDistanceFromSpatialQuery-torevert\n",
            "\n",
            "See HSEARCH-1872 for hints on use cases (they might not all be defined)., Similarity: 0.1786\n",
            "Summary & Description: tokenstream contract violation serialization index slave node jms cluster \n",
            " While setting up the JMS replication for the Lucene index via Hibernate Search i came across an error that complains about *TokenStream contract violation* (see the stack trace at the end of the description). \n",
            "\n",
            "After a research in the web i found out, that this is usually caused by the update of the TokenStream API that now requires a defined workflow to use it ( https://lucene.apache.org/core/5_3_0/core/org/apache/lucene/analysis/TokenStream.html ).\n",
            "\n",
            "After investigating all possible problems in my application, i reviewed the source code of the serialization classes in Hibernate Search. So i discovered that you use the TokenStream in your class _org.hibernate.search.indexes.serialization.impl.CopyTokenStream_ but don't comply with the defined workflow. In your method _createAttributeLists_ you need to insert a short line to reset the \"input\"-TokenStream. \n",
            "Testing my idea i added the method call and all works as expected. Below my code of the createAttributeList method in org.hibernate.search.indexes.serialization.impl.CopyTokenStream:\n",
            "\n",
            "{code:java}\n",
            "private static List<List<AttributeImpl>> createAttributeLists(TokenStream input) throws IOException {\n",
            "\tList<List<AttributeImpl>> results = new ArrayList<>();\n",
            "\t// added input.reset(), see API TokenStream   \n",
            "\tinput.reset();\n",
            "\twhile ( input.incrementToken() ) {\n",
            "\t\tList<AttributeImpl> attrs = new ArrayList<>();\n",
            "\t\tresults.add( attrs );\n",
            "\t\tIterator<AttributeImpl> iter = input.getAttributeImplsIterator();\n",
            "\t\twhile ( iter.hasNext() ) {\n",
            "\t\t\t//we need to clone as AttributeImpl instances can be reused across incrementToken() calls\n",
            "\t\t\tattrs.add( iter.next().clone() );\n",
            "\t\t}\n",
            "\t}\n",
            "\tinput.end();\n",
            "\treturn results;\n",
            "}\n",
            "\n",
            "{code}\n",
            "\n",
            "Is there any hidden purpose that you don't use the reset() call or is it just a bug? \n",
            "\n",
            "\n",
            "*Below the mentioned stack trace:*\n",
            "\n",
            "org.hibernate.search.exception.SearchException: HSEARCH000083: Unable to serialize List<LuceneWork>\n",
            "\tat org.hibernate.search.indexes.serialization.impl.LuceneWorkSerializerImpl.toSerializedModel(LuceneWorkSerializerImpl.java:109)\n",
            "\tat org.hibernate.search.backend.jms.impl.JmsBackendQueueTask.run(JmsBackendQueueTask.java:61)\n",
            "\tat org.hibernate.search.backend.jms.impl.JmsBackendQueueProcessor.applyWork(JmsBackendQueueProcessor.java:88)\n",
            "\tat org.hibernate.search.indexes.spi.DirectoryBasedIndexManager.performOperations(DirectoryBasedIndexManager.java:112)\n",
            "\tat org.hibernate.search.backend.impl.WorkQueuePerIndexSplitter.commitOperations(WorkQueuePerIndexSplitter.java:49)\n",
            "\tat org.hibernate.search.backend.impl.BatchedQueueingProcessor.performWorks(BatchedQueueingProcessor.java:81)\n",
            "\tat org.hibernate.search.backend.impl.PostTransactionWorkQueueSynchronization.flushWorks(PostTransactionWorkQueueSynchronization.java:114)\n",
            "\tat org.hibernate.search.backend.impl.TransactionalWorker.flushWorks(TransactionalWorker.java:165)\n",
            "\tat org.hibernate.search.impl.FullTextSessionImpl.flushToIndexes(FullTextSessionImpl.java:87)\n",
            "\tat com.sobis.jaf.JAFApplication.createIndexFor(JAFApplication.java:919)\n",
            "\tat com.sobis.jaf.JAFApplication.createIndexAndVerify(JAFApplication.java:820)\n",
            "\tat com.sobis.jaf.JAFApplication.createIndex(JAFApplication.java:796)\n",
            "\tat com.sobis.jaf.JAFApplication.createIndex(JAFApplication.java:672)\n",
            "\tat com.sobis.jaf.JAFApplication$1.performAction(JAFApplication.java:486)\n",
            "\tat com.sobis.jaf.services.thread.JAFThread.run(JAFThread.java:71)\n",
            "Caused by: java.lang.IllegalStateException: TokenStream contract violation: reset()/close() call missing, reset() called multiple times, or subclass does not call super.reset(). Please see Javadocs of TokenStream class for more information about the correct consuming workflow.\n",
            "\tat org.apache.lucene.analysis.Tokenizer$1.read(Tokenizer.java:111)\n",
            "\tat org.apache.lucene.analysis.core.KeywordTokenizer.incrementToken(KeywordTokenizer.java:68)\n",
            "\tat org.hibernate.search.indexes.serialization.impl.CopyTokenStream.createAttributeLists(CopyTokenStream.java:85)\n",
            "\tat org.hibernate.search.indexes.serialization.impl.CopyTokenStream.buildSerializableTokenStream(CopyTokenStream.java:39)\n",
            "\tat org.hibernate.search.indexes.serialization.spi.LuceneFieldContext.getTokenStream(LuceneFieldContext.java:137)\n",
            "\tat org.hibernate.search.indexes.serialization.avro.impl.AvroSerializer.addFieldWithTokenStreamData(AvroSerializer.java:281)\n",
            "\tat org.hibernate.search.indexes.serialization.impl.LuceneWorkSerializerImpl.serializeField(LuceneWorkSerializerImpl.java:237)\n",
            "\tat org.hibernate.search.indexes.serialization.impl.LuceneWorkSerializerImpl.serializeDocument(LuceneWorkSerializerImpl.java:175)\n",
            "\tat org.hibernate.search.indexes.serialization.impl.LuceneWorkSerializerImpl.toSerializedModel(LuceneWorkSerializerImpl.java:97)\n",
            "\t... 14 more\n",
            ", Similarity: 0.4143\n",
            "Summary & Description: enabling internal dynamic sharding hibernate search causes index creation elastic search fail \n",
            " I have a scenario in which indexing works perfectly fine in a simple hibernate-search Elasticsearch integration setup, but the same fails when sharding is enabled. On debugging I see that the json data generated by hibernate search with sharding enabled is incorrect. More details below:\n",
            "\n",
            "{code:java}\n",
            "@Entity\n",
            "public class AT {\n",
            "    @ManyToOne(fetch = FetchType.EAGER)\n",
            "    @JoinColumn(name = \"ARRM_IDE\", nullable = false)\n",
            "    private A arr;\n",
            "\n",
            "    private Date dateType;\n",
            "\n",
            "    (and other fields)\n",
            "}\n",
            "\n",
            "@Entity\n",
            "public class A {\n",
            "\n",
            "    @Id\n",
            "    @SequenceGenerator(name = \"C_SEQUENCE\", sequenceName = \"S_ARRM_01\")\n",
            "    @GeneratedValue(strategy = GenerationType.SEQUENCE, generator = \"C_SEQUENCE\")\n",
            "    @Column(name = \"IDE_ARR\")\n",
            "    private Long id;\n",
            "}\n",
            "\n",
            "SearchMapping mapping = new SearchMapping();\n",
            "mapping.entity(AT.class).indexed()\n",
            "        .property(\"dateType\", ElementType.FIELD)\n",
            "        .field()\n",
            "        .store(Store.YES)\n",
            "        .analyze(Analyze.NO)\n",
            "        .property(\"arr\", ElementType.FIELD)\n",
            "        .indexEmbedded()\n",
            "        .entity(A.class).indexed()\n",
            "        .property(\"id\", ElementType.FIELD).documentId().name(\"arrId\")\n",
            "        .field()\n",
            "        .store(Store.YES)\n",
            "        .analyze(Analyze.NO)\n",
            "        ;\n",
            "{code}\n",
            "\n",
            "without sharding in place the schema mapping and the insert data are like this:\n",
            "\n",
            "\n",
            "{code}\n",
            "{\"dynamic\":\"strict\",\"properties\":{\"__HSearch_TenantId\":{\"type\":\"string\",\"index\":\"not_analyzed\"},\"arr\":{\"properties\":{\"id\":{\"type\":\"long\",\"store\":true,\"index\":\"not_analyzed\",\"boost\":1.0}}},\"dateType\":{\"type\":\"date\",\"store\":true,\"index\":\"not_analyzed\",\"boost\":1.0}}}\"\n",
            "\n",
            "\"{\"dateType\":\"2016-06-22T00:53:19Z\",\"arr\":{\"id\":15302}}\"\n",
            "{code}\n",
            "\n",
            "I added the following to enable sharding\n",
            "\n",
            "\n",
            "{code}\n",
            "<property name=\"hibernate.search.at.sharding_strategy\" value=\"com....ATShardIdentifierProvider\" />\n",
            "{code}\n",
            "\n",
            "with this the mapping is same as above and insert data is as follows:\n",
            "\n",
            "{code}\n",
            "\"{\"dateType\":\"2016-06-22T01:05:08Z\",\"id\":15402}\"\n",
            "{code}\n",
            "\n",
            "and the indexing clearly then fails with:\n",
            "\n",
            "\n",
            "{code}\n",
            "Status: 400\n",
            "Error message: {\"root_cause\":[{\"type\":\"strict_dynamic_mapping_exception\",\"reason\":\"mapping set to strict, dynamic introduction of [id] within [AT] is not allowed\"}],\"type\":\"strict_dynamic_mapping_exception\",\"reason\":\"mapping set to strict, dynamic introduction of [id] within [AT] is not allowed\"}\n",
            "Cluster name: null\n",
            "Cluster status: 400\n",
            "{code}\n",
            "\n",
            "I am attaching a zip file containing a self contained testcase that can be used to reproduce this issue easily.\n",
            "\n",
            "We have to either fix it or explicitly state that it is not a supported configuration and throw a proper error.\n",
            "\n",
            "\n",
            "\n",
            ", Similarity: 0.2423\n",
            "Summary & Description: getting started documentation points old version luke \n",
            " Reading and trying to use Hibernate Search with Getting Started instructions I realize that there is a reference to an old version of Luke: https://code.google.com/archive/p/luke/. And doesn't work for Hibernate Search 5.5.4. \n",
            "Should be maybe this? https://github.com/DmitryKey/luke/releases/\n",
            "Cheers!\n",
            "Fabián., Similarity: 0.3440\n",
            "Summary & Description: documentation shouldnt suggest need indexed embedded association fields \n",
            " page 4 it is written \"On top of @IndexedEmbedded you will\n",
            "also have to mark all fields of the associated entity you want to have included in the index with\n",
            "@Indexed. \"\n",
            "\n",
            "i guess it should be \"mark all fields of the associated entity you want to have included in the index with @Field\"\n",
            "\n",
            "as in the given example the associated entity is not marked \"@Indexed\", Similarity: 0.2802\n",
            "Summary & Description: hibernate 52 compatible version hibernate search \n",
            " Hibernate ORM 5.2 is not compatible with any version of Hibernate Search, including 5.6.0.Beta1 since all version of Hibernate Search are compiled with previuos version of Hibernate ORM. This is making Hibernate ORM 5.2 impossible to use in any project that is using Hibernate Search.\n",
            "\n",
            "Example:\n",
            "\n",
            "ava.lang.NoSuchMethodError caught: java.lang.NoSuchMethodError: org.hibernate.event.spi.EventSource.getTransactionCoordinator()Lorg/hibernate/resource/transaction/TransactionCoordinator;\n",
            "\tat org.hibernate.search.backend.impl.EventSourceTransactionContext.isLocalTransaction(EventSourceTransactionContext.java:117)\n",
            "\tat org.hibernate.search.backend.impl.EventSourceTransactionContext.registerSynchronization(EventSourceTransactionContext.java:84)\n",
            "\tat org.hibernate.search.backend.impl.PerTransactionWorker.performWork(PerTransactionWorker.java:73)\n",
            "\tat org.hibernate.search.event.impl.FullTextIndexEventListener.processWork(FullTextIndexEventListener.java:237)\n",
            "\tat org.hibernate.search.event.impl.FullTextIndexEventListener.onPostUpdate(FullTextIndexEventListener.java:136)\n",
            "... etc, Similarity: 0.2614\n",
            "Summary & Description: upgrade hibernate orm 521final \n",
            " This needs to be done quickly to verify the impact of changes in Hibernate ORM but I'm not sure about which branch should receive this update.\n",
            "Needs to be discussed on the mailing list., Similarity: 0.1578\n",
            "Summary & Description: hibernate search 553final problem hibernate 520final \n",
            " After updating hibernate to 5.2.0 Version i have this error :\n",
            "testSearchLucene(org.geosdi.geoplatform.persistence.search.demo.PersistenceJpaSearchTest)  Time elapsed: 0.108 sec  <<< ERROR!\n",
            "java.lang.NoSuchMethodError: org.hibernate.event.spi.EventSource.getTransactionCoordinator()Lorg/hibernate/resource/transaction/TransactionCoordinator;\n",
            "\tat org.hibernate.search.backend.impl.EventSourceTransactionContext.isLocalTransaction(EventSourceTransactionContext.java:117)\n",
            "\tat org.hibernate.search.backend.impl.EventSourceTransactionContext.registerSynchronization(EventSourceTransactionContext.java:84)\n",
            "\tat org.hibernate.search.backend.impl.PerTransactionWorker.performWork(PerTransactionWorker.java:73)\n",
            "\tat org.hibernate.search.event.impl.FullTextIndexEventListener.processWork(FullTextIndexEventListener.java:237)\n",
            "\tat org.hibernate.search.event.impl.FullTextIndexEventListener.onPostInsert(FullTextIndexEventListener.java:110)\n",
            "\tat org.hibernate.action.internal.EntityInsertAction.postInsert(EntityInsertAction.java:164)\n",
            "\tat org.hibernate.action.internal.EntityInsertAction.execute(EntityInsertAction.java:131)\n",
            "\tat org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:560)\n",
            "\tat org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:434)\n",
            "\tat org.hibernate.event.internal.AbstractFlushingEventListener.performExecutions(AbstractFlushingEventListener.java:337)\n",
            "\tat org.hibernate.event.internal.DefaultFlushEventListener.onFlush(DefaultFlushEventListener.java:39)\n",
            "\tat org.hibernate.internal.SessionImpl.flush(SessionImpl.java:1396)\n",
            "\tat org.hibernate.internal.SessionImpl.managedFlush(SessionImpl.java:472)\n",
            "\tat org.hibernate.internal.SessionImpl.flushBeforeTransactionCompletion(SessionImpl.java:3132)\n",
            "\tat org.hibernate.internal.SessionImpl.beforeTransactionCompletion(SessionImpl.java:2369)\n",
            "\tat org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl.beforeTransactionCompletion(JdbcCoordinatorImpl.java:467)\n",
            "\tat org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl.beforeCompletionCallback(JdbcResourceLocalTransactionCoordinatorImpl.java:147)\n",
            "\tat org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl.access$100(JdbcResourceLocalTransactionCoordinatorImpl.java:38)\n",
            "\tat org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl$TransactionDriverControlImpl.commit(JdbcResourceLocalTransactionCoordinatorImpl.java:221)\n",
            "\tat org.hibernate.engine.transaction.internal.TransactionImpl.commit(TransactionImpl.java:68)\n",
            "\tat org.springframework.orm.jpa.JpaTransactionManager.doCommit(JpaTransactionManager.java:517)\n",
            "\tat org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:761)\n",
            "\tat org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:730)\n",
            "\tat org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:485)\n",
            "\tat org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:291)\n",
            "\tat org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96)\n",
            "\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n",
            "\tat org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:213)\n",
            "\tat com.sun.proxy.$Proxy57.persist(Unknown Source)\n",
            "\tat org.geosdi.geoplatform.persistence.search.demo.PersistenceJpaSearchTest.insert(PersistenceJpaSearchTest.java:88)\n",
            "\tat org.geosdi.geoplatform.persistence.search.demo.PersistenceJpaSearchTest.testSearchLucene(PersistenceJpaSearchTest.java:77), Similarity: 0.3025\n",
            "Summary & Description: decide type range query based field instead value \n",
            " This is a followup of a Stackoverflow question. See this comment here:\n",
            "http://stackoverflow.com/questions/37730874/numericrangequery-fails-for-int-field-in-hibernate-search/37731487?noredirect=1#comment62957944_37731487\n",
            "\n",
            "See {{NumericFieldUtils#createNumericRangeQuery()}}.\n",
            "\n",
            "Currently, when we build a range query with the DSL, if the field is defined as a Long but the range parameters are Integers, the query is built as if the field was an Integer and the query does not return any result as Long and Integers are encoded differently.\n",
            "\n",
            "This is not very user friendly: we should build the query with the field type in mind and throw an error if the field type and the range parameters are not compatible. We could be a bit permissive and allow Integers for a Long field type thus allowing above(0) to work for Long too., Similarity: 0.2443\n",
            "Summary & Description: numeric encoding type correctly set custom field bridge \n",
            " See http://stackoverflow.com/questions/37628389/hibernate-search-5-5-3-sort-by-collection-size-no-longer-working, Similarity: 0.2008\n",
            "Summary & Description: support hibernate 520final current causes javalangnosuchfielderror session \n",
            " Upgraded hibernate-core to 5.2.0.Final, do break hibernate-search integration.\n",
            "\n",
            "Caused by: java.lang.NoSuchFieldError: session\n",
            "at org.hibernate.search.impl.FullTextSessionImpl.getSearchIntegrator(FullTextSessionImpl.java:202)\n",
            "at org.hibernate.search.impl.FullTextSessionImpl.getSearchFactory(FullTextSessionImpl.java:195)\n",
            "at org.hibernate.search.jpa.impl.FullTextEntityManagerImpl.getSearchFactory(FullTextEntityManagerImpl.java:113)\n",
            "\n",
            "Worked well with hibernate 5.1.0.Final. , Similarity: 0.3592\n",
            "Summary & Description: distancesortfield support reverse sorting \n",
            " May be I do not know how to use the DistanceSortField class,\n",
            "But I want to do some column sorting on distance, and I am not able to do reverse sorting (in DESC direction).\n",
            "\n",
            "The DistanceSortField constructor do not accept a parameter 'reverse boolean'.\n",
            "I think the point is in the method\n",
            "org.hibernate.search.spatial.impl.DistanceComparatorSource#newComparator that do not handle the given reverse parameter.\n",
            "\n",
            "May be I miss something ?, Similarity: 0.2136\n",
            "Summary & Description: exception trying sort long field sortablefield \n",
            " I updated Hibernate Search to 5.5 and I saw that I should use the annotation @SortableField on all fields that I want to be sortable. It works fine for String fields and also for a Double field. But when I try to sort a Long field, I'm getting this exception:\n",
            "\n",
            "{code:java}\n",
            "java.lang.IllegalStateException: unexpected docvalues type NONE for field 'organizationStatistics.viewsSort' (expected=NUMERIC). Use UninvertingReader or index with docvalues.\n",
            "at org.apache.lucene.index.DocValues.checkField(DocValues.java:208) ~[lucene-core-5.3.1.jar:5.3.1 1703449 - noble - 2015-09-17 01:38:09]\n",
            "at org.apache.lucene.index.DocValues.getNumeric(DocValues.java:227) ~[lucene-core-5.3.1.jar:5.3.1 1703449 - noble - 2015-09-17 01:38:09]\n",
            "at org.apache.lucene.search.FieldComparator$NumericComparator.getNumericDocValues(FieldComparator.java:167) ~[lucene-core-5.3.1.jar:5.3.1 1703449 - noble - 2015-09-17 01:38:09]\n",
            "at org.apache.lucene.search.FieldComparator$NumericComparator.doSetNextReader(FieldComparator.java:153) ~[lucene-core-5.3.1.jar:5.3.1 1703449 - noble - 2015-09-17 01:38:09]\n",
            "at org.apache.lucene.search.SimpleFieldComparator.getLeafComparator(SimpleFieldComparator.java:36) ~[lucene-core-5.3.1.jar:5.3.1 1703449 - noble - 2015-09-17 01:38:09]\n",
            "at org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183) ~[lucene-core-5.3.1.jar:5.3.1 1703449 - noble - 2015-09-17 01:38:09]\n",
            "at org.apache.lucene.search.TopFieldCollector$NonScoringCollector.getLeafCollector(TopFieldCollector.java:141) ~[lucene-core-5.3.1.jar:5.3.1 1703449 - noble - 2015-09-17 01:38:09]\n",
            "at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:763) ~[lucene-core-5.3.1.jar:5.3.1 1703449 - noble - 2015-09-17 01:38:09]\n",
            "at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:486) ~[lucene-core-5.3.1.jar:5.3.1 1703449 - noble - 2015-09-17 01:38:09]\n",
            "at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:474) ~[lucene-core-5.3.1.jar:5.3.1 1703449 - noble - 2015-09-17 01:38:09]\n",
            "at org.hibernate.search.query.engine.impl.LazyQueryState.search(LazyQueryState.java:100) ~[hibernate-search-engine-5.5.2.Final.jar:5.5.2.Final]\n",
            "at org.hibernate.search.query.engine.impl.QueryHits.updateTopDocs(QueryHits.java:250) ~[hibernate-search-engine-5.5.2.Final.jar:5.5.2.Final]\n",
            "at org.hibernate.search.query.engine.impl.QueryHits.<init>(QueryHits.java:145) ~[hibernate-search-engine-5.5.2.Final.jar:5.5.2.Final]\n",
            "at org.hibernate.search.query.engine.impl.HSQueryImpl.getQueryHits(HSQueryImpl.java:480) ~[hibernate-search-engine-5.5.2.Final.jar:5.5.2.Final]\n",
            "at org.hibernate.search.query.engine.impl.HSQueryImpl.queryEntityInfos(HSQueryImpl.java:271) ~[hibernate-search-engine-5.5.2.Final.jar:5.5.2.Final]\n",
            "at org.hibernate.search.query.hibernate.impl.FullTextQueryImpl.list(FullTextQueryImpl.java:199) ~[hibernate-search-orm-5.5.2.Final.jar:5.5.2.Final]\n",
            "at com.third.rest.resources.retailers.PromotionTemplateService.hibernateSearch(PromotionTemplateService.java:65) ~[classes/:na]\n",
            "at com.third.rest.resources.retailers.PromotionTemplateService$$FastClassBySpringCGLIB$$4a03a5f2.invoke(<generated>) ~[classes/:na]\n",
            "at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) ~[spring-core-4.2.4.RELEASE.jar:4.2.4.RELEASE]\n",
            "at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:720) ~[spring-aop-4.2.4.RELEASE.jar:4.2.4.RELEASE]\n",
            "at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) ~[spring-aop-4.2.4.RELEASE.jar:4.2.4.RELEASE]\n",
            "at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99) ~[spring-tx-4.2.4.RELEASE.jar:4.2.4.RELEASE]\n",
            "at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:281) ~[spring-tx-4.2.4.RELEASE.jar:4.2.4.RELEASE]\n",
            "at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) ~[spring-tx-4.2.4.RELEASE.jar:4.2.4.RELEASE]\n",
            "at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-4.2.4.RELEASE.jar:4.2.4.RELEASE]\n",
            "at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:655) ~[spring-aop-4.2.4.RELEASE.jar:4.2.4.RELEASE]\n",
            "at com.third.rest.resources.retailers.PromotionTemplateService$$EnhancerBySpringCGLIB$$b9b560b8.hibernateSearch(<generated>) ~[classes/:na]\n",
            "at com.third.rest.resources.retailers.PromotionTemplateResourceImpl.list(PromotionTemplateResourceImpl.java:123) ~[classes/:na]\n",
            "at sun.reflect.GeneratedMethodAccessor586.invoke(Unknown Source) ~[na:na]\n",
            "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_25]\n",
            "at java.lang.reflect.Method.invoke(Method.java:483) ~[na:1.8.0_25]\n",
            "at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:302) ~[spring-aop-4.2.4.RELEASE.jar:4.2.4.RELEASE]\n",
            "at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190) ~[spring-aop-4.2.4.RELEASE.jar:4.2.4.RELEASE]\n",
            "at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) ~[spring-aop-4.2.4.RELEASE.jar:4.2.4.RELEASE]\n",
            "at org.springframework.validation.beanvalidation.MethodValidationInterceptor.invoke(MethodValidationInterceptor.java:139) ~[spring-context-4.2.4.RELEASE.jar:4.2.4.RELEASE]\n",
            "at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-4.2.4.RELEASE.jar:4.2.4.RELEASE]\n",
            "at org.springframework.security.access.intercept.aopalliance.MethodSecurityInterceptor.invoke(MethodSecurityInterceptor.java:64) ~[spring-security-core-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) ~[spring-aop-4.2.4.RELEASE.jar:4.2.4.RELEASE]\n",
            "at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:208) ~[spring-aop-4.2.4.RELEASE.jar:4.2.4.RELEASE]\n",
            "at com.sun.proxy.$Proxy258.list(Unknown Source) ~[na:na]\n",
            "at sun.reflect.GeneratedMethodAccessor586.invoke(Unknown Source) ~[na:na]\n",
            "at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_25]\n",
            "at java.lang.reflect.Method.invoke(Method.java:483) ~[na:1.8.0_25]\n",
            "at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60) ~[jersey-server-1.18.jar:1.18]\n",
            "at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185) ~[jersey-server-1.18.jar:1.18]\n",
            "at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75) ~[jersey-server-1.18.jar:1.18]\n",
            "at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302) ~[jersey-server-1.18.jar:1.18]\n",
            "at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108) ~[jersey-server-1.18.jar:1.18]\n",
            "at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147) ~[jersey-server-1.18.jar:1.18]\n",
            "at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84) ~[jersey-server-1.18.jar:1.18]\n",
            "at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542) [jersey-server-1.18.jar:1.18]\n",
            "at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473) [jersey-server-1.18.jar:1.18]\n",
            "at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419) [jersey-server-1.18.jar:1.18]\n",
            "at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409) [jersey-server-1.18.jar:1.18]\n",
            "at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409) [jersey-servlet-1.18.jar:1.18]\n",
            "at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:540) [jersey-servlet-1.18.jar:1.18]\n",
            "at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:715) [jersey-servlet-1.18.jar:1.18]\n",
            "at javax.servlet.http.HttpServlet.service(HttpServlet.java:729) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:291) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at com.third.rest.util.LogRawRequestFilter.doFilter(LogRawRequestFilter.java:61) [classes/:na]\n",
            "at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:330) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:118) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:84) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:342) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:113) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:342) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:103) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:342) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:113) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:342) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:154) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:342) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:45) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:342) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.oauth2.provider.authentication.OAuth2AuthenticationProcessingFilter.doFilter(OAuth2AuthenticationProcessingFilter.java:140) [spring-security-oauth2-2.0.4.RELEASE.jar:na]\n",
            "at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:342) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:110) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:342) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:57) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.4.RELEASE.jar:4.2.4.RELEASE]\n",
            "at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:342) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:87) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:342) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:50) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.4.RELEASE.jar:4.2.4.RELEASE]\n",
            "at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:342) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:192) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160) [spring-security-web-3.2.5.RELEASE.jar:3.2.5.RELEASE]\n",
            "at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:346) [spring-web-4.2.4.RELEASE.jar:4.2.4.RELEASE]\n",
            "at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:262) [spring-web-4.2.4.RELEASE.jar:4.2.4.RELEASE]\n",
            "at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at org.apache.catalina.filters.CorsFilter.handleSimpleCORS(CorsFilter.java:301) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at org.apache.catalina.filters.CorsFilter.doFilter(CorsFilter.java:165) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:212) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:106) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:502) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:141) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:521) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1096) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:674) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1500) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1456) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_25]\n",
            "at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_25]\n",
            "at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.0.30.jar:8.0.30]\n",
            "at java.lang.Thread.run(Thread.java:745) [na:1.8.0_25]\n",
            "{code}\n",
            "\n",
            "This is how my field is declared:\n",
            "\n",
            "{code:java}\n",
            "@Column(name = \"views\")\n",
            "@Field(name = \"viewsSort\", analyze = Analyze.NO, store = Store.NO, index = Index.NO)\n",
            "@SortableField(forField = \"viewsSort\")\n",
            "private Long view;\n",
            "{code}\n",
            "\n",
            "In the exactly same class, there is a double field declared exactly the same way and it works., Similarity: 0.2514\n",
            "Summary & Description: need explicit flush specific index \n",
            " We suspect we need two styles of refresh:\n",
            "- a global one which flushes all on SearchFactory (useful for testing).\n",
            "- one which setups a \"block on commit\" making the changes from the current TX visible to follow up operations of the same thread.\n",
            "\n",
            "Proposals:\n",
            " SearchFactory#forceVisibility()\n",
            "\n",
            " FullTextSession#onCommit().blockUntilIndexesUpdated(); \n",
            "or\n",
            " FullTextSession#onCommit().makeChangesVisible();\n",
            " FullTextSession#onCommit().awaitUntilChangesAreVisible(); <- favourite so far\n",
            "\n",
            "Not expected to work on the JMS slaves. Throw an exception?, Similarity: 0.2237\n",
            "Summary & Description: make javadoc generation quiet \n",
            " Might be a nice improvement for the build log., Similarity: 0.2704\n",
            "Summary & Description: speed travis build \n",
            " We can use the lessons learnt from OGM., Similarity: 0.2711\n",
            "Summary & Description: resources may cleaned bootstrap failure \n",
            " This is highlighted by debugging the JVM state after executing a test like {{org.hibernate.search.test.filter.fulltextfilterdefs.FullTextFilterDefsAnnotationTest.shouldNotBePossibleToHaveTwoFilterDefsWithTheSameName()}} :\n",
            "\n",
            "we verify that the {{SearchIntegrator}} refuses to boot on some illegal configurations, however some services might have been initialized already so they are not shut down gracefully.\n",
            "\n",
            "This might not be critical in case of most components, but it's also leaking started Thread instances and this would cause issues on deployment in containers., Similarity: 0.3664\n",
            "Summary & Description: support solr backend \n",
            " In the same way we support Elasticsearch as a backend, it would be nice to support Solr.\n",
            "\n",
            "Solr is different from Elasticsearch: it introduces the notion of cores, which are separate indexes with separate configuration files, schemas and so on.\n",
            "\n",
            "In a core, you can have one and only one schema which defines the way the data are stored. Note that the schema can be quite flexible as you have the notion of dynamic fields so you might decide that all *_int fields are mapped to an int and you can then add any field named with this scheme.\n",
            "\n",
            "Cores are manageable through an API and you can also manage the underlying schema with the API.\n",
            "\n",
            "AFAIK, it is possible to build join request across cores but there might be limitations: we would have to study this carefully if we want to support joins one day.\n",
            "\n",
            "Solr 6 introduces a JSON request API which allows to build requests with JSON: https://cwiki.apache.org/confluence/display/solr/JSON+Request+API . It's really far more readable than using the \"everything in the URL\" API., Similarity: 0.1694\n",
            "Summary & Description: marker annotation fields whose dirtiness irrelevant hsearch \n",
            " Following HSEARCH-1096, entities with {{@Transient}} indexed fields are always reindexed upon entity update, regardless of the dirty properties. This is fine, because Hibernate Search cannot know which properties the indexed fields depend on, but this may lead to performance nightmares, where simple changes trigger a full, resource-intensive reindexing of an entity and all its related {{@ContainedIn}} entities.\n",
            "\n",
            "In HSEARCH-1093, it was proposed to add a way for users to indicate which properties a given {{@Transient}} indexed field depend on. This has not been developed yet, probably because it would be quite complex.\n",
            "Another solution to this issue would be to provide a way for users to indicate which properties are *never* used in {{@Transient}} indexed fields. This way, if a user performs very frequently a tiny update operation on his entities that should not impact the indexes, the user only has to annotate the properties involved in this update operation. Then, when Hibernate performs the update, Hibernate Search will detect that the only changed fields are irrelevant to the indexes, and thus will skip the indexing.\n",
            "About the name of this annotation, there are a few possibilities: {{@DirtyIgnore}}, {{@IndexIgnore}}, {{@IndexTransient}}, ... My personnal favorite is {{@IndexTransient}}, because I think it more closely translates the characteristics that the annotated property should have.\n",
            "\n",
            "I already implemented this in our own project, by heavily overriding some key classes of Hibernate Search (most notably the FullTextIndexEventListener), but I think moving this implementation directly to Hibernate Search would prove very simple (20 to 30 lines of code). So, the question is: if I did provide a pull request, would this feature be accepted?, Similarity: 0.2297\n",
            "Summary & Description: support access elasticsearch cluster \n",
            " One option to access a cluster is to access a proxy that will then be able to dispatch to one random node.\n",
            "The alternative is for the client to have a list of defined hostname to access (instead of a single one).\n",
            "A third is some DNS round robin.\n",
            "\n",
            "We could do something special for case #2 but can someone check in the Elasticsearch community what is the recommended approach?, Similarity: 0.3181\n",
            "Summary & Description: rethink usage projectionconstants provide better validation wrongly used strings \n",
            " As initially raised in HSEARCH-2227 : we know accept both String constants for the Elasticsearch backend and the \"regular\" Lucene backend, but we can't say if the user is using the right constants as they are just strings to us.\n",
            "\n",
            "It would be interesting to find a way to distinguish the usage, either with typesafety to provide compile-time validation or at least a way to validate these at runtime.\n",
            "\n",
            "We also need to keep in mind that any stored indexed field is also a valid target for projection, and the most likely use case is to mix the identifiers from either set of constants and the field names: would be great to be able to validate projection of field names too., Similarity: 0.2531\n",
            "Summary & Description: use nested objects mapping parentchild relationship mapping \n",
            " Enable nested mapping as needed:\n",
            "* only needed for embedded *-to-many with more than one field\n",
            "* for these, the user should be able to opt out (nested would be the safe default mapping in this case, but they could want to opt out when only ever querying on single fields of the embeddable)\n",
            "\n",
            "It might be a logic we could also use for the Lucene backend and if we came up with such a complicated scheme to determine if a field is going to be nested or not, we will probably need to integrate these information in the metada., Similarity: 0.3180\n",
            "Summary & Description: deal index mappings creationupgradeconcurrency elasticsearch case \n",
            " We need to be able to upgrade the index mapping without ripping off all the index content.\n",
            "\n",
            "What happens if several nodes in a cluster try to create/upgrade the mappings?, Similarity: 0.3042\n",
            "Summary & Description: make fieldhelpergetnumericencodingtype work fields embedded types \n",
            " [~accountid:557058:6a9959ae-3b15-4370-ad41-e78c978f4f7b] could you explain what you had in mind with this one?, Similarity: 0.3054\n",
            "Summary & Description: add elasticsearch specific projection constants \n",
            " Might be a good idea to expose at least \"took\" and \"timed_out\".\n",
            "\n",
            "See https://www.elastic.co/guide/en/elasticsearch/reference/current/_the_search_api.html for reference., Similarity: 0.2307\n",
            "Summary & Description: consider adding option include tenant id field mapping \n",
            " I'm not really convinced about this: I think it's not that bad to always have the tenant id field in the mapping but happy to have other opinions., Similarity: 0.1064\n",
            "Summary & Description: improve conversion primitive types json conversion \n",
            " There are a couple of things that should be fixed/considered in {{ElasticsearchHSQueryImpl#convertFieldValue}}:\n",
            "- should we throw an exception if the type is not a JSON primitive one\n",
            "- we expose a specific Gson implementation of Number which doesn't seem right\n",
            "- maybe we should raise an exception if the type is unknown., Similarity: 0.2075\n",
            "Summary & Description: support singlevalued sorts fields within nested fields \n",
            " See org.hibernate.search.v6poc.integrationtest.backend.tck.search.SearchSortIT#nested, Similarity: 0.3175\n",
            "Summary & Description: document recommended sort id field \n",
            " In the Lucene backend, sorting on the id field leads to erratic behaviors (random sorting).\n",
            "\n",
            "In the Elasticsearch backend, when we sort by the id field, we use the _uid field to sort. The _uid field is defined as {{type#id}} so the behavior is not satisfactory when you query multiple times. Not that it's the best we can do as the {{_id}} field is not indexed and can't be used for sorting.\n",
            "\n",
            "So we'd better recommend staying away from the id field for sorting.\n",
            "\n",
            ", Similarity: 0.2046\n",
            "Summary & Description: remove deprecated threshold method fuzzy queries dsl \n",
            " It has been deprecated for a while and it's not really possible to compute the max edit distance from the threshold in the case of remote analyzer.\n",
            "\n",
            "Thus it looks like a good thing to remove it definitely., Similarity: 0.1478\n",
            "Summary & Description: parallel service lookup might fail find service \n",
            " Spotted by {{org.hibernate.search.test.engine.worker.AsyncWorkerTest}} when run on Elasticsearch, it seems sone threads will attempt to use a {{LuceneHSQuery}} instead:\n",
            "\n",
            "{noformat}org.hibernate.search.exception.SearchException: HSEARCH000302: Cannot execute query 'name:emmanuel', as targeted entity type 'org.hibernate.search.test.engine.worker.Employee' is indexed through a non directory-based backend\n",
            "\tat org.hibernate.search.query.engine.impl.LuceneHSQuery.getIndexManagers(LuceneHSQuery.java:595)\n",
            "\tat org.hibernate.search.query.engine.impl.LuceneHSQuery.buildSearcher(LuceneHSQuery.java:401)\n",
            "\tat org.hibernate.search.query.engine.impl.LuceneHSQuery.buildSearcher(LuceneHSQuery.java:363)\n",
            "\tat org.hibernate.search.query.engine.impl.LuceneHSQuery.queryEntityInfos(LuceneHSQuery.java:126)\n",
            "\tat org.hibernate.search.query.hibernate.impl.FullTextQueryImpl.list(FullTextQueryImpl.java:202)\n",
            "\tat org.hibernate.search.test.engine.worker.WorkerTestCase$Work.run(WorkerTestCase.java:109)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n",
            "\tat java.lang.Thread.run(Thread.java:745){noformat}, Similarity: 0.3698\n",
            "Summary & Description: update project tagline project description readme \n",
            " The tagline of the Hibernate Search project has been \"Apache Lucene integration\" - at least in the reference documentation.\n",
            "\n",
            "Since we're widening the scope of integrations, we need to update these.\n",
            "\n",
            "The README especially needs updating, but as far as I remember that content is also copied into several other introductions to the project (website, openhub, etc...), Similarity: 0.3917\n",
            "Summary & Description: duplicate methods abstractdocumentbuilder \n",
            " {code}org.hibernate.search.engine.spi.AbstractDocumentBuilder{code}\n",
            "\n",
            "There are two methods:\n",
            "* getMetadata()\n",
            "* getTypeMetadata()\n",
            "\n",
            "I suppose one of the two should be deprecated and remove in the next major release, Similarity: 0.2720\n",
            "Summary & Description: add dependency xmlbind es jboss modules modulexml \n",
            " {{ElasticsearchBridgeProvider.EsDateBridge}} has a dependency to JAXB's {{DatatypeConverter}} (for date formatting/parsing purposes), but we lack the required dependency in the module.xml definition:\n",
            "\n",
            "{code}\n",
            "<module name=\"javax.xml.bind.api\"/>\n",
            "{code}, Similarity: 0.5034\n",
            "Summary & Description: hsearch000268 facet request categoryfacet tries facet field categoryid either exists configured faceting via facet check configuration \n",
            " HSEARCH000268: Facet request 'categoryFacet' tries to facet on  field 'category.id' which either does not exists or is not configured for faceting (via @Facet). Check your configuration.\n",
            "\n",
            "\t\t\n",
            "{code:java}\n",
            "final FullTextEntityManager fullTextEntityManager = Search.getFullTextEntityManager(entityManager);\n",
            "\t\tfinal QueryBuilder builder = fullTextEntityManager.getSearchFactory().buildQueryBuilder().forEntity(Phrase.class).get();\n",
            "\t\tfinal FacetingRequest categoryFacetingRequest = builder.facet()\n",
            "\t\t\t    .name(\"categoryFacet\")\n",
            "\t\t\t    .onField(\"category.id\")\n",
            "\t\t\t    .discrete()\n",
            "\t\t\t    .orderedBy(FacetSortOrder.FIELD_VALUE)\n",
            "\t\t\t    .includeZeroCounts(false)\n",
            "\t\t\t    .maxFacetCount(3)\n",
            "\t\t\t    .createFacetingRequest();\n",
            "\t\t\n",
            "\t\t// create a fulltext query\n",
            "\t\tfinal Query luceneQuery = builder.all().createQuery();\n",
            "\t\tfinal FullTextQuery fullTextQuery = fullTextEntityManager.createFullTextQuery(luceneQuery, Phrase.class);\n",
            "\t\t\n",
            "\t\t// retrieve facet manager and apply faceting request\n",
            "\t\tfinal FacetManager facetManager = fullTextQuery.getFacetManager();\n",
            "\t\tfacetManager.enableFaceting(categoryFacetingRequest);\n",
            "\t\t\n",
            "\t\tfinal List<Facet> facets = facetManager.getFacets(\"categoryFacet\");\n",
            "{code}\n",
            "\n",
            "facet field\n",
            "\n",
            "{code:java}\n",
            "   @IndexedEmbedded({\"id\", \"name\"})\n",
            "   @Facet\n",
            "   @ManyToOne\n",
            "    Category category\n",
            "{code}\n",
            ", Similarity: 0.3362\n",
            "Summary & Description: add typenamingstrategy allow users change elasticsearch type name \n",
            " After discussions on HSEARCH-2216, we agreed:\n",
            "\n",
            "- not to change the Elasticsearch type name to a non qualified name by default (Sanne's lead hammer)\n",
            "- offer another strategy contract: {{TypeNamingStrategy}} which allow users to provide a different name for the Elasticsearch type (than the FQCN).\n",
            "\n",
            "The default {{TypeNamingStrategy}} would provide the FQCN as the type name.\n",
            "\n",
            "Questions remaining,\n",
            "\n",
            "* should we store the classname in the type structure {{_meta}}? We could offer a bidirectional {{TypeNamingStrategy}} and not store anything\n",
            "* if we decide to store, should we only store it when the {{TypeNamingStrategy}} deviates from the default one? how to recognized a true FQCN from a modified one?, Similarity: 0.1940\n",
            "Summary & Description: detect invalid cardinality fields mapped docvalues \n",
            " It appears that a mapping following this structure:\n",
            "\n",
            " root entity -> oneToMany -> Spatial fields\n",
            "\n",
            "will attempt to index the spatial coordinates multiple times for the same field name.\n",
            "Since Spatial now uses DocValues, this is an invalid mapping.\n",
            "\n",
            "The mapping has always been invalid as the pairs of coordinates would have been indexed in a mixed bag - so impossible to pair up a latitude with its related longitude - yet we didn't throw an exception at runtime when these were not DocValues.\n",
            "\n",
            "We should detect an illegal cardinality for DocValue fields at boot time, and fail fast.\n",
            "\n",
            "See also https://forum.hibernate.org/viewtopic.php?f=9&t=1043185, Similarity: 0.2642\n",
            "Summary & Description: document value given indexnullas must match field type \n",
            " That requirement has been added only recently, it should be reflected in the JavaDocs of {{indexNullAs()}}., Similarity: 0.2520\n",
            "Summary & Description: elasticsearchprojectionconstants exposes lucene constructs \n",
            " By inheritance, elasticsearch.ProjectionConstants exposes impossible things:\n",
            "\n",
            "* DOCUMENT: it's a Lucene document but that's not available and can be confused with SCORE: should we remove SCORE and map DOCUMENT to SCORE for the es backend?\n",
            "* DOCUMENT_ID: does ES expose a document id?\n",
            "* EXPLANATION: does Expose an explanation object? Same type as Lucene's? , Similarity: 0.3104\n",
            "Summary & Description: consider adding typed version query fulltextentitymanager \n",
            " {code}\n",
            "interface FullTextEntityManager {\n",
            "  //existing\n",
            "  FullTextQuery createFullTextQuery(Query var1, Class... var2);\n",
            "  FullTextQuery createFullTextQuery(QueryDescriptor var1, Class... var2);\n",
            "\n",
            "  //adding\n",
            "  // FullTextTypedQuery extends TypedQuery\n",
            "  <T> FullTextTypedQuery<T> createFullTextQuery(Query query, Class<T> uniqueClass);\n",
            "  <T> FullTextTypedQuery<T> createFullTextQuery(QueryDescriptor query, Class<T> uniqueClass);\n",
            "  \n",
            "{code}\n",
            "\n",
            "Today code change from JPA are a bit unfavorable., Similarity: 0.2208\n",
            "Summary & Description: indexing collection basic types documented \n",
            " Indexing collection of basic types is not documented.\n",
            "It is however used by Gunnar in its demo., Similarity: 0.1485\n",
            "Summary & Description: rename solranalyzerbuilder solr related anymore \n",
            " {{SolrAnalyzerBuilder}} is not related to Solr anymore as anything it uses has been integrated into Lucene.\n",
            "\n",
            "We should rename it and remove the leftovers of Solr related information., Similarity: 0.1240\n",
            "Summary & Description: document migration guide sort long id doesnt work anymore \n",
            " I recently upgraded from 5.3.0.Final to 5.6.0.Alpha3, following the migration guide.\n",
            "\n",
            "As soon as I did I noticed that sorting HS queries by \"id\" field (id is the name of the property that I have annotated with @Id) simply fails silently. I.e., no exception is thrown, but results are not sorted by id. This property is of type Long, which means that the Lucene field is of type NUMERIC.\n",
            "\n",
            "I then saw the following warning emitted by Hibernate whenever I run my query:\n",
            "\n",
            "{code:java}\n",
            "HSEARCH000289: Requested sort field(s) id are not configured for entity type com.fivoosh.entities.Applicant mapped to index com.fivoosh.entities.Applicant, thus an uninverting reader must be created. You should declare the missing sort fields using @SortableField.\n",
            "{code}\n",
            "\n",
            "Ok, I added the @SortableField annotation and reindexed, then tried running the query again. This time I got an exception:\n",
            "\n",
            "{code:java}\n",
            "Caused by: java.lang.IllegalStateException: unexpected docvalues type SORTED for field 'id' (expected=NUMERIC). Use UninvertingReader or index with docvalues.\n",
            "\tat org.apache.lucene.index.DocValues.checkField(DocValues.java:208)\n",
            "\tat org.apache.lucene.index.DocValues.getNumeric(DocValues.java:227)\n",
            "\tat org.apache.lucene.search.FieldComparator$NumericComparator.getNumericDocValues(FieldComparator.java:167)\n",
            "\tat org.apache.lucene.search.FieldComparator$NumericComparator.doSetNextReader(FieldComparator.java:153)\n",
            "\tat org.apache.lucene.search.SimpleFieldComparator.getLeafComparator(SimpleFieldComparator.java:36)\n",
            "\tat org.apache.lucene.search.FieldValueHitQueue.getComparators(FieldValueHitQueue.java:183)\n",
            "\tat org.apache.lucene.search.TopFieldCollector$SimpleFieldCollector.getLeafCollector(TopFieldCollector.java:164)\n",
            "\tat org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:812)\n",
            "\tat org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:535)\n",
            "\tat org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:523)\n",
            "\tat org.hibernate.search.query.engine.impl.LazyQueryState.search(LazyQueryState.java:100)\n",
            "\tat org.hibernate.search.query.engine.impl.QueryHits.updateTopDocs(QueryHits.java:241)\n",
            "\tat org.hibernate.search.query.engine.impl.QueryHits.<init>(QueryHits.java:136)\n",
            "\tat org.hibernate.search.query.engine.impl.LuceneHSQuery.getQueryHits(LuceneHSQuery.java:322)\n",
            "\tat org.hibernate.search.query.engine.impl.LuceneHSQuery.queryEntityInfos(LuceneHSQuery.java:131)\n",
            "\tat org.hibernate.search.query.hibernate.impl.FullTextQueryImpl.list(FullTextQueryImpl.java:200)\n",
            "\t... 123 common frames omitted\n",
            "{code}\n",
            "\n",
            "I tried changing the type in my SortField but alas -  the SortField.Type enum doesn't contain a value named \"SORTED\"., Similarity: 0.1962\n",
            "Summary & Description: use elasticsearch fields query capability projection \n",
            " Elasticsearch allows to define the list of fields to extract either from the Lucene store or the JSON document via the {{fields}} query option AFAIU. That is a way to avoid loading and transporting the full JSON document across the wire., Similarity: 0.4437\n",
            "Summary & Description: define analyzers via rest api \n",
            " Defining analyzer or any index.* properties in elasticsearch.yml is deprecated and will not work in Elasticsearch 5 (next version after 2.3). \n",
            "We should move away from using this approach and instead incorporate the Analyzer definition during the create index phase. \n",
            "Here is the API for it https://www.elastic.co/guide/en/elasticsearch/reference/2.3/indices-update-settings.html#update-settings-analysis\n",
            "\n",
            "This will work for all the analyzer def based on reasonable default implementations of Lucene / Elasticsearch. Each tokenizer and filter and char set can be given a name. \n",
            "One can also pass a fully qualified class name instead of the short name (to be verified)\n",
            "\n",
            "What about custom implementations of Tokenizer / Filter. The natural way in Elasticsearch is to write and deploy a plugin which contains a small implementation enlisting the tokenizers or filter by name and the actual implementations in a Jar. The main gotcha is that implementation classes must implement Elasticsearch interfaces. \n",
            "\n",
            "How far should we help users deploy their custom analyzer implementations :\n",
            "- build the plugin distro?\n",
            "- check the presence of the named analyzers or components (which ES API)?\n",
            "- change Analyzerdef to adopt a string based name solution like Elasticsearch?\n",
            "\n",
            ", Similarity: 0.2572\n",
            "Summary & Description: propagate storeyes elasticsearch lucene storage \n",
            " Elasticsearch stores the full document indexed as {{_SOURCE}}. One can use it to project fields even though they are not marked as {{Store.YES}} in Hibernate Search.\n",
            "But Elasticsearch also let people store the value of the field in Lucene itself (like Hibernate Search does). The reason is that it might be much faster to retrieve a small piece of stored info from Lucene vs loading the JSON document and filtering it out.\n",
            "\n",
            "So we should map Hibernate Search {{Store.YES}} to the Elasticsearch's Lucene Store.YES.\n",
            "\n",
            "That might be already done., Similarity: 0.3455\n",
            "Summary & Description: consider using meta field store fully qualified class name \n",
            " To make documents smaller, we could have smaller type name and use the {{_meta}} field of the mapping to store the fqcn.\n",
            "\n",
            "The main drawback is that we need the user to provide the shorter type name (it needs to be unique).\n",
            "\n",
            "Worth it?, Similarity: 0.2576\n",
            "Summary & Description: consider using fields feature elasticsearch properties mapped several fields \n",
            " Today we map each field in a Elasticsearch document field. If the bridge is the same, that means we copy the same data twice unnecessarily in the Elasticsearch document.\n",
            "\n",
            "Elasticsearch has the option to define multiple mappings for a given document attribute via the \"fields\" feature\n",
            "https://www.elastic.co/guide/en/elasticsearch/reference/2.3/multi-fields.html\n",
            "\n",
            "The drawback is that it cannot be done for different fieldbridges as the output might be different.\n",
            "Also it does not necessarily align with our naming conventions: they use nested properties for additional fields e.g. {{title}} and {{title.raw}} where we tend to do {{title}} and {{title_raw}}\n",
            "\n",
            "My gut feeling is that it's a lot of twists for a minor alignment and it should not be implemented., Similarity: 0.2515\n",
            "Summary & Description: provide option wait elasticsearch status yellow rather green \n",
            " Waiting for green is a bit aggressive especially for demos and other code level work. It requires to manually change in the configuration the replica numbers.\n",
            "[~accountid:557058:714ea766-3714-4d9f-a128-e54e195fc0c4] was mentioning that waiting for yellow might be good enough.\n",
            "\n",
            "We probably should make it an option., Similarity: 0.2229\n",
            "Summary & Description: missing types numericfieldutilsrequiresnumericrangequery \n",
            " This is a followup of https://github.com/hibernate/hibernate-search/pull/1046 .\n",
            "\n",
            "Note that the logic of NumericFieldUtils#requiresNumericRangeQuery is wrong in the general case as a type might be numeric or string depending on the backend used (see Date for the Elasticsearch backend for instance).\n",
            "\n",
            "It is used as a fallback when we don't have a DocumentFieldMetadata. It's documented as being used in the Infinispan case (see ConnectedMultiFieldsRangeQueryBuilder#createQuery) but it's currently also used for bridge defined fields which are not registered as DocumentFieldMetadata. In this latter case, we currently only support string and numerics so it won't be an issue., Similarity: 0.2662\n",
            "Summary & Description: switch classicsimilarity default similarity implementation \n",
            " Good old {{DefaultSimilarity}} is now deprecated, as it was renamed to {{ClassicSimilarity}}.\n",
            "\n",
            "This affects our docs and code to remove usage of the deprecated type, although it's not a change affecting functionality.\n",
            "\n",
            "We should backport this to 5.5 too., Similarity: 0.1712\n",
            "Summary & Description: treat booleanquery immutable query \n",
            " {{BooleanQuery}} has been used traditionally like this:\n",
            "{code}\n",
            "BooleanQuery q = new BooleanQuery();\n",
            "q.add( otherQuery, Occur.SOMETHING );\n",
            "{code}\n",
            "\n",
            "But now the no-arguments constructor is deprecated, and adding clauses to the instance is deprecated too.\n",
            "\n",
            "All our code needs to be updated to use {{org.apache.lucene.search.BooleanQuery.Builder}} instead, as in Lucene 6 all queries become immutable. {{BooleanQuery}} is used in many areas, including tests., Similarity: 0.2121\n",
            "Summary & Description: avoid using deprecated lucene apis internals \n",
            " \n",
            "Unless we expose the deprecated Lucene types on public APIs, we should stop using them.\n",
            "\n",
            "There are several categories of such bad usage in the code base, so I'll create sub tasks to split this work up.\n",
            "\n",
            "The test code needs to be polished as well, as the goal is to make it easier to eventually migrate to newer Lucene versions., Similarity: 0.3131\n",
            "Summary & Description: allow plug custom objectinitializer \n",
            " Hibernate OGM {{MultiGetGridDialect}} allows to fetch several entities by id in one round-trip. It'd be beneficial if we could plug in a custom object initializer into HSEARCH which leverages that capability of grid dialects., Similarity: 0.3478\n",
            "Summary & Description: reduce memory consumption entityinfoimpl objects \n",
            " Every instance of EntityInfoImpl references a LinkedList which is used to store the indexes of the entity in the projection even when ProjectionConstants.THIS was not specified in the projection fields. This can be easily avoided. We can use a placeholder in the projection array which will be replaced later in the #populateWithEntityInstance-method.\n",
            "\n",
            "Additionally the constructor of EntityInfoImpl makes a copy of the projected values array. This is not needed as the array was just created before the call to the constructor and the array is not modified after the call to the constructor., Similarity: 0.3534\n",
            "Summary & Description: allows use charfilter programmatic api searchmapping \n",
            " {{@AnalyzerDef}} got extended with an option to define {{CharFilter}}, however, the programmatic API does not offer this capability yet. , Similarity: 0.3093\n",
            "Summary & Description: amazon aws elasticsearch integration test failures \n",
            " # Create an AWS Elasticsearch domain\n",
            "# Set the environment property for tests to point at the AWS URL\n",
            "# Run the tests.  I ran them from the command line\n",
            "\n",
            "I can attach the test results if someone needs those.  Or, they can run the tests and see the results.  \n",
            "\n",
            "You also see \"Previously opened session wasn't closed\"\n",
            ", Similarity: 0.3206\n",
            "Summary & Description: amazon elasticsearch elasticsearchit takes 16 minutes run \n",
            " # Crate an elasticsearch instance.  You can use the free t2.micro. I also tested with m3.medium\n",
            "# Change the Elasticsearch environment variable to point at the AWS Elasticsearch domain\n",
            "# Run all unit test or just ElasticSearchIT\n",
            "It should take over 10 minutes to run. I have not yet run it in the debugger to where it is hanging.\n",
            "\n",
            "* The test eventually passes\n",
            "* All tests take very long ElasticsearchIndexMappingIT takes 107 seconds, Similarity: 0.2181\n",
            "Summary & Description: handling indexedembedded working correctly multilevel hierarchies \n",
            " If there is a entity {{A}}  which index-embeds another entity {{B}} and this one index-embeds yet another entity {{C}}, specifying {{includePaths}} on {{B.c}} leads to no fields from {{C}} being included at all into the index for {{A}}.\n",
            "\n",
            "Just specifying {{@IndexedEmbedded}} works, but sometimes you only want a subset of the {{C}} fields in the index of the embedding entity {{A}}.\n",
            "\n",
            "This is from the forum: https://forum.hibernate.org/viewtopic.php?f=9&t=1043055, Similarity: 0.1415\n",
            "Summary & Description: lucenebackendqueuetask release directory lock update failures \n",
            " LuceneBackendQueueTask always calls Workspace#afterTransactionApplied(boolean someFailureHappened, boolean streaming) with the parameter someFailureHappened=false in LuceneBackendQueueTask#applyUpdates() even when an exception occurs while updating an index., Similarity: 0.4111\n",
            "Summary & Description: highlighting search api \n",
            " Need a way to highlight search results much like {{lucene-highlighter}}, but maybe using a backend-agnostic projection? See [https://www.elastic.co/guide/en/elasticsearch/reference/current/highlighting.html|https://www.elastic.co/guide/en/elasticsearch/reference/current/highlighting.html], Similarity: 0.3145\n",
            "Summary & Description: make hibernate search modules valid wildfly feature pack file \n",
            " The Hibernate Search Modules ZIP[1]  should be a valid Wildfly Feature Pack[2]. This means changing the internal modules structures to start with {{/modules/system/layers/base/}} or {{/modules/add-ons/hibernate-search/}}\n",
            "\n",
            "[1] https://sourceforge.net/projects/hibernate/files/hibernate-search/5.6.0.Alpha3/hibernate-search-modules-5.6.0.Alpha3-wildfly-10-dist.zip/download\n",
            "\n",
            "[2] https://developer.jboss.org/wiki/WildflyBuildProcess, Similarity: 0.3414\n",
            "Summary & Description: document tested es versions \n",
            " While we should not depend on specific versions of ES, we should document the one(s) used for testing and thus known to work., Similarity: 0.1006\n",
            "Summary & Description: querying elastic search triggers exception result window large \n",
            " The following is the exact error:\n",
            "\n",
            "{code}\n",
            "Result window is too large, from + size must be less than or equal to: [10000] but was [10725]. See the scroll api for a more efficient way to request large data sets.\n",
            "{code}\n",
            "\n",
            "To reproduce the problem, I have an index with 11,228 products and issued a query that returned 10,722 hits.  The UI returns pages with a page size of 25 products, and so page 1 returned just fine with the first 25.  By selecting the last page, which is page 429, I got this error.\n",
            "\n",
            "Pagination parameters are provided to the FullTextQuery by specifying:\n",
            "\n",
            "{code}\n",
            "query.setFirstResult( ( page - 1 ) * pageSize ).setMaxResults( pageSize );\n",
            "{code}\n",
            "\n",
            "This results in 10,700 being the value for the first result.\n",
            "\n",
            "Stack Trace:\n",
            "{code}\n",
            "org.hibernate.search.exception.SearchException: HSEARCH400007: Elasticsearch request failed.\n",
            " Request:\n",
            "========\n",
            "Operation: Search\n",
            "Data:\n",
            "{\"query\":{\"filtered\":{\"query\":{\"bool\":{\"must\":[{\"bool\":{\"must\":{\"bool\":{\"should\":[{\"range\":{\"id.plantId\":{\"gte\":1.0,\"lte\":1.0,\"boost\":1.0}}},{\"range\":{\"id.plantId\":{\"gte\":3.0,\"lte\":3.0,\"boost\":1.0}}},{\"range\":{\"id.plantId\":{\"gte\":4.0,\"lte\":4.0,\"boost\":1.0}}},{\"range\":{\"id.plantId\":{\"gte\":5.0,\"lte\":5.0,\"boost\":1.0}}},{\"range\":{\"id.plantId\":{\"gte\":6.0,\"lte\":6.0,\"boost\":1.0}}},{\"range\":{\"id.plantId\":{\"gte\":7.0,\"lte\":7.0,\"boost\":1.0}}},{\"range\":{\"id.plantId\":{\"gte\":10.0,\"lte\":10.0,\"boost\":1.0}}},{\"range\":{\"id.plantId\":{\"gte\":8.0,\"lte\":8.0,\"boost\":1.0}}},{\"range\":{\"id.plantId\":{\"gte\":9.0,\"lte\":9.0,\"boost\":1.0}}}]}}}},{\"bool\":{\"must\":{\"bool\":{\"should\":[{\"wildcard\":{\"customerItemNumber\":{\"value\":\"*0*\",\"boost\":1.0}}},{\"wildcard\":{\"customerItemNumberScrubbed\":{\"value\":\"*0*\",\"boost\":1.0}}}]}}}},{\"term\":{\"serviceFlag\":{\"value\":\"false\",\"boost\":1.0}}}]}},\"filter\":{\"type\":{\"value\":\"com.setech.mrovelocityhub.inventory.domain.Item\"}}}},\"sort\":[{\"_score\":{\"order\":\"desc\"}}]}\n",
            "Response:\n",
            "=========\n",
            "Status: 500\n",
            "Error message: {\"root_cause\":[{\"type\":\"query_phase_execution_exception\",\"reason\":\"Result window is too large, from + size must be less than or equal to: [10000] but was [10725]. See the scroll api for a more efficient way to request large data sets. This limit can be set by changing the [index.max_result_window] index level parameter.\"}],\"type\":\"search_phase_execution_exception\",\"reason\":\"all shards failed\",\"phase\":\"query\",\"grouped\":true,\"failed_shards\":[{\"shard\":0,\"index\":\"com.setech.mrovelocityhub.inventory.domain.item\",\"node\":\"TK1fAfSZSxyqX0rwgGKLhw\",\"reason\":{\"type\":\"query_phase_execution_exception\",\"reason\":\"Result window is too large, from + size must be less than or equal to: [10000] but was [10725]. See the scroll api for a more efficient way to request large data sets. This limit can be set by changing the [index.max_result_window] index level parameter.\"}}]}\n",
            "\n",
            "\n",
            "\tat org.hibernate.search.backend.elasticsearch.client.impl.JestClient.executeRequest(JestClient.java:89)\n",
            "\tat org.hibernate.search.backend.elasticsearch.client.impl.JestClient.executeRequest(JestClient.java:80)\n",
            "\tat org.hibernate.search.backend.elasticsearch.impl.ElasticsearchHSQueryImpl$IndexSearcher.runSearch(ElasticsearchHSQueryImpl.java:488)\n",
            "\tat org.hibernate.search.backend.elasticsearch.impl.ElasticsearchHSQueryImpl.execute(ElasticsearchHSQueryImpl.java:257)\n",
            "\tat org.hibernate.search.backend.elasticsearch.impl.ElasticsearchHSQueryImpl.queryResultSize(ElasticsearchHSQueryImpl.java:145)\n",
            "\tat org.hibernate.search.query.hibernate.impl.FullTextQueryImpl.getResultSize(FullTextQueryImpl.java:223)\n",
            "\tat org.hibernate.search.jpa.impl.FullTextQueryImpl.getResultSize(FullTextQueryImpl.java:98)\n",
            "\tat com.setech.mrovelocityhub.inventory.dao.internal.ItemSearchJpaRepository.find(ItemSearchJpaRepository.java:134)\n",
            "\tat com.setech.mrovelocityhub.inventory.internal.ItemSearchServiceImpl.search(ItemSearchServiceImpl.java:171)\n",
            "\tat com.setech.mrovelocityhub.inventory.internal.ItemSearchServiceImpl.search(ItemSearchServiceImpl.java:1)\n",
            "\tat sun.reflect.GeneratedMethodAccessor600.invoke(Unknown Source)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.__invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java)\n",
            "\tat java.lang.reflect.Method.invoke(Method.java:497)\n",
            "\tat org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:302)\n",
            "\tat org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)\n",
            "\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)\n",
            "\tat org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99)\n",
            "\tat org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:281)\n",
            "\tat org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96)\n",
            "\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n",
            "\tat org.springframework.security.access.intercept.aopalliance.MethodSecurityInterceptor.invoke(MethodSecurityInterceptor.java:68)\n",
            "\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n",
            "\tat org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:208)\n",
            "\tat com.sun.proxy.$Proxy176.search(Unknown Source)\n",
            "\tat com.setech.mrovelocityhub.core.web.search.actions.SearchAction.getSearchResults(SearchAction.java:354)\n",
            "\tat com.setech.mrovelocityhub.core.web.search.actions.SearchAction.search(SearchAction.java:157)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.__invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java)\n",
            "\tat java.lang.reflect.Method.invoke(Method.java:497)\n",
            "\tat ognl.OgnlRuntime.invokeMethod(OgnlRuntime.java:891)\n",
            "\tat ognl.OgnlRuntime.callAppropriateMethod(OgnlRuntime.java:1293)\n",
            "\tat ognl.ObjectMethodAccessor.callMethod(ObjectMethodAccessor.java:68)\n",
            "\tat com.opensymphony.xwork2.ognl.accessor.XWorkMethodAccessor.callMethodWithDebugInfo(XWorkMethodAccessor.java:117)\n",
            "\tat com.opensymphony.xwork2.ognl.accessor.XWorkMethodAccessor.callMethod(XWorkMethodAccessor.java:108)\n",
            "\tat ognl.OgnlRuntime.callMethod(OgnlRuntime.java:1369)\n",
            "\tat ognl.ASTMethod.getValueBody(ASTMethod.java:90)\n",
            "\tat ognl.SimpleNode.evaluateGetValueBody(SimpleNode.java:212)\n",
            "\tat ognl.SimpleNode.getValue(SimpleNode.java:258)\n",
            "\tat ognl.Ognl.getValue(Ognl.java:494)\n",
            "\tat ognl.Ognl.getValue(Ognl.java:458)\n",
            "\tat com.opensymphony.xwork2.ognl.OgnlUtil$2.execute(OgnlUtil.java:309)\n",
            "\tat com.opensymphony.xwork2.ognl.OgnlUtil.compileAndExecute(OgnlUtil.java:340)\n",
            "\tat com.opensymphony.xwork2.ognl.OgnlUtil.getValue(OgnlUtil.java:307)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invokeAction(DefaultActionInvocation.java:423)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invokeActionOnly(DefaultActionInvocation.java:287)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:250)\n",
            "\tat com.opensymphony.xwork2.interceptor.DefaultWorkflowInterceptor.doIntercept(DefaultWorkflowInterceptor.java:167)\n",
            "\tat com.opensymphony.xwork2.interceptor.MethodFilterInterceptor.intercept(MethodFilterInterceptor.java:98)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.opensymphony.xwork2.validator.ValidationInterceptor.doIntercept(ValidationInterceptor.java:265)\n",
            "\tat org.apache.struts2.interceptor.validation.AnnotationValidationInterceptor.doIntercept(AnnotationValidationInterceptor.java:76)\n",
            "\tat com.opensymphony.xwork2.interceptor.MethodFilterInterceptor.intercept(MethodFilterInterceptor.java:98)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.opensymphony.xwork2.interceptor.ConversionErrorInterceptor.intercept(ConversionErrorInterceptor.java:138)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.opensymphony.xwork2.interceptor.ParametersInterceptor.doIntercept(ParametersInterceptor.java:229)\n",
            "\tat com.opensymphony.xwork2.interceptor.MethodFilterInterceptor.intercept(MethodFilterInterceptor.java:98)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.opensymphony.xwork2.interceptor.ParametersInterceptor.doIntercept(ParametersInterceptor.java:229)\n",
            "\tat com.opensymphony.xwork2.interceptor.MethodFilterInterceptor.intercept(MethodFilterInterceptor.java:98)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.opensymphony.xwork2.interceptor.StaticParametersInterceptor.intercept(StaticParametersInterceptor.java:191)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat org.apache.struts2.interceptor.FileUploadInterceptor.intercept(FileUploadInterceptor.java:253)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.opensymphony.xwork2.interceptor.ModelDrivenInterceptor.intercept(ModelDrivenInterceptor.java:100)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.opensymphony.xwork2.interceptor.ChainingInterceptor.intercept(ChainingInterceptor.java:145)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.opensymphony.xwork2.interceptor.PrepareInterceptor.doIntercept(PrepareInterceptor.java:171)\n",
            "\tat com.opensymphony.xwork2.interceptor.MethodFilterInterceptor.intercept(MethodFilterInterceptor.java:98)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat org.apache.struts2.interceptor.ServletConfigInterceptor.intercept(ServletConfigInterceptor.java:164)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.opensymphony.xwork2.interceptor.ParametersInterceptor.doIntercept(ParametersInterceptor.java:229)\n",
            "\tat com.opensymphony.xwork2.interceptor.MethodFilterInterceptor.intercept(MethodFilterInterceptor.java:98)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat org.apache.struts2.interceptor.MultiselectInterceptor.intercept(MultiselectInterceptor.java:73)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat org.apache.struts2.interceptor.DateTextFieldInterceptor.intercept(DateTextFieldInterceptor.java:125)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat org.apache.struts2.interceptor.CheckboxInterceptor.intercept(CheckboxInterceptor.java:91)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.opensymphony.xwork2.interceptor.I18nInterceptor.intercept(I18nInterceptor.java:139)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.opensymphony.xwork2.interceptor.AliasInterceptor.intercept(AliasInterceptor.java:193)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.opensymphony.xwork2.interceptor.ExceptionMappingInterceptor.intercept(ExceptionMappingInterceptor.java:189)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.setech.struts2.interceptors.ConversationInterceptor.intercept(ConversationInterceptor.java:147)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.setech.mrovelocityhub.core.web.struts.interceptor.MenuInterceptor.doInterceptInternal(MenuInterceptor.java:67)\n",
            "\tat com.setech.mrovelocityhub.core.web.struts.interceptor.AbstractAuthenticatedInterceptor.intercept(AbstractAuthenticatedInterceptor.java:35)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.setech.mrovelocityhub.core.web.struts.interceptor.UnreadNotificationsInterceptor.doInterceptInternal(UnreadNotificationsInterceptor.java:73)\n",
            "\tat com.setech.mrovelocityhub.core.web.struts.interceptor.AbstractAuthenticatedInterceptor.intercept(AbstractAuthenticatedInterceptor.java:35)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.setech.mrovelocityhub.core.web.struts.interceptor.SiteOptionsOverrideInterceptor.intercept(SiteOptionsOverrideInterceptor.java:69)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.setech.mrovelocityhub.core.web.struts.interceptor.UserAgentCompatibleInterceptor.intercept(UserAgentCompatibleInterceptor.java:41)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.setech.mrovelocityhub.core.web.struts.interceptor.AjaxRequestAwareInterceptor.intercept(AjaxRequestAwareInterceptor.java:36)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.setech.mrovelocityhub.core.web.struts.interceptor.LocaleContextHolderInterceptor.intercept(LocaleContextHolderInterceptor.java:42)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.setech.mrovelocityhub.core.web.struts.interceptor.UserContextHolderInterceptor.intercept(UserContextHolderInterceptor.java:46)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.opensymphony.xwork2.interceptor.I18nInterceptor.intercept(I18nInterceptor.java:139)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.setech.mrovelocityhub.core.web.struts.interceptor.UserAgentTrackingInterceptor.intercept(UserAgentTrackingInterceptor.java:59)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.setech.mrovelocityhub.core.web.struts.interceptor.TypeConverterAwareInterceptor.intercept(TypeConverterAwareInterceptor.java:49)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.setech.mrovelocityhub.core.web.struts.interceptor.RequestLoggingInterceptor.intercept(RequestLoggingInterceptor.java:55)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat com.setech.mrovelocityhub.core.web.struts.interceptor.TimerInterceptor.intercept(TimerInterceptor.java:46)\n",
            "\tat com.opensymphony.xwork2.DefaultActionInvocation.invoke(DefaultActionInvocation.java:244)\n",
            "\tat org.apache.struts2.impl.StrutsActionProxy.execute(StrutsActionProxy.java:54)\n",
            "\tat org.apache.struts2.dispatcher.Dispatcher.serviceAction(Dispatcher.java:564)\n",
            "\tat org.apache.struts2.dispatcher.ng.ExecuteOperations.executeAction(ExecuteOperations.java:81)\n",
            "\tat org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter.doFilter(StrutsPrepareAndExecuteFilter.java:99)\n",
            "\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)\n",
            "\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)\n",
            "\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:316)\n",
            "\tat com.setech.mrovelocityhub.core.web.security.filter.PasswordChangeRequiredFilter.doFilterInternal(PasswordChangeRequiredFilter.java:78)\n",
            "\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n",
            "\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:330)\n",
            "\tat org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:126)\n",
            "\tat org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:90)\n",
            "\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:330)\n",
            "\tat org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:114)\n",
            "\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:330)\n",
            "\tat org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:122)\n",
            "\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:330)\n",
            "\tat org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:111)\n",
            "\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:330)\n",
            "\tat org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:169)\n",
            "\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:330)\n",
            "\tat org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:48)\n",
            "\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:330)\n",
            "\tat org.springframework.security.web.authentication.www.BasicAuthenticationFilter.doFilterInternal(BasicAuthenticationFilter.java:158)\n",
            "\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n",
            "\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:330)\n",
            "\tat org.springframework.security.web.session.ConcurrentSessionFilter.doFilter(ConcurrentSessionFilter.java:133)\n",
            "\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:330)\n",
            "\tat org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:205)\n",
            "\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:330)\n",
            "\tat org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:120)\n",
            "\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:330)\n",
            "\tat org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:64)\n",
            "\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n",
            "\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:330)\n",
            "\tat org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:91)\n",
            "\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:330)\n",
            "\tat org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:53)\n",
            "\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n",
            "\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:330)\n",
            "\tat org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:213)\n",
            "\tat org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:176)\n",
            "\tat org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:346)\n",
            "\tat org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:262)\n",
            "\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)\n",
            "\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)\n",
            "\tat org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:121)\n",
            "\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n",
            "\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)\n",
            "\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)\n",
            "\tat org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)\n",
            "\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)\n",
            "\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)\n",
            "\tat org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:212)\n",
            "\tat org.apache.catalina.core.StandardContextValve.__invoke(StandardContextValve.java:106)\n",
            "\tat org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java)\n",
            "\tat org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:502)\n",
            "\tat org.apache.catalina.core.StandardHostValve.__invoke(StandardHostValve.java:141)\n",
            "\tat org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java)\n",
            "\tat org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)\n",
            "\tat org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:616)\n",
            "\tat org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88)\n",
            "\tat org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:518)\n",
            "\tat org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1096)\n",
            "\tat org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:674)\n",
            "\tat org.apache.tomcat.util.net.AprEndpoint$SocketProcessor.doRun(AprEndpoint.java:2500)\n",
            "\tat org.apache.tomcat.util.net.AprEndpoint$SocketProcessor.run(AprEndpoint.java:2489)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n",
            "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n",
            "\tat org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)\n",
            "\tat java.lang.Thread.run(Thread.java:745)\n",
            "{code}\n",
            "\n",
            "If I eliminate the call to {{getResultSize()}} and execute the {{getResultList()}} first, I get the same error., Similarity: 0.0926\n",
            "Summary & Description: numericfieldutils doesnt correctly checks type range boundaries \n",
            " When creating a range query with a date range, {{NumericFieldUtils.createNumericRangeQuery}} and {{NumericFieldUtils.requiresNumericRangeQuery}} methods don't correctly check for the {{Calendar}} or {{Date}} type.\n",
            "\n",
            "As a result, no numeric query is created and the query fails to return correct results.\n",
            "\n",
            "This was fixed in 5.5, I will submit a PR for 5.3 and 5.4 , Similarity: 0.1041\n",
            "Summary & Description: abstract direct usage lucenes document internal data container \n",
            " Currently, an instance of Lucene's {{Document}} class is used to represent index changes and is passed to index managers etc. This requires the Elasticsearch backend to do quite some tricks to asemble a JSON structure representing the document contents, specifically when it comes to nested contents.\n",
            "\n",
            "Hence we should find a more abstract representation of indexed \"documents\", allowing different backends (Embedded Lucene, Elasticsearch) custom implementations. Amongst others, the {{FieldBridge}} contract will need to be changed (or a new, alternative form be added) to work with this more abstract representation., Similarity: 0.3599\n",
            "Summary & Description: phrase query dsl consider ignoreanalyzer options \n",
            " This is an example of what I'm talking about:\n",
            "{code}\n",
            "Query query = queryBuilder\n",
            "                    .phrase()\n",
            "                        .onField( \"message\" )\n",
            "                            .ignoreAnalyzer()\n",
            "...\n",
            "                    .createQuery();\n",
            "\n",
            "{code}\n",
            "I'm not sure if  it make sense to ignore the analyzer when dealing with phrase queries. If it is not the case, we should remove the option from the dsl when dealing with phrase queries. Alternatively, we can log a warning/exception.\n",
            "\n",
            "See [ConnectedMultiFieldsPhraseQueryBuilder.java|https://github.com/hibernate/hibernate-search/blob/e2f3e1e98eb903e08f34339ee4408bef31d18e3a/engine/src/main/java/org/hibernate/search/query/dsl/impl/ConnectedMultiFieldsPhraseQueryBuilder.java#L77], Similarity: 0.1848\n",
            "Summary & Description: introduce build property customize elasticsearch port used testing \n",
            " This is mostly for convenient testing on systems which have the port 9200 occupied, but also seems a good idea to have it test connecting on a different port., Similarity: 0.3200\n",
            "Summary & Description: dont restrictive user customized loading criteria \n",
            " When {{setCriteria(c)}} is invoked on a {{FullTextQuery}}, the user will hit:\n",
            "\n",
            "org.hibernate.search.exception.SearchException: HSEARCH000105: Cannot safely compute getResultSize() when a Criteria with restriction is used. Use query.list().size() or query.getResultList().size().\n",
            "\n",
            "on using getResultSize() even if there are no restrictions being applied.\n",
            "It would be nice to allow this in this case; ideally by auto-detecting that it is safe, or failing that by providing an ad-hoc option., Similarity: 0.1782\n",
            "Summary & Description: remove stringhelper public api \n",
            " {{org.hibernate.search.util.StringHelper}} should not be exposed in the public API but rather be located in some {{impl}} package., Similarity: 0.3084\n",
            "Summary & Description: rename indexmanagercloseindexwriter flushandreleaseresources \n",
            " HSEARCH-2012 adds a new method {{closeIndexWriter()}} on {{IndexManager}}. -This should only be exposed through {{DirectoryBasedIndexManager}} as it doesn't apply to other backends such as Lucene.- This should be renamed to fit with non-Lucene-based backends, too., Similarity: 0.3167\n",
            "Summary & Description: hanging shutdown syncworkprocessor \n",
            " This behavior has been observed intermittently in the Infinispan test suite. Apparently an exception on Lucene prevents the shutdownLatch latch of the SyncWorkProcessor to be released.\n",
            "\n",
            "Error logged:\n",
            "\n",
            "{noformat}\n",
            "[22:04:42][org.infinispan:infinispan-directory-provider] Exception in thread \"Hibernate Search sync consumer thread for index emails\" java.lang.AssertionError: file _a.si does not exist; files=[_6.cfe, _3.si, _7.cfs, _c_Lucene50_0.tip, _a.si, _c_Lucene50_0.tim, _6.cfs, _7.cfe, _7.si, _2.si, _5.cfs, _4.cfe, _3.cfe, _b.si, _c.nvd, _3.cfs, _5.cfe, _4.cfs, _c.nvm, _6.si, _c.fnm, segments_c, _b.cfe, _1.cfe, _1.si, _c.cfs, _2.cfs, _c.si, _c.fdt, _1.cfs, _2.cfe, _c.fdx, _c_Lucene50_0.pos, _5.si, _9.si, _a.cfe, _0.si, _0.cfs, _c_Lucene50_0.doc, _8.cfe, _9.cfs, _a.cfs, _0.cfe, _b.cfs, _9.cfe, _4.si, _8.cfs, _c.cfe, _8.si]\n",
            "[22:04:42][org.infinispan:infinispan-directory-provider] \tat org.apache.lucene.index.IndexWriter.filesExist(IndexWriter.java:4327)\n",
            "[22:04:42][org.infinispan:infinispan-directory-provider] \tat org.apache.lucene.index.IndexWriter.startCommit(IndexWriter.java:4398)\n",
            "[22:04:42][org.infinispan:infinispan-directory-provider] \tat org.apache.lucene.index.IndexWriter.prepareCommitInternal(IndexWriter.java:2860)\n",
            "[22:04:42][org.infinispan:infinispan-directory-provider] \tat org.apache.lucene.index.IndexWriter.commitInternal(IndexWriter.java:2963)\n",
            "[22:04:42][org.infinispan:infinispan-directory-provider] \tat org.apache.lucene.index.IndexWriter.commit(IndexWriter.java:2930)\n",
            "[22:04:42][org.infinispan:infinispan-directory-provider] \tat org.hibernate.search.backend.impl.lucene.IndexWriterHolder.commitIndexWriter(IndexWriterHolder.java:146)\n",
            "[22:04:42][org.infinispan:infinispan-directory-provider] \tat org.hibernate.search.backend.impl.lucene.IndexWriterHolder.commitIndexWriter(IndexWriterHolder.java:159)\n",
            "[22:04:42][org.infinispan:infinispan-directory-provider] \tat org.hibernate.search.backend.impl.lucene.PerChangeSetCommitPolicy.onChangeSetApplied(PerChangeSetCommitPolicy.java:29)\n",
            "[22:04:42][org.infinispan:infinispan-directory-provider] \tat org.hibernate.search.backend.impl.lucene.AbstractWorkspaceImpl.afterTransactionApplied(AbstractWorkspaceImpl.java:97)\n",
            "[22:04:42][org.infinispan:infinispan-directory-provider] \tat org.hibernate.search.backend.impl.lucene.LuceneBackendQueueTask.applyUpdates(LuceneBackendQueueTask.java:105)\n",
            "[22:04:42][org.infinispan:infinispan-directory-provider] \tat org.hibernate.search.backend.impl.lucene.LuceneBackendQueueTask.run(LuceneBackendQueueTask.java:46)\n",
            "[22:04:42][org.infinispan:infinispan-directory-provider] \tat org.hibernate.search.backend.impl.lucene.SyncWorkProcessor$Consumer.applyChangesets(SyncWorkProcessor.java:158)\n",
            "[22:04:42][org.infinispan:infinispan-directory-provider] \tat org.hibernate.search.backend.impl.lucene.SyncWorkProcessor$Consumer.run(SyncWorkProcessor.java:147)\n",
            "[22:04:42][org.infinispan:infinispan-directory-provider] \tat java.lang.Thread.run(Thread.java:745)\n",
            "{noformat}\n",
            "\n",
            "Stack trace:\n",
            "\n",
            "{noformat}\n",
            "\"main\" #1 prio=5 os_prio=0 tid=0x00007f1884008800 nid=0x5889 waiting on condition [0x00007f188a32d000]\n",
            "   java.lang.Thread.State: TIMED_WAITING (parking)\n",
            "\tat sun.misc.Unsafe.park(Native Method)\n",
            "\t- parking to wait for  <0x00000000841d43a8> (a java.util.concurrent.CountDownLatch$Sync)\n",
            "\tat java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)\n",
            "\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1037)\n",
            "\tat java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1328)\n",
            "\tat java.util.concurrent.CountDownLatch.await(CountDownLatch.java:277)\n",
            "\tat org.hibernate.search.backend.impl.lucene.SyncWorkProcessor.shutdown(SyncWorkProcessor.java:117)\n",
            "\tat org.hibernate.search.backend.impl.lucene.LuceneBackendQueueProcessor.close(LuceneBackendQueueProcessor.java:69)\n",
            "\tat org.hibernate.search.indexes.spi.DirectoryBasedIndexManager.destroy(DirectoryBasedIndexManager.java:78)\n",
            "\tat org.hibernate.search.indexes.impl.IndexManagerHolder.stop(IndexManagerHolder.java:197)\n",
            "\t- locked <0x000000008325e288> (a org.hibernate.search.indexes.impl.IndexManagerHolder)\n",
            "\tat org.hibernate.search.engine.impl.ImmutableSearchFactory.close(ImmutableSearchFactory.java:230)\n",
            "\tat org.hibernate.search.engine.impl.MutableSearchFactory.close(MutableSearchFactory.java:137)\n",
            "\tat org.hibernate.search.hcore.impl.HibernateSearchSessionFactoryObserver.sessionFactoryClosed(HibernateSearchSessionFactoryObserver.java:99)\n",
            "\tat org.hibernate.internal.SessionFactoryObserverChain.sessionFactoryClosed(SessionFactoryObserverChain.java:48)\n",
            "\tat org.hibernate.internal.SessionFactoryImpl.close(SessionFactoryImpl.java:1084)\n",
            "\tat org.hibernate.search.test.util.FullTextSessionBuilder.close(FullTextSessionBuilder.java:149)\n",
            "\tat org.infinispan.hibernate.search.LiveRunningTest.liveRun(LiveRunningTest.java:54)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
            "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.lang.reflect.Method.invoke(Method.java:497)\n",
            "\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)\n",
            "\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n",
            "\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)\n",
            "\tat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n",
            "\tat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)\n",
            "\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)\n",
            "\tat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)\n",
            "\tat org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)\n",
            "\tat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)\n",
            "\tat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)\n",
            "\tat org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)\n",
            "\tat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)\n",
            "\tat org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\n",
            "\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)\n",
            "\tat org.junit.runners.ParentRunner.run(ParentRunner.java:309)\n",
            "\tat org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:283)\n",
            "\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:173)\n",
            "\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153)\n",
            "\tat org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:128)\n",
            "\tat org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:203)\n",
            "\tat org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:155)\n",
            "\tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103\n",
            "{noformat}, Similarity: 0.3941\n",
            "Summary & Description: provide way map hash spatial strategy geohashes es \n",
            " Currently the \"hash\" spatial strategy is mapped to HSEARCH specific hash fields in ES. But there is there concept of geohashes in ES, too, which alternatively could be used. This seems to be not as precise as the current custom mapping as per [~accountid:557058:71e31052-f0d7-46e3-a9d7-8b9acd6998d8], but it's more compact. So there should be an option to make use of geohashes alternatively., Similarity: 0.1612\n",
            "Summary & Description: nonnull properties persisted null es value equals indexnullas \n",
            " The following property is persisted as {{null}} in Elasticsearch if it has the value {{false}}:\n",
            "\n",
            "{code}\n",
            "@Field(indexNullAs = \"false\")\n",
            "private Boolean active;\n",
            "{code}\n",
            "\n",
            "The reason being, that we go through the (two-way) field bridge to obtain the boolean value, but doing so we cannot know whether {{false}} actually means {{false}} or {{null}}.\n",
            "\n",
            "The problem exists for any type, because what we do when indexing is comparing the value, and if it matches the null token, we replace it with null. So if an actual value happens to be the same as the null token, it will be replaced with null..., Similarity: 0.0823\n",
            "Summary & Description: convert query values correct type \n",
            " When building a query e.g. for a boolean property:\n",
            "\n",
            "{code}\n",
            "QueryBuilder qb = ...;\n",
            "kb.keyword()\n",
            "    .onField( \"active\" )\n",
            "    .matching( true )\n",
            "    .createQuery();\n",
            "{code}\n",
            "\n",
            "Then we pass the String \"true\"/\"false\" as part of the JSON query instead of the actual boolean.\n",
            "\n",
            "It doesn't make a difference in this specific case as ES will still return the right results by converting the value itself, but it might not be working for some other cases (dates?)., Similarity: 0.1507\n",
            "Summary & Description: rename indexmanagementstrategy \n",
            " quoting from chat:\n",
            "\n",
            "Emmanuel: {quote}IndexManagermentStrategy -> IndexCreationStrategy or IndexSchemaStrategy ? When reading Management I thought about how the index interaction was handled like an IndexManager basically{quote}\n",
            "Martin: {quote}IndexCreationStrategy sounds the most intuitive{quote}\n",
            "\n",
            "I also like {{IndexCreationStrategy}} but wondering if we should separate the effects on schema from the index in that case., Similarity: 0.1776\n",
            "Summary & Description: missing sortablefield performance tests \n",
            " The Book entity is in need of a few @SortableFields annotations., Similarity: 0.2838\n",
            "Summary & Description: validate global custom analyzer name elasticsearch \n",
            " It seems that at the moment this is not possible and we have to wait for the release 2.3.x.\n",
            "\n",
            "Elasticsearch issue: https://github.com/elastic/elasticsearch/issues/15148\n",
            "\n",
            "Note that _analyze might not work with global analyzer if it's not used with an index, as explained [by this response on stack overflow|http://stackoverflow.com/questions/16913073/define-analyzer-globally-es], Similarity: 0.2708\n",
            "Summary & Description: elasticsearch spatial implement hash strategy \n",
            " Currently we use the range strategy regardless of the fieldbridge configuration. We should use a geohash approach when we use the hash cells., Similarity: 0.1836\n",
            "Summary & Description: wait index status green index creation elasticsearch \n",
            " Currently after sending the REST commands to create an index we only check if the request to define the index was accepted, but then we might start attempt using the index before it was actually made available (green) on the Elasticsearch cluster., Similarity: 0.2245\n",
            "Summary & Description: spatialfieldbridge implementations reuse target field name \n",
            " Each instance of SpatialFieldBridge is bound to a specific couple of field names, generated from the original field name invoking {{SpatialHelper.formatFieldName}}, {{SpatialHelper.formatLatitude}} and/or {{SpatialHelper.formatLongitude}}.\n",
            "\n",
            "The parent class should define the field names as final, and the helpers should be invoked only once at constructor time rather than re-allocating the field name for each Document write., Similarity: 0.3033\n",
            "Summary & Description: elasticsearch async request reader refresh operations write \n",
            " We should consider if applying the tricks we implemented as HSEARCH-1693 can be useful to the Elasticsearch backend as well.\n",
            ", Similarity: 0.2464\n",
            "Summary & Description: handle every lucene query subtypes elasticsearchlucenequerytranslator \n",
            " See this Lucene bug I opened with a patch: https://issues.apache.org/jira/browse/LUCENE-7058\n",
            "\n",
            "UPDATE: the Lucene bug has been fixed in version 6, so we'll have to switch to Lucene 6 first.\n",
            "\n",
            "Note: there are tests that should pass when this ticket is resolved, and that are currently disabled in the pom.xml of the Elasticsearch module. Those tests will be (or have been) outlined as part of HSEARCH-2390., Similarity: 0.3761\n",
            "Summary & Description: enable scripting support elasticsearch \n",
            " This is useful at least for the spatial support: we need it to get the geo_distance in the results., Similarity: 0.2394\n",
            "Summary & Description: elasticsearch support multiphrasequery \n",
            " Currently the phrase query support of Hibernate Search might generate a MultiPhraseQuery if your analyzer returns several words for a given position (typically with synonyms).\n",
            "\n",
            "This is not supported by the Elasticsearch backend and should probably not be supported as we need to remove the analyzer part in this case and let Elasticsearch do the analyze thing.\n",
            "\n",
            "Just wanted to log this issue somewhere so we can be sure it gets tackled before the release., Similarity: 0.2102\n",
            "Summary & Description: split dsltest facilitate elasticsearch testing \n",
            " - Separate non working tests\n",
            "- Separate Spatial tests in their own test, Similarity: 0.1397\n",
            "Summary & Description: edgecasefacettest unreliable elasticsearch \n",
            " As initially reported on HSEARCH-2119, the test {{org.hibernate.search.test.query.facet.EdgeCaseFacetTest}} is not consistently successful when run on Elasticsearch., Similarity: 0.2568\n",
            "Summary & Description: manualindexingstrategytest unreliable run elasticsearch \n",
            " The Hibernate Search ElasticSearch test suite fails on two tests on my Windows machine(s):\n",
            "\n",
            "ManualIndexingStrategyTest.testMultipleEntitiesPerIndex (trace: http://pastebin.com/sUZDmnAQ)\n",
            "EdgeCaseFacetTest.testFacetingOnEmptyIndex (trace: http://pastebin.com/tMtMUv5i)\n",
            "\n",
            "However if I run these manually, they work. Seems like some test running before these two causes them to break.\n",
            "\n",
            "This issue tracks state for {{ManualIndexingStrategyTest}}; see HSEARCH-2120 for {{EdgeCaseFacetTest}}.\n",
            ", Similarity: 0.2631\n",
            "Summary & Description: make configurable whether prettyprint json \n",
            " Currently the JSON we send to ES is not pretty-printed, which is a good default behavior. But it should optionally possible to do so, as it makes examining the source documents stored in ES easier, e.g. for debugging purposes., Similarity: 0.2754\n",
            "Summary & Description: allow extensions contribute short names new indexmanager implementations \n",
            " The only \"third party\" {{IndexManager}} we had so far is the {{InfinispanIndexManager}} - living in the Infinispan Query project - , which overrides the {{DefaultIndexManagerFactory}} as it actually also *overrides* the resolution of names.\n",
            "\n",
            "This approach doesn't scale to other jars wanting to contribute additional short names, for example the Elasticsearch integration module can not define an additional {{IndexManagerFactory}} as that wouldn't \"compose\" with the Infinispan approach.\n",
            "\n",
            "Rather than overriding a core service this needs an ad-hoc approach., Similarity: 0.2885\n",
            "Summary & Description: elasticsearchindexworkvisitor release services consumes \n",
            " The {{ElasticsearchIndexWorkVisitor}} requests services at runtime but is never closing them.\n",
            "\n",
            "Also, it shouldn't request a new service instance repeatedly as that's not how the ServiceRegistry is meant to be used., Similarity: 0.3264\n",
            "Summary & Description: add support composite id types es backend \n",
            " I am not sure what currently happens for composite id types. Maybe we should map them to actual document fields for the sake of searchability? That needs some more research., Similarity: 0.2315\n",
            "Summary & Description: advanced mechanism propagating index updates using oracle db \n",
            " Oracle provides several interesting mechanisms which we could leverage to detect data changes done by other applications which require an index update.\n",
            "\n",
            "* [Data change notifications|https://docs.oracle.com/cd/E11882_01/java.112/e16548/dbchgnf.htm#JJDBC28820] allow to trigger registed Java callbacks (\"registrations\") upon data changes\n",
            "* [Oracle Advanced Queuing|https://docs.oracle.com/cd/B28359_01/java.111/b31224/streamsaq.htm] provides a persistent JMS queue implementation backed by the database itself; This allows to enqueue messages e.g. via triggers in a transactionally safe fashion, which the HSEARCH application could be consume and trigger index updates from\n",
            "\n",
            "The second alternative is especially promising, as it will keep index invalidation messages in a persistent queue in case the Java application is offline.\n",
            "\n",
            "I don't think this is something we can do ourselves given our constrained resources, but it may be an interesting feature to be tackled by a contributor or maybe GSoC student. Any feedback welcome., Similarity: 0.3042\n",
            "Summary & Description: discuss unique projectionconstants api \n",
            " We're currently exposing both a {{org.hibernate.search.backend.elasticsearch.ProjectionConstants}} and a {{org.hibernate.search.engine.ProjectionConstants}}.\n",
            "\n",
            "It's not nice to have two classes in the public API which have the same name, as the package difference isn't very clear when reading code.\n",
            "\n",
            "Should we simply expose the Elasticsearch specific projection constants in the parent class?\n",
            "\n",
            "Should we make these options somehow better errorprone, maybe via typesafety, to prevent using a constant which isn't accepted?\n",
            "\n",
            "At the very least we should verify that the non-Elasticsearch backend recognises the constants currently defined on {{org.hibernate.search.backend.elasticsearch.ProjectionConstants}} and warns about a possible mistake. I believe it would currently attempt to load a stored field having the name of the constant value., Similarity: 0.3496\n",
            "Summary & Description: optimise function lazyquerystatevalidatequery \n",
            " The code in {{org.hibernate.search.query.engine.impl.LazyQueryState.validateQuery()}} has an impact on performance and we should be able to rethink it in some smart way.\n",
            "\n",
            "For example, I suspect we're currently collecting all fieldnames for each cathegory to simplify the code and make it easy to throw a user-friendly exception, but I wonder if we could attempt an \"optimistic validation\" which doesn't collect anything unless something is actually wrong, in that case we can fall back to the slower strategy to still show a user friendly error., Similarity: 0.2059\n",
            "Summary & Description: clarify documentation indexedembeddedprefix \n",
            " The description of the default behavior is contradictory:\n",
            "\n",
            "* \"defaults to {@code propertyname.}\"\n",
            "* \"Default to \".\"\", Similarity: 0.2870\n",
            "Summary & Description: elasticsearch backend honor indexedembeddedprefix \n",
            " Currently, in the Elasticsearch backend, we consider that a field is nested if it contains a \"{{.}}\". The fact is that you can configure the prefix used by IndexedEmbedded in the annotation with {{prefix}}., Similarity: 0.2191\n",
            "Summary & Description: configurationpropertiesprovider leaks configuration properties \n",
            " During development of the Elasticsearch integration, a class {{ConfigurationPropertiesProvider}} was added as temporary helper to access all configuration properties in the scope of an IndexManager.\n",
            "\n",
            "We should avoid this and not keep references to the initial configuration Properties as they might contain rather large objects, including leaks when run in application servers.\n",
            "\n",
            "I suspect we have other places which should be checked against this too., Similarity: 0.4083\n",
            "Summary & Description: clarify meaning constant names indexschemamanagementstrategy \n",
            " The new enum {{IndexManagementStrategy}} presents various options regarding to drop,create,.. existing indexes on an Elasticsearch cluster.\n",
            "\n",
            "We need to discuss these names; for example I'm not sure that it's clear enough that using \"CREATE\" will wipe out existing data.\n",
            "\n",
            "Regarding \"MERGE\": it looks like a nice idea but we don't implement that yet, so I wonder if we should rather not have this option yet., Similarity: 0.1711\n",
            "Summary & Description: elasticsearchindexworkvisitor allocated operation \n",
            " The intention of the {{WorkVisitor}} system is to minimize object allocation, and benefit from other reuse capabilities; for example we could make sure to lookup the {{JestClient}} only once., Similarity: 0.2461\n",
            "Summary & Description: take advantage orms capability multiloading list ids \n",
            " Consider taking advantage of the new \n",
            "{code}List<User> users = session.byMultipleIds(User.class)\n",
            "    .multiLoad( 1, 2, 3 );{code}\n",
            "\n",
            "See also https://hibernate.atlassian.net/browse/HHH-7572\n",
            "\n",
            "Other than maintainability, do we have any other benefit on changing the current proven strategies?\n",
            "\n",
            "The drawback is that this would require Hibernate ORM 5.1.0\n",
            ", Similarity: 0.2387\n",
            "Summary & Description: lucene filter deprecated use query occurfilter instead \n",
            " Lucene Filter has been deprecated in favor of Query with Occur.FILTER.\n",
            "\n",
            "We should clean up our API by removing any reference to Filter., Similarity: 0.2760\n",
            "Summary & Description: reverse containedin onetomany working \n",
            " If you annotate a OneToMany relation with @ContainedIn, a change to the containing entity doesn't lead to a reindexing of the referencing entities.\n",
            "\n",
            "{code}\n",
            "\tpublic class Forum{\n",
            "\n",
            "\t\t@Field\n",
            "\t\tboolean hidden;\n",
            "\n",
            "\t\t@OneToMany\n",
            "\t\t@ContainedIn\n",
            "\t\tList<Post> posts;\n",
            "\t}\n",
            "\n",
            "\tpublic class Post{\n",
            "\n",
            "\t\t@ManyToOne\n",
            "\t\t@IndexedEmbedded(includePaths={\"hidden\"})\n",
            "\t\tForum forum;\n",
            "\t}\n",
            "{code}\n",
            "\n",
            "This issue has been around forever. I thought I reported it before but I couldn't find a reference, so I'm reporting it here., Similarity: 0.2599\n",
            "Summary & Description: provide api keep frozen view index open user defined scope \n",
            " An idea after discussing reliable pagination strategies and the need for repeatable-read in some scenarios. Not reopening the index might be useful in other cases too, for example to provide repeatable-read within a Session when no changes have been flushed to the index, not least it will improve performance as it will avoid some IO hits to verify if the IndexReader is still up to date (or in worst case when it's not up to date that would even force a refresh).\n",
            "\n",
            "So overall this could improve usability by better matching repeatable-read semantics within a Session, and improve performance by reducing the index reopening ratio., Similarity: 0.2397\n",
            "Summary & Description: fsmasterdirectoryprovider copies indexes master mastercopy mass index \n",
            " When a mass index is started, the FSMasterDirectoryProvider will continue to copy the configured master directory structures to the master-copy directory structures.  The FSMasterDirectoryProvider should not attempt to copy any index being currently reindexed., Similarity: 0.2261\n",
            "Summary & Description: shardidentifierprovider allow customization shards deletion \n",
            " {{IndexShardingStrategy}} is marked as deprecated and {{ShardIdentifierProvider}} is the replacement, but the latter does not allow choice to pick the shards used for deletion as the former does, Similarity: 0.1645\n",
            "Summary & Description: unable fully load entity idclass lazily max fetch depth \n",
            " I’m trying to fetch entities from the database that have hierarchical composite identifiers and the relationship between entities is lazy loaded. Additionally I’m repeating the same fetch with lazily loaded entities and the max fetch depth configured. In both of my tests, I’m seeing issues with Hibernate fetching the data from the database.\n",
            "\n",
            "I’ve attached a patch file containing the unit tests and one small fix that I identified. The are a couple of errors remaining but I’m not familiar enough with Hibernate to resolve them., Similarity: 0.2961\n",
            "Summary & Description: cannot parse quoted table name \n",
            " Entities using the annotations {{@GeneratedValue}}, {{@GenericGenerator }}and {{@SecondaryTable }}that have a table name not following the standard format of {{\"schema.catalog.tableName\"}} cannot be parsed regardless of physical-strategy property.  Example table name:{{com.proj.db::base.folder}}. Adding quotes does not fix the issue.\n",
            "\n",
            "This issues has appeared in versions later that {{6.1.3}} (last version without the issue).\n",
            "\n",
            "Example Entity: \n",
            "\n",
            "{noformat}@Entity\n",
            "@Table(name = Folder.TABLE_NAME)\n",
            "@SecondaryTable(name = RelationView.TABLE_NAME, pkJoinColumns = @PrimaryKeyJoinColumn(name = \"NODE\"))\n",
            "@JsonIgnoreProperties(ignoreUnknown = true)\n",
            "public class Folder {\n",
            "\n",
            "    public static final String TABLE_NAME_NO_QUOTES = \"com.proj.db::base.folder\";\n",
            "\n",
            "    public static final String TABLE_NAME = \"`\" + TABLE_NAME_NO_QUOTES + \"`\";\n",
            "\n",
            "    @Id\n",
            "    @Column(name = \"ID\", nullable = false)\n",
            "    @GeneratedValue(strategy = GenerationType.SEQUENCE, generator = \"ENTITY_SEQUENCE\")\n",
            "    @GenericGenerator(name = \"ENTITY_SEQUENCE\",\n",
            "            strategy = ...SequenceStyleGenerator\")\n",
            "    private Integer folderId;\n",
            "...other fields{noformat}\n",
            "\n",
            "Stack Trace: \n",
            "\n",
            "{noformat}Caused by: java.lang.IllegalStateException: PostInitCallback queue could not be processed...\n",
            "        - PostInitCallbackEntry - Entity(com.backend.model.Folder) `sqmMultiTableMutationStrategy` interpretation\n",
            "        - PostInitCallbackEntry - Entity(com.backend.model.Folder) `sqmMultiTableInsertStrategy` interpretation\n",
            "\n",
            "\tat org.hibernate.metamodel.mapping.internal.MappingModelCreationProcess.executePostInitCallbacks(MappingModelCreationProcess.java:144)\n",
            "\tat org.hibernate.metamodel.mapping.internal.MappingModelCreationProcess.execute(MappingModelCreationProcess.java:88)\n",
            "\tat org.hibernate.metamodel.mapping.internal.MappingModelCreationProcess.process(MappingModelCreationProcess.java:40)\n",
            "\tat org.hibernate.metamodel.model.domain.internal.MappingMetamodelImpl.finishInitialization(MappingMetamodelImpl.java:201)\n",
            "\tat org.hibernate.internal.SessionFactoryImpl.initializeMappingModel(SessionFactoryImpl.java:319)\n",
            "\tat org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:269)\n",
            "\tat org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:431)\n",
            "\tat org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:1455)\n",
            "\tat org.hibernate.jpa.HibernatePersistenceProvider.createContainerEntityManagerFactory(HibernatePersistenceProvider.java:142)\n",
            "\tat org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:376)\n",
            "\tat org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:409)\n",
            "\t... 54 more\n",
            "\tSuppressed: org.hibernate.HibernateException: Unable to parse object name: \"com.proj.db::base.folder\"\n",
            "\t\tat org.hibernate.boot.model.relational.QualifiedNameParser.parse(QualifiedNameParser.java:149)\n",
            "\t\tat org.hibernate.boot.model.relational.QualifiedNameParser.parse(QualifiedNameParser.java:199)\n",
            "\t\tat org.hibernate.dialect.temptable.TemporaryTable.<init>(TemporaryTable.java:83)\n",
            "\t\tat org.hibernate.dialect.temptable.TemporaryTable.createEntityTable(TemporaryTable.java:302)\n",
            "\t\tat org.hibernate.dialect.H2Dialect.getFallbackSqmInsertStrategy(H2Dialect.java:693)\n",
            "\t\tat org.hibernate.query.sqm.mutation.internal.SqmMultiTableMutationStrategyProviderStandard.createInsertStrategy(SqmMultiTableMutationStrategyProviderStandard.java:53)\n",
            "\t\tat org.hibernate.persister.entity.AbstractEntityPersister.interpretSqmMultiTableInsertStrategy(AbstractEntityPersister.java:4807)\n",
            "\t\tat org.hibernate.persister.entity.AbstractEntityPersister.lambda$prepareMappingModel$17(AbstractEntityPersister.java:4659)\n",
            "\t\tat org.hibernate.metamodel.mapping.internal.MappingModelCreationProcess$PostInitCallbackEntry.process(MappingModelCreationProcess.java:246)\n",
            "\t\tat org.hibernate.metamodel.mapping.internal.MappingModelCreationProcess.executePostInitCallbacks(MappingModelCreationProcess.java:106)\n",
            "\t\t... 64 more{noformat}\n",
            "\n",
            "Additional Notes:\n",
            "\n",
            "From what I can tell looking in the hibernate code the issue comes from {{org.hibernate.dialect.temptable.TemporaryTable  }}constructor, which from version {{6.1.4}} has changed the way it parses the table name to use {{QualifiedNameParser }}which restricts the acceptable table names to the previously mentioned format: {{\"schema.catalog.tableName\"}}. Also this seems to ignore the physical naming strategy property.\n",
            "\n",
            "This is a breaking change for our projects and probably many others.\n",
            "\n",
            "Links: \n",
            "\n",
            "Reported at: [https://discourse.hibernate.org/t/hibernate-6-issues-with-table-name/7763|https://discourse.hibernate.org/t/hibernate-6-issues-with-table-name/7763|smart-link] \n",
            "\n",
            "PR to reproduce the issue: [https://github.com/hibernate/hibernate-test-case-templates/pull/276|https://github.com/hibernate/hibernate-test-case-templates/pull/276|smart-link] , Similarity: 0.2861\n",
            "Summary & Description: schemamigrator generates ora22859 errors columns annotated lob \n",
            " Hello,\n",
            "\n",
            "Using Hibernate in Update mode generates “alter table” on columns of type blob/clob which seems to be forbidden in Oracle. Each time the alter table command is sent on these columns, Oracle responds with an error of type ORA-22859.\n",
            "\n",
            "From the test case I made, the corresponding exception looks like this : \n",
            "\n",
            "{quote}org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL \"\n",
            "    alter table LobModel\n",
            "       modify blob blob\" via JDBC [ORA-22859: modification non valide des colonnes\n",
            "\n",
            "{quote}\n",
            "\n",
            "My test case is available at : [https://github.com/brivalin/hibernate-test-case-templates|https://github.com/brivalin/hibernate-test-case-templates|smart-link] \n",
            "\n",
            "To reproduce the problem you have to : \n",
            "\n",
            "# Modify the persistence.xml to point to your own Oracle database\n",
            "# Run it once to generate the schema\n",
            "# Run it a second time to throw the ORA-22859 error\n",
            "\n",
            "\n",
            "\n",
            "The original Discussion is available here : [https://discourse.hibernate.org/t/schemamigrator-wants-to-alter-my-columns/7697/13|https://discourse.hibernate.org/t/schemamigrator-wants-to-alter-my-columns/7697/13|smart-link] , Similarity: 0.2045\n",
            "Summary & Description: multitenant filter work \n",
            " I used column-based partitioning for multi-tenancy, but it didn't work. I tried lowering the version to 6.1.x final versions and it worked.\n",
            "\n",
            "\n",
            "\n",
            "{code:java}    // This will fail in 6.2.4final\n",
            "    @Test\n",
            "    void contextLoads() {\n",
            "        currentTenantIdentifierResolver.setCurrentTenant(\"1\");\n",
            "        Person person = new Person();\n",
            "        person.setId(1L);\n",
            "        personRepository.save(person);\n",
            "\n",
            "        currentTenantIdentifierResolver.setCurrentTenant(\"2\");\n",
            "        Assertions.assertTrue(personRepository.findById(1L).isEmpty());\n",
            "    }{code}\n",
            "\n",
            "That's the problem now. I haven't had time to find out why, Similarity: 0.2345\n",
            "Summary & Description: merge fails entity embedded java record \n",
            " [https://discourse.hibernate.org/t/hibernate-6-and-java-records-unable-so-persist/7761|https://discourse.hibernate.org/t/hibernate-6-and-java-records-unable-so-persist/7761]\n",
            "\n",
            "Test case:\n",
            "\n",
            "{noformat}package org.hibernate.bugs;\n",
            "\n",
            "import jakarta.persistence.*;\n",
            "\n",
            "import org.junit.After;\n",
            "import org.junit.Before;\n",
            "import org.junit.Test;\n",
            "\n",
            "/**\n",
            "\n",
            "This template demonstrates how to develop a test case for Hibernate ORM, using the Java Persistence API.\n",
            " */\n",
            "public class JPAUnitTestCase {\n",
            "\n",
            "private EntityManagerFactory entityManagerFactory;\n",
            "\n",
            "@Before\n",
            "public void init() {\n",
            "entityManagerFactory = Persistence.createEntityManagerFactory( \"templatePU\" );\n",
            "}\n",
            "\n",
            "@After\n",
            "public void destroy() {\n",
            "entityManagerFactory.close();\n",
            "}\n",
            "\n",
            "// Entities are auto-discovered, so just add them anywhere on class-path\n",
            "// Add your tests, using standard JUnit.\n",
            "\n",
            "@Test\n",
            "public void test()  {\n",
            "EntityManager entityManager = entityManagerFactory.createEntityManager();\n",
            "entityManager.getTransaction().begin();\n",
            "\n",
            "entityManager.persist( new MyEntity( 1L, new MyRecord( \"test\", \"abc\" ) ) );\n",
            "\n",
            "entityManager.getTransaction().commit();\n",
            "entityManager.close();\n",
            "\n",
            "entityManager = entityManagerFactory.createEntityManager();\n",
            "entityManager.getTransaction().begin();\n",
            "\n",
            "entityManager.merge( new MyEntity( 1L, new MyRecord( \"test\", \"d\" ) ) );\n",
            "\n",
            "entityManager.getTransaction().commit();\n",
            "entityManager.close();\n",
            "}\n",
            "\n",
            "@Entity(name = \"MyEntity\")\n",
            "public static class MyEntity {\n",
            "@Id\n",
            "Long id;\n",
            "@Embedded\n",
            "MyRecord record;\n",
            "\n",
            "public MyEntity() {\n",
            "}\n",
            "\n",
            "public MyEntity(Long id, MyRecord record) {\n",
            "this.id = id;\n",
            "this.record = record;\n",
            "}\n",
            "\n",
            "public Long getId() {\n",
            "return id;\n",
            "}\n",
            "\n",
            "public MyRecord getRecord() {\n",
            "return record;\n",
            "}\n",
            "\n",
            "public void setId(Long id) {\n",
            "this.id = id;\n",
            "}\n",
            "\n",
            "public void setRecord(MyRecord record) {\n",
            "this.record = record;\n",
            "}\n",
            "}\n",
            "\n",
            "@Embeddable\n",
            "public static record MyRecord(String name, String description) {}\n",
            "}{noformat}\n",
            "\n",
            "Exception:\n",
            "\n",
            "\n",
            "{noformat}2023-06-06 17:13:47 INFO  LogHelper:31 - HHH000204: Processing PersistenceUnitInfo [name: templatePU]\n",
            "2023-06-06 17:13:47 INFO  Version:44 - HHH000412: Hibernate ORM core version 6.2.4.Final\n",
            "2023-06-06 17:13:47 INFO  Environment:159 - HHH000205: Loaded properties from resource hibernate.properties: {hibernate.format_sql=true, jakarta.persistence.validation.mode=NONE, hibernate.dialect=org.hibernate.dialect.H2Dialect, hibernate.connection.username=sa, hibernate.connection.url=jdbc:h2:mem:db1;DB_CLOSE_DELAY=-1, hibernate.max_fetch_depth=5, hibernate.show_sql=false, hibernate.jdbc.batch_versioned_data=true, hibernate.connection.driver_class=org.h2.Driver, hibernate.connection.password=****, hibernate.bytecode.use_reflection_optimizer=true, hibernate.cache.region_prefix=hibernate.test, hibernate.connection.pool_size=5, hibernate.cache.region.factory_class=org.hibernate.testing.cache.CachingRegionFactory, hibernate.service.allow_crawling=false, hibernate.session.events.log=true}\n",
            "2023-06-06 17:13:47 INFO  Environment:191 - HHH000406: Using bytecode reflection optimizer\n",
            "2023-06-06 17:13:47 WARN  CachingRegionFactory:48 - org.hibernate.testing.cache.CachingRegionFactory should be only used for testing.\n",
            "2023-06-06 17:13:47 WARN  pooling:80 - HHH10001002: Using built-in connection pool (not intended for production use)\n",
            "2023-06-06 17:13:47 INFO  pooling:139 - HHH10001005: Loaded JDBC driver class: org.h2.Driver\n",
            "2023-06-06 17:13:47 INFO  pooling:161 - HHH10001012: Connecting with JDBC URL [jdbc:h2:mem:db1;DB_CLOSE_DELAY=-1]\n",
            "2023-06-06 17:13:47 INFO  pooling:170 - HHH10001001: Connection properties: {password=****, user=sa}\n",
            "2023-06-06 17:13:47 INFO  pooling:174 - HHH10001003: Autocommit mode: false\n",
            "2023-06-06 17:13:47 INFO  pooling:366 - HHH10001115: Connection pool size: 5 (min=1)\n",
            "2023-06-06 17:13:48 INFO  BytecodeProviderInitiator:53 - HHH000021: Bytecode provider name : bytebuddy\n",
            "2023-06-06 17:13:48 INFO  JtaPlatformInitiator:51 - HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.WildFlyStandAloneJtaPlatform]\n",
            "Hibernate: \n",
            "drop table if exists MyEntity cascade \n",
            "2023-06-06 17:13:48 INFO  access:52 - HHH10001501: Connection obtained from JdbcConnectionAccess [org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator$ConnectionProviderJdbcConnectionAccess@4b9c411] for (non-JTA) DDL execution was not in auto-commit mode; the Connection 'local transaction' will be committed and the Connection will be set into auto-commit mode.\n",
            "Hibernate: \n",
            "create table MyEntity (\n",
            "id bigint not null,\n",
            "description varchar(255),\n",
            "name varchar(255),\n",
            "primary key (id)\n",
            ")\n",
            "2023-06-06 17:13:48 INFO  access:52 - HHH10001501: Connection obtained from JdbcConnectionAccess [org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator$ConnectionProviderJdbcConnectionAccess@3e4d40ea] for (non-JTA) DDL execution was not in auto-commit mode; the Connection 'local transaction' will be committed and the Connection will be set into auto-commit mode.\n",
            "Hibernate: \n",
            "insert \n",
            "into\n",
            "MyEntity\n",
            "(name,description,id) \n",
            "values\n",
            "(?,?,?)\n",
            "2023-06-06 17:13:48 INFO  StatisticalLoggingSessionEventListener:261 - Session Metrics {\n",
            "30649 nanoseconds spent acquiring 1 JDBC connections;\n",
            "73209 nanoseconds spent releasing 1 JDBC connections;\n",
            "1667250 nanoseconds spent preparing 1 JDBC statements;\n",
            "642541 nanoseconds spent executing 1 JDBC statements;\n",
            "0 nanoseconds spent executing 0 JDBC batches;\n",
            "0 nanoseconds spent performing 0 L2C puts;\n",
            "0 nanoseconds spent performing 0 L2C hits;\n",
            "0 nanoseconds spent performing 0 L2C misses;\n",
            "25512091 nanoseconds spent executing 1 flushes (flushing a total of 1 entities and 0 collections);\n",
            "0 nanoseconds spent executing 0 partial-flushes (flushing a total of 0 entities and 0 collections)\n",
            "}\n",
            "Hibernate: \n",
            "select\n",
            "m1_0.id,\n",
            "m1_0.name,\n",
            "m1_0.description \n",
            "from\n",
            "MyEntity m1_0 \n",
            "where\n",
            "m1_0.id=?\n",
            "Hibernate: \n",
            "drop table if exists MyEntity cascade \n",
            "2023-06-06 17:13:48 INFO  access:52 - HHH10001501: Connection obtained from JdbcConnectionAccess [org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator$ConnectionProviderJdbcConnectionAccess@388be5fd] for (non-JTA) DDL execution was not in auto-commit mode; the Connection 'local transaction' will be committed and the Connection will be set into auto-commit mode.\n",
            "2023-06-06 17:13:48 INFO  pooling:608 - HHH10001008: Cleaning up connection pool [jdbc:h2:mem:db1;DB_CLOSE_DELAY=-1]\n",
            "2023-06-06 17:13:48 ERROR pooling:470 - Connection leak detected: there are 1 unclosed connections upon shutting down pool jdbc:h2:mem:db1;DB_CLOSE_DELAY=-1\n",
            "2023-06-06 17:13:48 ERROR pooling:301 - Connection leak detected: there are 1 unclosed connections\n",
            "\n",
            "org.hibernate.PropertyAccessException: Could not set value of type [java.lang.String] : `org.hibernate.bugs.JPAUnitTestCase$MyRecord.name` (setter)\n",
            "\n",
            "at org.hibernate.property.access.spi.SetterFieldImpl.set(SetterFieldImpl.java:86)\n",
            "at org.hibernate.metamodel.mapping.internal.AbstractEmbeddableMapping.setValues(AbstractEmbeddableMapping.java:112)\n",
            "at org.hibernate.type.ComponentType.setPropertyValues(ComponentType.java:450)\n",
            "at org.hibernate.type.ComponentType.replace(ComponentType.java:564)\n",
            "at org.hibernate.type.TypeHelper.replace(TypeHelper.java:89)\n",
            "at org.hibernate.event.internal.DefaultMergeEventListener.copyValues(DefaultMergeEventListener.java:502)\n",
            "at org.hibernate.event.internal.DefaultMergeEventListener.entityIsDetached(DefaultMergeEventListener.java:354)\n",
            "at org.hibernate.event.internal.DefaultMergeEventListener.merge(DefaultMergeEventListener.java:149)\n",
            "at org.hibernate.event.internal.DefaultMergeEventListener.doMerge(DefaultMergeEventListener.java:142)\n",
            "at org.hibernate.event.internal.DefaultMergeEventListener.onMerge(DefaultMergeEventListener.java:126)\n",
            "at org.hibernate.event.internal.DefaultMergeEventListener.onMerge(DefaultMergeEventListener.java:80)\n",
            "at org.hibernate.event.service.internal.EventListenerGroupImpl.fireEventOnEachListener(EventListenerGroupImpl.java:127)\n",
            "at org.hibernate.internal.SessionImpl.fireMerge(SessionImpl.java:848)\n",
            "at org.hibernate.internal.SessionImpl.merge(SessionImpl.java:834)\n",
            "at org.hibernate.bugs.JPAUnitTestCase.test(JPAUnitTestCase.java:43)\n",
            "at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
            "at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "at java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
            "at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)\n",
            "at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n",
            "at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)\n",
            "at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n",
            "at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\n",
            "at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)\n",
            "at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\n",
            "at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)\n",
            "at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)\n",
            "at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)\n",
            "at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)\n",
            "at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)\n",
            "at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)\n",
            "at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)\n",
            "at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)\n",
            "at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)\n",
            "at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\n",
            "at org.junit.runners.ParentRunner.run(ParentRunner.java:413)\n",
            "at org.junit.runner.JUnitCore.run(JUnitCore.java:137)\n",
            "at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)\n",
            "at com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)\n",
            "at com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)\n",
            "at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)\n",
            "at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)\n",
            "at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)\n",
            "Caused by: java.lang.IllegalAccessException: Can not set final java.lang.String field org.hibernate.bugs.JPAUnitTestCase$MyRecord.name to java.lang.String\n",
            "at java.base/jdk.internal.reflect.UnsafeFieldAccessorImpl.throwFinalFieldIllegalAccessException(UnsafeFieldAccessorImpl.java:76)\n",
            "at java.base/jdk.internal.reflect.UnsafeFieldAccessorImpl.throwFinalFieldIllegalAccessException(UnsafeFieldAccessorImpl.java:80)\n",
            "at java.base/jdk.internal.reflect.UnsafeQualifiedObjectFieldAccessorImpl.set(UnsafeQualifiedObjectFieldAccessorImpl.java:79)\n",
            "at java.base/java.lang.reflect.Field.set(Field.java:799)\n",
            "at org.hibernate.property.access.spi.SetterFieldImpl.set(SetterFieldImpl.java:55)\n",
            "... 43 more\n",
            "\n",
            "{noformat}, Similarity: 0.4179\n",
            "Summary & Description: hibernate throws error using elementcollection \n",
            " When using @ElementCollection with Set = SetOf() I get org.hibernate.NotYetImplementedFor6Exception: Only support for basic-valued, entity-valued and embedded model-parts have been implemented : userNames [PluralAttribute]\n",
            "\n",
            "This worked before upgrading to hibernate 6\n",
            "\n",
            "\n",
            "\n",
            "@SqlResultSetMappings(\n",
            "    SqlResultSetMapping(\n",
            "        name = \"Mapping.User\",\n",
            "        entities = [\n",
            "            EntityResult(\n",
            "                entityClass = User::class,\n",
            "                fields = [\n",
            "                    FieldResult(name = \"id\", column = \"id\"),\n",
            "                    FieldResult(name = \"userNames\", column = \"user_names\"),\n",
            "                ]\n",
            "            )\n",
            "        ],\n",
            "\n",
            " ),\n",
            "    SqlResultSetMapping(\n",
            "        name = \"Mapping.User.count\",\n",
            "        columns = [ColumnResult(name = \"rowCount\")]\n",
            "    )\n",
            ")\n",
            "\n",
            "@Entity\n",
            "@Table(name = \"users\")\n",
            "data class User(\n",
            "    @Id\n",
            "    @GeneratedValue(generator = \"UUID\")\n",
            "    @GenericGenerator(\n",
            "        name = \"UUID\",\n",
            "        strategy = \"org.hibernate.id.UUIDGenerator\"\n",
            "    )\n",
            "    @Column(name = \"id\")\n",
            "    var id: UUID = UUID.randomUUID(),@ElementCollection(fetch = FetchType.EAGER)\n",
            "    @CollectionTable(\n",
            "        name = \"users_names\",\n",
            "        joinColumns = [JoinColumn(name = \"user_id\", referencedColumnName = \"id\")]\n",
            "    )\n",
            "    @Column(name = \"user_names\")\n",
            "    var userNames: Set<String> = setOf(),\n",
            "\n",
            "), Similarity: 0.2692\n",
            "Summary & Description: parameters pageable correctly propagated final query migration hibernate 53x 600 \n",
            " Hello!\n",
            "\n",
            "After the migration from Spring Boot *2.7.10* to Spring Boot *3.0.5* and from Hibernate *5.6.0.Final* to Hibernate *6.2.2 Final*\n",
            "\n",
            "The query form Spring-data-jpa for PostgreSQL is generated differently (please see link to repo with branches + examples)\n",
            "\n",
            "I am using JDK 17 Correto (*17.07)*, and db is PostgreSQL *9.6.6*\n",
            "\n",
            "Before migration generated SQL query looks like this:\n",
            "{{select exportenti0_.uuid as uuid1_0_, exportenti0_.domain_uuid as domain_u2_0_, exportenti0_.created_by as created_3_0_, exportenti0_.created_date as created_4_0_, exportenti0_.updated_by as updated_5_0_, exportenti0_.updated_date as updated_6_0_, exportenti0_.version as version7_0_, exportenti0_.currency_ex_uuid as currency8_0_, exportenti0_.cutoff_time as cutoff_t9_0_, exportenti0_.data_domain_uid as data_do10_0_, exportenti0_.is_force as is_forc11_0_, exportenti0_.status as status12_0_, exportenti0_.is_use_latest_date as is_use_13_0_ from export exportenti0_ where exportenti0_.domain_uuid=? order by exportenti0_.updated_date desc limit ?}}\n",
            "\n",
            "-- executes correctly.\n",
            "\n",
            "After the migration the same query looks like follows:\n",
            "{{ select e1_0.uuid, e1_0.created_by, e1_0.created_date, e1_0.currency_ex_uuid, e1_0.cutoff_time, e1_0.data_domain_uid, e1_0.domain_uuid, e1_0.is_force, e1_0.status, e1_0.updated_by, e1_0.updated_date, e1_0.is_use_latest_date, e1_0.version from export e1_0 where e1_0.domain_uuid=? order by e1_0.updated_date desc offset ? rows fetch first ? rows only}}\n",
            "\n",
            "Problem is with line *desc offset ..... rows only* which is added after query translation from java model to SQL at the end.\n",
            "As you may expected it crashes.\n",
            "{{org.postgresql.util.PSQLException: ERROR: syntax error at or near \"$3\" Position: 328 at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2713) ~[postgresql-42.6.0.jar:42.6.0]}}\n",
            "\n",
            "I am using the latest driver for postgreSQL, not sure what exactly is causing this issue.\n",
            "\n",
            "Link to examples with issue:\n",
            "[Repo link|https://github.com/Krzysztof1985/spring-boot3-jpa]\n",
            "\n",
            "Thank you in advance!\n",
            "\n",
            "Regards\n",
            "Krzysztof, Similarity: 0.3107\n",
            "Summary & Description: orphanremoval work bytecode enhancement enabled \n",
            " Our project has the following construct in use in various places:\n",
            "\n",
            "{noformat}@Entity\n",
            "@Table\n",
            "@DynamicInsert\n",
            "@DynamicUpdate\n",
            "@Getter\n",
            "public class Workorder implements Serializable {}\n",
            "  ...\n",
            "  @OneToOne(fetch = LAZY, cascade = ALL, orphanRemoval = true, mappedBy = \"workorder\")\n",
            "  @LazyToOne(NO_PROXY) @LazyGroup(\"caring-workorder\")\n",
            "  @Fetch(SELECT)\n",
            "  protected AdditionalCaring caringWorkorder;\n",
            "  ...\n",
            "}{noformat}\n",
            "\n",
            "If bytecode enhancement is enabled, orphanRemoval does not work. If in this case caringWorkorder had an associated entity and it is set to null, Hibernate does not delete the entry from the table associated with AdditionalCaring.\n",
            "\n",
            "This problem occurs both with unidirectional and bidirectional 1:1 associations.\n",
            "\n",
            "It would be helpful to know - for the time being - if there’s a workaround for this problem., Similarity: 0.2633\n",
            "Summary & Description: npe retrieving static metamodel attribute generic embeddable extending superclass \n",
            " A NullPointerException is thrown, while trying to retrieve an attribute of a static metamodel class, generated for an Embeddable within an entity. The Embeddable class should be a generic type, extend from a parent class  and the attribute should belong to the parent class for this exception to occur.\n",
            "\n",
            "\n",
            "\n",
            "{noformat}java.lang.NullPointerException: Cannot invoke \"org.hibernate.metamodel.model.domain.PersistentAttribute.getName()\" because \"attribute\" is null\n",
            "        at org.hibernate.query.sqm.tree.domain.AbstractSqmPath.resolvePath(AbstractSqmPath.java:185)\n",
            "        at org.hibernate.query.sqm.tree.domain.AbstractSqmPath.get(AbstractSqmPath.java:218)\n",
            "        at org.hibernate.query.sqm.tree.domain.AbstractSqmPath.get(AbstractSqmPath.java:37)\n",
            "        at org.hibernate.RunHibernateTest.handleQueryResult(RunHibernateTest.java:65)\n",
            "        at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)\n",
            "{noformat}, Similarity: 0.2471\n",
            "Summary & Description: unable use sql functions usertype attribute \n",
            " Similar to [https://hibernate.atlassian.net/browse/HHH-16241|https://hibernate.atlassian.net/browse/HHH-16241|smart-link] , but concerns querying when type conversion is done using UserType.\n",
            "\n",
            "Given an attribute:\n",
            "\n",
            "{code:java}@Type(YearMonthUserType.class)\n",
            "private YearMonth yearMonth;{code}\n",
            "\n",
            "and {{UserType}}:\n",
            "\n",
            "{noformat}\tpublic static class YearMonthUserType implements UserType<YearMonth> {\n",
            "\t\t@Override\n",
            "\t\tpublic int getSqlType() {\n",
            "\t\t\treturn SqlTypes.INTEGER;\n",
            "\t\t}\n",
            "\n",
            "\t\t@Override\n",
            "\t\tpublic Class<YearMonth> returnedClass() {\n",
            "\t\t\treturn YearMonth.class;\n",
            "\t\t}\n",
            "\n",
            "\t\t@Override\n",
            "\t\tpublic boolean equals(YearMonth x, YearMonth y) {\n",
            "\t\t\treturn Objects.equals(x, y);\n",
            "\t\t}\n",
            "\n",
            "\t\t@Override\n",
            "\t\tpublic int hashCode(YearMonth x) {\n",
            "\t\t\treturn Objects.hashCode(x);\n",
            "\t\t}\n",
            "\n",
            "\t\t@Override\n",
            "\t\tpublic YearMonth nullSafeGet(ResultSet rs, int position, SharedSessionContractImplementor session, Object owner) throws SQLException {\n",
            "\t\t\tint intValue = rs.getInt( position );\n",
            "\t\t\tif ( rs.wasNull() ) {\n",
            "\t\t\t\treturn null;\n",
            "\t\t\t}\n",
            "\t\t\treturn YearMonth.of( intValue / 100, intValue % 100 );\n",
            "\t\t}\n",
            "\n",
            "\t\t@Override\n",
            "\t\tpublic void nullSafeSet(PreparedStatement st, YearMonth value, int index, SharedSessionContractImplementor session) throws SQLException {\n",
            "\t\t\tif ( value == null ) {\n",
            "\t\t\t\tst.setNull( index, Types.INTEGER );\n",
            "\t\t\t}\n",
            "\t\t\telse {\n",
            "\t\t\t\tst.setInt( index, ( value.getYear() * 100 ) + value.getMonth().getValue() );\n",
            "\t\t\t}\n",
            "\t\t}\n",
            "\n",
            "\t\t@Override\n",
            "\t\tpublic YearMonth deepCopy(YearMonth value) {\n",
            "\t\t\treturn value;\n",
            "\t\t}\n",
            "\n",
            "\t\t@Override\n",
            "\t\tpublic boolean isMutable() {\n",
            "\t\t\treturn false;\n",
            "\t\t}\n",
            "\n",
            "\t\t@Override\n",
            "\t\tpublic Serializable disassemble(YearMonth value) {\n",
            "\t\t\treturn value;\n",
            "\t\t}\n",
            "\n",
            "\t\t@Override\n",
            "\t\tpublic YearMonth assemble(Serializable cached, Object owner) {\n",
            "\t\t\treturn cached instanceof YearMonth ? (YearMonth) cached : null;\n",
            "\t\t}\n",
            "\t}{noformat}\n",
            "\n",
            "it’s impossible to eg. {{SELECT max(yearMonth)}}, because query creation fails with:\n",
            "\n",
            "{quote}java.lang.IllegalArgumentException: org.hibernate.QueryException: Parameter 1 of function max() has type COMPARABLE, but argument is of type java.time.YearMonth{quote}\n",
            "\n",
            "Attached test case was made as a copy of [https://github.com/hibernate/hibernate-orm/blob/6.2.4/hibernate-core/src/test/java/org/hibernate/orm/test/mapping/converted/converter/YearMonthConverterTest.java|https://github.com/hibernate/hibernate-orm/blob/6.2.4/hibernate-core/src/test/java/org/hibernate/orm/test/mapping/converted/converter/YearMonthConverterTest.java|smart-link], but uses {{@Type}} instead of {{AttributeConverter}}.\n",
            "\n",
            "{{@JavaType}} also doesn’t work (test case in JavaType.zip, copied from [https://hibernate.atlassian.net/browse/HHH-16671|https://hibernate.atlassian.net/browse/HHH-16671|smart-link])., Similarity: 0.2615\n",
            "Summary & Description: interpretation queries select multiple elements explicit result class \n",
            " In Hibernate 6, Steve wanted to make a breaking change where a query like this:\n",
            "\n",
            "{code:sql}from Author a join a.books b where b.title = :title{code}\n",
            "\n",
            "would be interpreted as returning a single {{Author}} entity, rather than returning an array with an {{Author}} and a {{Book}}.\n",
            "\n",
            "A priori, this is a completely legit and natural interpretation, but I was _very_ worried about breaking the semantics of existing code by changing something that has had a stable interpretation as far back as Hibernate 1.0.\n",
            "\n",
            "After some discussion, we settled on what I think was an excellent compromise: to use the result type as a hint to how such queries should be interpreted. So:\n",
            "\n",
            "{code:java}s.createSelectionQuery(\"from Author a join a.books b where b.title = :title\", Author.class){code}\n",
            "\n",
            "would have the interpretation Steve prefers, whereas:\n",
            "\n",
            "{code:java}s.createSelectionQuery(\"from Author a join a.books b where b.title = :title\", Object[].class){code}\n",
            "\n",
            "would have the same interpretation as always.\n",
            "\n",
            "I’m completely happy with this, because it doesn’t break old code, and simply turns a case which was previously an _error_ into something useful. Perfect. We released this change in Hibernate 6. I’ve continued along a similar line of thought in [https://hibernate.atlassian.net/browse/HHH-16710|https://hibernate.atlassian.net/browse/HHH-16710|smart-link].\n",
            "\n",
            "But, while working on 16710, I noticed a hole in what has actually been implemented. The issue is that we have an overload of {{createSelectionQuery()}} which does not accept a result class. (I’m not sure why we even need this.) There’s also a similar legacy {{createQuery()}} method required for JPA compatibility that is marked deprecated. (That’s the method old code is all using.)\n",
            "\n",
            "And in this case, the current implementation does not the first thing, not the second thing, but a secret (i.e. undocumented) third thing in certain more complicated cases. Consider:\n",
            "\n",
            "{code:java}s.createSelectionQuery(\"from Author a join a.books b, Author c\"){code}\n",
            "\n",
            "This is currently interpreted to return instances of {{Object[]}}containing two {{Author}}s. But if I were to _explicitly_ pass the result type {{Object[].class}} like so:\n",
            "\n",
            "{code:java}s.createSelectionQuery(\"from Author a join a.books b, Author c\", Object[].class){code}\n",
            "\n",
            "Then I would get instances of {{Object[]}} with _three_ elements. That’s pretty inconsistent!\n",
            "\n",
            "Furthermore, if I write the query with a {{cross join}}  instead of a comma:\n",
            "\n",
            "{code:java}s.createSelectionQuery(\"from Author a join a.books b cross join Author c\"){code}\n",
            "\n",
            "then now I get a single {{Author}} as the result. So {{cross join}} and {{,}} are suddenly pretty different things.\n",
            "\n",
            "Now, this behavior is at best buglike, and since it has no tests asserting that it was _intentional,_ I’m going to go ahead and call it a bug. \n",
            "\n",
            "Frankly, in light of all this, I would prefer that we threw an actual exception in the case of a query with no {{select}} clause, multiple identification variables, and no explicit result type. I don’t think there even is any “natural” interpretation there. So I would like to have some reasonable way to simply “deprecate” this usage. (But I can’t think of anything better than a damn {{WARN}}.)\n",
            "\n",
            "Anyway, the only straightforward “fix” that I can see here that doesn’t make things worse is to revert to the behavior of H5 when there’s no explicit result class. That breaks no tests, ensures that old code continues to work, and eliminates the “secret third thing” interpretation that’s undocumented and quite buglike., Similarity: 0.1062\n",
            "Summary & Description: error call procedure postgresql refcursor \n",
            " persistence.xml\n",
            "\n",
            "{code:xml}<persistence xmlns=\"http://xmlns.jcp.org/xml/ns/persistence\"\n",
            "             xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n",
            "             xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/persistence\n",
            "             http://xmlns.jcp.org/xml/ns/persistence/persistence_2_1.xsd\"\n",
            "             version=\"2.1\">\n",
            "\n",
            "    <persistence-unit name=\"orientsoftware\">\n",
            "        <description>\n",
            "            Persistence unit for Hibernate User Guide\n",
            "        </description>\n",
            "\n",
            "        <provider>org.hibernate.jpa.HibernatePersistenceProvider</provider>\n",
            "\n",
            "        <class>org.hibernate.documentation.userguide.Document</class>\n",
            "\n",
            "        <properties>\n",
            "            <property name=\"jakarta.persistence.jdbc.driver\" value=\"org.postgresql.Driver\" />\n",
            "\n",
            "            <property name=\"jakarta.persistence.jdbc.url\" value=\"jdbc:postgresql://localhost:5432/test\" />\n",
            "\n",
            "            <property name=\"jakarta.persistence.jdbc.user\" value=\"postgres\" />\n",
            "\n",
            "            <property name=\"jakarta.persistence.jdbc.password\" value=\"postgres\" />\n",
            "\n",
            "            <property name=\"hibernate.show_sql\" value=\"true\" />\n",
            "\n",
            "            <property name=\"hibernate.hbm2ddl.auto\" value=\"create\" />\n",
            "            \n",
            "            <property name=\"hibernate.default_schema\" value=\"test\"/>\n",
            "            \n",
            "        </properties>\n",
            "\n",
            "    </persistence-unit>\n",
            "\n",
            "</persistence>{code}\n",
            "\n",
            "Hibernate.java\n",
            "\n",
            "{code:java}package hibernate.models;\n",
            "\n",
            "import jakarta.persistence.Access;\n",
            "import jakarta.persistence.AccessType;\n",
            "import jakarta.persistence.Column;\n",
            "import jakarta.persistence.Entity;\n",
            "import jakarta.persistence.GeneratedValue;\n",
            "import jakarta.persistence.GenerationType;\n",
            "import jakarta.persistence.Id;\n",
            "import jakarta.persistence.Table;\n",
            "import lombok.AccessLevel;\n",
            "import lombok.Getter;\n",
            "import lombok.Setter;\n",
            "import lombok.experimental.FieldDefaults;\n",
            "\n",
            "@Entity\n",
            "@Table(name = \"hibernate\", schema = \"test\")\n",
            "@Access(AccessType.FIELD)\n",
            "@FieldDefaults(level = AccessLevel.PRIVATE)\n",
            "@Getter\n",
            "@Setter\n",
            "public class Hibernate {\n",
            "\n",
            "\t@Id\n",
            "\t@GeneratedValue(strategy = GenerationType.IDENTITY)\n",
            "\t@Column(name = \"id\", nullable = false)\n",
            "\tLong id;\n",
            "\t\n",
            "\t@Column(name = \"name\")\n",
            "\tString name;\n",
            "}\n",
            "{code}\n",
            "\n",
            "\n",
            "\n",
            "pom.xml\n",
            "\n",
            "{code:xml}<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n",
            "\txmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n",
            "\txsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\">\n",
            "\t<modelVersion>4.0.0</modelVersion>\n",
            "\t<groupId>com.orientsoftware</groupId>\n",
            "\t<artifactId>hibernate</artifactId>\n",
            "\t<version>0.0.1-SNAPSHOT</version>\n",
            "\n",
            "\t<properties>\n",
            "\t\t<hib.version>6.2.4.Final</hib.version>\n",
            "\t</properties>\n",
            "\n",
            "\t<build>\n",
            "\t\t<finalName>hibernate</finalName>\n",
            "\t\t<plugins>\n",
            "\t\t\t<plugin>\n",
            "\t\t\t\t<groupId>org.apache.maven.plugins</groupId>\n",
            "\t\t\t\t<artifactId>maven-compiler-plugin</artifactId>\n",
            "\t\t\t\t<version>3.8.1</version>\n",
            "\t\t\t\t<configuration>\n",
            "\t\t\t\t\t<release>17</release>\n",
            "\t\t\t\t</configuration>\n",
            "\t\t\t</plugin>\n",
            "\t\t</plugins>\n",
            "\t</build>\n",
            "\n",
            "\t<dependencies>\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.hibernate.orm</groupId>\n",
            "\t\t\t<artifactId>hibernate-core</artifactId>\n",
            "\t\t\t<version>${hib.version}</version>\n",
            "\t\t</dependency>\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.hibernate.orm</groupId>\n",
            "\t\t\t<artifactId>hibernate-c3p0</artifactId>\n",
            "\t\t\t<version>${hib.version}</version>\n",
            "\t\t</dependency>\n",
            "\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.hibernate.orm</groupId>\n",
            "\t\t\t<artifactId>hibernate-envers</artifactId>\n",
            "\t\t\t<version>${hib.version}</version>\n",
            "\t\t</dependency>\n",
            "\n",
            "\t\t<!--\n",
            "\t\thttps://mvnrepository.com/artifact/org.hibernate.validator/hibernate-validator -->\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.hibernate.validator</groupId>\n",
            "\t\t\t<artifactId>hibernate-validator</artifactId>\n",
            "\t\t\t<version>8.0.0.Final</version>\n",
            "\t\t</dependency>\n",
            "\t\t\n",
            "\t\t <!-- https://mvnrepository.com/artifact/org.projectlombok/lombok -->\n",
            "\t\t<dependency>\n",
            "\t\t\t<groupId>org.projectlombok</groupId>\n",
            "\t\t\t<artifactId>lombok</artifactId>\n",
            "\t\t\t<version>1.18.24</version>\n",
            "\t\t</dependency>\n",
            "\t\t\n",
            "\t\t<dependency>\n",
            "            <groupId>org.postgresql</groupId>\n",
            "            <artifactId>postgresql</artifactId>\n",
            "            <version>42.5.4</version>\n",
            "        </dependency>\n",
            "\t\t\n",
            "\t</dependencies>\n",
            "</project>{code}\n",
            "\n",
            "\n",
            "\n",
            "App.java\n",
            "\n",
            "{code:java}package hibernate;\n",
            "\n",
            "import java.util.Iterator;\n",
            "import java.util.List;\n",
            "\n",
            "import org.hibernate.Session;\n",
            "import org.hibernate.procedure.ProcedureCall;\n",
            "import org.hibernate.result.Output;\n",
            "import org.hibernate.result.ResultSetOutput;\n",
            "\n",
            "import hibernate.models.Hibernate;\n",
            "import jakarta.persistence.EntityManager;\n",
            "import jakarta.persistence.EntityManagerFactory;\n",
            "import jakarta.persistence.ParameterMode;\n",
            "import jakarta.persistence.Persistence;\n",
            "\n",
            "public class App {\n",
            "\n",
            "\tpublic static void main(String[] args) {\n",
            "\t\t\n",
            "\t\tEntityManagerFactory factory = Persistence.createEntityManagerFactory(\"orientsoftware\");\n",
            "\t\tEntityManager entityManager = factory.createEntityManager();\n",
            "\t\t\n",
            "\t\tentityManager.find(Hibernate.class, 1l);\n",
            "\t\t\n",
            "\t\tSession session = entityManager.unwrap(Session.class);\n",
            "\t\tProcedureCall sp = session.createStoredProcedureCall(\"test.test_function\");\n",
            "\t\tsp.registerParameter(1, void.class, ParameterMode.REF_CURSOR);\n",
            "\t\tsp.registerParameter(2, String.class, ParameterMode.IN);\n",
            "\t\tsp.setParameter(2, \"name\");\n",
            "\t\t\n",
            "\t\tOutput output = sp.getOutputs().getCurrent();\n",
            "\t\tList<Object[]> resultList = ((ResultSetOutput) output).getResultList();\n",
            "\t\t\n",
            "\t\tIterator itr = resultList.iterator();\n",
            "\t\tSystem.out.println(itr.toString());\n",
            "\t\t\n",
            "\t\tsession.close();\n",
            "\t\tentityManager.close();\n",
            "\t}\n",
            "}\n",
            "{code}\n",
            "\n",
            "\n",
            "\n",
            "script database\n",
            "\n",
            "{code:sql}CREATE OR REPLACE FUNCTION test.test_function(\n",
            "\tparam text)\n",
            "    RETURNS refcursor\n",
            "    LANGUAGE 'plpgsql'\n",
            "    COST 100\n",
            "    VOLATILE PARALLEL UNSAFE\n",
            "AS $BODY$ \n",
            "\tDECLARE\n",
            "\t\tresultSet REFCURSOR;\n",
            "    BEGIN\n",
            "     \tselect * from test.hibernate\n",
            "\t\twhere name like param;\n",
            "\t\tRETURN resultSet;\n",
            "    END;\t\n",
            "$BODY$;\n",
            "\n",
            "ALTER FUNCTION test.test_function(text)\n",
            "    OWNER TO postgres;{code}\n",
            "\n",
            "\n",
            "\n",
            "Output:\n",
            "\n",
            "{noformat}Exception in thread \"main\" org.hibernate.exception.SQLGrammarException: Error calling CallableStatement.getMoreResults [ERROR: test.test_function(character varying) is not a procedure\n",
            "  Hint: To call a function, use SELECT.\n",
            "  Position: 6] [com.mchange.v2.c3p0.impl.NewProxyCallableStatement@5efeb117 [wrapping: call test.test_function(NULL,'name')]]\n",
            "\tat org.hibernate.exception.internal.SQLStateConversionDelegate.convert(SQLStateConversionDelegate.java:89)\n",
            "\tat org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:56)\n",
            "\tat org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:108)\n",
            "\tat org.hibernate.result.internal.OutputsImpl.convert(OutputsImpl.java:96)\n",
            "\tat org.hibernate.result.internal.OutputsImpl.executeStatement(OutputsImpl.java:73)\n",
            "\tat org.hibernate.procedure.internal.ProcedureOutputsImpl.<init>(ProcedureOutputsImpl.java:49)\n",
            "\tat org.hibernate.procedure.internal.ProcedureCallImpl.buildOutputs(ProcedureCallImpl.java:710)\n",
            "\tat org.hibernate.procedure.internal.ProcedureCallImpl.getOutputs(ProcedureCallImpl.java:594)\n",
            "\tat hibernate.App.main(App.java:33)\n",
            "Caused by: org.postgresql.util.PSQLException: ERROR: test.test_function(character varying) is not a procedure\n",
            "  Hint: To call a function, use SELECT.\n",
            "  Position: 6\n",
            "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2676)\n",
            "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2366)\n",
            "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)\n",
            "\tat org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:496)\n",
            "\tat org.postgresql.jdbc.PgStatement.execute(PgStatement.java:413)\n",
            "\tat org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:190)\n",
            "\tat org.postgresql.jdbc.PgCallableStatement.executeWithFlags(PgCallableStatement.java:84)\n",
            "\tat org.postgresql.jdbc.PgPreparedStatement.execute(PgPreparedStatement.java:177)\n",
            "\tat com.mchange.v2.c3p0.impl.NewProxyCallableStatement.execute(NewProxyCallableStatement.java:3214)\n",
            "\tat org.hibernate.result.internal.OutputsImpl.executeStatement(OutputsImpl.java:69)\n",
            "\t... 4 more{noformat}, Similarity: 0.3545\n",
            "Summary & Description: transientobjectexception loading versioned entity secondlevel cache onetoone lazy mapping \n",
            " While upgrading from Hibernate ORM 5.3.28.Final to 6.2.1.Final (due to an application server update from Wildfly 26.1.3 to Wildfly 28.0.1) we encountered following error when fetching data from our database / 2nd Level Cache:\n",
            "\n",
            "{code:none}Caused by: org.hibernate.TransientObjectException: object references an unsaved transient instance - save the transient instance before flushing: tld.domain.Model\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.engine.internal.ForeignKeys.getEntityIdentifierIfNotUnsaved(ForeignKeys.java:346)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.type.ManyToOneType.disassemble(ManyToOneType.java:171)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.cache.spi.entry.CacheEntryHelper.disassemble(CacheEntryHelper.java:48)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.cache.spi.entry.StandardCacheEntryImpl.<init>(StandardCacheEntryImpl.java:50)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.persister.entity.AbstractEntityPersister$StandardCacheEntryHelper.buildCacheEntry(AbstractEntityPersister.java:4456)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.persister.entity.AbstractEntityPersister.buildCacheEntry(AbstractEntityPersister.java:3604)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.results.graph.entity.AbstractEntityInitializer.putInCache(AbstractEntityInitializer.java:939)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.results.graph.entity.AbstractEntityInitializer.updateCaches(AbstractEntityInitializer.java:873)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.results.graph.entity.AbstractEntityInitializer.finishUpRow(AbstractEntityInitializer.java:1140)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.results.internal.InitializersList.finishUpRow(InitializersList.java:64)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.results.internal.StandardRowReader.afterRow(StandardRowReader.java:104)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.results.internal.StandardRowReader.readRow(StandardRowReader.java:97)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.results.spi.ListResultsConsumer.consume(ListResultsConsumer.java:179)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.results.spi.ListResultsConsumer.consume(ListResultsConsumer.java:33)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.exec.internal.JdbcSelectExecutorStandardImpl.doExecuteQuery(JdbcSelectExecutorStandardImpl.java:362)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.exec.internal.JdbcSelectExecutorStandardImpl.executeQuery(JdbcSelectExecutorStandardImpl.java:168)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.exec.internal.JdbcSelectExecutorStandardImpl.list(JdbcSelectExecutorStandardImpl.java:93)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.exec.spi.JdbcSelectExecutor.list(JdbcSelectExecutor.java:31)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.loader.ast.internal.SingleUniqueKeyEntityLoaderStandard.load(SingleUniqueKeyEntityLoaderStandard.java:98)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.persister.entity.AbstractEntityPersister.loadByUniqueKey(AbstractEntityPersister.java:2460)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.persister.entity.AbstractEntityPersister.loadByUniqueKey(AbstractEntityPersister.java:2452)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.results.graph.entity.internal.EntitySelectFetchByUniqueKeyInitializer.initializeInstance(EntitySelectFetchByUniqueKeyInitializer.java:85)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.results.internal.InitializersList.initializeInstance(InitializersList.java:70)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.results.internal.StandardRowReader.coordinateInitializers(StandardRowReader.java:111)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.results.internal.StandardRowReader.readRow(StandardRowReader.java:87)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.results.spi.ListResultsConsumer.consume(ListResultsConsumer.java:199)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.results.spi.ListResultsConsumer.consume(ListResultsConsumer.java:33)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.exec.internal.JdbcSelectExecutorStandardImpl.doExecuteQuery(JdbcSelectExecutorStandardImpl.java:362)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.exec.internal.JdbcSelectExecutorStandardImpl.executeQuery(JdbcSelectExecutorStandardImpl.java:168)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.exec.internal.JdbcSelectExecutorStandardImpl.list(JdbcSelectExecutorStandardImpl.java:93)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.sql.exec.spi.JdbcSelectExecutor.list(JdbcSelectExecutor.java:31)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.query.sqm.internal.ConcreteSqmSelectQueryPlan.lambda$new$0(ConcreteSqmSelectQueryPlan.java:109)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.query.sqm.internal.ConcreteSqmSelectQueryPlan.withCacheableSqmInterpretation(ConcreteSqmSelectQueryPlan.java:302)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.query.sqm.internal.ConcreteSqmSelectQueryPlan.performList(ConcreteSqmSelectQueryPlan.java:243)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.query.sqm.internal.QuerySqmImpl.doList(QuerySqmImpl.java:521)\n",
            "at org.hibernate@6.2.1.Final//org.hibernate.query.spi.AbstractSelectionQuery.list(AbstractSelectionQuery.java:367{code}\n",
            "\n",
            "\n",
            "\n",
            "After digging deeper we found out that the following combination:\n",
            "\n",
            "* Second Level Caching enabled\n",
            "* Optimistic locking using the @Version annotation\n",
            "* @OneToOne{FetchType.LAZY) on a one-to-one bidrectional (on the property of the referenced entity)\n",
            "\n",
            "is causing this TransientObjectException while trying to fetch data.\n",
            "\n",
            "This issue seems to be close to [https://hibernate.atlassian.net/browse/HHH-16126|https://hibernate.atlassian.net/browse/HHH-16126|smart-link] .\n",
            "\n",
            "We validated that the issue still exists in: 6.2.4, 6.2.3 and 6.2.2., Similarity: 0.3385\n",
            "Summary & Description: wrong class created reusing join column different entities multiple manytoone \n",
            " Consider the following abridged model (please note the reused {{food_id}} column and the self-referencing {{@ManyToOne}} in {{Fruit}} and {{Cheese}}): \n",
            "\n",
            "{code:java}class Container {\n",
            "}\n",
            "\n",
            "class FruitContainer extends Container {\n",
            "\t\t@ManyToOne\n",
            "\t\t@JoinColumn(name = \"food_id\")\n",
            "\t\t@Fetch(FetchMode.SELECT)\n",
            "\t\tprivate Fruit fruit;\n",
            "}\n",
            "\n",
            "class CheeseContainer extends Container {\n",
            "\t\t@ManyToOne\n",
            "\t\t@JoinColumn(name = \"food_id\")\n",
            "\t\t@Fetch(FetchMode.SELECT)\n",
            "\t\tprivate Cheese cheese;\n",
            "}\n",
            "\n",
            "class Food {\n",
            "}\n",
            "\n",
            "class Fruit extends Food {\n",
            "\t\t@ManyToOne\n",
            "\t\t@Fetch(FetchMode.SELECT)\n",
            "\t\tprivate Fruit bestPairedWith;\n",
            "}\n",
            "\n",
            "class Cheese extends Food {\n",
            "\t\t@ManyToOne\n",
            "\t\t@Fetch(FetchMode.SELECT)\n",
            "\t\tprivate Cheese bestPairedWith;\n",
            "}{code}\n",
            "\n",
            "When batch-loading several {{Container}} objects, Hibernate seems to create the wrong class (a {{Cheese}} instead of a {{Fruit}})\n",
            "\n",
            "I’m not sure if reusing a column in different branches of an inheritance tree is supported but this seemed to work in Hibernate 5.\n",
            "\n",
            "In Hibernate 6 an initializer seems to be associated with the column during the batch load but it only works for one of the types., Similarity: 0.2567\n",
            "Summary & Description: arrayindexoutofboundsexception calling tuplegetelements \n",
            " We are in the process of migrating an application from Hibernate 4.3 to Hibernate 6.2. Within our application, we can create custom reports that rely on the aliases provided in the custom HQL when rendering the table. In Hibernate 4, we used\n",
            "\n",
            "{{String[] alias = query.getReturnAliases();}}\n",
            "\n",
            "which no longer exists. So in Hibernate 6, we have started using jakarta.persistence.Tuple as the result class for the query. However, if the same column is returned two times, with different aliases, calling Tuple.getElements() throws ArrayIndexOutOfBoundsException.\n",
            "\n",
            "Here is an example. Imagine a simple entity:\n",
            "\n",
            "{noformat}@Entity\n",
            "@Table(name = \"test_entity\")\n",
            "public class TestEntity {\n",
            "    private UUID id;\n",
            "    private String name;\n",
            "    private String value;\n",
            "    \n",
            "    @Id\n",
            "    @GeneratedValue\n",
            "    @Column(name = \"id\")\n",
            "    public UUID getId() { return id; }\n",
            "    public void setId(UUID id) { this.id = id; }\n",
            "    \n",
            "    @Column(name = \"name\")\n",
            "    public String getName() { return name; }\n",
            "    public void setName(String name) { this.name = name; }\n",
            "\n",
            "    @Column(name = \"val\")\n",
            "    public String getValue() { return value; }\n",
            "    public void setValue(String value) { this.value = value; }\n",
            "}{noformat}\n",
            "\n",
            "And the following code using the following query\n",
            "\n",
            "{{select name as Reference, name as Name, value as Value from TestEntity}}\n",
            "\n",
            "returning the TestEntity.name column two times:\n",
            "\n",
            "{noformat}// Get a list of tuples\n",
            "List<Tuple> list = hibSession.createQuery(\n",
            "    \"select name as Reference, name as Name, value as Value from TestEntity\",\n",
            "    Tuple.class).list();\n",
            "        \n",
            "// Print the returned tuples\n",
            "for (Tuple tuple: list)\n",
            "    for (TupleElement<?> e: tuple.getElements())\n",
            "        System.out.println(e.getAlias() + \": \" + tuple.get(e));{noformat}\n",
            "\n",
            "Calling tuple.getElements() on line 6 results in the following exception:\n",
            "\n",
            "{noformat}java.lang.ArrayIndexOutOfBoundsException: Index 2 out of bounds for length 2\n",
            "    at org.hibernate.sql.results.internal.TupleMetadata.getList(TupleMetadata.java:52)\n",
            "    at org.hibernate.sql.results.internal.TupleImpl.getElements(TupleImpl.java:113)\n",
            "    at org.hibernate.bugs.tuples.TupleTest.testDuplicates(TupleTest.java:67)\n",
            "    ...{noformat}\n",
            "\n",
            "The problem only occurs when the same column is listed two times (in any position). This can happen as our custom reports are used to provide integration data with other applications, which may need the same property listed two times under different names.\n",
            "\n",
            "See the attached files for the whole test.\n",
            "\n",
            "[^TupleTest.java]\n",
            "[^TestEntity.java]\n",
            "\n",
            ", Similarity: 0.3019\n",
            "Summary & Description: badjpqlgrammarexception using column names coinciding functions projection \n",
            " Summary: I am unable to use columns with names identical to function names in projections.\n",
            "\n",
            "Context:\n",
            "\n",
            "Given I have an entity with a column called `sign`:\n",
            "\n",
            "\n",
            "{code:java}\n",
            "@Entity\n",
            "@Table(name = \"test\")\n",
            "@Getter\n",
            "@Setter\n",
            "@AllArgsConstructor\n",
            "@NoArgsConstructor\n",
            "public class TestEntity{\n",
            "\n",
            "    @Id\n",
            "    @GeneratedValue(strategy = GenerationType.AUTO)\n",
            "    @Column(name = \"task_id\", nullable = false, updatable = false)\n",
            "    private UUID taskId;\n",
            "\n",
            "    @Column(name = \"title\", nullable = false)\n",
            "    private boolean sign;\n",
            "}\n",
            "{code}\n",
            "\n",
            "With a pojo defined that I want to project into:\n",
            "\n",
            "{code:java}\n",
            "public class TestProjection {\n",
            "    private boolean title;\n",
            "\n",
            "    public TestProjection(boolean title){\n",
            "        this.title = title;\n",
            "    }\n",
            "}\n",
            "{code}\n",
            "\n",
            "Now, defining and running the following jpql query\n",
            "\n",
            "{code:java}\n",
            "public interface TestRepository extends JpaRepository<TestEntity, UUID> {\n",
            "\n",
            "    @Query(\n",
            "            \"\"\"\n",
            "            select new some.entity.TestProjection(\n",
            "                t.sign\n",
            "            )\n",
            "            from TestEntity t\n",
            "        \"\"\"\n",
            "    )\n",
            "    List<TestProjection> getAll();\n",
            "}\n",
            "{code}\n",
            "\n",
            "leads to an exception\n",
            "\n",
            "{code:java}\n",
            "org.springframework.dao.InvalidDataAccessApiUsageException: org.springframework.data.jpa.repository.query.BadJpqlGrammarException: Line 2:10 no viable alternative at input 't.sign'; Bad JPQL grammar [    select new some.entity.TestProjection(\n",
            "        t.sign\n",
            "    )\n",
            "    from TestEntity t\n",
            "]\n",
            "\n",
            "\tat org.springframework.orm.jpa.EntityManagerFactoryUtils.convertJpaAccessExceptionIfPossible(EntityManagerFactoryUtils.java:371)\n",
            "\tat org.springframework.orm.jpa.vendor.HibernateJpaDialect.translateExceptionIfPossible(HibernateJpaDialect.java:234)\n",
            "\tat org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.translateExceptionIfPossible(AbstractEntityManagerFactoryBean.java:550)\n",
            "\tat org.springframework.dao.support.ChainedPersistenceExceptionTranslator.translateExceptionIfPossible(ChainedPersistenceExceptionTranslator.java:61)\n",
            "\tat org.springframework.dao.support.DataAccessUtils.translateIfNecessary(DataAccessUtils.java:242)\n",
            "\tat org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:152)\n",
            "\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)\n",
            "\tat org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:134)\n",
            "\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)\n",
            "\tat org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)\n",
            "\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)\n",
            "\tat org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:223)\n",
            "\tat jdk.proxy2/jdk.proxy2.$Proxy307.getAll(Unknown Source)\n",
            "\tat some.TestEntityTest.test(TestEntityTest.java:27)\n",
            "\tat java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)\n",
            "\tat java.base/java.lang.reflect.Method.invoke(Method.java:578)\n",
            "\tat org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:727)\n",
            "\tat org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)\n",
            "\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)\n",
            "\tat org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:156)\n",
            "\tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:147)\n",
            "\tat org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:86)\n",
            "\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:103)\n",
            "\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93)\n",
            "\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)\n",
            "\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)\n",
            "\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)\n",
            "\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)\n",
            "\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:92)\n",
            "\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:86)\n",
            "\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:217)\n",
            "\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n",
            "\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:213)\n",
            "\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:138)\n",
            "\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:68)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)\n",
            "\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\n",
            "\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\n",
            "\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\n",
            "\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1511)\n",
            "\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)\n",
            "\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\n",
            "\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\n",
            "\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\n",
            "\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1511)\n",
            "\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)\n",
            "\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\n",
            "\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\n",
            "\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\n",
            "\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)\n",
            "\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)\n",
            "\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)\n",
            "\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:147)\n",
            "\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:127)\n",
            "\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:90)\n",
            "\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:55)\n",
            "\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:102)\n",
            "\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:54)\n",
            "\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)\n",
            "\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)\n",
            "\tat org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)\n",
            "\tat org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)\n",
            "\tat com.intellij.junit5.JUnit5IdeaTestRunner.startRunnerWithArgs(JUnit5IdeaTestRunner.java:57)\n",
            "\tat com.intellij.rt.junit.IdeaTestRunner$Repeater$1.execute(IdeaTestRunner.java:38)\n",
            "\tat com.intellij.rt.execution.junit.TestsRepeater.repeat(TestsRepeater.java:11)\n",
            "\tat com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:35)\n",
            "\tat com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:232)\n",
            "\tat com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:55)\n",
            "Caused by: java.lang.IllegalArgumentException: org.springframework.data.jpa.repository.query.BadJpqlGrammarException: Line 2:10 no viable alternative at input 't.sign'; Bad JPQL grammar [    select new some.entity.TestProjection(\n",
            "        t.sign\n",
            "    )\n",
            "    from TestEntity t\n",
            "]\n",
            "\tat org.springframework.data.jpa.repository.query.JpaQueryParserSupport.renderSortedQuery(JpaQueryParserSupport.java:56)\n",
            "\tat org.springframework.data.jpa.repository.query.JpaQueryEnhancer.applySorting(JpaQueryEnhancer.java:88)\n",
            "\tat org.springframework.data.jpa.repository.query.JpaQueryEnhancer.applySorting(JpaQueryEnhancer.java:100)\n",
            "\tat org.springframework.data.jpa.repository.query.AbstractStringBasedJpaQuery.doCreateQuery(AbstractStringBasedJpaQuery.java:96)\n",
            "\tat org.springframework.data.jpa.repository.query.AbstractJpaQuery.createQuery(AbstractJpaQuery.java:234)\n",
            "\tat org.springframework.data.jpa.repository.query.JpaQueryExecution$CollectionExecution.doExecute(JpaQueryExecution.java:129)\n",
            "\tat org.springframework.data.jpa.repository.query.JpaQueryExecution.execute(JpaQueryExecution.java:92)\n",
            "\tat org.springframework.data.jpa.repository.query.AbstractJpaQuery.doExecute(AbstractJpaQuery.java:148)\n",
            "\tat org.springframework.data.jpa.repository.query.AbstractJpaQuery.execute(AbstractJpaQuery.java:136)\n",
            "\tat org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:136)\n",
            "\tat org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:120)\n",
            "\tat org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:164)\n",
            "\tat org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:143)\n",
            "\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)\n",
            "\tat org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:77)\n",
            "\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)\n",
            "\tat org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:123)\n",
            "\tat org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:391)\n",
            "\tat org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119)\n",
            "\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)\n",
            "\tat org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)\n",
            "\t... 76 more\n",
            "Caused by: org.springframework.data.jpa.repository.query.BadJpqlGrammarException: Line 2:10 no viable alternative at input 't.sign'; Bad JPQL grammar [    select new some.entity.TestProjection(\n",
            "        t.sign\n",
            "    )\n",
            "    from TestEntity t\n",
            "]\n",
            "\tat org.springframework.data.jpa.repository.query.BadJpqlGrammarErrorListener.syntaxError(BadJpqlGrammarErrorListener.java:39)\n",
            "\tat org.antlr.v4.runtime.ProxyErrorListener.syntaxError(ProxyErrorListener.java:41)\n",
            "\tat org.antlr.v4.runtime.Parser.notifyErrorListeners(Parser.java:543)\n",
            "\tat org.antlr.v4.runtime.DefaultErrorStrategy.reportNoViableAlternative(DefaultErrorStrategy.java:310)\n",
            "\tat org.antlr.v4.runtime.DefaultErrorStrategy.reportError(DefaultErrorStrategy.java:136)\n",
            "\tat org.springframework.data.jpa.repository.query.HqlParser.expressionOrPredicate(HqlParser.java:8356)\n",
            "\tat org.springframework.data.jpa.repository.query.HqlParser.instantiationArgument(HqlParser.java:9229)\n",
            "\tat org.springframework.data.jpa.repository.query.HqlParser.instantiationArguments(HqlParser.java:9157)\n",
            "\tat org.springframework.data.jpa.repository.query.HqlParser.instantiation(HqlParser.java:2395)\n",
            "\tat org.springframework.data.jpa.repository.query.HqlParser.selectExpression(HqlParser.java:3275)\n",
            "\tat org.springframework.data.jpa.repository.query.HqlParser.selection(HqlParser.java:3208)\n",
            "\tat org.springframework.data.jpa.repository.query.HqlParser.selectionList(HqlParser.java:3145)\n",
            "\tat org.springframework.data.jpa.repository.query.HqlParser.selectClause(HqlParser.java:3097)\n",
            "\tat org.springframework.data.jpa.repository.query.HqlParser.query(HqlParser.java:633)\n",
            "\tat org.springframework.data.jpa.repository.query.HqlParser.orderedQuery(HqlParser.java:507)\n",
            "\tat org.springframework.data.jpa.repository.query.HqlParser.queryExpression(HqlParser.java:434)\n",
            "\tat org.springframework.data.jpa.repository.query.HqlParser.selectStatement(HqlParser.java:380)\n",
            "\tat org.springframework.data.jpa.repository.query.HqlParser.ql_statement(HqlParser.java:311)\n",
            "\tat org.springframework.data.jpa.repository.query.HqlParser.start(HqlParser.java:250)\n",
            "\tat org.springframework.data.jpa.repository.query.HqlQueryParser.parseQuery(HqlQueryParser.java:53)\n",
            "\tat org.springframework.data.jpa.repository.query.HqlQueryParser.parse(HqlQueryParser.java:63)\n",
            "\tat org.springframework.data.jpa.repository.query.JpaQueryParserSupport$ParseState.lambda$new$0(JpaQueryParserSupport.java:182)\n",
            "\tat org.springframework.data.util.Lazy.getNullable(Lazy.java:245)\n",
            "\tat org.springframework.data.util.Lazy.get(Lazy.java:114)\n",
            "\tat org.springframework.data.jpa.repository.query.JpaQueryParserSupport$ParseState.getContext(JpaQueryParserSupport.java:194)\n",
            "\tat org.springframework.data.jpa.repository.query.JpaQueryParserSupport.renderSortedQuery(JpaQueryParserSupport.java:54)\n",
            "\t... 96 more\n",
            "\n",
            "18:06:09.049 W [utdownHook] o.s.b.f.s.DisposableBeanAdapter          |    : Invocation of close method failed on bean with name 'getAllocator': java.lang.IllegalStateException: Shutdown in progress\n",
            "Disconnected from the target VM, address: '127.0.0.1:45117', transport: 'socket'\n",
            "\n",
            "Process finished with exit code 255\n",
            "{code}\n",
            "\n",
            "I would expect it to resolve `t.sign` to be the `sign` property of the `TestEntity` what I think is what really happens is that `sign` is resolved to be the `sign()` function (i.e. `sign(-10) = -1`).\n",
            "\n",
            "A similar exception occurs, when the column gets renamed to other popular function names such as `log` or `exp`. Renaming the column to `signing` leads to the query working as expected.\n",
            ", Similarity: 0.3643\n",
            "Summary & Description: interpretation numeric literals without explicit type suffix \n",
            " This could be either a documentation or implementation issue.\n",
            "\n",
            "Section “16.3.3. Numeric literals” of the documentation shows some examples of numeric literals, with and without explicit type suffixes:\n",
            "\n",
            "* “1” is indicated as a “simple integer literal”;\n",
            "* “1L” is a “simple integer literal, typed as a long”;\n",
            "* “100.5” is “decimal notation”;\n",
            "* “100.5F” is “decimal notation, typed as a float”;\n",
            "* “1e+2” is “scientific notation”;\n",
            "* “1e+2F” is “scientific notation, typed as a float”.\n",
            "\n",
            "It also states that “It’s not usually necessary to specify the precision explicitly.”\n",
            "\n",
            "The problem I have with this is that it does not state how literals are interpreted when the type suffix is not specified. \n",
            "\n",
            "My initial reading was that “100.5” would be interpreted as a BigDecimal. This is because the term “decimal” itself is a bit ambiguous, and the example is distinguished from the next one, which is indicated as “typed as float”. \n",
            "\n",
            "However, it seems that it is in fact interpreted as float. I ran into this with a JPQL query containing a literal value that cannot be exactly represented as a float:\n",
            "\n",
            "{{SELECT b.isbn, b.title, b.score FROM Book b WHERE b.score = 199999.99}}\n",
            "\n",
            "Which is translated to the following SQL:\n",
            "\n",
            "{{select b1_0.ISBN_,b1_0.TITLE_,b1_0.SCORE_ from BOOK b1_0 where b1_0.SCORE_=199999.98}}\n",
            "\n",
            "(Note that Book.score is a BigDecimal in the Java model class)\n",
            "\n",
            "So IMO it would help if the documentation would explicitly state how such literals are interpreted. One might also wonder if float (rather than say, double) is a good default representation. In Java, according to the JLS Section 3.10.2, \"Floating-Point Literals,\" a floating-point literal without a suffix is of type {{double}} by default. The JPA 3.1 spec states that “Approximate literals support the use Java floating point literal syntax as well as SQL approximate numeric literal syntax.” This would suggest to me that {{double}} should be the default for JPQL as well., Similarity: 0.0423\n",
            "Summary & Description: state kotlins overridden properties correctly retrieved field access used \n",
            " This came up while looking into [https://github.com/quarkusio/quarkus/issues/33740|https://github.com/quarkusio/quarkus/issues/33740|smart-link] \n",
            "\n",
            "When there’s an entity hierarchy that relies on the usage of overridden properties, a state built for a subtype ends up having nulls for such a property. For example, with a model\n",
            "\n",
            "{noformat}@Entity\n",
            "@Table(name = \"shape\")\n",
            "@Inheritance(strategy = InheritanceType.JOINED)\n",
            "abstract class Shape(\n",
            "\n",
            "  @Id\n",
            "  @JdbcTypeCode(SqlTypes.VARCHAR)\n",
            "  @Column(name = \"id\", updatable = false, nullable = false, unique = true)\n",
            "  open val id: UUID,\n",
            "\n",
            "  @Length(max = 100)\n",
            "  @Column(name = \"name\", nullable = false, length = 100)\n",
            "  open var name: String,\n",
            ")\n",
            "\n",
            "@Entity\n",
            "@Table(name = \"rectangle\")\n",
            "@PrimaryKeyJoinColumn(name = \"shape_id\")\n",
            "data class Rectangle(\n",
            "  override val id: UUID,\n",
            "  override var name: String,\n",
            ") : Shape(id, name) {noformat}\n",
            "\n",
            "trying to persist a rectangle entity : \n",
            "\n",
            "{noformat}val rectangle = Rectangle(\n",
            "      id = UUID.randomUUID(),\n",
            "      name = \"Rectangle\",\n",
            "      color = Color.Red,\n",
            "      properties = Properties(\"foo\", \"bar\")\n",
            "    )\n",
            "\n",
            "em.persist(rectangle){noformat}\n",
            "\n",
            "will result in [https://github.com/hibernate/hibernate-orm/blob/f22d7e1328c0e063528eb8a16ccaf6a064e8f713/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractSaveEventListener.java#L325|https://github.com/hibernate/hibernate-orm/blob/f22d7e1328c0e063528eb8a16ccaf6a064e8f713/hibernate-core/src/main/java/org/hibernate/event/internal/AbstractSaveEventListener.java#L325|smart-link] returning an array of nulls and failing the operation.\n",
            "\n",
            "Also, confirmed that switching to {{@Access(AccessType.PROPERTY)}} for such properties helps to work around the problem.\n",
            "\n",
            "\n",
            "\n",
            "Note: issue does not affect 5.6 as, in the end – fields were accessed by a Feild form a subtype rather than a supertype. , Similarity: 0.1703\n",
            "Summary & Description: polymorphic queries interfaces results exception sqmroot yet resolved tablegroup \n",
            " Query  SELECT COUNT(xref) from org.hibernate.bugs.IEntityA xref \n",
            "\n",
            "results in exception\n",
            "\n",
            "java.lang.IllegalArgumentException: org.hibernate.query.sqm.InterpretationException: Error interpreting query [SqmRoot not yet resolved to TableGroup]; this may indicate a semantic (user query) problem or a bug in the parser [SqmRoot not yet resolved to TableGroup], Similarity: 0.2722\n",
            "Summary & Description: hql id function work mappings \n",
            " The {{type()}} function _does_ work., Similarity: 0.1434\n",
            "Summary & Description: fix hhh15759 broke code \n",
            " Hello Hibernate Team,\n",
            "\n",
            "My team and I have tried updating one of our main software projects from Hibernate 6.1.6 to 6.2.3 and we are unable to perform this upgrade due to an issue.\n",
            "\n",
            "I have dug around enough, and have figured out the particular commit which is causing the issue.\n",
            "\n",
            "The following code (hibernate-core/src/main/java/org/hibernate/mapping/Set.java:createPrimaryKey) needs to be looked at again and re-evaluated. I can provide a test-case in time, but as of right now, I do not have the test-case for you.\n",
            "\n",
            "Here is a link to the particular commit which prevents us from upgrading to 6.2.3:\n",
            "\n",
            "[https://github.com/hibernate/hibernate-orm/commit/9341df0b8b5c1eee2a54efd9c2404d511490c836|https://github.com/hibernate/hibernate-orm/commit/9341df0b8b5c1eee2a54efd9c2404d511490c836|smart-link] \n",
            "\n",
            "Old (working) code from 6.1.6 tag:\n",
            "\n",
            "{noformat}void createPrimaryKey() {\n",
            "\tif ( !isOneToMany() ) {\n",
            "\t\tPrimaryKey pk = new PrimaryKey( getCollectionTable() );\n",
            "\t\tpk.addColumns( getKey() );{noformat}\n",
            "\n",
            "\n",
            "New (broken) code from 6.2.3 tag:\n",
            "\n",
            "{noformat}void createPrimaryKey() {\n",
            "\tif ( !isOneToMany() ) {\n",
            "\t\tfinal Table collectionTable = getCollectionTable();\n",
            "\t\tPrimaryKey pk = collectionTable.getPrimaryKey();\n",
            "\t\tif ( pk == null ) {\n",
            "\t\t\tpk = new PrimaryKey( getCollectionTable() );\n",
            "\t\t}\n",
            "\t\tpk.addColumns( getKey() );{noformat}\n",
            "\n",
            "\n",
            "\n",
            "It looks like dreab8 (*Andrea Boriero*) was trying to solve this particular Jira ID: [https://hibernate.atlassian.net/browse/HHH-15759|https://hibernate.atlassian.net/browse/HHH-15759|smart-link]\n",
            "\n",
            "\n",
            "\n",
            "Now I am not sure what the final fix should be, as reverting this commit may cause the original issue to break as well, however I am certain that current state the code is in is not the correct solution, as it causes major breakage in our (very) large project.\n",
            "\n",
            "I would suggest playing around with a debugger to understand what is going on here.\n",
            "\n",
            "Here’s my annotation:\n",
            "\n",
            "{noformat}@ElementCollection(fetch=FetchType.EAGER)\n",
            "@CollectionTable(name=\"interlocking\",joinColumns=@JoinColumn(name=\"ctl_interlocking\"))\n",
            "@Column(name=\"idn\")\n",
            "private Set<Integer> ctlInterlockingInterlockingIdns  = new HashSet<Integer>();{noformat}\n",
            "\n",
            "\n",
            "\n",
            "Here is the original exception I got:\n",
            "\n",
            "{noformat}Exception in thread \"main\" org.hibernate.MappingException: Foreign key (FKntc3fe3p6srhxyr5cbmvtcq40:contact_rail_at_location [interlocking])) must have same number of columns as the referenced primary key (interlocking [idn,ctl_interlocking])\n",
            "        at org.hibernate.mapping.ForeignKey.alignColumns(ForeignKey.java:138)\n",
            "        at org.hibernate.mapping.ForeignKey.alignColumns(ForeignKey.java:119)\n",
            "        at org.hibernate.boot.internal.InFlightMetadataCollectorImpl.secondPassCompileForeignKeys(InFlightMetadataCollectorImpl.java:2010)\n",
            "        at org.hibernate.boot.internal.InFlightMetadataCollectorImpl.secondPassCompileForeignKeys(InFlightMetadataCollectorImpl.java:1974)\n",
            "        at org.hibernate.boot.internal.InFlightMetadataCollectorImpl.processSecondPasses(InFlightMetadataCollectorImpl.java:1818)\n",
            "        at org.hibernate.boot.model.process.spi.MetadataBuildingProcess.complete(MetadataBuildingProcess.java:328)\n",
            "        at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.metadata(EntityManagerFactoryBuilderImpl.java:1380)\n",
            "        at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:1451)\n",
            "        at org.hibernate.jpa.HibernatePersistenceProvider.createEntityManagerFactory(HibernatePersistenceProvider.java:55)\n",
            "        at jakarta.persistence.Persistence.createEntityManagerFactory(Persistence.java:80)\n",
            "        at g.b.c.p.JpaManager.<init>(JpaManager.java:122)\n",
            "        at g.b.i.r.c.SvgLoad.<init>(SvgLoad.java:47)\n",
            "        at g.b.i.r.c.SvgLoad.main(SvgLoad.java:65)\n",
            "{noformat}\n",
            "\n",
            "In our particular situation, we believe “idn” in this case should not be part of the referenced primary key (interlocking [idn,ctl_interlocking]). That is the mistake that is breaking the code., Similarity: 0.2456\n",
            "Summary & Description: upgrading 617final 622final breaks criteria queries model inheritance \n",
            " Error message:\n",
            "\n",
            "{code:java}\n",
            "Cannot invoke \"org.hibernate.sql.ast.tree.from.TableGroup.findTableGroupJoin(org.hibernate.sql.ast.tree.from.TableGroup)\" because \"parentParentTableGroup\" is null\n",
            "java.lang.NullPointerException: Cannot invoke \"org.hibernate.sql.ast.tree.from.TableGroup.findTableGroupJoin(org.hibernate.sql.ast.tree.from.TableGroup)\" because \"parentParentTableGroup\" is null\n",
            "{code}\n",
            "\n",
            "Discovered while upgrading a spring-boot+jpa app from 3.0.7 to 3.1.0, which upgrades Hibernate from 6.1.7 to 6.2.2.\n",
            "See testcase H8BugTest for a reproducer (the project also contains ways to trigger this from a spring-boot app, but the mentioned one should be good enough).\n",
            "The testcase findStreet which uses a CriteriaQuery to fetch a Street works on all versions.\n",
            "The testcase findAddress which uses a CriteriaQuery to fetch an Address breaks on 6.2.2+, but works on 6.1.7. Address has a simple use of inheritance, which seems to be the trigger of the problem.\n",
            "Versions of Hibernate to use can be controlled from gradle.properties. [^hibernate-bug2.zip] , Similarity: 0.3142\n",
            "Summary & Description: unexpected warning hhh100001 jdbc driver return expected number row counts \n",
            " When batching is turned on for entities that update multiple tables  when updated following warn is logged:\n",
            "\n",
            "{{HHH100001: JDBC driver did not return the expected number of row counts}}\n",
            "\n",
            "Problem is in {{org.hibernate.engine.jdbc.batch.internal.BatchImpl.checkRowCounts}} when determining {{expectedNumberOfCounts}}. In case when we are updating one entity (which will set {{batchPosition}} to 1 ) which  for example extends entity with inheritance strategy set to {{InheritanceType.JOINED}} , thus creating two update statements to be executed in DB, {{expectedNumberOfCounts}} will be wrongfully  determined to be 0 (1/2) and warning will be logged. This is definitely wrong. Also in {{org.hibernate.engine.jdbc.batch.internal.BatchImpl.checkRowCounts }}  when logging warning expected  and actual are switched.  Attached test case produces warning, see the console after execution\n",
            "\n",
            "Edit: One more thing, in example described above (first entity inheriting other via {{InheritanceType.JOINED}} …) {{org.hibernate.engine.jdbc.batch.internal.BatchImpl.checkRowCounts}} is called only for identifier table, it seems that it should be called for all affected tables. , Similarity: 0.2263\n",
            "Summary & Description: ispartofkey assertion throws quering complex embeddedid \n",
            " {{java.lang.AssertionError}} is thrown when quering entity id which is complex embedded id\n",
            "\n",
            "Problems was noticed in Hibernate 6.2.3.Final with Spring Boot 3.0.0, In Hibernate 5 function worked correctly. (I am migrating my application to new Spring Boot 3.0.0)\n",
            "\n",
            "!image-20230529-100327.png|width=100%!\n",
            "\n",
            "To reproduce problem use attached example application, run {{DemoApplicationTests.fetchSomeEntityIds}} test, Similarity: 0.3334\n",
            "Summary & Description: reading entities using mappedsuperclass work classes foreign packages \n",
            " {noformat}@MappedSuperclass\n",
            "Inherited\n",
            "  @Id\n",
            "  String id;\n",
            "  String name;\n",
            "  \n",
            "Inheriting extends Inherited{noformat}\n",
            "\n",
            "\n",
            "\n",
            "{{java.lang.NoSuchMethodError}} is thrown when reading entity extending other class in different package,\n",
            "when both classes (inherited and inheriting) are in same package problem disappears\n",
            "\n",
            "Problems was noticed in Hibernate 6.2.3.Final with Spring Boot 3.0.0, In Hibernate 5 function worked correctly. (I am migrating my application to new Spring Boot 3.0.0)\n",
            "\n",
            "!image-20230529-082030.png|width=100%!\n",
            "\n",
            "To reproduce problem use attached example application, execute get endpoint, Similarity: 0.3346\n",
            "Summary & Description: embeddedid foreign key comparator throws npe orderupdates enabled \n",
            " {{java.lang.NullPointerException}} is thrown when saving entity having complex embedded foreign keys with {{order_updates}} set to true (maybe same might happen with {{order_inserts}} set to true)\n",
            "\n",
            "Problems was noticed in Hibernate 6.2.3.Final with Spring Boot 3.0.0, In Hibernate 5 function worked correctly. (I am migrating my application to new Spring Boot 3.0.0)\n",
            "\n",
            "Of course you may require to implement {{Comparable}} in complex embedded id structures, but please check if it was intended requirement\n",
            "\n",
            "!image-20230527-213441.png|width=100%!\n",
            "\n",
            "To reproduce problem use attached example application, execute post endpoint\n",
            ", Similarity: 0.3428\n",
            "Summary & Description: sql string two entityloader different byte arrays uncomfortable gc1 stringdeduplication \n",
            " Hello,\n",
            "I have a hibernate application with a huge object graph (over 2000 tables with over 20 columns per table).\n",
            "As known, this will lead to huge memory usage during startup. So I walked over the known tips; configuring the Query plan cache, the default_batch_fetch_size, the batch_fetch_style, and all the stuff.\n",
            "\n",
            "Now, some of my EntityLoaders (within the same singleTableEntityPersister), have exactly the same generated SQL (exactly character by character), so I was looking if Hibernate offers a way to share these Strings (SQL) between EntityLoaders without success.\n",
            "\n",
            "So I used the GC1 StringDeduplication but without gaining too much. The reason seems to be that even if Sql(s) are the same (visually) they do not have the same byte array, and the GC1 won't be able to deduplicate the String and memory still occupied.\n",
            "Can It be related to Encoding when hibernate create the SQl String? No idea. Maybe I'm missing something.\n",
            "\n",
            "PS: I know that there was a big improvement beginning from version 5.2.18 but I created this ticket maybe the same behavior still exists., Similarity: 0.2418\n",
            "Summary & Description: saving entities using mappedsuperclass work classes foreign packages \n",
            " {noformat}@MappedSuperclass\n",
            "Inherited\n",
            "  @Id\n",
            "  String id;\n",
            "  String name;\n",
            "  \n",
            "Inheriting extends Inherited{noformat}\n",
            "\n",
            "\n",
            "\n",
            "{{java.lang.NoSuchMethodError}} is thrown when saving entity extending other class in different package,\n",
            "when both classes (inherited and inheriting) are in same package problem disappears\n",
            "\n",
            "Problems was noticed in Hibernate 6.2.3.Final with Spring Boot 3.0.0, In Hibernate 5 function worked correctly. (I am migrating my application to new Spring Boot 3.0.0)\n",
            "\n",
            "!image-20230526-154045.png|width=100%!\n",
            "\n",
            "\n",
            "\n",
            "To reproduce problem use attached example application, execute post endpoint, Similarity: 0.3535\n",
            "Summary & Description: persister null validation lazy collections \n",
            " A NullPointerException is thrown during delete when using an entity with lazy collections and tomcat-embed-el:10.1.8 on the classpath. The issue only occurs when a fresh entitymanager instance is used to delete the entity.\n",
            "\n",
            "For a more detailled analysis please have a look at the discussion here: [https://github.com/spring-projects/spring-boot/issues/35617|https://github.com/spring-projects/spring-boot/issues/35617|smart-link] \n",
            "\n",
            "A sample application showcasing the bug can be found here: [https://github.com/wilkinsona/spring-hibernate-bug-demo/tree/pure-jpa|https://github.com/wilkinsona/spring-hibernate-bug-demo/tree/pure-jpa|smart-link] \n",
            "\n",
            "\n",
            "\n",
            "{noformat}ay 25, 2023 5:47:45 PM org.hibernate.jpa.internal.util.LogHelper logPersistenceUnitInformation\n",
            "INFO: HHH000204: Processing PersistenceUnitInfo [name: test]\n",
            "May 25, 2023 5:47:46 PM org.hibernate.Version logVersion\n",
            "INFO: HHH000412: Hibernate ORM core version 6.2.2.Final\n",
            "May 25, 2023 5:47:46 PM org.hibernate.cfg.Environment <clinit>\n",
            "INFO: HHH000406: Using bytecode reflection optimizer\n",
            "May 25, 2023 5:47:46 PM org.hibernate.engine.jdbc.connections.internal.ConnectionProviderInitiator initiateService\n",
            "INFO: HHH000130: Instantiating explicit connection provider: org.hibernate.hikaricp.internal.HikariCPConnectionProvider\n",
            "[main] INFO com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Starting...\n",
            "[main] INFO com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Added connection conn0: url=jdbc:h2:mem:test user=ROOT\n",
            "[main] INFO com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Start completed.\n",
            "May 25, 2023 5:47:46 PM org.hibernate.engine.jdbc.dialect.internal.DialectFactoryImpl logSelectedDialect\n",
            "INFO: HHH035001: Using dialect: org.hibernate.dialect.H2Dialect, version: 2.1.214\n",
            "May 25, 2023 5:47:46 PM org.hibernate.bytecode.internal.BytecodeProviderInitiator buildBytecodeProvider\n",
            "INFO: HHH000021: Bytecode provider name : bytebuddy\n",
            "May 25, 2023 5:47:46 PM org.hibernate.validator.internal.util.Version <clinit>\n",
            "INFO: HV000001: Hibernate Validator 8.0.0.Final\n",
            "May 25, 2023 5:47:47 PM org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator initiateService\n",
            "INFO: HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]\n",
            "Exception in thread \"main\" jakarta.persistence.RollbackException: Error while committing the transaction\n",
            "\tat org.hibernate.internal.ExceptionConverterImpl.convertCommitException(ExceptionConverterImpl.java:65)\n",
            "\tat org.hibernate.engine.transaction.internal.TransactionImpl.commit(TransactionImpl.java:104)\n",
            "\tat com.example.demo.DemoApplication.deleteUsers(DemoApplication.java:30)\n",
            "\tat com.example.demo.DemoApplication.main(DemoApplication.java:20)\n",
            "Caused by: jakarta.validation.ValidationException: HV000028: Unexpected exception during isValid call.\n",
            "\tat org.hibernate.validator.internal.engine.constraintvalidation.ConstraintTree.validateSingleConstraint(ConstraintTree.java:186)\n",
            "\tat org.hibernate.validator.internal.engine.constraintvalidation.SimpleConstraintTree.validateConstraints(SimpleConstraintTree.java:66)\n",
            "\tat org.hibernate.validator.internal.engine.constraintvalidation.ConstraintTree.validateConstraints(ConstraintTree.java:75)\n",
            "\tat org.hibernate.validator.internal.metadata.core.MetaConstraint.doValidateConstraint(MetaConstraint.java:130)\n",
            "\tat org.hibernate.validator.internal.metadata.core.MetaConstraint.validateConstraint(MetaConstraint.java:123)\n",
            "\tat org.hibernate.validator.internal.engine.ValidatorImpl.validateMetaConstraint(ValidatorImpl.java:555)\n",
            "\tat org.hibernate.validator.internal.engine.ValidatorImpl.validateConstraintsForSingleDefaultGroupElement(ValidatorImpl.java:518)\n",
            "\tat org.hibernate.validator.internal.engine.ValidatorImpl.validateConstraintsForDefaultGroup(ValidatorImpl.java:488)\n",
            "\tat org.hibernate.validator.internal.engine.ValidatorImpl.validateConstraintsForCurrentGroup(ValidatorImpl.java:450)\n",
            "\tat org.hibernate.validator.internal.engine.ValidatorImpl.validateInContext(ValidatorImpl.java:400)\n",
            "\tat org.hibernate.validator.internal.engine.ValidatorImpl.validate(ValidatorImpl.java:172)\n",
            "\tat org.hibernate.boot.beanvalidation.BeanValidationEventListener.validate(BeanValidationEventListener.java:128)\n",
            "\tat org.hibernate.boot.beanvalidation.BeanValidationEventListener.onPreUpdate(BeanValidationEventListener.java:92)\n",
            "\tat org.hibernate.action.internal.EntityUpdateAction.preUpdate(EntityUpdateAction.java:329)\n",
            "\tat org.hibernate.action.internal.EntityUpdateAction.execute(EntityUpdateAction.java:159)\n",
            "\tat org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:618)\n",
            "\tat org.hibernate.engine.spi.ActionQueue.lambda$executeActions$1(ActionQueue.java:489)\n",
            "\tat java.base/java.util.LinkedHashMap.forEach(LinkedHashMap.java:721)\n",
            "\tat org.hibernate.engine.spi.ActionQueue.executeActions(ActionQueue.java:486)\n",
            "\tat org.hibernate.event.internal.AbstractFlushingEventListener.performExecutions(AbstractFlushingEventListener.java:358)\n",
            "\tat org.hibernate.event.internal.DefaultFlushEventListener.onFlush(DefaultFlushEventListener.java:39)\n",
            "\tat org.hibernate.event.service.internal.EventListenerGroupImpl.fireEventOnEachListener(EventListenerGroupImpl.java:127)\n",
            "\tat org.hibernate.internal.SessionImpl.doFlush(SessionImpl.java:1412)\n",
            "\tat org.hibernate.internal.SessionImpl.managedFlush(SessionImpl.java:485)\n",
            "\tat org.hibernate.internal.SessionImpl.flushBeforeTransactionCompletion(SessionImpl.java:2296)\n",
            "\tat org.hibernate.internal.SessionImpl.beforeTransactionCompletion(SessionImpl.java:1961)\n",
            "\tat org.hibernate.engine.jdbc.internal.JdbcCoordinatorImpl.beforeTransactionCompletion(JdbcCoordinatorImpl.java:439)\n",
            "\tat org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl.beforeCompletionCallback(JdbcResourceLocalTransactionCoordinatorImpl.java:169)\n",
            "\tat org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl$TransactionDriverControlImpl.commit(JdbcResourceLocalTransactionCoordinatorImpl.java:267)\n",
            "\tat org.hibernate.engine.transaction.internal.TransactionImpl.commit(TransactionImpl.java:101)\n",
            "\t... 2 more\n",
            "Caused by: java.lang.NullPointerException: Cannot invoke \"org.hibernate.persister.collection.CollectionPersister.isExtraLazy()\" because \"persister\" is null\n",
            "\tat org.hibernate.collection.spi.AbstractPersistentCollection.lambda$readSize$0(AbstractPersistentCollection.java:155)\n",
            "\tat org.hibernate.collection.spi.AbstractPersistentCollection.withTemporarySessionIfNeeded(AbstractPersistentCollection.java:265)\n",
            "\tat org.hibernate.collection.spi.AbstractPersistentCollection.readSize(AbstractPersistentCollection.java:148)\n",
            "\tat org.hibernate.collection.spi.PersistentSet.size(PersistentSet.java:151)\n",
            "\tat org.hibernate.validator.internal.constraintvalidators.bv.notempty.NotEmptyValidatorForCollection.isValid(NotEmptyValidatorForCollection.java:37)\n",
            "\tat org.hibernate.validator.internal.constraintvalidators.bv.notempty.NotEmptyValidatorForCollection.isValid(NotEmptyValidatorForCollection.java:22)\n",
            "\tat org.hibernate.validator.internal.engine.constraintvalidation.ConstraintTree.validateSingleConstraint(ConstraintTree.java:180)\n",
            "\t... 31 more\n",
            "{noformat}, Similarity: 0.2807\n",
            "Summary & Description: polymorphic association ignores column insertableupdatable attributes \n",
            " Starting in Hibernate ORM 6.2, polymorphic associations using {{@Any}} raise {{MappingException}}s if either the key or discriminator column is mapped to another (mutable) attribute in the owning entity. This prevents read-only {{@Any}} associations in which the duplicated column mappings cannot be defined with {{@Column(insertable=false, updatable=false)}}\n",
            "\n",
            "\n",
            "\n",
            "*Solution*\n",
            "\n",
            "{code:java}package org.hibernate.mapping;\n",
            "\n",
            "...\n",
            "\n",
            "public class Any extends SimpleValue {\n",
            "  \n",
            "  ... \n",
            "   \n",
            "  public void setDiscriminator(BasicValue discriminatorDescriptor) {\n",
            "\tthis.discriminatorDescriptor = discriminatorDescriptor;\n",
            "\tif ( discriminatorDescriptor.getColumn() instanceof Column ) {\n",
            "\t\t// Current: justAddColumn( (Column) discriminatorDescriptor.getColumn() );\n",
            "\t\tjustAddColumn(\n",
            "\t\t\t(Column) discriminatorDescriptor.getColumn(),\n",
            "\t\t\t// Pass insertable/updatable from discriminatorDescriptor\n",
            "\t\t\tdiscriminatorDescriptor.isColumnInsertable(0),\n",
            "\t\t\tdiscriminatorDescriptor.isColumnUpdateable(0)\n",
            "\t\t);\n",
            "\t}\n",
            "\telse {\n",
            "\t\tjustAddFormula( (Formula) discriminatorDescriptor.getColumn() );\n",
            "\t}\n",
            "  }\n",
            "  \n",
            "  ...\n",
            "  \n",
            "  public void setKey(BasicValue keyDescriptor) {\n",
            "\tthis.keyDescriptor = keyDescriptor;\n",
            "\tif ( keyDescriptor.getColumn() instanceof Column ) {\n",
            "\t\t// Current: justAddColumn( (Column) keyDescriptor.getColumn() );\n",
            "\t\tjustAddColumn(\n",
            "\t\t\t(Column) keyDescriptor.getColumn(),\n",
            "\t\t\t// Pass insertable/updatable from keyDescriptor\n",
            "\t\t\tkeyDescriptor.isColumnInsertable(0),\n",
            "\t\t\tkeyDescriptor.isColumnUpdateable(0)\n",
            "\t\t);\n",
            "\t}\n",
            "\telse {\n",
            "\t\tjustAddFormula( (Formula) keyDescriptor.getColumn() );\n",
            "\t}\n",
            "  }\n",
            "}\n",
            "{code}, Similarity: 0.1567\n",
            "Summary & Description: auto type discovery aggregate functions wrongly determines integer instead bigdecimal oracle \n",
            " Hi,\n",
            "\n",
            "\n",
            "\n",
            "The Oracle PL/SQL Native SUM function (calcaulated field) is not working as expected, it is converting float to integer values, the next is a following example:\n",
            "\n",
            "\n",
            "\n",
            "{noformat}    @Override\n",
            "    public ArrayList<Object[]> testSUMError() {\n",
            "        Session session = sessionFactory.getCurrentSession();\n",
            "        \n",
            "        Query objQuery = session.createNativeQuery(\"\"\"\n",
            "            SELECT \n",
            "                19.80 COLUMN_OK, \\\n",
            "                SUM(39.74) COLUMN_FAIL \\\n",
            "            FROM DUAL                                                                      \n",
            "        \"\"\", Object.class);\n",
            "        \n",
            "        return (ArrayList<Object[]>) objQuery.list();\n",
            "    }{noformat}\n",
            "\n",
            "\n",
            "\n",
            "If we test the SELECT the return object is:\n",
            "\n",
            "!imagen-20230531-171622.png|width=1254,height=329!\n",
            "\n",
            "\n",
            "\n",
            "as you can see, the 39 is not even rounding, it only deletes the decimals., Similarity: 0.1356\n",
            "Summary & Description: hibernatecore 620 stopped invoking postgresqldialectinitializefunctionregistryqueryengine \n",
            " Using custom dialect extending PostgreSQLDialect and configured with\n",
            "hibernate.dialect: com.xyz.repository.CustomPostgresqlDialect\n",
            "\n",
            "hibernate-core starting with 6.2.0 stopped invoking initializeFunctionRegistry:\n",
            "\n",
            "custom dialect:\n",
            "{noformat}\n",
            "public class CustomPostgresqlDialect extends PostgreSQLDialect {\n",
            "    public CustomPostgresqlDialect() {\n",
            "        super(DatabaseVersion.make(14, 4));\n",
            "    }\n",
            "    \n",
            "    public CustomPostgresqlDialect(DialectResolutionInfo info) {\n",
            "        super(info);\n",
            "    }\n",
            "\n",
            "    public CustomPostgresqlDialect(DatabaseVersion version) {\n",
            "        super(version);\n",
            "    }\n",
            "\n",
            "    public CustomPostgresqlDialect(DatabaseVersion version, PostgreSQLDriverKind driverKind) {\n",
            "        super(version);\n",
            "    }\n",
            "\n",
            "    @Override\n",
            "    public void initializeFunctionRegistry(QueryEngine queryEngine) {\n",
            "        super.initializeFunctionRegistry(queryEngine);\n",
            "        queryEngine.getSqmFunctionRegistry().register(PostgresqlJsonArrayFunction.NAME, new PostgresqlJsonArrayFunction());\n",
            "    }\n",
            "}\n",
            "{noformat}\n",
            ", Similarity: 0.2761\n",
            "Summary & Description: mappedsuperclass generic collections mapped correctly \n",
            " We have noticed a critical issue with loading of entities with MapperSuperClasses having generic collections. The entities are not loaded correctly, where these generic collection fields are configured with other entities extending the same MapperSuperClass. Let me explain the situation with an example:\n",
            "\n",
            "\n",
            "\n",
            "Let’s say we have a MappedSuperClass A with a generic collection field:\n",
            "\n",
            "\n",
            "\n",
            "{code:java}@MappedSuperclass\n",
            "public abstract class Configuration<T> {\n",
            "\n",
            "    @Id\n",
            "    @GeneratedValue(strategy = GenerationType.IDENTITY)\n",
            "    @Column(name = \"ID\", nullable = false)\n",
            "    private Long id;\n",
            "\n",
            "    @OneToMany(mappedBy = \"configuration\", cascade = ALL, orphanRemoval = true)\n",
            "    private Set<T> items;\n",
            "    \n",
            "}{code}\n",
            "\n",
            "\n",
            "\n",
            "and subtypes:\n",
            "\n",
            "\n",
            "\n",
            "{noformat}@Entity\n",
            "@Entity\n",
            "@Table(name = \"A_CONFIGURATION\")\n",
            "public class AConfiguration extends Configuration<AItem> {\n",
            "\n",
            "}\n",
            "\n",
            "@Entity\n",
            "@Table(name = \"A_ITEM\")\n",
            "public class AItem { \n",
            "\n",
            "    @Id\n",
            "    @GeneratedValue(strategy = GenerationType.IDENTITY)\n",
            "    @Column(name = \"ID\", updatable = false, nullable = false)\n",
            "    private Long id;\n",
            "\n",
            "    @ManyToOne(fetch = FetchType.LAZY, cascade = CascadeType.ALL)\n",
            "    @JoinColumn(name = \"CONFIGURATION_ID\")\n",
            "    private AConfiguration configuration;\n",
            "    \n",
            "}\n",
            "\n",
            "@Entity\n",
            "@Table(name = \"B_CONFIGURATION\")\n",
            "public class BConfiguration extends Configuration<BItem> {\n",
            "\n",
            "}\n",
            "\n",
            "@Entity\n",
            "@Table(name = \"B_ITEM\")\n",
            "public class BItem { \n",
            "    \n",
            "    @Id\n",
            "    @GeneratedValue(strategy = GenerationType.IDENTITY)\n",
            "    @Column(name = \"ID\", updatable = false, nullable = false)\n",
            "    private Long id;\n",
            "\n",
            "    @ManyToOne(fetch = FetchType.LAZY, cascade = CascadeType.ALL)\n",
            "    @JoinColumn(name = \"CONFIGURATION_ID\")\n",
            "    private BConfiguration configuration;\n",
            "\n",
            "    @OneToMany(mappedBy = \"item\", cascade = CascadeType.ALL, orphanRemoval = true)\n",
            "    private Set<BItemChild> children = new LinkedHashSet<>();\n",
            "}\n",
            "\n",
            "@Entity\n",
            "@Table(name = \"B_ITEM_CHILD\")\n",
            "public class BItemChild {\n",
            "\n",
            "    @Id\n",
            "    @GeneratedValue(strategy = GenerationType.IDENTITY)\n",
            "    @Column(name = \"id\", nullable = false)\n",
            "    private Long id;\n",
            "\n",
            "    @ManyToOne(fetch = FetchType.LAZY, cascade = CascadeType.ALL)\n",
            "    @JoinColumn(name = \"CONFIGURATION_ID\")\n",
            "    private BItem item;\n",
            "}{noformat}\n",
            "\n",
            "\n",
            "\n",
            "The following jpql query throws an error:\n",
            "\n",
            "\n",
            "\n",
            "{code:sql}    select config from BConfiguration config\n",
            "                        left join treat(config.items as BItem) item\n",
            "                        left join item.children child\n",
            "                        left join child.id{code}\n",
            "\n",
            "Stacktrace:\n",
            "\n",
            "{noformat}...\n",
            "\n",
            "Caused by: org.hibernate.query.sqm.InterpretationException: Error interpreting query [select config from BConfiguration config\n",
            "            left join treat(config.items as BItem) item\n",
            "            left join item.children child\n",
            "            left join child.id\n",
            "]; this may indicate a semantic (user query) problem or a bug in the parser [select config from BConfiguration config\n",
            "            left join treat(config.items as BItem) item\n",
            "            left join item.children child\n",
            "            left join child.id\n",
            "]\n",
            "\tat org.hibernate.query.hql.internal.StandardHqlTranslator.translate(StandardHqlTranslator.java:97) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.internal.AbstractSharedSessionContract.lambda$interpretHql$2(AbstractSharedSessionContract.java:744) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.internal.QueryInterpretationCacheStandardImpl.createHqlInterpretation(QueryInterpretationCacheStandardImpl.java:141) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.internal.QueryInterpretationCacheStandardImpl.resolveHqlInterpretation(QueryInterpretationCacheStandardImpl.java:128) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.internal.AbstractSharedSessionContract.interpretHql(AbstractSharedSessionContract.java:741) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.internal.AbstractSharedSessionContract.createQuery(AbstractSharedSessionContract.java:786) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\t... 43 common frames omitted\n",
            "Caused by: java.lang.IllegalArgumentException: org.hibernate.query.SemanticException: Could not resolve attribute 'children' of 'com.example.demo.entities.AItem'\n",
            "\tat org.hibernate.query.sqm.SqmPathSource.getSubPathSource(SqmPathSource.java:61) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.QualifiedJoinPathConsumer.createJoin(QualifiedJoinPathConsumer.java:182) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.QualifiedJoinPathConsumer$AttributeJoinDelegate.consumeIdentifier(QualifiedJoinPathConsumer.java:236) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.QualifiedJoinPathConsumer.consumeIdentifier(QualifiedJoinPathConsumer.java:103) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.SemanticQueryBuilder.visitSimplePath(SemanticQueryBuilder.java:5208) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.SemanticQueryBuilder.visitIndexedPathAccessFragment(SemanticQueryBuilder.java:5155) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.SemanticQueryBuilder.visitGeneralPathFragment(SemanticQueryBuilder.java:5124) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.SemanticQueryBuilder.visitGeneralPathFragment(SemanticQueryBuilder.java:253) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.grammars.hql.HqlParser$GeneralPathFragmentContext.accept(HqlParser.java:4513) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.SemanticQueryBuilder.visitPath(SemanticQueryBuilder.java:5116) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.SemanticQueryBuilder.visitPath(SemanticQueryBuilder.java:253) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.grammars.hql.HqlParser$PathContext.accept(HqlParser.java:4311) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.SemanticQueryBuilder.consumeJoin(SemanticQueryBuilder.java:2193) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.SemanticQueryBuilder.visitEntityWithJoins(SemanticQueryBuilder.java:1887) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.SemanticQueryBuilder.visitFromClause(SemanticQueryBuilder.java:1865) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.SemanticQueryBuilder.visitQuery(SemanticQueryBuilder.java:1141) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.SemanticQueryBuilder.visitQuerySpecExpression(SemanticQueryBuilder.java:937) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.SemanticQueryBuilder.visitQuerySpecExpression(SemanticQueryBuilder.java:253) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.grammars.hql.HqlParser$QuerySpecExpressionContext.accept(HqlParser.java:1818) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.SemanticQueryBuilder.visitSimpleQueryGroup(SemanticQueryBuilder.java:931) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.SemanticQueryBuilder.visitSimpleQueryGroup(SemanticQueryBuilder.java:253) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.grammars.hql.HqlParser$SimpleQueryGroupContext.accept(HqlParser.java:1711) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.SemanticQueryBuilder.visitSelectStatement(SemanticQueryBuilder.java:418) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.SemanticQueryBuilder.visitStatement(SemanticQueryBuilder.java:377) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.SemanticQueryBuilder.buildSemanticModel(SemanticQueryBuilder.java:295) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\tat org.hibernate.query.hql.internal.StandardHqlTranslator.translate(StandardHqlTranslator.java:81) ~[hibernate-core-6.2.3.Final.jar:6.2.3.Final]\n",
            "\t... 48 common frames omitted\n",
            "Caused by: org.hibernate.query.SemanticException: Could not resolve attribute 'children' of 'com.example.demo.entities.AItem'\n",
            "\t... 74 common frames omitted{noformat}\n",
            "\n",
            "\n",
            "\n",
            "So from the error it seems hibernate thinks ‘children' field belongs to the 'com.example.demo.entities.AItem' which doesn’t have this field. \n",
            "\n",
            "\n",
            "\n",
            "Also I noticed that hibernate searches for a suitable type for the generic collection and it assigns it the first subtype it encounters such as AConfiguration instead of BConfiguration. If we had renamed Aconfiguration to CConfiguration then it doesn’t complain anymore.\n",
            "\n",
            "\n",
            "\n",
            "This is a blocker for us and prevents us from using generic collections in the MappedSuperClasses., Similarity: 0.3122\n",
            "Summary & Description: dirty attributes updated entities superclasses \n",
            " {{AbstractEntityPersister#resolveDirtyAttributeIndexes}} checks the arrays of dirty attributes against the entity’s attribute mappings. (Line 2607 in version 6.1.7) As an optimization, it assumes that both arrays are alphabetically sorted to reduce the algorithmoic complexity to O(n). However, for entities with superclasses, the attribute mappings aren’t sorted alphabatically. The superclass attributes are always listed first. This causes some dirty attribute names to never be checked against their appropriate attribute mapping.\n",
            "\n",
            "In our case, this causes some changed fields to be silently skipped on updates, leading to data corruption and unexpected/undefined behaviour in our application logic., Similarity: 0.1355\n",
            "Summary & Description: changes jdbctypecodesqltypesjson written db \n",
            " I have a JSON-Mapping in my entity\n",
            "\n",
            "{code:java}@Entity\n",
            "public class MyEntity {\n",
            "    @Id\n",
            "    private Long id;\n",
            "    @JdbcTypeCode(SqlTypes.JSON)\n",
            "    private MyJson jsonProperty;\n",
            "    private String info;\n",
            "  }{code}\n",
            "\n",
            "MyJson is a simple POJO:\n",
            "\n",
            "{code:java}@Embeddable\n",
            "public class MyJson {\n",
            "    private String stringProp;\n",
            "    private Long longProp;\n",
            "}{code}\n",
            "\n",
            "If i change only the jsonProperty, it seems the entity is _not marked dirty_ → changes are not written to the DB.\n",
            "\n",
            "If i change any other field-value, too (in my test-case the String-field _info_), the entity is marked dirty and all changes are written to DB, even the JSON-changes.\n",
            "\n",
            " (see _MyEntityTest.java_ in attached Test-project):\n",
            "\n",
            "{code:java}@QuarkusTest\n",
            "@Transactional(Transactional.TxType.REQUIRES_NEW)\n",
            "class MyEntityTest {\n",
            "\n",
            "    @Inject\n",
            "    EntityManager em;\n",
            "    static final long PK = 123L;\n",
            "    static final String CHANGED = \"CHANGED\";\n",
            "\n",
            "    @Test\n",
            "    void shouldCreateUpdateAndSelectMyEntity() throws Exception {\n",
            "        insert();\n",
            "        findAndUpdate();\n",
            "        selectFiltered();\n",
            "    }\n",
            "\n",
            "    void insert() {\n",
            "        MyEntity myEntity = new MyEntity();\n",
            "        myEntity.setId(PK);\n",
            "        MyJson myJson = new MyJson();\n",
            "        myJson.setLongProp(100L);\n",
            "        myJson.setStringProp(\"Hello\");\n",
            "        myEntity.setJsonProperty(myJson);\n",
            "        em.persist(myEntity);\n",
            "    }\n",
            "\n",
            "    void findAndUpdate() {\n",
            "        MyEntity found = em.find(MyEntity.class, PK);\n",
            "        found.getJsonProperty().setStringProp(CHANGED);\n",
            "//        found.setInfo(CHANGED); // by changing any other property of the entity, it will be marked as dirty and EVERY change will be written to the DB\n",
            "    }\n",
            "\n",
            "    void selectFiltered() {\n",
            "        List<MyEntity> result = em\n",
            "                .createQuery(\"SELECT e FROM MyEntity e WHERE e.jsonProperty.longProp = :x\", MyEntity.class)\n",
            "                .setParameter(\"x\", 100L)\n",
            "                .getResultList();\n",
            "        assertEquals(1, result.size());\n",
            "        assertEquals(CHANGED, result.get(0).getJsonProperty().getStringProp(), \"json property not changed\");\n",
            "        //assertEquals(CHANGED, result.get(0).getInfo(), \"plain property not changed\"); //see commented code in method 'findAndUpdate'\n",
            "    }\n",
            "}{code}\n",
            "\n",
            "see [https://discourse.hibernate.org/t/changes-in-jsonb-field-do-not-mark-entity-as-dirty/7684/6|https://discourse.hibernate.org/t/changes-in-jsonb-field-do-not-mark-entity-as-dirty/7684/6|smart-link] , Similarity: 0.3417\n",
            "Summary & Description: cant disable global temporary table creation \n",
            " Hibernate creates temporary tables for bulk operations.\n",
            "\n",
            "We're using Oracle (_v19.0.0.0.0_) and our user won't have the privilege to create temporary table.\n",
            "\n",
            "I've tried a lot of different configurations, but {{HTE_}} tables are still created at startup :\n",
            "\n",
            "{noformat}09:07:43.658 INFO  [com.zaxxer.hikari.HikariDataSource      ] HikariPool-1 - Starting...\n",
            "09:07:44.285 INFO  [com.zaxxer.hikari.pool.HikariPool       ] HikariPool-1 - Added connection oracle.jdbc.driver.T4CConnection@6dc5e857\n",
            "09:07:44.286 INFO  [com.zaxxer.hikari.HikariDataSource      ] HikariPool-1 - Start completed.\n",
            "09:07:44.596 INFO  [SQL dialect                             ] HHH000400: Using dialect: org.hibernate.dialect.Oracle12cDialect\n",
            "Hibernate: create global temporary table HTE_xxxxx(...) on commit delete rows\n",
            "Hibernate: create global temporary table HTE_yyyyy(...) on commit delete rows\n",
            "09:07:45.551 INFO  [j.LocalContainerEntityManagerFactoryBean] Initialized JPA EntityManagerFactory for persistence unit 'default'{noformat}\n",
            "\n",
            "Here is the properties I’ve tried : \n",
            "\n",
            "{noformat}spring.jpa.properties.hibernate.query.mutation_strategy=org.hibernate.query.sqm.mutation.internal.inline.InlineMutationStrategy\n",
            "\n",
            "spring.jpa.properties.hibernate.hql.bulk_id_strategy.persistent.create_tables=false\n",
            "spring.jpa.properties.hibernate.hql.bulk_id_strategy.persistent.drop_tables=false\n",
            "spring.jpa.properties.hibernate.hql.bulk_id_strategy.global_temporary.create_tables=false\n",
            "spring.jpa.properties.hibernate.hql.bulk_id_strategy.global_temporary.drop_tables=false{noformat}\n",
            "\n",
            "I can’t find a {{spring.jpa.properties.hibernate.query.insert_strategy}} that is working because it gives me an exception :\n",
            "\n",
            "{noformat}Cannot instantiate the class [org.hibernate.query.sqm.mutation.internal.temptable.LocalTemporaryTableMutationStrategy] because it does not have a constructor that accepts a dialect or an empty constructor{noformat}\n",
            "\n",
            "I didn’t find anything more to try, according to the documentation : [https://docs.jboss.org/hibernate/orm/6.1/userguide/html_single/Hibernate_User_Guide.html#batch-bulk-hql-strategies-non-temporary-table|https://docs.jboss.org/hibernate/orm/6.1/userguide/html_single/Hibernate_User_Guide.html#batch-bulk-hql-strategies-non-temporary-table|smart-link] \n",
            "\n",
            "I also tried to find some help on [StackOverflow|https://stackoverflow.com/questions/76312361/hibernate-6-1-x-spring-boot-avoid-global-temporary-table-creation], without succcess., Similarity: 0.2818\n",
            "Summary & Description: treat correlated alias generates broken sql \n",
            " See the discussion here: [https://discourse.hibernate.org/t/6-2-3-brokes-query-building/7682|https://discourse.hibernate.org/t/6-2-3-brokes-query-building/7682|smart-link] , Similarity: 0.2463\n",
            "Summary & Description: assertionerror queryliteralinit using update versioned entity version long \n",
            " If an entity has a long (or Long) @Version field\n",
            "\n",
            "{noformat}    @Version\n",
            "    private long optimisticVersion;{noformat}\n",
            "\n",
            "A query like the following:\n",
            "\n",
            "{noformat}update versioned Entity set x=true where x=false{noformat}\n",
            "\n",
            "will lead to the following Assertion:\n",
            "\n",
            "{noformat}ava.lang.AssertionError: null\n",
            "\tat org.hibernate.sql.ast.tree.expression.QueryLiteral.<init>(QueryLiteral.java:36)\n",
            "\tat org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.addVersionedAssignment(BaseSqmToSqlAstConverter.java:910)\n",
            "\tat org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.visitUpdateStatement(BaseSqmToSqlAstConverter.java:829)\n",
            "\tat org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.visitUpdateStatement(BaseSqmToSqlAstConverter.java:429)\n",
            "\tat org.hibernate.query.sqm.tree.update.SqmUpdateStatement.accept(SqmUpdateStatement.java:168)\n",
            "\tat org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.translate(BaseSqmToSqlAstConverter.java:767)\n",
            "\tat org.hibernate.query.sqm.internal.SimpleUpdateQueryPlan.createUpdateTranslator(SimpleUpdateQueryPlan.java:116)\n",
            "\tat org.hibernate.query.sqm.internal.SimpleUpdateQueryPlan.executeUpdate(SimpleUpdateQueryPlan.java:61)\n",
            "\tat org.hibernate.query.sqm.internal.QuerySqmImpl.doExecuteUpdate(QuerySqmImpl.java:735)\n",
            "\tat org.hibernate.query.sqm.internal.QuerySqmImpl.executeUpdate(QuerySqmImpl.java:705){noformat}\n",
            "\n",
            "Changing the type of the optimisticVersion field to int/Integer allows to workaround the issue.\n",
            "\n",
            "I have tracked down the problem to the following code in {{BaseSqmToSqlAstConverter.addVersionedAssignment(...)}}:\n",
            "\n",
            "{noformat}\t\t\tvalue = new BinaryArithmeticExpression(\n",
            "\t\t\t\t\tversionColumn,\n",
            "\t\t\t\t\tADD,\n",
            "\t\t\t\t\tnew QueryLiteral<>( 1, versionType ),\n",
            "\t\t\t\t\tversionType\n",
            "\t\t\t);{noformat}\n",
            "\n",
            "1 is an Integer whereas versionType.getJdbcMapping() is a LongJavaType, explaining why the assertions fails in the QueryLiteral constructor.\n",
            "\n",
            "The assertion should probably be relaxed to take into account that an int can be promoted to a long.\n",
            "\n",
            "Or alternatively something like in the caller : \n",
            "\n",
            "versionType.getJavaTypeClass() == Long.class ? {{new QueryLiteral<>( 1L, versionType )}} : {{new QueryLiteral<>( 1, versionType )}}\n",
            "\n",
            "The same issue may happen with other primitive types supporting promotion., Similarity: 0.1693\n",
            "Summary & Description: query path comparison working primary keys \n",
            " Before Version 6.2 it was possible to just write the primary key (mostly a {{long}}) of the type referenced in CriteriaBuilder's {{equal}}, {{in}}, ...-Methods.\n",
            "\n",
            "Since Version 6.2 this no longer works. This is mentioned in the [https://docs.jboss.org/hibernate/orm/6.2/migration-guide/migration-guide.html#query-path-comparison|https://docs.jboss.org/hibernate/orm/6.2/migration-guide/migration-guide.html#query-path-comparison|smart-link] however I assume that the Primary Keys have been overlooked.\n",
            "\n",
            "e.g. the following Code fails\n",
            "\n",
            "{code:java}...\n",
            "\t\tfinal CriteriaBuilder cb = this.getEntityManager().getCriteriaBuilder();\n",
            "\t\tfinal CriteriaQuery<UserAuthLog> cq = cb.createQuery(UserAuthLog.class);\n",
            "\t\t\n",
            "\t\tfinal Root<UserAuthLog> root = cq.from(UserAuthLog.class);\n",
            "\t\tcq.select(root);\n",
            "\t\t\n",
            "\t\t// Problem here\n",
            "\t\tcq.where(cb.equal(root.get(UserAuthLog_.user), userId));\n",
            "\t\t\n",
            "\t\t...{code}\n",
            "\n",
            "where the class {{UserAuthLog}} looks like this:\n",
            "\n",
            "{noformat}\t...\n",
            "\t@NotNull\n",
            "\t@ManyToOne(fetch = FetchType.EAGER)\n",
            "\t@JoinColumn(\n",
            "\t\tname = \"user_id\",\n",
            "\t\tforeignKey = @jakarta.persistence.ForeignKey(value = ConstraintMode.CONSTRAINT)\n",
            "\t)\n",
            "\tprivate UserDetail user;\n",
            "\t...{noformat}\n",
            "\n",
            "and {{UserDetail}} like this\n",
            "\n",
            "{code:java}public class UserDetail\n",
            "{\n",
            "\t...\n",
            "\t\n",
            "\t@Id\n",
            "\t@GeneratedValue(strategy = IDENTITY)\n",
            "\t@Column(name = \"id\", unique = true, nullable = false)\n",
            "\tprivate long id;\n",
            "\t...{code}\n",
            "\n",
            "with the following exception\n",
            "\n",
            "{code:java}Caused by: java.lang.IllegalArgumentException: Can't compare test expression of type [UserDetail] with element of type [basicType@1228(java.lang.Long,-5)]\n",
            "\tat org.hibernate.query.sqm.internal.SqmCriteriaNodeBuilder.assertComparable(SqmCriteriaNodeBuilder.java:2098)\n",
            "\tat org.hibernate.query.sqm.internal.SqmCriteriaNodeBuilder.equal(SqmCriteriaNodeBuilder.java:2121)\n",
            "\tat org.hibernate.query.sqm.internal.SqmCriteriaNodeBuilder.equal(SqmCriteriaNodeBuilder.java:182)\n",
            "\tat XXX.getUserLoginLogs(XXX.java:39)\n",
            "\t...{code}\n",
            "\n",
            "Also consider that some methods like {{in}} use collections with primary keys.\n",
            "\n",
            "\n",
            "\n",
            "The changes were done here: [https://github.com/hibernate/hibernate-orm/pull/6189|https://github.com/hibernate/hibernate-orm/pull/6189]  / [https://hibernate.atlassian.net/browse/HHH-15802|https://hibernate.atlassian.net/browse/HHH-15802] \n",
            "\n",
            "\n",
            "\n",
            "If this can’t be fixed it would be great if we could somehow disable this early query path comparison, so that we don’t have to check our entire DAL-Layer (we are talking about thousands of lines of code) for problems., Similarity: 0.3320\n",
            "Summary & Description: unable query key attribute uses attributeconverter \n",
            " Same as [https://hibernate.atlassian.net/browse/HHH-16241|https://hibernate.atlassian.net/browse/HHH-16241|smart-link], but for entity keys, so I will be reusing most of that issue’s contents (I didn’t test inserts, but I suppose they may be also broken).\n",
            "\n",
            "The model has {{java.time.YearMonth}} attributes being mapped to integers on the DB (MariaDB):\n",
            "\n",
            "{code:java}@Convert(converter = YearMonthConverter.class)\n",
            "@Column(name = \"month\", nullable = false)\n",
            "@Id\n",
            "private YearMonth reportMonth;{code}\n",
            "\n",
            "Converter class:\n",
            "\n",
            "{code:java}public class YearMonthConverter implements AttributeConverter<YearMonth, Integer> {\n",
            "    @Override\n",
            "    public Integer convertToDatabaseColumn(YearMonth attribute) {\n",
            "        return attribute == null ? null : (attribute.getYear() * 100) + attribute.getMonth().getValue();\n",
            "    }\n",
            "\n",
            "    @Override\n",
            "    public YearMonth convertToEntityAttribute(Integer dbData) {\n",
            "        return dbData == null ? null : YearMonth.of(dbData / 100, dbData % 100);\n",
            "    }\n",
            "}{code}\n",
            "\n",
            "Or use {{YearMonthDateType}} from Hypersistence Utils - the result is the same, i.e. building a query like\n",
            "\n",
            "{code:java}entityManager.createQuery(\"SELECT MAX(de.yearMonthKey) FROM DemoEntity de\");{code}\n",
            "\n",
            "results in an exception:\n",
            "\n",
            "{noformat}org.hibernate.QueryException: Parameter 1 of function max() has type COMPARABLE, but argument is of type java.time.YearMonth\n",
            "java.lang.IllegalArgumentException: org.hibernate.QueryException: Parameter 1 of function max() has type COMPARABLE, but argument is of type java.time.YearMonth\n",
            "\tat org.hibernate.internal.ExceptionConverterImpl.convert(ExceptionConverterImpl.java:138)\n",
            "\tat org.hibernate.internal.ExceptionConverterImpl.convert(ExceptionConverterImpl.java:162)\n",
            "\tat org.hibernate.internal.ExceptionConverterImpl.convert(ExceptionConverterImpl.java:168)\n",
            "\tat org.hibernate.internal.AbstractSharedSessionContract.createQuery(AbstractSharedSessionContract.java:795)\n",
            "\tat org.hibernate.internal.AbstractSharedSessionContract.createQuery(AbstractSharedSessionContract.java:704)\n",
            "\tat org.hibernate.internal.AbstractSharedSessionContract.createQuery(AbstractSharedSessionContract.java:120)\n",
            "...\n",
            "Caused by: org.hibernate.QueryException: Parameter 1 of function max() has type COMPARABLE, but argument is of type java.time.YearMonth\n",
            "\tat app//org.hibernate.query.sqm.produce.function.ArgumentTypesValidator.throwError(ArgumentTypesValidator.java:253)\n",
            "\tat app//org.hibernate.query.sqm.produce.function.ArgumentTypesValidator.checkType(ArgumentTypesValidator.java:199)\n",
            "\tat app//org.hibernate.query.sqm.produce.function.ArgumentTypesValidator.validate(ArgumentTypesValidator.java:98)\n",
            "\tat app//org.hibernate.query.sqm.function.AbstractSqmFunctionDescriptor.generateAggregateSqmExpression(AbstractSqmFunctionDescriptor.java:121)\n",
            "\tat app//org.hibernate.query.hql.internal.SemanticQueryBuilder.visitGenericFunction(SemanticQueryBuilder.java:4010)\n",
            "\tat app//org.hibernate.grammars.hql.HqlParser$GenericFunctionContext.accept(HqlParser.java:11403)\n",
            "\tat app//org.antlr.v4.runtime.tree.AbstractParseTreeVisitor.visitChildren(AbstractParseTreeVisitor.java:46)\n",
            "\tat app//org.hibernate.grammars.hql.HqlParserBaseVisitor.visitFunction(HqlParserBaseVisitor.java:1217)\n",
            "\tat app//org.hibernate.grammars.hql.HqlParser$FunctionContext.accept(HqlParser.java:11171)\n",
            "\tat app//org.hibernate.query.hql.internal.SemanticQueryBuilder.visitFunctionExpression(SemanticQueryBuilder.java:1758)\n",
            "\tat app//org.hibernate.query.hql.internal.SemanticQueryBuilder.visitFunctionExpression(SemanticQueryBuilder.java:253)\n",
            "\tat app//org.hibernate.grammars.hql.HqlParser$FunctionExpressionContext.accept(HqlParser.java:7476)\n",
            "\tat app//org.antlr.v4.runtime.tree.AbstractParseTreeVisitor.visitChildren(AbstractParseTreeVisitor.java:46)\n",
            "\tat app//org.hibernate.grammars.hql.HqlParserBaseVisitor.visitBarePrimaryExpression(HqlParserBaseVisitor.java:720)\n",
            "\tat app//org.hibernate.grammars.hql.HqlParser$BarePrimaryExpressionContext.accept(HqlParser.java:7064)\n",
            "\tat app//org.antlr.v4.runtime.tree.AbstractParseTreeVisitor.visitChildren(AbstractParseTreeVisitor.java:46)\n",
            "\tat app//org.hibernate.grammars.hql.HqlParserBaseVisitor.visitExpressionOrPredicate(HqlParserBaseVisitor.java:860)\n",
            "\tat app//org.hibernate.grammars.hql.HqlParser$ExpressionOrPredicateContext.accept(HqlParser.java:7813)\n",
            "\tat app//org.hibernate.query.hql.internal.SemanticQueryBuilder.visitSelectableNode(SemanticQueryBuilder.java:1278)\n",
            "\tat app//org.hibernate.query.hql.internal.SemanticQueryBuilder.visitSelection(SemanticQueryBuilder.java:1252)\n",
            "\tat app//org.hibernate.query.hql.internal.SemanticQueryBuilder.visitSelectClause(SemanticQueryBuilder.java:1235)\n",
            "\tat app//org.hibernate.query.hql.internal.SemanticQueryBuilder.visitQuery(SemanticQueryBuilder.java:1155)\n",
            "\tat app//org.hibernate.query.hql.internal.SemanticQueryBuilder.visitQuerySpecExpression(SemanticQueryBuilder.java:937)\n",
            "\tat app//org.hibernate.query.hql.internal.SemanticQueryBuilder.visitQuerySpecExpression(SemanticQueryBuilder.java:253)\n",
            "\tat app//org.hibernate.grammars.hql.HqlParser$QuerySpecExpressionContext.accept(HqlParser.java:1818)\n",
            "\tat app//org.hibernate.query.hql.internal.SemanticQueryBuilder.visitSimpleQueryGroup(SemanticQueryBuilder.java:931)\n",
            "\tat app//org.hibernate.query.hql.internal.SemanticQueryBuilder.visitSimpleQueryGroup(SemanticQueryBuilder.java:253)\n",
            "\tat app//org.hibernate.grammars.hql.HqlParser$SimpleQueryGroupContext.accept(HqlParser.java:1711)\n",
            "\tat app//org.hibernate.query.hql.internal.SemanticQueryBuilder.visitSelectStatement(SemanticQueryBuilder.java:418)\n",
            "\tat app//org.hibernate.query.hql.internal.SemanticQueryBuilder.visitStatement(SemanticQueryBuilder.java:377)\n",
            "\tat app//org.hibernate.query.hql.internal.SemanticQueryBuilder.buildSemanticModel(SemanticQueryBuilder.java:295)\n",
            "\tat app//org.hibernate.query.hql.internal.StandardHqlTranslator.translate(StandardHqlTranslator.java:81)\n",
            "\tat app//org.hibernate.internal.AbstractSharedSessionContract.lambda$interpretHql$2(AbstractSharedSessionContract.java:744)\n",
            "\tat app//org.hibernate.query.internal.QueryInterpretationCacheStandardImpl.createHqlInterpretation(QueryInterpretationCacheStandardImpl.java:141)\n",
            "\tat app//org.hibernate.query.internal.QueryInterpretationCacheStandardImpl.resolveHqlInterpretation(QueryInterpretationCacheStandardImpl.java:128)\n",
            "\tat app//org.hibernate.internal.AbstractSharedSessionContract.interpretHql(AbstractSharedSessionContract.java:741)\n",
            "\tat app//org.hibernate.internal.AbstractSharedSessionContract.createQuery(AbstractSharedSessionContract.java:786)\n",
            "\t... 100 more\n",
            "{noformat}, Similarity: 0.2722\n",
            "Summary & Description: concurrentmodificationexception using criteria window functions hibernate 6 \n",
            " When using hibernate reactive with hibernate 6, I’m getting a org.hibernate.HibernateException: java.util.ConcurrentModificationException when trying to use window functions with the HibernateCriteriaBuilder.\n",
            "\n",
            "h4. Example\n",
            "\n",
            "{code:java}final var cb = sessionFactory.getCriteriaBuilder();\n",
            "final var query = cb.createQuery(Long.class);\n",
            "final var root = query.from(Entity.class);\n",
            "final var rowNumber = cb.rowNumber(\n",
            "    cb.createWindow()\n",
            "        .partitionBy(root.get(\"chargePoint\"))\n",
            "        .orderBy(cb.desc(root.get(\"startTime\")))\n",
            ");\n",
            "query.select(rowNumber.alias(\"rowNumber\"));\n",
            "session.createQuery(query).getResultList();{code}\n",
            "\n",
            "h4. Expected result\n",
            "\n",
            "A query is generated that retrieves a list of the row numbers of the entities.\n",
            "\n",
            "h4. Actual result\n",
            "\n",
            "\n",
            "{noformat}org.hibernate.HibernateException: java.util.ConcurrentModificationException\n",
            "\tat org.hibernate.reactive.session.impl.ReactiveExceptionConverter.convert(ReactiveExceptionConverter.java:28)\n",
            "\tat org.hibernate.reactive.session.impl.ReactiveSessionImpl.createReactiveQuery(ReactiveSessionImpl.java:368)\n",
            "\tat org.hibernate.reactive.mutiny.impl.MutinySessionImpl.createQuery(MutinySessionImpl.java:140)\n",
            "\tat de.porsche.ho.chargepointservice.database.repository.ChargeTransactionRepository.lambda$findUserTransactions$0(ChargeTransactionRepository.java:99)\n",
            "\tat io.smallrye.context.impl.wrappers.SlowContextualFunction.apply(SlowContextualFunction.java:21)\n",
            "\tat io.smallrye.mutiny.operators.uni.UniOnItemTransformToUni$UniOnItemTransformToUniProcessor.performInnerSubscription(UniOnItemTransformToUni.java:68)\n",
            "\tat io.smallrye.mutiny.operators.uni.UniOnItemTransformToUni$UniOnItemTransformToUniProcessor.onItem(UniOnItemTransformToUni.java:57)\n",
            "\tat io.smallrye.mutiny.operators.uni.builders.UniCreateFromKnownItem$KnownItemSubscription.forward(UniCreateFromKnownItem.java:38)\n",
            "\tat io.smallrye.mutiny.operators.uni.builders.UniCreateFromKnownItem.subscribe(UniCreateFromKnownItem.java:23)\n",
            "\tat io.smallrye.mutiny.operators.AbstractUni.subscribe(AbstractUni.java:36)\n",
            "\tat io.smallrye.mutiny.operators.uni.UniOnItemTransformToUni.subscribe(UniOnItemTransformToUni.java:25)\n",
            "\tat io.smallrye.mutiny.operators.AbstractUni.subscribe(AbstractUni.java:36)\n",
            "\tat io.smallrye.mutiny.operators.uni.UniOnItemTransform.subscribe(UniOnItemTransform.java:22)\n",
            "\tat io.smallrye.mutiny.operators.AbstractUni.subscribe(AbstractUni.java:36)\n",
            "\tat io.smallrye.mutiny.operators.uni.UniOnItemConsume.subscribe(UniOnItemConsume.java:30)\n",
            "\tat io.smallrye.mutiny.operators.AbstractUni.subscribe(AbstractUni.java:36)\n",
            "\tat io.smallrye.mutiny.operators.uni.UniOnItemTransformToUni.subscribe(UniOnItemTransformToUni.java:25)\n",
            "\tat io.smallrye.mutiny.operators.AbstractUni.subscribe(AbstractUni.java:36)\n",
            "\tat io.smallrye.mutiny.operators.uni.UniOnItemTransformToUni.subscribe(UniOnItemTransformToUni.java:25)\n",
            "\tat io.smallrye.mutiny.operators.AbstractUni.subscribe(AbstractUni.java:36)\n",
            "\tat io.smallrye.mutiny.operators.uni.UniOnFailureFlatMap.subscribe(UniOnFailureFlatMap.java:31)\n",
            "\tat io.smallrye.mutiny.operators.AbstractUni.subscribe(AbstractUni.java:36)\n",
            "\tat io.smallrye.mutiny.operators.uni.UniOnCancellationCall.subscribe(UniOnCancellationCall.java:27)\n",
            "\tat io.smallrye.mutiny.operators.AbstractUni.subscribe(AbstractUni.java:36)\n",
            "\tat io.smallrye.mutiny.operators.uni.UniOnItemTransformToUni.subscribe(UniOnItemTransformToUni.java:25)\n",
            "\tat io.smallrye.mutiny.operators.AbstractUni.subscribe(AbstractUni.java:36)\n",
            "\tat io.smallrye.mutiny.operators.uni.UniOnItemTransformToUni.subscribe(UniOnItemTransformToUni.java:25)\n",
            "\tat io.smallrye.mutiny.operators.AbstractUni.subscribe(AbstractUni.java:36)\n",
            "\tat io.smallrye.mutiny.operators.uni.UniOnItemTransformToUni$UniOnItemTransformToUniProcessor.performInnerSubscription(UniOnItemTransformToUni.java:81)\n",
            "\tat io.smallrye.mutiny.operators.uni.UniOnItemTransformToUni$UniOnItemTransformToUniProcessor.onItem(UniOnItemTransformToUni.java:57)\n",
            "\tat io.smallrye.mutiny.operators.uni.builders.UniCreateFromCompletionStage$CompletionStageUniSubscription.forwardResult(UniCreateFromCompletionStage.java:63)\n",
            "\tat java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863)\n",
            "\tat java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:841)\n",
            "\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\n",
            "\tat java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2147)\n",
            "\tat io.vertx.core.Future.lambda$toCompletionStage$3(Future.java:384)\n",
            "\tat io.vertx.core.impl.future.FutureImpl$3.onSuccess(FutureImpl.java:141)\n",
            "\tat io.vertx.core.impl.future.FutureImpl$ListenerArray.onSuccess(FutureImpl.java:262)\n",
            "\tat io.vertx.core.impl.future.FutureBase.emitSuccess(FutureBase.java:60)\n",
            "\tat io.vertx.core.impl.future.FutureImpl.tryComplete(FutureImpl.java:211)\n",
            "\tat io.vertx.core.impl.future.PromiseImpl.tryComplete(PromiseImpl.java:23)\n",
            "\tat io.vertx.core.impl.future.PromiseImpl.onSuccess(PromiseImpl.java:49)\n",
            "\tat io.vertx.core.impl.future.PromiseImpl.handle(PromiseImpl.java:41)\n",
            "\tat io.vertx.sqlclient.impl.TransactionImpl.lambda$wrap$0(TransactionImpl.java:72)\n",
            "\tat io.vertx.core.impl.future.FutureImpl$3.onSuccess(FutureImpl.java:141)\n",
            "\tat io.vertx.core.impl.future.FutureBase.lambda$emitSuccess$0(FutureBase.java:54)\n",
            "\tat io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:174)\n",
            "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:167)\n",
            "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470)\n",
            "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:569)\n",
            "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
            "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
            "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
            "Caused by: java.util.ConcurrentModificationException\n",
            "\tat java.base/java.util.ArrayList$Itr.checkForComodification(ArrayList.java:1013)\n",
            "\tat java.base/java.util.ArrayList$Itr.next(ArrayList.java:967)\n",
            "\tat org.hibernate.query.sqm.tree.expression.SqmWindow.copy(SqmWindow.java:173)\n",
            "\tat org.hibernate.query.sqm.tree.expression.SqmOver.copy(SqmOver.java:73)\n",
            "\tat org.hibernate.query.sqm.tree.expression.SqmOver.copy(SqmOver.java:23)\n",
            "\tat org.hibernate.query.sqm.tree.select.SqmSelection.copy(SqmSelection.java:47)\n",
            "\tat org.hibernate.query.sqm.tree.select.SqmSelectClause.copy(SqmSelectClause.java:52)\n",
            "\tat org.hibernate.query.sqm.tree.select.SqmQuerySpec.copy(SqmQuerySpec.java:101)\n",
            "\tat org.hibernate.query.sqm.tree.select.SqmQuerySpec.copy(SqmQuerySpec.java:53)\n",
            "\tat org.hibernate.query.sqm.tree.select.SqmSelectStatement.copy(SqmSelectStatement.java:131)\n",
            "\tat org.hibernate.query.sqm.tree.select.SqmSelectStatement.copy(SqmSelectStatement.java:42)\n",
            "\tat org.hibernate.query.sqm.internal.QuerySqmImpl.<init>(QuerySqmImpl.java:228)\n",
            "\tat org.hibernate.reactive.query.sqm.iternal.ReactiveQuerySqmImpl.<init>(ReactiveQuerySqmImpl.java:112)\n",
            "\tat org.hibernate.reactive.session.impl.ReactiveSessionImpl.createCriteriaQuery(ReactiveSessionImpl.java:373)\n",
            "\tat org.hibernate.reactive.session.impl.ReactiveSessionImpl.createReactiveQuery(ReactiveSessionImpl.java:362)\n",
            "\t... 52 more{noformat}\n",
            "\n",
            "\n",
            "\n",
            "From quick debugging I’ve found these lines to be very suspicious:\n",
            "\n",
            "hibernate-core-6.2.1.Final-sources.jar!/org/hibernate/query/sqm/tree/expression/SqmWindow.java:174\n",
            "\n",
            "hibernate-core-6.2.1.Final-sources.jar!/org/hibernate/query/sqm/tree/expression/SqmWindow.java:178\n",
            "\n",
            "In this fragment from hibernate-core-6.2.1.Final-sources.jar!/org/hibernate/query/sqm/tree/expression/SqmWindow.java it looks like when copying from partitions and orderList it is added to the original lists instead of the newly created {{partitionsCopy}} and {{orderListCopy}} which causes the ConcurrentModificationException.\n",
            "\n",
            "{code:java}\t\tfinal List<SqmExpression<?>> partitionsCopy = new ArrayList<>( this.partitions.size() );\n",
            "\t\tfor ( SqmExpression<?> partition : this.partitions ) {\n",
            "\t\t\tpartitions.add( partition.copy( context ) );\n",
            "\t\t}\n",
            "\t\tfinal List<SqmSortSpecification> orderListCopy = new ArrayList<>( this.orderList.size() );\n",
            "\t\tfor ( SqmSortSpecification sortSpecification : this.orderList ) {\n",
            "\t\t\torderList.add( sortSpecification.copy( context ) );\n",
            "\t\t}{code}, Similarity: 0.2994\n",
            "Summary & Description: false positive hibernateexception found shared references collection 622 \n",
            " So I have the following setup:\n",
            "Product → one-to-one->Sku-(embeds)-PriceListSkuImpl->one-to-many->SkuPriceData\n",
            "|\n",
            "one-to-many\n",
            "|\n",
            "CategoryProductXref->many-to-one->Category\n",
            "\n",
            "At some point I’m “cloning” a product(given the error I checked a number of times that I don’t re-assign or “clone” any collection) which in test-case I mimic by creating a new product. Then do refresh to both original and clone and that’s it.\n",
            "In test I also read category, and some other product, and initialize collections by accessing them, which seems is required to reproduce the issue.\n",
            "So once the final flush is happening I’m getting the Found shared references error for SkuImpl.priceListSku.priceDataList\n",
            "And the interesting thing that error(if you do debug) will be related to some other product/sku that didn’t participate in the cloning process, but just belong to the same category that original product does.\n",
            "\n",
            "While debigging I think there is some issue with handling cycles in the entity graph, so seems it does:\n",
            "Product->sku->priceDataList\n",
            "then it does\n",
            "Product->category_xref->category->all-product-in-category->category_xref->product->sku->priceDatalist\n",
            "and fails…, Similarity: 0.2593\n",
            "Summary & Description: npe mappingmetamodelimpl inheritance used idclass \n",
            " In Hibernate-Core 6.1.7 we could use inheritance in IdClasses like so:\n",
            "\n",
            "{code:java}@Data\n",
            "@NoArgsConstructor\n",
            "@AllArgsConstructor\n",
            "public class ParentPrimaryKey implements Serializable {\n",
            "    private UUID parentId;\n",
            "}\n",
            "\n",
            "@Data\n",
            "@NoArgsConstructor\n",
            "@AllArgsConstructor\n",
            "@EqualsAndHashCode(callSuper = true)\n",
            "public class ChildPrimaryKey extends ParentPrimaryKey  {\n",
            "    private UUID childId;\n",
            "}\n",
            "{code}\n",
            "\n",
            "But since 6.2.x this will raise a cryptic NPE:\n",
            "\n",
            "{noformat}jakarta.persistence.PersistenceException: [PersistenceUnit: default] Unable to build Hibernate SessionFactory; nested exception is java.lang.NullPointerException: Cannot invoke \"org.hibernate.metamodel.mapping.EmbeddableValuedModelPart.getNavigableRole()\" because \"mappingModelPart\" is null{noformat}\n",
            "\n",
            "\n",
            "\n",
            "h4. Expected Behavior\n",
            "\n",
            "Instead of an NPE, I would expect a more helpfull message, i.e.: \n",
            "\n",
            "{quote}Illegal embeddable valued model definition: com.example.PK.class. {quote}, Similarity: 0.2389\n",
            "Summary & Description: tck failure due wrong refactoring schema management action enum \n",
            " The refactoring in [https://github.com/hibernate/hibernate-orm/commit/18ddbe15d6a8b83f3bae25183518640b8c615cc7|https://github.com/hibernate/hibernate-orm/commit/18ddbe15d6a8b83f3bae25183518640b8c615cc7|smart-link]  introduced a regression which causes {{com/sun/ts/tests/jpa/se/schemaGeneration/scripts/Client}} tests to fail., Similarity: 0.2827\n",
            "Summary & Description: composite key fetch join results unknowntablereferenceexception \n",
            " Hi we are currently starting with the migration to Quarkus 3,\n",
            "\n",
            "We face some issues with our existing database structure and Hibernate 6. It seems to be the combination of a composite key and a fetch join. Due to the changes I checked the documentation and migration guide again in case we did something wrong or forgot something. I do not see it 😞 . I created a reproducer here:\n",
            "\n",
            "[https://github.com/holomekc/quarkus-quickstarts/tree/main/hibernate-reactive-panache-quickstart|https://github.com/holomekc/quarkus-quickstarts/tree/main/hibernate-reactive-panache-quickstart|smart-link] \n",
            "\n",
            "But maybe here in short as well:\n",
            "\n",
            "{code:java}@Entity\n",
            "@Table(name = \"fruit_basket\")\n",
            "public class FruitBasket extends PanacheEntity {\n",
            "\n",
            "    @Column\n",
            "    public String name;\n",
            "\n",
            "    @OneToMany(mappedBy = \"basket\", fetch = FetchType.LAZY)\n",
            "    public Collection<Fruit> fruits;\n",
            "}\n",
            "{code}\n",
            "\n",
            "{code:java}@Entity\n",
            "@IdClass(FruitId.class)\n",
            "@Table(name = \"fruit\")\n",
            "public class Fruit extends PanacheEntityBase {\n",
            "\n",
            "    @Id\n",
            "    @GeneratedValue\n",
            "    public Long id;\n",
            "\n",
            "    @Id\n",
            "    @JoinColumn(name = \"basket_id\", referencedColumnName = \"id\", foreignKey = @ForeignKey(name = \"basket_fk\"))\n",
            "    @ManyToOne(fetch = FetchType.LAZY)\n",
            "    public FruitBasket basket;\n",
            "\n",
            "    @Column(length = 40, unique = true)\n",
            "    public String name;\n",
            "\n",
            "\n",
            "    public Fruit() {\n",
            "    }\n",
            "\n",
            "    public Fruit(String name) {\n",
            "        this.name = name;\n",
            "    }\n",
            "}{code}\n",
            "\n",
            "{noformat}public class FruitId implements Serializable {\n",
            "\n",
            "    private Long id;\n",
            "    private FruitBasket basket;\n",
            "\n",
            "    public Long getId() {\n",
            "        return id;\n",
            "    }\n",
            "\n",
            "    public FruitId setId(Long id) {\n",
            "        this.id = id;\n",
            "        return this;\n",
            "    }\n",
            "\n",
            "    public FruitBasket getBasket() {\n",
            "        return basket;\n",
            "    }\n",
            "\n",
            "    public FruitId setBasket(FruitBasket basket) {\n",
            "        this.basket = basket;\n",
            "        return this;\n",
            "    }\n",
            "\n",
            "    @Override\n",
            "    public boolean equals(Object o) {\n",
            "        if (this == o) {\n",
            "            return true;\n",
            "        }\n",
            "        if (o == null || getClass() != o.getClass()) {\n",
            "            return false;\n",
            "        }\n",
            "        FruitId fruitId = (FruitId) o;\n",
            "        return Objects.equals(id, fruitId.id) && Objects.equals(basket, fruitId.basket);\n",
            "    }\n",
            "\n",
            "    @Override\n",
            "    public int hashCode() {\n",
            "        return Objects.hash(id, basket);\n",
            "    }\n",
            "}{noformat}\n",
            "\n",
            "{noformat}2023-05-22 04:35:33,895 ERROR [org.acm.hib.orm.pan.FruitResource] (vert.x-eventloop-thread-2) Failed to handle request: org.hibernate.HibernateException: Could not generate fetch : org.acme.hibernate.orm.panache.Fruit(f) -> {id}\n",
            "        at org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.buildFetch(BaseSqmToSqlAstConverter.java:7466)\n",
            "        at org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.createFetch(BaseSqmToSqlAstConverter.java:7295)\n",
            "        at org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.visitIdentifierFetch(BaseSqmToSqlAstConverter.java:7143)\n",
            "        at org.hibernate.sql.results.graph.entity.AbstractEntityResultGraphNode.afterInitialize(AbstractEntityResultGraphNode.java:63)\n",
            "        at org.hibernate.reactive.persister.entity.impl.ReactiveAbstractPersisterDelegate.createDomainResult(ReactiveAbstractPersisterDelegate.java:106)\n",
            "        at org.hibernate.reactive.persister.entity.impl.ReactiveSingleTableEntityPersister.createDomainResult(ReactiveSingleTableEntityPersister.java:105)\n",
            "        at org.hibernate.query.sqm.sql.internal.AbstractSqmPathInterpretation.createDomainResult(AbstractSqmPathInterpretation.java:55)\n",
            "        at org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.lambda$visitSelection$23(BaseSqmToSqlAstConverter.java:2240)\n",
            "        at java.base/java.util.Collections$SingletonList.forEach(Collections.java:4966)\n",
            "        at org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.visitSelection(BaseSqmToSqlAstConverter.java:2235)\n",
            "        at org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.visitSelectClause(BaseSqmToSqlAstConverter.java:2153)\n",
            "        at org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.visitQuerySpec(BaseSqmToSqlAstConverter.java:2021)\n",
            "        at org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.visitQuerySpec(BaseSqmToSqlAstConverter.java:425)\n",
            "        at org.hibernate.query.sqm.tree.select.SqmQuerySpec.accept(SqmQuerySpec.java:122)\n",
            "        at org.hibernate.query.sqm.spi.BaseSemanticQueryWalker.visitQueryPart(BaseSemanticQueryWalker.java:221)\n",
            "        at org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.visitQueryPart(BaseSqmToSqlAstConverter.java:1881)\n",
            "        at org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.visitSelectStatement(BaseSqmToSqlAstConverter.java:1566)\n",
            "        at org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.visitSelectStatement(BaseSqmToSqlAstConverter.java:425)\n",
            "        at org.hibernate.query.sqm.tree.select.SqmSelectStatement.accept(SqmSelectStatement.java:222)\n",
            "        at org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.translate(BaseSqmToSqlAstConverter.java:759)\n",
            "        at org.hibernate.reactive.query.sqm.iternal.ConcreteSqmSelectReactiveQueryPlan.buildCacheableSqmInterpretation(ConcreteSqmSelectReactiveQueryPlan.java:208)\n",
            "        at org.hibernate.reactive.query.sqm.iternal.ConcreteSqmSelectReactiveQueryPlan.withCacheableSqmInterpretation(ConcreteSqmSelectReactiveQueryPlan.java:138)\n",
            "        at org.hibernate.reactive.query.sqm.iternal.ConcreteSqmSelectReactiveQueryPlan.reactivePerformList(ConcreteSqmSelectReactiveQueryPlan.java:122)\n",
            "        at org.hibernate.reactive.query.sqm.iternal.ReactiveQuerySqmImpl.doReactiveList(ReactiveQuerySqmImpl.java:200)\n",
            "        at org.hibernate.reactive.query.spi.ReactiveAbstractSelectionQuery.doReactiveList(ReactiveAbstractSelectionQuery.java:287)\n",
            "        at org.hibernate.reactive.query.spi.ReactiveAbstractSelectionQuery.reactiveList(ReactiveAbstractSelectionQuery.java:202)\n",
            "        at org.hibernate.reactive.query.sqm.iternal.ReactiveQuerySqmImpl.reactiveList(ReactiveQuerySqmImpl.java:154)\n",
            "        at org.hibernate.reactive.query.ReactiveSelectionQuery.getReactiveResultList(ReactiveSelectionQuery.java:42)\n",
            "        at io.smallrye.context.impl.wrappers.SlowContextualSupplier.get(SlowContextualSupplier.java:21)\n",
            "        at io.smallrye.mutiny.operators.uni.builders.UniCreateFromCompletionStage.subscribe(UniCreateFromCompletionStage.java:24)\n",
            "        at io.smallrye.mutiny.operators.AbstractUni.subscribe(AbstractUni.java:36)\n",
            "        at io.smallrye.mutiny.operators.uni.UniRunSubscribeOn.lambda$subscribe$0(UniRunSubscribeOn.java:27)\n",
            "        at org.hibernate.reactive.context.impl.VertxContext.execute(VertxContext.java:90)\n",
            "        at io.smallrye.mutiny.operators.uni.UniRunSubscribeOn.subscribe(UniRunSubscribeOn.java:25)\n",
            "        at io.smallrye.mutiny.operators.AbstractUni.subscribe(AbstractUni.java:36)\n",
            "        at io.smallrye.mutiny.operators.uni.UniOnItemTransformToUni$UniOnItemTransformToUniProcessor.performInnerSubscription(UniOnItemTransformToUni.java:81)\n",
            "        at io.smallrye.mutiny.operators.uni.UniOnItemTransformToUni$UniOnItemTransformToUniProcessor.onItem(UniOnItemTransformToUni.java:57)\n",
            "        at io.smallrye.mutiny.operators.uni.UniOnItemConsume$UniOnItemComsumeProcessor.onItem(UniOnItemConsume.java:43)\n",
            "        at io.smallrye.mutiny.operators.uni.UniOnItemTransform$UniOnItemTransformProcessor.onItem(UniOnItemTransform.java:43)\n",
            "        at io.smallrye.mutiny.operators.uni.UniOnItemTransformToUni$UniOnItemTransformToUniProcessor.onItem(UniOnItemTransformToUni.java:60)\n",
            "        at io.smallrye.mutiny.operators.uni.UniOperatorProcessor.onItem(UniOperatorProcessor.java:47)\n",
            "        at io.smallrye.mutiny.operators.uni.builders.UniCreateFromItemSupplier.subscribe(UniCreateFromItemSupplier.java:29)\n",
            "        at io.smallrye.mutiny.operators.AbstractUni.subscribe(AbstractUni.java:36)\n",
            "        at io.smallrye.mutiny.operators.uni.UniOnFailureFlatMap.subscribe(UniOnFailureFlatMap.java:31)\n",
            "        at io.smallrye.mutiny.operators.AbstractUni.subscribe(AbstractUni.java:36)\n",
            "        at io.smallrye.mutiny.operators.uni.UniOnItemTransformToUni$UniOnItemTransformToUniProcessor.performInnerSubscription(UniOnItemTransformToUni.java:81)\n",
            "        at io.smallrye.mutiny.operators.uni.UniOnItemTransformToUni$UniOnItemTransformToUniProcessor.onItem(UniOnItemTransformToUni.java:57)\n",
            "        at io.smallrye.mutiny.operators.uni.UniOperatorProcessor.onItem(UniOperatorProcessor.java:47)\n",
            "        at io.smallrye.mutiny.operators.uni.builders.UniCreateFromCompletionStage$CompletionStageUniSubscription.forwardResult(UniCreateFromCompletionStage.java:63)\n",
            "        at java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863)\n",
            "        at java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:841)\n",
            "        at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)\n",
            "        at java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2147)\n",
            "        at io.vertx.core.Future.lambda$toCompletionStage$3(Future.java:384)\n",
            "        at io.vertx.core.impl.future.FutureImpl$3.onSuccess(FutureImpl.java:141)\n",
            "        at io.vertx.core.impl.future.FutureBase.emitSuccess(FutureBase.java:60)\n",
            "        at io.vertx.core.impl.future.FutureImpl.tryComplete(FutureImpl.java:211)\n",
            "        at io.vertx.core.impl.future.Mapping.onSuccess(Mapping.java:40)\n",
            "        at io.vertx.core.impl.future.FutureBase.lambda$emitSuccess$0(FutureBase.java:54)\n",
            "        at io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:174)\n",
            "        at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:167)\n",
            "        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470)\n",
            "        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:569)\n",
            "        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
            "        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
            "        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
            "        at java.base/java.lang.Thread.run(Thread.java:833)\n",
            "Caused by: org.hibernate.HibernateException: Could not generate fetch : org.acme.hibernate.orm.panache.Fruit(f).{id}(598220203321057) -> basket\n",
            "        at org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.buildFetch(BaseSqmToSqlAstConverter.java:7466)\n",
            "        at org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.createFetch(BaseSqmToSqlAstConverter.java:7295)\n",
            "        at org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.visitFetches(BaseSqmToSqlAstConverter.java:7412)\n",
            "        at org.hibernate.sql.results.graph.AbstractFetchParent.afterInitialize(AbstractFetchParent.java:32)\n",
            "        at org.hibernate.sql.results.graph.embeddable.internal.EmbeddableFetchImpl.<init>(EmbeddableFetchImpl.java:75)\n",
            "        at org.hibernate.metamodel.internal.AbstractCompositeIdentifierMapping.geetch(AbstractCompositeIdentifierMapping.java:109)\n",
            "        at org.hibernate.sql.results.graph.FetchParent.generateFetchableFetch(FetchParent.java:108)\n",
            "        at org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.buildFetch(BaseSqmToSqlAstConverter.java:7455)\n",
            "        ... 66 more\n",
            "Caused by: org.hibernate.sql.ast.tree.from.UnknownTableReferenceException: Unable to determine TableReference (`fruit`) for `org.acme.hibernate.orm.panache.Fruit(f).{id}(598220203321057).basket.{fk}`\n",
            "        at org.hibernate.sql.ast.tree.from.LazyTableGroup.resolveTableReference(LazyTableGroup.java:256)\n",
            "        at org.hibernate.sql.ast.tree.from.DelegatingTableGroup.resolveTableReference(DelegatingTableGroup.java:62)\n",
            "        at org.hibernate.metamodel.mapping.internal.SimpleForeignKeyDescriptor.createDomainResult(SimpleForeignKeyDescriptor.java:305)\n",
            "        at org.hibernate.metamodel.mapping.internal.SimpleForeignKeyDescriptor.createDomainResult(SimpleForeignKeyDescriptor.java:254)\n",
            "        at org.hibernate.metamodel.mapping.internal.ToOneAttributeMapping.generateFetch(ToOneAttributeMapping.java:1487)\n",
            "        at org.hibernate.metamodel.mapping.internal.ToOneAttributeMapping.generateFetch(ToOneAttributeMapping.java:107)\n",
            "        at org.hibernate.sql.results.graph.FetchParent.generateFetchableFetch(FetchParent.java:108)\n",
            "        at org.hibernate.query.sqm.sql.BaseSqmToSqlAstConverter.buildFetch(BaseSqmToSqlAstConverter.java:7455)\n",
            "        ... 73 more{noformat}\n",
            "\n",
            "Br,\n",
            "\n",
            "Chris, Similarity: 0.3498\n",
            "Summary & Description: loss precision due usage float data type instead bigdecimal case oracle jdbc driver returning 127 scale 0 precision precisionscale unknown might happen unexpectedly requires close inspection used sql \n",
            " Dear Hibernate Team,\n",
            "\n",
            "The Oracle JDBC Driver generally returns a value of “-127” for method \"getScale()\" and a value of “0” for method \"getPrecision()\" (on “OracleResultSetMetaData”) in case the scale and the precision of a returned numeric column is unknown. Starting with Hibernate 6, Hibernate will return the data as Float data type (according to “'org.hibernate.dialect.OracleDialect.resolveSqlTypeDescriptor()”) instead of BigDecimal (in previous versions). From my point of view, this is a pretty bad design decision as it:\n",
            "\n",
            "* breaks existing code which uses native queries (which do not feature explicit type mappings via ‘addScalar’)\n",
            "* even worse: causes loss in predictability and loss in precision, e.g., a SQL query like:\n",
            "\n",
            "SELECT col1 FROM testTable UNION ALL 123.54356 AS col1 FROM DUAL\n",
            "\n",
            "will return “col1” as Float value EVEN if you specify “col1” as NUMBER(38,0)!! Data loss is garuanteed. Basically it means, that SQL queries that do not look as being problematic at the first glance, may reveal as such at a much closer look. If code features hundreds of native queries, you need to closely inspect each of them (not that I’m a big fan of native queries but sometimes it is was it is…)\n",
            "\n",
            "\n",
            "\n",
            "If Oracle returns a value of “-127” for method \"getScale()\" and a value of “0” for method \"getPrecision() it simply mean that precision and scale are unknown and in such case using BigDecimal is the right decision whereas Float data type is definitely not.\n",
            "\n",
            "\n",
            "\n",
            "Bye,\n",
            "\n",
            "Ralf, Similarity: 0.1703\n",
            "Summary & Description: hibernateremove doesnt work \n",
            " The tests for {{Hibernate.remove()}} were wrong, and it turns out the functionality does nothing (the queued operations never get executed)., Similarity: 0.2203\n",
            "Summary & Description: ordercolumn fails generic collection npe xpropertygetmapkey \n",
            " @OrderColumn on a generic collection type fails at entityManagerFactory startup with a NPE :\n",
            "\n",
            "{noformat}Caused by: java.lang.NullPointerException: Cannot invoke \"org.hibernate.annotations.common.reflection.XClass.getName()\" because the return value of \"org.hibernate.annotations.common.reflection.XProperty.getMapKey()\" is null\n",
            "\tat org.hibernate.boot.model.internal.ClassPropertyHolder$1.doSecondPass(ClassPropertyHolder.java:312)\n",
            "\tat org.hibernate.boot.internal.InFlightMetadataCollectorImpl.processSecondPasses(InFlightMetadataCollectorImpl.java:1846)\n",
            "\tat org.hibernate.boot.internal.InFlightMetadataCollectorImpl.processSecondPasses(InFlightMetadataCollectorImpl.java:1803){noformat}\n",
            "\n",
            "\n",
            "\n",
            "Collection declaration :\n",
            "\n",
            "{code:java}(in abstract)\n",
            "...\n",
            "\t@OneToMany(mappedBy=\"withGeneric\")\n",
            "\t@OrderColumn\n",
            "\tpublic List<T> targets;\n",
            "...{code}\n",
            "\n",
            "Generic type is setup in concrete class.\n",
            "\n",
            "This pattern used to work with Hibernate (works for Hibernate 5.6.15, and previous versions).\n",
            "\n",
            "A minimal test-case based on [https://github.com/hibernate/hibernate-test-case-templates|https://github.com/hibernate/hibernate-test-case-templates|smart-link]  is coming.\n",
            "\n",
            "There is an existing ticket already open with a similar error [https://hibernate.atlassian.net/browse/HHH-16562|https://hibernate.atlassian.net/browse/HHH-16562|smart-link]  but :\n",
            "\n",
            "* it does not imply a generic collection\n",
            "* my minimal test case shows that a non-generic @OneToMany collection is OK\n",
            "\n",
            "\n",
            "\n",
            "I’ll post my github repository with a minimal test-case in a few minutes., Similarity: 0.3242\n",
            "Summary & Description: table generator id generation strategy returns low number doesnt respect initial value table \n",
            " Tried the following test case in hibernate 6.2.2:\n",
            "Created entity with the following setup for id\n",
            "\n",
            "{noformat}@GeneratedValue(generator= \"entityD\", strategy = GenerationType.TABLE)\n",
            "    @TableGenerator(name = \"entityD\", table=\"my_seq\",pkColumnName = \"my_seq_name\", valueColumnName = \"my_seq_val\")\n",
            "{noformat}\n",
            "\n",
            "after that update generator for corresponding entity to 50 in the my_seq table via sql.\n",
            "and ask hibernate to insert new entity.\n",
            "The id will be assigned is 2, while I would expect 51…(or 52, or >50 I don’t care)\n",
            "if I update generator to 100, the assigned id will be 52…\n",
            "\n",
            "Seems a bug? In prev versions(3-5) it was working as expected.\n",
            "\n",
            "Looking briefly in the code I see hibernate reads value from the table, updates with increment and then returns the value that was read, and after that applies formula value read - (increment size-1).\n",
            "Seems logic should either return value after update or don’t substract increment size, which is 50 by default…, Similarity: 0.1659\n",
            "Summary & Description: criteria api already registered copy \n",
            " With Criteria API, reusing Predicates with subqueries we are getting this error:\n",
            "\n",
            "{noformat}Already registered a copy: org.hibernate.query.sqm.tree.select.SqmSubQuery@4416e18d{noformat}\n",
            "\n",
            "Without subqueries, we are getting other error\n",
            "\n",
            "{noformat}org.hibernate.sql.ast.SqlTreeCreationException: Could not locate TableGroup{noformat}\n",
            "\n",
            "Sample:\n",
            "\n",
            "{noformat}CriteriaBuilder cb = entityManager.getCriteriaBuilder();\n",
            "\n",
            "CriteriaQuery<MyEntity> cq = cb.createQuery(MyEntity.class);\n",
            "Root<MyEntity> root = cq.from(MyEntity.class);\n",
            "\n",
            "List<Predicate> predicates = getPredicates(cb,cq, root, \"1\");\n",
            "\n",
            "cq.select(root).where(predicates.toArray(Predicate[]::new));\n",
            "\n",
            "TypedQuery<MyEntity> q = entityManager.createQuery(cq);\n",
            "\n",
            "long count = count(entityManager, predicates);{noformat}\n",
            "\n",
            "\n",
            "Same code in hibernate 5 works fine.\n",
            "\n",
            "\n",
            "\n",
            "Test case: [https://github.com/DanielNovo/hibernate-test-case-templates/commit/e6b5f461d3da4075bca35f1fc3305997ca191203|https://github.com/DanielNovo/hibernate-test-case-templates/commit/e6b5f461d3da4075bca35f1fc3305997ca191203|smart-link] , Similarity: 0.3367\n",
            "Summary & Description: associations fields beginning underscore \n",
            " As originally reported here:[https://stackoverflow.com/questions/76268282/hibernate-5-x-to-hibernate-6-x-alias-issue|https://stackoverflow.com/questions/76268282/hibernate-5-x-to-hibernate-6-x-alias-issue|smart-link] joining an association on a field beginning with underscore, for example:\n",
            "\n",
            "{code:java}    @ManyToOne\n",
            "    Event _event;{code}\n",
            "\n",
            "results in generated SQL with aliases beginning with {{_}}:\n",
            "\n",
            "{code:sql}join Event _1_0{code}, Similarity: 0.2606\n",
            "Summary & Description: fetchtypeeager make entity dirty bytecode enhancement \n",
            " only query.FetchType.LAZY is good, Similarity: 0.2512\n",
            "Summary & Description: caching queries filter parameters included cache key \n",
            " While working on [https://hibernate.atlassian.net/browse/HHH-16385|https://hibernate.atlassian.net/browse/HHH-16385|smart-link], I noticed that query caching does not include filter parameters in the cache key, leading to invalid cache results.\n",
            "\n",
            "The enabled filter parameters should be included in the {{parameterBindingsMemento}} field of the QueryKey object., Similarity: 0.2878\n",
            "Summary & Description: typo logic handling beforeafter table creation auxiliary database objects \n",
            " In org.hibernate.tool.schema.internal.AbstractSchemaMigrator#performMigration creation of auxiliary database objects that should be created after tables creation is performed before and vice versa.\n",
            "\n",
            "\n",
            "\n",
            "This is caused by  minor typo (placing '!' where should not be and vice verssa), so I will not create test case. And it is not easy to reach this situation, anyway., Similarity: 0.1995\n",
            "Summary & Description: lazy manytoone cacheable association retrieved initialized \n",
            " Having a set of entities:\n",
            "\n",
            "{noformat}@Entity(name = \"AbstractEntity\")\n",
            "@Cacheable // NOTE: that all these entities are cacheable; if not -- issue is not reproducable.\n",
            "public abstract class AbstractEntity {\n",
            "\n",
            "\t@Id\n",
            "\t@GeneratedValue\n",
            "\tprivate Integer id;\n",
            "}\n",
            "\n",
            "@Entity(name = \"ConcreteEntity\")\n",
            "@Cacheable\n",
            "public class ConcreteEntity extends AbstractEntity {\n",
            "\n",
            "\tprivate String content;\n",
            "}\n",
            "\n",
            "@Entity(name = \"LazyAbstractEntityReference\")\n",
            "@Cacheable\n",
            "public class LazyAbstractEntityReference {\n",
            "\n",
            "\t@Id\n",
            "\t@GeneratedValue\n",
            "\tprivate Integer id;\n",
            "\n",
            "\t@ManyToOne(fetch = FetchType.LAZY)\n",
            "\tprivate AbstractEntity entity; // NOTE: there's an `AbstractEntity` used. If a concrete entity type is used - issue is also not reproducable.\n",
            "}{noformat}\n",
            "\n",
            "While retrieving a {{LazyAbstractEntityReference}} would previously return an uninitialized lazy property ({{Hibernate.isInitialized(LazyAbstractEntityReference.entity) == false}}, now it has it initialized. \n",
            "\n",
            "A test case reproducing the issue will be submitted soon., Similarity: 0.2839\n",
            "Summary & Description: npe jdbctypecodesqltypesjson combination explicit table nameowner \n",
            " I have a JSON-Mapping in my entity\n",
            "\n",
            "{noformat}@Entity\n",
            "public class MyEntity {\n",
            "\n",
            "    @Id\n",
            "    @Column\n",
            "    public Long id;\n",
            "\n",
            "    @JdbcTypeCode(SqlTypes.JSON)\n",
            "    MyJson jsonProperty;\n",
            "}{noformat}\n",
            "\n",
            "MyJson is a simple POJO:\n",
            "\n",
            "{noformat}@Embeddable\n",
            "@Access( AccessType.PROPERTY )\n",
            "public class MyJson {\n",
            "\n",
            "    private String stringProp;\n",
            "    private Long longProp;\n",
            "\n",
            "    public String getStringProp() {\n",
            "        return stringProp;\n",
            "    }\n",
            "\n",
            "    public void setStringProp(String aStringProp) {\n",
            "        this.stringProp = aStringProp;\n",
            "    }\n",
            "\n",
            "    public Long getLongProp() {\n",
            "        return longProp;\n",
            "    }\n",
            "\n",
            "    public void setLongProp(Long aLongProp) {\n",
            "        this.longProp = aLongProp;\n",
            "    }\n",
            "}{noformat}\n",
            "\n",
            "Without @Table-Annotation with explicit name and owner, everything works.\n",
            "\n",
            "Adding @Table-Annotation with explicit name and owner like this\n",
            "\n",
            "{noformat}@Entity\n",
            "@Table(name = \"MY_ENTITY\", schema = \"base\") //with explict table-name & schema it won't work\n",
            "public class MyEntity {\n",
            "...{noformat}\n",
            "\n",
            "will cause an NullPointerException in _org.hibernate.sql.model.ast.builder.ColumnValuesTableMutationBuilder.addValueColumn:_\n",
            "\n",
            "{quote}java.lang.RuntimeException: java.lang.RuntimeException: Failed to start quarkus\n",
            "\tat io.quarkus.test.junit.QuarkusTestExtension.throwBootFailureException(QuarkusTestExtension.java:625)\n",
            "\tat io.quarkus.test.junit.QuarkusTestExtension.interceptTestClassConstructor(QuarkusTestExtension.java:696)\n",
            "\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93)\n",
            "\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)\n",
            "\tat org.junit.jupiter.api.extension.InvocationInterceptor.interceptTestClassConstructor(InvocationInterceptor.java:73)\n",
            "\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93)\n",
            "\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)\n",
            "\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)\n",
            "\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)\n",
            "\tat org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)\n",
            "\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:92)\n",
            "\tat org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:62)\n",
            "\tat org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeTestClassConstructor(ClassBasedTestDescriptor.java:363)\n",
            "\tat org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.instantiateTestClass(ClassBasedTestDescriptor.java:310)\n",
            "\tat org.junit.jupiter.engine.descriptor.ClassTestDescriptor.instantiateTestClass(ClassTestDescriptor.java:79)\n",
            "\tat org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.instantiateAndPostProcessTestInstance(ClassBasedTestDescriptor.java:286)\n",
            "\tat org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$4(ClassBasedTestDescriptor.java:278)\n",
            "\tat java.base/java.util.Optional.orElseGet(Optional.java:364)\n",
            "\tat org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$testInstancesProvider$5(ClassBasedTestDescriptor.java:277)\n",
            "\tat org.junit.jupiter.engine.execution.TestInstancesProvider.getTestInstances(TestInstancesProvider.java:31)\n",
            "\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$prepare$0(TestMethodTestDescriptor.java:105)\n",
            "\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n",
            "\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:104)\n",
            "\tat org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.prepare(TestMethodTestDescriptor.java:68)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$prepare$2(NodeTestTask.java:123)\n",
            "\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.prepare(NodeTestTask.java:123)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:90)\n",
            "\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1511)\n",
            "\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)\n",
            "\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\n",
            "\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\n",
            "\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\n",
            "\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1511)\n",
            "\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)\n",
            "\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\n",
            "\tat org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\n",
            "\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\n",
            "\tat org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)\n",
            "\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)\n",
            "\tat org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)\n",
            "\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:147)\n",
            "\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:127)\n",
            "\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:90)\n",
            "\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:55)\n",
            "\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:102)\n",
            "\tat org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:54)\n",
            "\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)\n",
            "\tat org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)\n",
            "\tat org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)\n",
            "\tat org.apache.maven.surefire.junitplatform.LazyLauncher.execute(LazyLauncher.java:50)\n",
            "\tat org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:184)\n",
            "\tat org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:148)\n",
            "\tat org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:122)\n",
            "\tat org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)\n",
            "\tat org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)\n",
            "\tat org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:507)\n",
            "\tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:495)\n",
            "Caused by: java.lang.RuntimeException: Failed to start quarkus\n",
            "\tat io.quarkus.runner.ApplicationImpl.doStart(Unknown Source)\n",
            "\tat io.quarkus.runtime.Application.start(Application.java:101)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
            "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
            "\tat io.quarkus.runner.bootstrap.StartupActionImpl.run(StartupActionImpl.java:273)\n",
            "\tat io.quarkus.test.junit.QuarkusTestExtension.doJavaStart(QuarkusTestExtension.java:250)\n",
            "\tat io.quarkus.test.junit.QuarkusTestExtension.ensureStarted(QuarkusTestExtension.java:592)\n",
            "\tat io.quarkus.test.junit.QuarkusTestExtension.beforeAll(QuarkusTestExtension.java:640)\n",
            "\tat org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeBeforeAllCallbacks$12(ClassBasedTestDescriptor.java:395)\n",
            "\tat org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\n",
            "\tat org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeBeforeAllCallbacks(ClassBasedTestDescriptor.java:395)\n",
            "\tat org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:211)\n",
            "\tat org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:84)\n",
            "\tat org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:148)\n",
            "\t... 37 more\n",
            "Caused by: java.lang.RuntimeException: jakarta.persistence.PersistenceException: [PersistenceUnit: <default>] Unable to build Hibernate SessionFactory\n",
            "\tat io.quarkus.hibernate.orm.runtime.JPAConfig.startAll(JPAConfig.java:78)\n",
            "\tat io.quarkus.hibernate.orm.runtime.HibernateOrmRecorder.startAllPersistenceUnits(HibernateOrmRecorder.java:101)\n",
            "\tat io.quarkus.deployment.steps.HibernateOrmProcessor$startPersistenceUnits1868654632.deploy_0(Unknown Source)\n",
            "\tat io.quarkus.deployment.steps.HibernateOrmProcessor$startPersistenceUnits1868654632.deploy(Unknown Source)\n",
            "\t... 53 more\n",
            "Caused by: jakarta.persistence.PersistenceException: [PersistenceUnit: <default>] Unable to build Hibernate SessionFactory\n",
            "\tat io.quarkus.hibernate.orm.runtime.boot.FastBootEntityManagerFactoryBuilder.persistenceException(FastBootEntityManagerFactoryBuilder.java:126)\n",
            "\tat io.quarkus.hibernate.orm.runtime.boot.FastBootEntityManagerFactoryBuilder.build(FastBootEntityManagerFactoryBuilder.java:86)\n",
            "\tat io.quarkus.hibernate.orm.runtime.FastBootHibernatePersistenceProvider.createEntityManagerFactory(FastBootHibernatePersistenceProvider.java:74)\n",
            "\tat jakarta.persistence.Persistence.createEntityManagerFactory(Persistence.java:80)\n",
            "\tat jakarta.persistence.Persistence.createEntityManagerFactory(Persistence.java:55)\n",
            "\tat io.quarkus.hibernate.orm.runtime.JPAConfig$LazyPersistenceUnit.get(JPAConfig.java:156)\n",
            "\tat io.quarkus.hibernate.orm.runtime.JPAConfig$1.run(JPAConfig.java:64)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
            "Caused by: java.lang.NullPointerException: Cannot invoke \"org.hibernate.sql.model.ast.builder.ColumnValuesTableMutationBuilder.addValueColumn(org.hibernate.metamodel.mapping.SelectableMapping)\" because \"mutationBuilder\" is null\n",
            "\tat org.hibernate.sql.model.ast.builder.MutationGroupBuilder.accept(MutationGroupBuilder.java:80)\n",
            "\tat org.hibernate.metamodel.mapping.internal.EmbeddableMappingTypeImpl.forEachInsertable(EmbeddableMappingTypeImpl.java:709)\n",
            "\tat org.hibernate.metamodel.mapping.EmbeddableValuedModelPart.forEachInsertable(EmbeddableValuedModelPart.java:141)\n",
            "\tat org.hibernate.persister.entity.mutation.InsertCoordinator.lambda$applyTableInsertDetails$9(InsertCoordinator.java:378)\n",
            "\tat org.hibernate.sql.model.ast.builder.MutationGroupBuilder.lambda$forEachTableMutationBuilder$0(MutationGroupBuilder.java:71)\n",
            "\tat java.base/java.util.LinkedHashMap.forEach(LinkedHashMap.java:721)\n",
            "\tat org.hibernate.sql.model.ast.builder.MutationGroupBuilder.forEachTableMutationBuilder(MutationGroupBuilder.java:71)\n",
            "\tat org.hibernate.persister.entity.mutation.InsertCoordinator.applyTableInsertDetails(InsertCoordinator.java:367)\n",
            "\tat org.hibernate.persister.entity.mutation.InsertCoordinator.generateStaticOperationGroup(InsertCoordinator.java:346)\n",
            "\tat org.hibernate.persister.entity.mutation.InsertCoordinator.<init>(InsertCoordinator.java:75)\n",
            "\tat org.hibernate.persister.entity.AbstractEntityPersister.buildInsertCoordinator(AbstractEntityPersister.java:3298)\n",
            "\tat org.hibernate.persister.entity.AbstractEntityPersister.doLateInit(AbstractEntityPersister.java:3081)\n",
            "\tat org.hibernate.persister.entity.AbstractEntityPersister.postInstantiate(AbstractEntityPersister.java:3325)\n",
            "\tat org.hibernate.metamodel.model.domain.internal.MappingMetamodelImpl.finishInitialization(MappingMetamodelImpl.java:204)\n",
            "\tat org.hibernate.internal.SessionFactoryImpl.initializeMappingModel(SessionFactoryImpl.java:319)\n",
            "\tat org.hibernate.internal.SessionFactoryImpl.<init>(SessionFactoryImpl.java:269)\n",
            "\tat io.quarkus.hibernate.orm.runtime.boot.FastBootEntityManagerFactoryBuilder.build(FastBootEntityManagerFactoryBuilder.java:84){quote}\n",
            "\n",
            "MutationGroupBuilder tries to find table details with the entity-Name (Without owner) but the internal map has a owner-prefixed tablename as key. So the TabelMutationBuilder is not found and that causes a NPE (see debug-screenshot).\n",
            "\n",
            "See also [Quarkus-zulip chat|https://quarkusio.zulipchat.com/#narrow/stream/187030-users/topic/hibernate.206.20json.20query] and attached Quarkus-Project that shows the problem.\n",
            "\n",
            "!grafik-20230516-111651.png|width=1215,height=416!, Similarity: 0.3480\n",
            "Summary & Description: sybase error orghibernateenginejdbcspisqlexceptionhelper dbtablename found \n",
            " I use a Sybase-Instance with 2 databases. One database is in the jdbc url included. To access tables from the other database i use the @Table annotation with the name, schema und catalog attribute. This worked in 6.1.7 and 5.x.\n",
            "\n",
            "Since i upgrade to version 6.2.2 the full table-name is build only with the name + catalog attributes but without the schema attribute and i got the error “table not found”.\n",
            "\n",
            "I debugged and the reason i found is:\n",
            "\n",
            "In the SybaseDialect in the method “public NameQualifierSupport getNameQualifierSupport()” the “NameQualifierSupport” changed from BOTH to CATALOG, therefore in the class “QualifiedObjectNameFormatterStandardImpl” the “CatalogNameFormat” class is used instead of the “CatalogSchemaNameFormat” to build the rootTableName (in the “SingleTableEntityPersister” class).\n",
            "\n",
            " , Similarity: 0.3516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Calculate similarity scores\n",
        "similarities = calculate_similarity(sum_desc_input, df[\"embeddingsSumDesc\"])\n",
        "\n",
        "# Display results\n",
        "for i, row in df.iterrows():\n",
        "  SumDesc = row[\"SumDesc\"]\n",
        "  similarity = similarities[i]\n",
        "  print(f\"Summary & Description: {SumDesc}, Similarity: {similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raVQf1CAB9cB",
        "outputId": "6e6ac777-6c49-4c15-bb23-13d978693d82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9419"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "len(similarities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUdzNb74B9fO",
        "outputId": "6d764bc3-3da1-431c-a0ca-6413ee09e4b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar summary: plugin configimport found jfrog artifactory cloud implementation \r\n",
            " I am following the steps from [https://docs.jfrog-applications.jfrog.io/jfrog-applications/jfrog-cli/cli-for-jfrog-cloud-transfer#routing-the-traffic-from-the-source-to-the-target-through-an-https-proxy|https://docs.jfrog-applications.jfrog.io/jfrog-applications/jfrog-cli/cli-for-jfrog-cloud-transfer#routing-the-traffic-from-the-source-to-the-target-through-an-https-proxy|smart-link]  where I have to install and activate two plugins to use the transfer-config option through the cli.\n",
            "\n",
            "The plugin config-import has to be installed on the target server  (cloud ), but the wanted plugin is not found.\n",
            "\n",
            "The debug logging gives the following messages:\n",
            "\n",
            "Debug] Downloading plugin's executable from: [https://releases.jfrog.io/artifactory/jfrog-cli-plugins/config-import/latest/linux-amd64/config-import|https://releases.jfrog.io/artifactory/jfrog-cli-plugins/config-import/latest/linux-amd64/config-import]\n",
            "[Info] Downloading: config-import\n",
            "[Debug] Sending HTTP GET request to: [https://releases.jfrog.io/artifactory/jfrog-cli-plugins/config-import/latest/linux-amd64/config-import|https://releases.jfrog.io/artifactory/jfrog-cli-plugins/config-import/latest/linux-amd64/config-import]\n",
            "\n",
            "The subdirectory config-import is completly missing on the server repo [https://releases.jfrog.io/artifactory/jfrog-cli-plugins|https://releases.jfrog.io/artifactory/jfrog-cli-plugins/config-import/latest/linux-amd64/config-import]\n",
            "\n",
            "The plugin is provided in [https://releases.jfrog.io/artifactory/jfrog-releases/config-import/1.3.1/|https://releases.jfrog.io/artifactory/jfrog-releases/config-import/1.3.1/]  \n",
            " , Similarity: 1.0000 \n",
            "\n",
            "Similar summary: support splunk log analysis artifactory cloud \r\n",
            " For on-premises customers, we have released an official integration to allow processing Artifactory logs in Splunk: [https://jfrog.com/blog/unified-jfrog-log-analytics-with-splunk/]\r\n",
            "\r\n",
            "This feature request is for supporting the Splunk integration for Artifactory Cloud.  \n",
            " , Similarity: 0.6621 \n",
            "\n",
            "Similar summary: enable get requests artifactoryapisystemconfiguration artifactory saas setups \r\n",
            " Hi JFrog team,\n",
            "\n",
            "We want to use Terraform to configure LDAP settings for our Artifactory SaaS instance. JFrog’s Terraform provider [https://registry.terraform.io/providers/jfrog/artifactory/latest|https://registry.terraform.io/providers/jfrog/artifactory/latest|smart-link]  needs to use the {{/artifactory/api/system/configuration}} route to do the configuration.\n",
            "\n",
            "While {{PATCH}} requests to this route works, {{GET}} ones do not with the following error:\n",
            "\n",
            "{quote}{\n",
            "\n",
            " \"errors\" : [ {\n",
            "\n",
            "  \"status\" : 400,\n",
            "\n",
            "  \"message\" : \"Artifactory Online does not support accessing this API endpoint, please contact [support@jfrog.com|mailto:support@jfrog.com] for further assistance if required.\"\n",
            "\n",
            " } ]\n",
            "\n",
            "}{quote}\n",
            "\n",
            "I’ve previously created a support ticket and was redirected here to create an issue instead.\n",
            "\n",
            "Terraform provider needs to be able to read the current settings to understand whether there’s a configuration drift and it needs to apply changes.\n",
            "\n",
            "As per documentation [https://www.jfrog.com/confluence/display/JFROG/JFrog+Platform+REST+API#:~:text=General%20Configuration-,This%20API%20is%20available%20only%20in%20Self%2Dhosted%20instances.,-Description%3A%20Get%20the|https://www.jfrog.com/confluence/display/JFROG/JFrog+Platform+REST+API#:~:text=General%20Configuration-,This%20API%20is%20available%20only%20in%20Self%2Dhosted%20instances.,-Description%3A%20Get%20the|smart-link] , the GET method for this route is currently only available for the self-hosted instances. \n",
            " , Similarity: 0.6451 \n",
            "\n",
            "Similar summary: artifactory pro registry docker image support nginx configuration mounted volume \r\n",
            " When using the jfrog-docker-registry.bintray.io/jfrog/artifactory-registry:latest-image described on https://www.jfrog.com/confluence/display/RTF/Running+with+Docker#RunningwithDocker-RunningArtifactoryProRegistry, some level of nginx-configuration is to be expected. For example, running with a self signed certificate over https is not a good practice.\n",
            "\n",
            "Today, configuring nginx requires configurations inside the image. It would be preferable if such configurations could be handled using one of the exposed volumes.\n",
            "\n",
            "For example, these items would help:\n",
            "\n",
            "* On startup, if there is no nginx configuration file at /var/opt/jfrog/artifactory/etc/nginx/nginx.conf, create one using defaults\n",
            "* Next, run nginx using this configuration file\n",
            " \n",
            " , Similarity: 0.6317 \n",
            "\n",
            "Similar summary: artifactory needs link jfrogs jira server \r\n",
            " Was trying to file a bug. It would be handy to have a link within each webpage that would have the page ID and the release information which would populate the JIRA issue.\n",
            "\n",
            "Basically, lower the barrier to filing a defect and increase the quality.\n",
            "\n",
            "Bonus would be for the server to send up a lightweight configuration and settings dump (if so configured of course).\n",
            "\n",
            "Marking as a blocker because the link seems easy to do and would help with getting the release perfected. \n",
            " , Similarity: 0.6109 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Store summaries with similarity > 0.7 and their scores in a list\n",
        "similar_sum_desc_and_scores = []\n",
        "for sumdesc, similarity in zip(df[\"SumDesc\"], similarities):\n",
        "  if similarity > 0.5:\n",
        "    similar_sum_desc_and_scores.append((sumdesc, similarity))\n",
        "\n",
        "# Sort similar summaries by similarity score (highest first)\n",
        "sorted_similar_sum_desc_and_scores = sorted(similar_sum_desc_and_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Print top 5 similar sentences and their scores\n",
        "for i, (sumdesc, similarity) in enumerate(sorted_similar_sum_desc_and_scores):\n",
        "  if len(similarities) == 0:\n",
        "    print('No similar tickets found.')\n",
        "  if i == 5:\n",
        "    break  # Print only the top 5\n",
        "  print(f\"Similar summary: {sumdesc} \\n , Similarity: {similarity:.4f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O01vvT34B9h2",
        "outputId": "b28e6bb9-9ebe-4117-a270-dc88b00ca75e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "len(similar_sum_desc_and_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "6113d32de1a741fcaf4980b51d6f30fc",
            "f69bc805a8dd45779856e56724724c81",
            "4e403788f8d342ae86929037b7e563ac",
            "540c78d4b38641fdbb0f4fd43d58a32f",
            "92e385c1359047aeb6984a6d581ddea8",
            "94f1b3f9e32c483da497cc6b4bd6fe86",
            "ad80e711ff7b42b28e7eb544dc381b73",
            "e4ed39f78c5d493bae5a2d567fd12d48",
            "cd2e2ad55e6d4ff880f64bb31603321c",
            "2fa29868369b4f599fd45fe9c3cdf615",
            "1d23e3e2050744c59c0c9344a257c0fa",
            "5ce59b6f69b445048286ee04804e89a6",
            "6153ac61f6de4473a99aa597fff48bca",
            "92d2fc1e30744f77afa9388e4b722b42",
            "d6b1acf179d84b79b68d44d2c4ef9d24",
            "7e3a813f542a43b39f4fd7623d588383",
            "63f785d22c6d4c999adbfd745bf4c909",
            "6a9f8523edd341df850d48c17d8dac6e",
            "c779c4cb99d14d05aa98894f338cfed9",
            "2d57b70396814599ab2fca72dd7619ee",
            "c0c6141e17154c75885820cd6aaa36de",
            "35adb9877cf84146a9c6c64b8cbe3c73",
            "e11b9c6ccfaa49d9ad1c0f12f56fdfa5",
            "203d026fa55b4f2c8fb44299054baf19",
            "edf6120f175e4dcc9a7a7bdc414c0971",
            "0a0f1ac187664e8394ead4877b4f4e2f",
            "9eacd5cc150b4107bbbed987b23d9b3e",
            "d2efbff9334e486697d77606345f0b10",
            "dfa9eaa77eaa4a4ea8cc1b19e234307c",
            "c122337f3f0d49b0880218a60d247738",
            "ab8a0202868a4216bc721e8950b83456",
            "f781752b1a504a69ae93a63b8fe4aeee",
            "fb83c23163224a9b8cb01f7019afb7b6",
            "45ec53d47f1c4400ab40c55f4cb4fcdd",
            "0310625a99ac4315a6284b1141c30249",
            "e8090c30142c4d79a7097a7805a759a1",
            "7935dca88cde41cf9cc0c267b7246be3",
            "98a25fe6b6be43d08060cefac1e41f75",
            "369b624bc5ed4de984d85ef5bf44a0c1",
            "5fb1d61057da411ba5c57f8d7f067a75",
            "2998e4afdbfb4430a8bf7370a559c40e",
            "233c2d3376c44f57ac804a6be9a3463c",
            "9fa52c017e94466eae08a7ca4bdb3e31",
            "abc8973f3ff84ad19a384ff8a19ee7bc",
            "70db733ffe2f4882a36a3fb656bcc2e6",
            "fde6964b2cb04800800faf6e8f641883",
            "a2e10e6d8e8d4aa2bff80d2e981b6e30",
            "391c1c7745b4482f948ff4526e7c3c70",
            "530606b175814c65a360032b8da7ddc5",
            "975bc619523c4a139496a543ec4e199a",
            "10a139d73ae945a68e892d5a563be8d8",
            "740f6f262df640e3817f6d52ceb5020f",
            "a793f1ddd405429cb6158647712a58bd",
            "def27bb8ceeb41a59a9af9fdaf89710a",
            "dd1c61ff3b4d45c0bf3d2f2382d9a6dc",
            "09c7ff02e6924eb0b65c2835d7dcf055",
            "b8ee135d00a9423cb699e16925891959",
            "678aa82160be4059ab56116ab2677593",
            "8770bf15069643bd8531eb7322009632",
            "99ace9d882224d56bd52cacccc4078b1",
            "cdebe94b40c64e73a680f0b849444db0",
            "bfad8dfa2a6345dd9ed5c97e3e084cde",
            "0a1a540001174ab79eefb7b9f871884c",
            "af581be1b2b949ea8f402dd54bdcf3eb",
            "20c11521d3ac42afa2e233a6ac109e70",
            "4fca9bb673f846f08a63259b3e03ef41",
            "ed3bbfa2468a410c9fd8e61dd1364929",
            "6983b9a8897a46e6b743313eaf5bab2a",
            "2a6b5b9b5b95439d9ca23bdec6c7f8d9",
            "a4c839ae546a432987909a858ba52aca",
            "3ee634835dd84307b9464c6c7800f020",
            "dfcd3b71b8af42b38e98369244b38e34",
            "1a75a8881de6433ca1a5dfb174b99b1b",
            "337b39408a9f46b9a0a8729f397c4e53",
            "04437adc44ed4633abd005329beb86e3",
            "2f02b5ff068d45bd92638fca45f73513",
            "31352a21db5e43b6a326e003211882a5",
            "a95818d175e242a98f52cd6dbdc7acee",
            "f85a76c7a40b4346b0c0df1e5676b9cc",
            "c0109d1777f0482b88d57e02ab0ab90a",
            "d2745b75207a47a896f5c0587fea981f",
            "6dd9e3ff1ef94089843ec5edb666330c",
            "7863a9bc56854da9a20d8291b51f534a",
            "57aa9f41dc724845b2f1f70966f73dfa",
            "1ab386925e444dd5b1f86f3553420dc8",
            "c12386d64cfa4463b5619699d588d878",
            "dde1b54c00ec4d09aa074ce960e9dc4a",
            "3b59b06357d947cf825721dee63c818c",
            "9b2a50470dd24d539a6874bada4fc1bf",
            "7b682039f3a74d94b90ad24278e0ed53",
            "ee26f888d17b419c863ea4d22baaea1a",
            "20a1a40bb51e41cfbfae01720f58df67",
            "40ed3a488eb14ce687cb41d959f03bcb",
            "20bb00786e7943e29d7e3229718b7914",
            "f921d734290848ef849788a949d6d786",
            "b2ae31d025ad4aae85ea14296cb49bf0",
            "8b0f3f8eb8354ef3ba1cb170480af9da",
            "9b73fe5b2e454487aabb0ceb2db1a7b6",
            "408665d3b5cc402383b443dd2fa8c221",
            "7a62c11cbb6d45bab5ed999b0ce0e2c9",
            "a891d23791534edbb30154ca2a72976a",
            "e9c593c9e32a4027a3107725e15b4aaa",
            "d7d68f40b37747e292f1393a1730b853",
            "ad5cf78b06384c72b06956270927caae",
            "5069bee8de91434c909d7f7250c70ebf",
            "121060036a334930b6829ebdd1eab1a9",
            "d9010badf2844057bf9a07a72969b635",
            "b83292c58c944f80af34ae8919e654bc",
            "1a608d047ad545968265c87d0f96d35f",
            "4df7f3a7e17b4dfc8917e76daf911b3e",
            "82bb69e7b80d46d19a36c507c1955d74",
            "1daa07cf01434770b734cc0ecaefe9d0",
            "23094032d44e45b1be1196f1b46bfaca",
            "a2a557a6d7c04812bab597e1e647dbea",
            "688733ac63824cf0ad556ff01709093d",
            "b210de8cd54748f3adbc2451c9bab8b1",
            "a944d6ca9c36457ca912ab4d71abb564",
            "769b0f34f5ac4a889d89433837f3a00c",
            "d740f766153b4daeabf9664e03d8d764",
            "b1c5d9a656f94e89b9ebfcbcb474cffd",
            "387ccc8b2d0f406f9fd38d6badeeacea"
          ]
        },
        "id": "zd87uVvhco-F",
        "outputId": "5f6649b9-7250-4a3a-eeda-9e3ce6737d55"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6113d32de1a741fcaf4980b51d6f30fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ce59b6f69b445048286ee04804e89a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/9.25k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e11b9c6ccfaa49d9ad1c0f12f56fdfa5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45ec53d47f1c4400ab40c55f4cb4fcdd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70db733ffe2f4882a36a3fb656bcc2e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09c7ff02e6924eb0b65c2835d7dcf055"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed3bbfa2468a410c9fd8e61dd1364929"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a95818d175e242a98f52cd6dbdc7acee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b2a50470dd24d539a6874bada4fc1bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a62c11cbb6d45bab5ed999b0ce0e2c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82bb69e7b80d46d19a36c507c1955d74"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "ss_model = SentenceTransformer('multi-qa-mpnet-base-cos-v1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0ahSRxXcpM_"
      },
      "outputs": [],
      "source": [
        "query_embedding = ss_model.encode(sum_desc_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWGqrDV2JdDc"
      },
      "outputs": [],
      "source": [
        "comments_for_similar_descriptions = []\n",
        "\n",
        "for description, similarity in similar_descriptions_and_scores:\n",
        "\n",
        "  # Find the index of the matching description in the original DataFrame\n",
        "  description_index = df[df['Description'] == description].index[0]\n",
        "\n",
        "  # Extract the corresponding comment\n",
        "  comment = df.loc[description_index, 'Comments']\n",
        "\n",
        "  # Append a tuple (description, similarity, comment) to the comments list\n",
        "  comments_for_similar_descriptions.append((comment))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEJWnUH2NEPb"
      },
      "outputs": [],
      "source": [
        "emb_coms = []\n",
        "for comment in comments_for_similar_descriptions :\n",
        "  emb_com = ss_model.encode(comment)\n",
        "  emb_coms.append(emb_com)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzKlCbwlQNGL"
      },
      "outputs": [],
      "source": [
        "query_embedding = ss_model.encode(des_input_sen)\n",
        "\n",
        "s_search = []\n",
        "for i in emb_coms:\n",
        "  ss_score = util.semantic_search(query_embedding.reshape(1, -1), i)\n",
        "  s_search.append(ss_score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s_search1 = []\n",
        "for i in s_search:\n",
        "  for j in i :\n",
        "    s_search1.append(i)"
      ],
      "metadata": {
        "id": "9uTczAdLIQ2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sublist in enumerate(s_search):\n",
        "  print(f\"Sentence {i+1} similar descriptions:\")\n",
        "  for item in sublist:\n",
        "    for j in item :\n",
        "      corpus_id = j['corpus_id']\n",
        "      score = j['score']\n",
        "      comment = comments_for_similar_descriptions[i][corpus_id]  # Access comment by corpus_id\n",
        "      print(f\"\\t Score: {score:.2f}, \\n Comment: {comment}\")"
      ],
      "metadata": {
        "id": "2lKxUbuzKuOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('df.csv', index=False)"
      ],
      "metadata": {
        "id": "PXQ7LBefruUg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ed6be22ba8ec47bcb978181e0be41bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04385d4d08204922921ce276ba5053a0",
              "IPY_MODEL_48d493ec48ee48039bcd338c34af59f8",
              "IPY_MODEL_acad1cfbb84649e0acf30f1a461058e0"
            ],
            "layout": "IPY_MODEL_261e1c07b313413484f5613c6d6056ac"
          }
        },
        "04385d4d08204922921ce276ba5053a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2e3b2dc5d6d4451b5736896051d99cd",
            "placeholder": "​",
            "style": "IPY_MODEL_4e15742b25a147a8bb546fe3afdc962d",
            "value": "modules.json: 100%"
          }
        },
        "48d493ec48ee48039bcd338c34af59f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53ad4119c9dd4c25bb89facbaf8e4cbf",
            "max": 229,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5582687724204a16bfdbe9f30403a6c0",
            "value": 229
          }
        },
        "acad1cfbb84649e0acf30f1a461058e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e15625a4b670404198d00cdc82490a79",
            "placeholder": "​",
            "style": "IPY_MODEL_f36172cb31e64ebf96a5828c66cf0e39",
            "value": " 229/229 [00:00&lt;00:00, 5.70kB/s]"
          }
        },
        "261e1c07b313413484f5613c6d6056ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2e3b2dc5d6d4451b5736896051d99cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e15742b25a147a8bb546fe3afdc962d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53ad4119c9dd4c25bb89facbaf8e4cbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5582687724204a16bfdbe9f30403a6c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e15625a4b670404198d00cdc82490a79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f36172cb31e64ebf96a5828c66cf0e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9df22c3c4f494beaaba071ab1c19794c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_257df0ed51c1405f95e5b86d653d0e2e",
              "IPY_MODEL_71c26ccae0e64215a8eeaa1b91c17035",
              "IPY_MODEL_996255f77e3c42caa12cda0a9eff5671"
            ],
            "layout": "IPY_MODEL_f4c9b70759384ae991ba44abf514cdaa"
          }
        },
        "257df0ed51c1405f95e5b86d653d0e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_965c422228fd4087a0cdfa251e4ab0e7",
            "placeholder": "​",
            "style": "IPY_MODEL_4369bb9fbc0e4a5db92e6a4f1f95e66d",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "71c26ccae0e64215a8eeaa1b91c17035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_399869597f174dbd8c19593097e96a3f",
            "max": 122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_027acf9363924f1896905a01228d0a99",
            "value": 122
          }
        },
        "996255f77e3c42caa12cda0a9eff5671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a472bb1391549daaf3bc8e7cdf7328e",
            "placeholder": "​",
            "style": "IPY_MODEL_4fd0d4d719114e7eaf3b831ba82ab6e3",
            "value": " 122/122 [00:00&lt;00:00, 1.47kB/s]"
          }
        },
        "f4c9b70759384ae991ba44abf514cdaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "965c422228fd4087a0cdfa251e4ab0e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4369bb9fbc0e4a5db92e6a4f1f95e66d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "399869597f174dbd8c19593097e96a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "027acf9363924f1896905a01228d0a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a472bb1391549daaf3bc8e7cdf7328e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fd0d4d719114e7eaf3b831ba82ab6e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1445669c0fd94b9096f059dafb72581e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_118d00faac834328a3e02aa8046354d2",
              "IPY_MODEL_9c90ae623fd641cd86e8401a25cdf12a",
              "IPY_MODEL_09cefdc8289f4322a2afebc5c6a88992"
            ],
            "layout": "IPY_MODEL_5f3b5887f93a478d82866a0b79958695"
          }
        },
        "118d00faac834328a3e02aa8046354d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4e82e494aeb41de984521cb47bb4310",
            "placeholder": "​",
            "style": "IPY_MODEL_0ae38b56bc6044e692baaa07840a9cf0",
            "value": "README.md: 100%"
          }
        },
        "9c90ae623fd641cd86e8401a25cdf12a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39127f5d2ad14dc7872837ff6f936912",
            "max": 4126,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b2360a169764927b269ab2ec59eb6bb",
            "value": 4126
          }
        },
        "09cefdc8289f4322a2afebc5c6a88992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9fb23fc097a4d8d8dc7fa4c9c366274",
            "placeholder": "​",
            "style": "IPY_MODEL_56fa35d75ca444e3b5dbd8e2568dffc4",
            "value": " 4.13k/4.13k [00:00&lt;00:00, 46.5kB/s]"
          }
        },
        "5f3b5887f93a478d82866a0b79958695": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4e82e494aeb41de984521cb47bb4310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ae38b56bc6044e692baaa07840a9cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39127f5d2ad14dc7872837ff6f936912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b2360a169764927b269ab2ec59eb6bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9fb23fc097a4d8d8dc7fa4c9c366274": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56fa35d75ca444e3b5dbd8e2568dffc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f2c27dfc79d4dc2b7599e7f7cda84c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f291a7ab9704fa5b99a542915194c17",
              "IPY_MODEL_aa929ed0753445cea3cca612cd0af954",
              "IPY_MODEL_0ccf9e1a0c84456197b3931718f9a70a"
            ],
            "layout": "IPY_MODEL_dbf7ba34bd954167a724536e1e8776a8"
          }
        },
        "7f291a7ab9704fa5b99a542915194c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce9aef5534d34df298a25d6a556f3e54",
            "placeholder": "​",
            "style": "IPY_MODEL_5020085629c7458996f2c880033b19c9",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "aa929ed0753445cea3cca612cd0af954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d42493b74f29421ab454d50ee11507a4",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db61459def914176b3db737a3c47633c",
            "value": 53
          }
        },
        "0ccf9e1a0c84456197b3931718f9a70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed9f65e96d4f45c89bf48f5299cfbd02",
            "placeholder": "​",
            "style": "IPY_MODEL_03f38aee514b497e939aad53e4419f36",
            "value": " 53.0/53.0 [00:00&lt;00:00, 460B/s]"
          }
        },
        "dbf7ba34bd954167a724536e1e8776a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce9aef5534d34df298a25d6a556f3e54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5020085629c7458996f2c880033b19c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d42493b74f29421ab454d50ee11507a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db61459def914176b3db737a3c47633c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed9f65e96d4f45c89bf48f5299cfbd02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03f38aee514b497e939aad53e4419f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "889e5dcec45749b583eaf649921a3d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2833050431b648d695abf127edfa88a2",
              "IPY_MODEL_bd392a988bc143b892d2c78b8a4c4ad9",
              "IPY_MODEL_06721bad3df34edaa7eb25a75a16fefe"
            ],
            "layout": "IPY_MODEL_bd0770be78374e15aab4b7a586d11703"
          }
        },
        "2833050431b648d695abf127edfa88a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d70c63c68f4546448efd1e865ebe59ed",
            "placeholder": "​",
            "style": "IPY_MODEL_ac101e1de97c4a32824cb45b8a54c66f",
            "value": "config.json: 100%"
          }
        },
        "bd392a988bc143b892d2c78b8a4c4ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea10952187484c019c709e3a15fcf646",
            "max": 723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa57d7c43d1540f48b996832e1a45b03",
            "value": 723
          }
        },
        "06721bad3df34edaa7eb25a75a16fefe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b562f6f3e3242d9aa263bdb5025a0e6",
            "placeholder": "​",
            "style": "IPY_MODEL_705766867bdd47d9a97ffcb7b06579a7",
            "value": " 723/723 [00:00&lt;00:00, 10.9kB/s]"
          }
        },
        "bd0770be78374e15aab4b7a586d11703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d70c63c68f4546448efd1e865ebe59ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac101e1de97c4a32824cb45b8a54c66f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea10952187484c019c709e3a15fcf646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa57d7c43d1540f48b996832e1a45b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b562f6f3e3242d9aa263bdb5025a0e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "705766867bdd47d9a97ffcb7b06579a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abf760063b22455f994c3f6bb78c1937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_772cf655b96d4aa6ab60c0e9efca1124",
              "IPY_MODEL_3da94b12827a43afb6f9af00ecf8286e",
              "IPY_MODEL_c78a661540a24d56b9fe6cf677644fa7"
            ],
            "layout": "IPY_MODEL_67d47d25264c474a93db83c8f7d5f58f"
          }
        },
        "772cf655b96d4aa6ab60c0e9efca1124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7b5be369e824b5097759f7a48a2d3c2",
            "placeholder": "​",
            "style": "IPY_MODEL_fdd59660a61345c0aa1db274a01f0f09",
            "value": "model.safetensors: 100%"
          }
        },
        "3da94b12827a43afb6f9af00ecf8286e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d70f88dd6134e4dacca2779a8b0719b",
            "max": 1112201288,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe694215208047caad80ac00520ec42d",
            "value": 1112201288
          }
        },
        "c78a661540a24d56b9fe6cf677644fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80654f68a3c8454d98ed213ff1fc9920",
            "placeholder": "​",
            "style": "IPY_MODEL_19c239f50d9f4b38a30e00f3039a19c7",
            "value": " 1.11G/1.11G [00:09&lt;00:00, 91.6MB/s]"
          }
        },
        "67d47d25264c474a93db83c8f7d5f58f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7b5be369e824b5097759f7a48a2d3c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdd59660a61345c0aa1db274a01f0f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d70f88dd6134e4dacca2779a8b0719b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe694215208047caad80ac00520ec42d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80654f68a3c8454d98ed213ff1fc9920": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19c239f50d9f4b38a30e00f3039a19c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19f3e8272d9142eeb2b470169362b52c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8978aaf3f6324cfd9d7b6c6f79730407",
              "IPY_MODEL_644fa2d39a3d4a258d61f579ca5cf0b8",
              "IPY_MODEL_46cc0255ba3a41a39cad73b588e88f07"
            ],
            "layout": "IPY_MODEL_ba4295f101514252833cac5a94dfda4d"
          }
        },
        "8978aaf3f6324cfd9d7b6c6f79730407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78f247274d1e47c6b5a0ef399e24ff06",
            "placeholder": "​",
            "style": "IPY_MODEL_f1149055106b49f0bb0a3318ba6a7fcf",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "644fa2d39a3d4a258d61f579ca5cf0b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72cf8e24fa03424fbfa4aaca37296551",
            "max": 402,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7233d349b4b44300a3d85e77e403fbc0",
            "value": 402
          }
        },
        "46cc0255ba3a41a39cad73b588e88f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_442380d3aedb427bafd3295154348043",
            "placeholder": "​",
            "style": "IPY_MODEL_75d51402cfbc45d8ab00fa71ec8e1848",
            "value": " 402/402 [00:00&lt;00:00, 7.39kB/s]"
          }
        },
        "ba4295f101514252833cac5a94dfda4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78f247274d1e47c6b5a0ef399e24ff06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1149055106b49f0bb0a3318ba6a7fcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72cf8e24fa03424fbfa4aaca37296551": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7233d349b4b44300a3d85e77e403fbc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "442380d3aedb427bafd3295154348043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75d51402cfbc45d8ab00fa71ec8e1848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db9237ecd82946a2b007a0ce83ecff30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67fc70461bbd4050a6b727e12533e6d6",
              "IPY_MODEL_3f451ab9868f4a04ba113cc253a6516d",
              "IPY_MODEL_4fb445ea32b1433790001cdc4e0a0132"
            ],
            "layout": "IPY_MODEL_15fef7c0db194356987e1b2d60d29304"
          }
        },
        "67fc70461bbd4050a6b727e12533e6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99b190ec8db04c1ea380544e7e27b306",
            "placeholder": "​",
            "style": "IPY_MODEL_069d41bffae74617920fdc585b1cd371",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "3f451ab9868f4a04ba113cc253a6516d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_633b2719f3d14c70b6839f8e5b889475",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fff435e6b74a483ebb2746785cb480aa",
            "value": 5069051
          }
        },
        "4fb445ea32b1433790001cdc4e0a0132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa10594f640d47dc9ea6494e69f4925b",
            "placeholder": "​",
            "style": "IPY_MODEL_bf9fa08d888c4a7ebb7b37c56d39ecd8",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 28.8MB/s]"
          }
        },
        "15fef7c0db194356987e1b2d60d29304": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99b190ec8db04c1ea380544e7e27b306": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "069d41bffae74617920fdc585b1cd371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "633b2719f3d14c70b6839f8e5b889475": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fff435e6b74a483ebb2746785cb480aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa10594f640d47dc9ea6494e69f4925b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf9fa08d888c4a7ebb7b37c56d39ecd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9df1a6ca5174863b3b3e3a44544ab51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_191041283bc9484ab386bd9cc2d2a432",
              "IPY_MODEL_03474a161aa34e13abf9d2b125ab59da",
              "IPY_MODEL_1379c19b37b94e3f99be4b043aba60be"
            ],
            "layout": "IPY_MODEL_66fb2c4acda84eff811ef8b26b77855e"
          }
        },
        "191041283bc9484ab386bd9cc2d2a432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46c6665f653646a0bef42120fff00bc5",
            "placeholder": "​",
            "style": "IPY_MODEL_5b8771aad9324fb997ab9c1b5372fb93",
            "value": "tokenizer.json: 100%"
          }
        },
        "03474a161aa34e13abf9d2b125ab59da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e93c498fe79e45d48e3085e15820e145",
            "max": 9081518,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9618620cdc794e9296d031e5c6273390",
            "value": 9081518
          }
        },
        "1379c19b37b94e3f99be4b043aba60be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bca854aac50496da16e4b6ba45d5413",
            "placeholder": "​",
            "style": "IPY_MODEL_6b4b438591b44e96a57bf236883aedea",
            "value": " 9.08M/9.08M [00:00&lt;00:00, 21.8MB/s]"
          }
        },
        "66fb2c4acda84eff811ef8b26b77855e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46c6665f653646a0bef42120fff00bc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b8771aad9324fb997ab9c1b5372fb93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e93c498fe79e45d48e3085e15820e145": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9618620cdc794e9296d031e5c6273390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bca854aac50496da16e4b6ba45d5413": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b4b438591b44e96a57bf236883aedea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab2a1fa7344b45af95683648db624352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31f32efc207f4f31b680dd20584ed536",
              "IPY_MODEL_8e8291d407ad4a2cb573a3ceb65f6756",
              "IPY_MODEL_523a4f7a67314b6a940db733ffa1b757"
            ],
            "layout": "IPY_MODEL_55940f797eaf451aa1a7d87ec47f5e8d"
          }
        },
        "31f32efc207f4f31b680dd20584ed536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_522894360b794237b95587ea7ef82c92",
            "placeholder": "​",
            "style": "IPY_MODEL_f82971e96cf046999507b19f320db759",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "8e8291d407ad4a2cb573a3ceb65f6756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ad61085d6c5448e972d83e92957d577",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8ff7da5251947c3b9360f0b1fa4a7d8",
            "value": 239
          }
        },
        "523a4f7a67314b6a940db733ffa1b757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f2d75797fa34cea8607f5d1682cfdcc",
            "placeholder": "​",
            "style": "IPY_MODEL_f17c8a9962c64763b9f1cfef4b7a6d4d",
            "value": " 239/239 [00:00&lt;00:00, 4.09kB/s]"
          }
        },
        "55940f797eaf451aa1a7d87ec47f5e8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "522894360b794237b95587ea7ef82c92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f82971e96cf046999507b19f320db759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ad61085d6c5448e972d83e92957d577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8ff7da5251947c3b9360f0b1fa4a7d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f2d75797fa34cea8607f5d1682cfdcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f17c8a9962c64763b9f1cfef4b7a6d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efb5a74d1fdf4e3b9def5ffd17035597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc99920c78ab43e39fbe274f827a093b",
              "IPY_MODEL_3bc23d1ef541466caac333920154d0a9",
              "IPY_MODEL_b3e163e26d384732b21d897dacbe26b6"
            ],
            "layout": "IPY_MODEL_03164a3308834f88a404af8a35df1ee5"
          }
        },
        "fc99920c78ab43e39fbe274f827a093b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33934068158f4982b36ae4d6f1963274",
            "placeholder": "​",
            "style": "IPY_MODEL_8a98b1646d034f92ab37b8a73ef94b08",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "3bc23d1ef541466caac333920154d0a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e63e907e48441a9921094c6f8df240a",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf38787c02ae4a56ab25e57129b458c9",
            "value": 190
          }
        },
        "b3e163e26d384732b21d897dacbe26b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e532e4a197c048b99f4bacf20568f91b",
            "placeholder": "​",
            "style": "IPY_MODEL_40b01e34f632432a8a62db18fe7e38e9",
            "value": " 190/190 [00:00&lt;00:00, 6.52kB/s]"
          }
        },
        "03164a3308834f88a404af8a35df1ee5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33934068158f4982b36ae4d6f1963274": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a98b1646d034f92ab37b8a73ef94b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e63e907e48441a9921094c6f8df240a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf38787c02ae4a56ab25e57129b458c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e532e4a197c048b99f4bacf20568f91b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40b01e34f632432a8a62db18fe7e38e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6113d32de1a741fcaf4980b51d6f30fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f69bc805a8dd45779856e56724724c81",
              "IPY_MODEL_4e403788f8d342ae86929037b7e563ac",
              "IPY_MODEL_540c78d4b38641fdbb0f4fd43d58a32f"
            ],
            "layout": "IPY_MODEL_92e385c1359047aeb6984a6d581ddea8"
          }
        },
        "f69bc805a8dd45779856e56724724c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94f1b3f9e32c483da497cc6b4bd6fe86",
            "placeholder": "​",
            "style": "IPY_MODEL_ad80e711ff7b42b28e7eb544dc381b73",
            "value": "modules.json: 100%"
          }
        },
        "4e403788f8d342ae86929037b7e563ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4ed39f78c5d493bae5a2d567fd12d48",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd2e2ad55e6d4ff880f64bb31603321c",
            "value": 349
          }
        },
        "540c78d4b38641fdbb0f4fd43d58a32f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fa29868369b4f599fd45fe9c3cdf615",
            "placeholder": "​",
            "style": "IPY_MODEL_1d23e3e2050744c59c0c9344a257c0fa",
            "value": " 349/349 [00:00&lt;00:00, 9.18kB/s]"
          }
        },
        "92e385c1359047aeb6984a6d581ddea8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94f1b3f9e32c483da497cc6b4bd6fe86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad80e711ff7b42b28e7eb544dc381b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4ed39f78c5d493bae5a2d567fd12d48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd2e2ad55e6d4ff880f64bb31603321c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fa29868369b4f599fd45fe9c3cdf615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d23e3e2050744c59c0c9344a257c0fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ce59b6f69b445048286ee04804e89a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6153ac61f6de4473a99aa597fff48bca",
              "IPY_MODEL_92d2fc1e30744f77afa9388e4b722b42",
              "IPY_MODEL_d6b1acf179d84b79b68d44d2c4ef9d24"
            ],
            "layout": "IPY_MODEL_7e3a813f542a43b39f4fd7623d588383"
          }
        },
        "6153ac61f6de4473a99aa597fff48bca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63f785d22c6d4c999adbfd745bf4c909",
            "placeholder": "​",
            "style": "IPY_MODEL_6a9f8523edd341df850d48c17d8dac6e",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "92d2fc1e30744f77afa9388e4b722b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c779c4cb99d14d05aa98894f338cfed9",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d57b70396814599ab2fca72dd7619ee",
            "value": 116
          }
        },
        "d6b1acf179d84b79b68d44d2c4ef9d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0c6141e17154c75885820cd6aaa36de",
            "placeholder": "​",
            "style": "IPY_MODEL_35adb9877cf84146a9c6c64b8cbe3c73",
            "value": " 116/116 [00:00&lt;00:00, 3.82kB/s]"
          }
        },
        "7e3a813f542a43b39f4fd7623d588383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63f785d22c6d4c999adbfd745bf4c909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a9f8523edd341df850d48c17d8dac6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c779c4cb99d14d05aa98894f338cfed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d57b70396814599ab2fca72dd7619ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0c6141e17154c75885820cd6aaa36de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35adb9877cf84146a9c6c64b8cbe3c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e11b9c6ccfaa49d9ad1c0f12f56fdfa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_203d026fa55b4f2c8fb44299054baf19",
              "IPY_MODEL_edf6120f175e4dcc9a7a7bdc414c0971",
              "IPY_MODEL_0a0f1ac187664e8394ead4877b4f4e2f"
            ],
            "layout": "IPY_MODEL_9eacd5cc150b4107bbbed987b23d9b3e"
          }
        },
        "203d026fa55b4f2c8fb44299054baf19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2efbff9334e486697d77606345f0b10",
            "placeholder": "​",
            "style": "IPY_MODEL_dfa9eaa77eaa4a4ea8cc1b19e234307c",
            "value": "README.md: 100%"
          }
        },
        "edf6120f175e4dcc9a7a7bdc414c0971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c122337f3f0d49b0880218a60d247738",
            "max": 9254,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab8a0202868a4216bc721e8950b83456",
            "value": 9254
          }
        },
        "0a0f1ac187664e8394ead4877b4f4e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f781752b1a504a69ae93a63b8fe4aeee",
            "placeholder": "​",
            "style": "IPY_MODEL_fb83c23163224a9b8cb01f7019afb7b6",
            "value": " 9.25k/9.25k [00:00&lt;00:00, 420kB/s]"
          }
        },
        "9eacd5cc150b4107bbbed987b23d9b3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2efbff9334e486697d77606345f0b10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfa9eaa77eaa4a4ea8cc1b19e234307c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c122337f3f0d49b0880218a60d247738": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab8a0202868a4216bc721e8950b83456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f781752b1a504a69ae93a63b8fe4aeee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb83c23163224a9b8cb01f7019afb7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45ec53d47f1c4400ab40c55f4cb4fcdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0310625a99ac4315a6284b1141c30249",
              "IPY_MODEL_e8090c30142c4d79a7097a7805a759a1",
              "IPY_MODEL_7935dca88cde41cf9cc0c267b7246be3"
            ],
            "layout": "IPY_MODEL_98a25fe6b6be43d08060cefac1e41f75"
          }
        },
        "0310625a99ac4315a6284b1141c30249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_369b624bc5ed4de984d85ef5bf44a0c1",
            "placeholder": "​",
            "style": "IPY_MODEL_5fb1d61057da411ba5c57f8d7f067a75",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "e8090c30142c4d79a7097a7805a759a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2998e4afdbfb4430a8bf7370a559c40e",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_233c2d3376c44f57ac804a6be9a3463c",
            "value": 53
          }
        },
        "7935dca88cde41cf9cc0c267b7246be3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fa52c017e94466eae08a7ca4bdb3e31",
            "placeholder": "​",
            "style": "IPY_MODEL_abc8973f3ff84ad19a384ff8a19ee7bc",
            "value": " 53.0/53.0 [00:00&lt;00:00, 2.33kB/s]"
          }
        },
        "98a25fe6b6be43d08060cefac1e41f75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "369b624bc5ed4de984d85ef5bf44a0c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fb1d61057da411ba5c57f8d7f067a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2998e4afdbfb4430a8bf7370a559c40e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "233c2d3376c44f57ac804a6be9a3463c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9fa52c017e94466eae08a7ca4bdb3e31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abc8973f3ff84ad19a384ff8a19ee7bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70db733ffe2f4882a36a3fb656bcc2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fde6964b2cb04800800faf6e8f641883",
              "IPY_MODEL_a2e10e6d8e8d4aa2bff80d2e981b6e30",
              "IPY_MODEL_391c1c7745b4482f948ff4526e7c3c70"
            ],
            "layout": "IPY_MODEL_530606b175814c65a360032b8da7ddc5"
          }
        },
        "fde6964b2cb04800800faf6e8f641883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_975bc619523c4a139496a543ec4e199a",
            "placeholder": "​",
            "style": "IPY_MODEL_10a139d73ae945a68e892d5a563be8d8",
            "value": "config.json: 100%"
          }
        },
        "a2e10e6d8e8d4aa2bff80d2e981b6e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_740f6f262df640e3817f6d52ceb5020f",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a793f1ddd405429cb6158647712a58bd",
            "value": 571
          }
        },
        "391c1c7745b4482f948ff4526e7c3c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_def27bb8ceeb41a59a9af9fdaf89710a",
            "placeholder": "​",
            "style": "IPY_MODEL_dd1c61ff3b4d45c0bf3d2f2382d9a6dc",
            "value": " 571/571 [00:00&lt;00:00, 19.1kB/s]"
          }
        },
        "530606b175814c65a360032b8da7ddc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "975bc619523c4a139496a543ec4e199a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10a139d73ae945a68e892d5a563be8d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "740f6f262df640e3817f6d52ceb5020f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a793f1ddd405429cb6158647712a58bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "def27bb8ceeb41a59a9af9fdaf89710a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd1c61ff3b4d45c0bf3d2f2382d9a6dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09c7ff02e6924eb0b65c2835d7dcf055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8ee135d00a9423cb699e16925891959",
              "IPY_MODEL_678aa82160be4059ab56116ab2677593",
              "IPY_MODEL_8770bf15069643bd8531eb7322009632"
            ],
            "layout": "IPY_MODEL_99ace9d882224d56bd52cacccc4078b1"
          }
        },
        "b8ee135d00a9423cb699e16925891959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdebe94b40c64e73a680f0b849444db0",
            "placeholder": "​",
            "style": "IPY_MODEL_bfad8dfa2a6345dd9ed5c97e3e084cde",
            "value": "model.safetensors: 100%"
          }
        },
        "678aa82160be4059ab56116ab2677593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a1a540001174ab79eefb7b9f871884c",
            "max": 437971872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af581be1b2b949ea8f402dd54bdcf3eb",
            "value": 437971872
          }
        },
        "8770bf15069643bd8531eb7322009632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20c11521d3ac42afa2e233a6ac109e70",
            "placeholder": "​",
            "style": "IPY_MODEL_4fca9bb673f846f08a63259b3e03ef41",
            "value": " 438M/438M [00:05&lt;00:00, 96.2MB/s]"
          }
        },
        "99ace9d882224d56bd52cacccc4078b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdebe94b40c64e73a680f0b849444db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfad8dfa2a6345dd9ed5c97e3e084cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a1a540001174ab79eefb7b9f871884c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af581be1b2b949ea8f402dd54bdcf3eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20c11521d3ac42afa2e233a6ac109e70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fca9bb673f846f08a63259b3e03ef41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed3bbfa2468a410c9fd8e61dd1364929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6983b9a8897a46e6b743313eaf5bab2a",
              "IPY_MODEL_2a6b5b9b5b95439d9ca23bdec6c7f8d9",
              "IPY_MODEL_a4c839ae546a432987909a858ba52aca"
            ],
            "layout": "IPY_MODEL_3ee634835dd84307b9464c6c7800f020"
          }
        },
        "6983b9a8897a46e6b743313eaf5bab2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfcd3b71b8af42b38e98369244b38e34",
            "placeholder": "​",
            "style": "IPY_MODEL_1a75a8881de6433ca1a5dfb174b99b1b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2a6b5b9b5b95439d9ca23bdec6c7f8d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_337b39408a9f46b9a0a8729f397c4e53",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04437adc44ed4633abd005329beb86e3",
            "value": 363
          }
        },
        "a4c839ae546a432987909a858ba52aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f02b5ff068d45bd92638fca45f73513",
            "placeholder": "​",
            "style": "IPY_MODEL_31352a21db5e43b6a326e003211882a5",
            "value": " 363/363 [00:00&lt;00:00, 16.8kB/s]"
          }
        },
        "3ee634835dd84307b9464c6c7800f020": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfcd3b71b8af42b38e98369244b38e34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a75a8881de6433ca1a5dfb174b99b1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "337b39408a9f46b9a0a8729f397c4e53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04437adc44ed4633abd005329beb86e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f02b5ff068d45bd92638fca45f73513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31352a21db5e43b6a326e003211882a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a95818d175e242a98f52cd6dbdc7acee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f85a76c7a40b4346b0c0df1e5676b9cc",
              "IPY_MODEL_c0109d1777f0482b88d57e02ab0ab90a",
              "IPY_MODEL_d2745b75207a47a896f5c0587fea981f"
            ],
            "layout": "IPY_MODEL_6dd9e3ff1ef94089843ec5edb666330c"
          }
        },
        "f85a76c7a40b4346b0c0df1e5676b9cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7863a9bc56854da9a20d8291b51f534a",
            "placeholder": "​",
            "style": "IPY_MODEL_57aa9f41dc724845b2f1f70966f73dfa",
            "value": "vocab.txt: 100%"
          }
        },
        "c0109d1777f0482b88d57e02ab0ab90a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ab386925e444dd5b1f86f3553420dc8",
            "max": 231536,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c12386d64cfa4463b5619699d588d878",
            "value": 231536
          }
        },
        "d2745b75207a47a896f5c0587fea981f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dde1b54c00ec4d09aa074ce960e9dc4a",
            "placeholder": "​",
            "style": "IPY_MODEL_3b59b06357d947cf825721dee63c818c",
            "value": " 232k/232k [00:00&lt;00:00, 3.12MB/s]"
          }
        },
        "6dd9e3ff1ef94089843ec5edb666330c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7863a9bc56854da9a20d8291b51f534a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57aa9f41dc724845b2f1f70966f73dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ab386925e444dd5b1f86f3553420dc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c12386d64cfa4463b5619699d588d878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dde1b54c00ec4d09aa074ce960e9dc4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b59b06357d947cf825721dee63c818c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b2a50470dd24d539a6874bada4fc1bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b682039f3a74d94b90ad24278e0ed53",
              "IPY_MODEL_ee26f888d17b419c863ea4d22baaea1a",
              "IPY_MODEL_20a1a40bb51e41cfbfae01720f58df67"
            ],
            "layout": "IPY_MODEL_40ed3a488eb14ce687cb41d959f03bcb"
          }
        },
        "7b682039f3a74d94b90ad24278e0ed53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20bb00786e7943e29d7e3229718b7914",
            "placeholder": "​",
            "style": "IPY_MODEL_f921d734290848ef849788a949d6d786",
            "value": "tokenizer.json: 100%"
          }
        },
        "ee26f888d17b419c863ea4d22baaea1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2ae31d025ad4aae85ea14296cb49bf0",
            "max": 466021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b0f3f8eb8354ef3ba1cb170480af9da",
            "value": 466021
          }
        },
        "20a1a40bb51e41cfbfae01720f58df67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b73fe5b2e454487aabb0ceb2db1a7b6",
            "placeholder": "​",
            "style": "IPY_MODEL_408665d3b5cc402383b443dd2fa8c221",
            "value": " 466k/466k [00:00&lt;00:00, 3.66MB/s]"
          }
        },
        "40ed3a488eb14ce687cb41d959f03bcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20bb00786e7943e29d7e3229718b7914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f921d734290848ef849788a949d6d786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2ae31d025ad4aae85ea14296cb49bf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b0f3f8eb8354ef3ba1cb170480af9da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b73fe5b2e454487aabb0ceb2db1a7b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "408665d3b5cc402383b443dd2fa8c221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a62c11cbb6d45bab5ed999b0ce0e2c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a891d23791534edbb30154ca2a72976a",
              "IPY_MODEL_e9c593c9e32a4027a3107725e15b4aaa",
              "IPY_MODEL_d7d68f40b37747e292f1393a1730b853"
            ],
            "layout": "IPY_MODEL_ad5cf78b06384c72b06956270927caae"
          }
        },
        "a891d23791534edbb30154ca2a72976a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5069bee8de91434c909d7f7250c70ebf",
            "placeholder": "​",
            "style": "IPY_MODEL_121060036a334930b6829ebdd1eab1a9",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "e9c593c9e32a4027a3107725e15b4aaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9010badf2844057bf9a07a72969b635",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b83292c58c944f80af34ae8919e654bc",
            "value": 239
          }
        },
        "d7d68f40b37747e292f1393a1730b853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a608d047ad545968265c87d0f96d35f",
            "placeholder": "​",
            "style": "IPY_MODEL_4df7f3a7e17b4dfc8917e76daf911b3e",
            "value": " 239/239 [00:00&lt;00:00, 9.60kB/s]"
          }
        },
        "ad5cf78b06384c72b06956270927caae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5069bee8de91434c909d7f7250c70ebf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "121060036a334930b6829ebdd1eab1a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9010badf2844057bf9a07a72969b635": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b83292c58c944f80af34ae8919e654bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a608d047ad545968265c87d0f96d35f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4df7f3a7e17b4dfc8917e76daf911b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82bb69e7b80d46d19a36c507c1955d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1daa07cf01434770b734cc0ecaefe9d0",
              "IPY_MODEL_23094032d44e45b1be1196f1b46bfaca",
              "IPY_MODEL_a2a557a6d7c04812bab597e1e647dbea"
            ],
            "layout": "IPY_MODEL_688733ac63824cf0ad556ff01709093d"
          }
        },
        "1daa07cf01434770b734cc0ecaefe9d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b210de8cd54748f3adbc2451c9bab8b1",
            "placeholder": "​",
            "style": "IPY_MODEL_a944d6ca9c36457ca912ab4d71abb564",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "23094032d44e45b1be1196f1b46bfaca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_769b0f34f5ac4a889d89433837f3a00c",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d740f766153b4daeabf9664e03d8d764",
            "value": 190
          }
        },
        "a2a557a6d7c04812bab597e1e647dbea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1c5d9a656f94e89b9ebfcbcb474cffd",
            "placeholder": "​",
            "style": "IPY_MODEL_387ccc8b2d0f406f9fd38d6badeeacea",
            "value": " 190/190 [00:00&lt;00:00, 6.33kB/s]"
          }
        },
        "688733ac63824cf0ad556ff01709093d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b210de8cd54748f3adbc2451c9bab8b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a944d6ca9c36457ca912ab4d71abb564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "769b0f34f5ac4a889d89433837f3a00c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d740f766153b4daeabf9664e03d8d764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1c5d9a656f94e89b9ebfcbcb474cffd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "387ccc8b2d0f406f9fd38d6badeeacea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}